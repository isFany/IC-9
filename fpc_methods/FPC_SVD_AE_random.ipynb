{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FPC_SVD_AE_random.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"n4fcdzt1L0fL"},"source":["## Mounting your google drive\n","\n","You can use google drive to store and access files e.g. storing and loading data from numpy or CSV files.  \n","Use the following command to mount your GDrive and access your files."]},{"cell_type":"code","metadata":{"id":"ydOU6YpVLaow","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656154888,"user_tz":-60,"elapsed":21584,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"52c4b8bb-32ee-4f05-88ae-99bbdb9f0bed"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aSRYEjk782Cc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656174857,"user_tz":-60,"elapsed":19974,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"5623cba6-b7e9-4815-f304-c6ea536e6d2a"},"source":["!pip install ffmpeg\n","!pip install vtk"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","Building wheels for collected packages: ffmpeg\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=7b1c7c2a695b4d39ccb52bcfcceeca1f1a8d17e51a54e0fdfd584d356ebb3373\n","  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n","Successfully built ffmpeg\n","Installing collected packages: ffmpeg\n","Successfully installed ffmpeg-1.4\n","Collecting vtk\n","  Downloading vtk-9.0.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (59.5 MB)\n","\u001b[K     |████████████████████████████████| 59.5 MB 40 kB/s \n","\u001b[?25hCollecting wslink>=0.1.3\n","  Downloading wslink-1.0.6-py3-none-any.whl (20 kB)\n","Collecting autobahn>=17.7.1\n","  Downloading autobahn-21.3.1-py2.py3-none-any.whl (495 kB)\n","\u001b[K     |████████████████████████████████| 495 kB 81.9 MB/s \n","\u001b[?25hCollecting Twisted>=17.5.0\n","  Downloading Twisted-21.7.0-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 68.9 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from vtk) (3.2.2)\n","Collecting cryptography>=3.4.6\n","  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 60.1 MB/s \n","\u001b[?25hCollecting hyperlink>=21.0.0\n","  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.0 MB/s \n","\u001b[?25hCollecting txaio>=21.2.1\n","  Downloading txaio-21.2.1-py2.py3-none-any.whl (30 kB)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=3.4.6->autobahn>=17.7.1->vtk) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=3.4.6->autobahn>=17.7.1->vtk) (2.20)\n","Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=21.0.0->autobahn>=17.7.1->vtk) (2.10)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk) (0.10.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk) (1.19.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->vtk) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.0.0->vtk) (1.15.0)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.5.0->vtk) (3.7.4.3)\n","Collecting constantly>=15.1\n","  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n","Collecting zope.interface>=4.4.2\n","  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 91.7 MB/s \n","\u001b[?25hCollecting Automat>=0.8.0\n","  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from Twisted>=17.5.0->vtk) (21.2.0)\n","Collecting incremental>=21.3.0\n","  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting aiohttp\n","  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 82.3 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=4.4.2->Twisted>=17.5.0->vtk) (57.4.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n","\u001b[K     |████████████████████████████████| 142 kB 92.2 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n","\u001b[K     |████████████████████████████████| 294 kB 69.1 MB/s \n","\u001b[?25hCollecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->wslink>=0.1.3->vtk) (3.0.4)\n","Installing collected packages: multidict, yarl, async-timeout, zope.interface, txaio, incremental, hyperlink, cryptography, constantly, Automat, aiohttp, wslink, Twisted, autobahn, vtk\n","Successfully installed Automat-20.2.0 Twisted-21.7.0 aiohttp-3.7.4.post0 async-timeout-3.0.1 autobahn-21.3.1 constantly-15.1.0 cryptography-3.4.7 hyperlink-21.0.0 incremental-21.3.0 multidict-5.1.0 txaio-21.2.1 vtk-9.0.3 wslink-1.0.6 yarl-1.6.3 zope.interface-5.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lD9BrjrtYDPi","executionInfo":{"status":"ok","timestamp":1629656177096,"user_tz":-60,"elapsed":2242,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["import os\n","# change the current path. The user can adjust the path depend on the requirement\n","os.chdir(\"/content/gdrive/MyDrive/Cola-Notebooks/FYP/YF\")\n","import vtktools"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"k2FU1lqyFRva","executionInfo":{"status":"ok","timestamp":1629656177097,"user_tz":-60,"elapsed":5,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["# !unzip csv_data.zip "],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"sqsQSr0eyMDy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656182824,"user_tz":-60,"elapsed":5731,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"c5e43b51-af05-4888-8049-805346df3593"},"source":["%matplotlib inline\n","import numpy as np\n","import pandas as pd\n","import scipy\n","import numpy.linalg as la\n","import scipy.linalg as sl\n","import scipy.sparse.linalg as spl\n","import matplotlib.pyplot as plt\n","import torch.nn as nn  # Neural network module\n","import scipy.sparse as sp\n","import scipy.optimize as sop\n","import progressbar\n","# making slopes\n","import torch\n","from torch.utils.data import TensorDataset\n","import torch.nn.functional as F\n","from matplotlib.pyplot import LinearLocator\n","import matplotlib as mpl\n","import matplotlib.colors as colors\n","\n","\n","# create an animation\n","from matplotlib import animation\n","from IPython.display import HTML\n","\n","from matplotlib import animation\n","import math\n","import ffmpeg\n","\n","!pip install pycm livelossplot\n","%pylab inline\n","from livelossplot import PlotLosses\n","\n","from torch.utils.data import DataLoader\n","import torch.utils.data as Data\n","\n","import time\n","import platform\n","print('python version', platform.python_version())\n","print('torch version', torch.__version__)\n","print('numpy version', np.version.version)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting pycm\n","  Downloading pycm-3.2-py2.py3-none-any.whl (64 kB)\n","\u001b[?25l\r\u001b[K     |█████                           | 10 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 2.3 MB/s \n","\u001b[?25hCollecting livelossplot\n","  Downloading livelossplot-0.5.4-py3-none-any.whl (22 kB)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pycm) (1.19.5)\n","Collecting art>=1.8\n","  Downloading art-5.2-py2.py3-none-any.whl (571 kB)\n","\u001b[K     |████████████████████████████████| 571 kB 15.5 MB/s \n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot) (5.5.0)\n","Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n","Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.2)\n","Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n","Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (21.0)\n","Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.7.4.3)\n","Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot) (2.4.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (57.4.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.8.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (1.0.18)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (5.0.5)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.3.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->livelossplot) (0.7.0)\n","Installing collected packages: art, pycm, livelossplot\n","Successfully installed art-5.2 livelossplot-0.5.4 pycm-3.2\n","Populating the interactive namespace from numpy and matplotlib\n","python version 3.7.11\n","torch version 1.9.0+cu102\n","numpy version 1.19.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rk1Uza3iuS6d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656182824,"user_tz":-60,"elapsed":17,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"6c5e05b5-0b44-4467-a96d-bd3dd645cf2e"},"source":["def set_seed(seed):\n","    \"\"\"\n","    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n","    torch.backends.cudnn.enabled   = True\n","\n","    return True\n","\n","device = 'cuda'  # Set out device to GPU\n","\n","print('Cuda installed, running on GPU!')  # print sentence"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Cuda installed, running on GPU!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eSVlHxGrEKn3"},"source":["# SVD"]},{"cell_type":"code","metadata":{"id":"V3xsNdqRyCc6","executionInfo":{"status":"ok","timestamp":1629656182825,"user_tz":-60,"elapsed":13,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["def saveIndex(path_train, path_valid, path_test,train_index, valid_index, test_index):\n","    # save training and validation loss    \n","    np.savetxt(path_train,train_index, delimiter=',')\n","    np.savetxt(path_valid,valid_index, delimiter=',')\n","    np.savetxt(path_test,test_index, delimiter=',')\n","\n","def getIndex(path_train,path_valid,path_test):\n","    train_index = np.loadtxt(path_train,delimiter=\",\")\n","    valid_index = np.loadtxt(path_valid,delimiter=\",\")\n","    test_index = np.loadtxt(path_test,delimiter=\",\")\n","    return train_index,valid_index,test_index"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"C9ZyNS6lyEl9","executionInfo":{"status":"ok","timestamp":1629656182826,"user_tz":-60,"elapsed":14,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["path_train = \"/content/gdrive/MyDrive/Cola-Notebooks/FYP/YF/\"+\"new_FPC_train_index.csv\"\n","path_valid = \"/content/gdrive/MyDrive/Cola-Notebooks/FYP/YF/\"+\"new_FPC_valid_index.csv\"\n","path_test = \"/content/gdrive/MyDrive/Cola-Notebooks/FYP/YF/\"+\"new_FPC_test_index.csv\"\n","# saveIndex(path_train, path_valid, path_test,train_index, valid_index, test_index)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWG30jpbyJUe","executionInfo":{"status":"ok","timestamp":1629656183611,"user_tz":-60,"elapsed":798,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"f9933177-dda5-4df1-f4dc-c5b9f1e74e96"},"source":["# Load the train_index, valid_index and test_index\n","train_index,valid_index,test_index= getIndex(path_train,path_valid,path_test)\n","print(test_index)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[ 133.  490. 1480.  730.  481. 1382.  440.  750. 1502. 1451.  692. 1094.\n"," 1679.  510. 1241. 1101.  543. 1312. 1432. 1988. 1148. 1801. 1519.  367.\n"," 1858. 1043. 1175. 1218. 1479.  103. 1363.  800.  258. 1851.  267.  999.\n","  611. 1824.  318.  753. 1413.  727. 1273. 1358. 1090.  838.  250. 1763.\n"," 1038.  439. 1199.  334. 1848. 1924. 1013.  271.  936.  600. 1553.  423.\n"," 1467. 1658.  929. 1748.  783.  329.  303. 1067.  868.  374. 1102. 1843.\n","  683.  449.  855. 1142. 1393.  194. 1112.  636. 1617. 1910. 1722.  536.\n"," 1149. 1765.  468. 1922. 1703. 1311.  341.  110. 1258. 1257. 1711.   93.\n"," 1969.  396. 1259.  199.  962. 1704.  462. 1407.  634.  535. 1505.  537.\n","  612. 1707. 1565. 1963. 1955.    3. 1058. 1946.  372. 1653. 1077.  414.\n","  469.  680. 1430.  649.  215.  234. 1692.  653. 1455.  582. 1169. 1138.\n","  411.  518.  865. 1977. 1688.  822.  397. 1388. 1221.  239.  249. 1781.\n"," 1751.  915.  278. 1970.  907.  477. 1552.  703.  870.  916. 1650.  561.\n"," 1401.  129. 1123. 1804. 1871. 1527.  308.   94. 1911. 1425. 1574.   72.\n","  399. 1410. 1818.  926.  897. 1238. 1628.  498. 1066. 1908.   36.  550.\n"," 1010.  524.  996.  732. 1048. 1041. 1474. 1339. 1889. 1289. 1795.  869.\n"," 1935. 1837.  684.  380.  967. 1445. 1729.  160.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DrlG4u5-Otly"},"source":["## SVD"]},{"cell_type":"markdown","metadata":{"id":"rMkDfCiOBcNa"},"source":["### load data"]},{"cell_type":"code","metadata":{"id":"PBNpFB2vC5gb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656183611,"user_tz":-60,"elapsed":8,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"b71a11d8-9f5d-4505-a9dc-d996a4e565b7"},"source":["os.chdir('/content/gdrive/MyDrive/Cola-Notebooks/FYP/YF')\n","print(os.getcwd())\n","\n","# read in the data (1000 csv files)\n","nTrain = 1600\n","nValid = 200\n","nTest = 200\n","nTotal = nTrain + nValid + nTest\n","nNodes = 20550 # should really work this out\n","\n","\n","# The below method to load data is too slow. Therefore, we use load pt file\n","\n","# [:, :, 2] is speed, [:, :, 3] is u, [:, :, 4] is v\n","# (speed not really needed)\n","# [:, :, 0] and [:, :, 1] are the SFC orderings\n","\n","# training_data = np.zeros((nTrain,nNodes,5))\n","# for i in range(nTrain):\n","#     data = np.loadtxt('csv_data/data_' +str(int(train_index[i]))+ '.csv', delimiter=',')\n","#     training_data[i,:,:] = data\n","# training_data = np.array(training_data)\n","# print('size training data', training_data.shape)\n","\n","# valid_data = np.zeros((nValid,nNodes,5))\n","# for i in range(nValid):\n","#     data = np.loadtxt('csv_data/data_' +str(int(valid_index[i]))+ '.csv', delimiter=',')\n","#     valid_data[i,:,:] = data\n","# valid_data = np.array(valid_data)\n","# print('size validation data', valid_data.shape)\n","\n","# test_data = np.zeros((nTest,nNodes,5))\n","# for i in range(nTest):\n","#     data = np.loadtxt('csv_data/data_' +str(int(test_index[i]))+ '.csv', delimiter=',')\n","#     test_data[i,:,:] = data\n","# test_data = np.array(test_data)\n","# print('size test data', test_data.shape)\n","\n","# total_data = np.zeros((nTotal,nNodes,5))\n","# for i in range(len(train_index)):\n","#     total_data[int(train_index[i]),:,:] = training_data[i,:,:]\n","\n","# for i in range(len(valid_index)):\n","#     total_data[int(valid_index[i]),:,:] = valid_data[i,:,:]\n","\n","# for i in range(len(test_index)):\n","#     total_data[int(test_index[i]),:,:] = test_data[i,:,:]\n","# print('size total data', total_data.shape)\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Cola-Notebooks/FYP/YF\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DhZtSCoUUVXz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656242370,"user_tz":-60,"elapsed":58762,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"856db28e-946c-46f4-84da-df2240de283e"},"source":["# load the data, this method save the time\n","training_data = torch.load('/content/gdrive/MyDrive/FPC_new_random_train.pt')\n","valid_data = torch.load('/content/gdrive/MyDrive/FPC_new_random_valid.pt')\n","test_data = torch.load('/content/gdrive/MyDrive/FPC_new_random_test.pt')\n","total_data = torch.load('/content/gdrive/MyDrive/FPC_new_random_total.pt')\n","print(training_data.shape)\n","print(valid_data.shape)\n","print(test_data.shape)\n","print(total_data.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(1600, 20550, 5)\n","(200, 20550, 5)\n","(200, 20550, 5)\n","(2000, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iaBjPCuEUdJX","executionInfo":{"status":"ok","timestamp":1629656242371,"user_tz":-60,"elapsed":13,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["# total_data = np.concatenate((training_data, valid_data, test_data))\n","# print(total_data.shape)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXRsMOCwUxwU","executionInfo":{"status":"ok","timestamp":1629656244716,"user_tz":-60,"elapsed":2357,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["# rescale the data so that u and v data lies in the range [-1,1] (and speed in [0,1])\n","ma = np.max(training_data[:, :, 2])\n","mi = np.min(training_data[:, :, 2])\n","k = 1./(ma - mi)\n","b = 1 - k*ma #k*mi\n","# training_data[:, :, 2] = k * training_data[:, :, 2] + b #- b\n","# this won't be used\n","\n","ma = np.max(training_data[:, :, 3])\n","mi = np.min(training_data[:, :, 3])\n","ku = 2./(ma - mi)\n","bu = 1 - ku*ma \n","training_data[:, :, 3] = ku * training_data[:, :, 3] + bu\n","valid_data[:, :, 3] = ku * valid_data[:, :, 3] + bu\n","test_data[:, :, 3] = ku * test_data[:, :, 3] + bu\n","total_data[:, :, 3] = ku * total_data[:, :, 3] + bu\n","\n","ma = np.max(training_data[:, :, 4])\n","mi = np.min(training_data[:, :, 4])\n","kv = 2./(ma - mi)\n","bv = 1 - kv*ma\n","training_data[:, :, 4] = kv * training_data[:, :, 4] + bv\n","valid_data[:, :, 4] = kv * valid_data[:, :, 4] + bv\n","test_data[:, :, 4] = kv * test_data[:, :, 4] + bv\n","total_data[:, :, 4] = kv * total_data[:, :, 4] + bv"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFI8cNEXNbH6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656245921,"user_tz":-60,"elapsed":1216,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"81f76c43-7caf-4c35-bc11-cbc61d54ed61"},"source":["snaps = np.zeros([nTrain,nNodes])\n","snaps1 = np.zeros([nTrain,nNodes])\n","snaps2 = np.zeros([nValid,nNodes])\n","snaps3 = np.zeros([nValid,nNodes])\n","snaps4 = np.zeros([nTest,nNodes])\n","snaps5 = np.zeros([nTest,nNodes])\n","\n","for i in range(nTrain):\n","    snaps[i,:] = training_data[i,:,3]\n","    snaps1[i,:] = training_data[i,:,4]\n","\n","snapstrain = np.c_[snaps,snaps1]\n","#the train matrix\n","print('snapstrain shape: ',snapstrain.shape)\n","\n","for i in range(nValid):\n","    snaps2[i,:] = valid_data[i,:,3]\n","    snaps3[i,:] = valid_data[i,:,4]\n","\n","snapsvalid = np.c_[snaps2,snaps3]\n","#the valid matrix\n","print('snapsvalid shape',snapsvalid.shape)\n","\n","for i in range(nTest):\n","    snaps4[i,:] = test_data[i,:,3]\n","    snaps5[i,:] = test_data[i,:,4]\n","\n","snapstest = np.c_[snaps4,snaps5]\n","#the test matrix\n","print('snaptest shape:', snapstest.shape)\n","\n","snapstotal = np.zeros([nTotal,2*nNodes])\n","for i in range(nTotal):\n","    snapstotal[i,:20550] = total_data[i,:,3]\n","    snapstotal[i,20550:] = total_data[i,:,4]\n","print('snaptotal shape:', snapstotal.shape)\n","\n","\n","#the total matrix\n","# snapstotal = np.r_[snapstrain,snapsvalid]\n","# snapstotal = np.r_[snapstotal,snapstest]\n","# print('snaptotal shape',snapstotal.shape)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["snapstrain shape:  (1600, 41100)\n","snapsvalid shape (200, 41100)\n","snaptest shape: (200, 41100)\n","snaptotal shape: (2000, 41100)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N1MehNWcOyTg"},"source":["### SVD of the snapshot matrix"]},{"cell_type":"code","metadata":{"id":"14ld0bHQOzHz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656271766,"user_tz":-60,"elapsed":25848,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"1364427a-c03e-4a3d-ac7c-6148d0b0476c"},"source":["# Uisng la.svd to do the singular value decomposition\n","t_train_0 = time.time()\n","vt,sigma2,u= la.svd(snapstrain,False)\n","t_train_1 = time.time()\n","print(u.shape)\n","print(sigma2.shape)\n","print(vt.shape)\n","print('Train time: ',t_train_1 - t_train_0)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600,)\n","(1600, 1600)\n","Train time:  25.806854248046875\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TxgNMrSgqH19"},"source":["### Apply SVD to input"]},{"cell_type":"code","metadata":{"id":"7PJKKhp2q0vB","executionInfo":{"status":"ok","timestamp":1629656271767,"user_tz":-60,"elapsed":13,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["kNodes= 20550\n","\n","# train_index=[]\n","# valid_index=[]\n","# test_index = []\n","# for i in range(1600):\n","#     train_index.append(i)\n","\n","# for i in range(200):\n","#     valid_index.append(i+1600)\n","\n","# for i in range(200):\n","#     test_index.append(i+1800)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"hr-taxmKqLaG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656271768,"user_tz":-60,"elapsed":13,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"55a0bd42-63c6-4424-9172-df7e4dfe6fc7"},"source":["# Choose the number of the basis function, which means we use SVD to reduce variables from 41100 to 1600\n","R = u[0:1600,:]\n","print(R.shape)\n","RT = R.transpose()\n","print(RT.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(41100, 1600)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4eZqolR5qhRB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656353764,"user_tz":-60,"elapsed":82008,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"67cf2deb-7e2c-4ed3-89e7-a5009eae6b78"},"source":["# Use the SVD to reduce the variable from 41100 to 1600\n","train_data_svd = np.zeros([len(train_index),1600])\n","valid_data_svd = np.zeros([len(valid_index),1600])\n","test_data_svd = np.zeros([len(test_index),1600])\n","total_data_svd = np.zeros([nTrain+nValid+nTest,1600])\n","\n","t_train_2 = time.time()\n","for i in range(len(train_index)):\n","    train_data_svd[i,:] = snapstotal[int(train_index[i]),:]@ RT\n","\n","for i in range(len(valid_index)):\n","    valid_data_svd[i,:] = snapstotal[int(valid_index[i]),:]@ RT\n","\n","for i in range(len(test_index)):\n","    test_data_svd[i,:] = snapstotal[int(test_index[i]),:]@ RT\n","t_train_3 = time.time()\n","\n","for i in range(nTrain+nValid+nTest):\n","    total_data_svd[i,:] = snapstotal[i,:]@ RT\n","\n","print('train_data_svd.shape: ',train_data_svd.shape)\n","print('valid_data_svd.shape: ',valid_data_svd.shape)\n","print('test_data_svd.shape: ',test_data_svd.shape)\n","print('total_data_svd.shape: ',total_data_svd.shape)\n","print(\"train2:\", t_train_3 - t_train_2)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["train_data_svd.shape:  (1600, 1600)\n","valid_data_svd.shape:  (200, 1600)\n","test_data_svd.shape:  (200, 1600)\n","total_data_svd.shape:  (2000, 1600)\n","train2: 40.99463105201721\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oD7Q7E30vh4Y"},"source":["## Fully connected autoencoder"]},{"cell_type":"markdown","metadata":{"id":"GzlCOph0ZW5P"},"source":["### Network structure"]},{"cell_type":"code","metadata":{"id":"hEc0TdmYZc5l","executionInfo":{"status":"ok","timestamp":1629656353765,"user_tz":-60,"elapsed":16,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["class FC(nn.Module):\n","    def __init__(self,hidden_1):\n","        super(FC, self).__init__()\n","        self.fc1 = nn.Sequential(\n","            nn.Linear(1600, hidden_1),\n","            nn.LeakyReLU(0.2)\n","            # nn.ReLU(),\n","            # nn.Sigmoid(),\n","            # nn.Tanh(),\n","\n","           \n","        )\n","        self.fc2 = nn.Sequential(\n","            nn.Linear(hidden_1, 1600),\n","            nn.LeakyReLU(0.2)\n","            # nn.ReLU(),\n","            # nn.Sigmoid(),\n","            # nn.Tanh(),\n","        )\n","\n","\n","    def forward(self,x):\n","        encoded = self.fc1(x)\n","        decoded = self.fc2(encoded)\n","        return encoded, decoded\n","\n","\n","def weight_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Linear\")!=-1:\n","        # Using xavier normalisation to linear layer\n","        nn.init.xavier_normal_(m.weight.data)\n","        nn.init.constant_(m.bias, 0.01)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qg3qPiVgvrkt"},"source":["#### 1 variable"]},{"cell_type":"code","metadata":{"id":"vL_G0Dd6v-rc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629654346082,"user_tz":-60,"elapsed":616,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"60b64b9d-915d-43f3-bbd0-34e35e017be2"},"source":["print(\"compress to 1\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 4000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["compress to 1\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hue4L9RtzSzL","executionInfo":{"status":"ok","timestamp":1629654817590,"user_tz":-60,"elapsed":470897,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"17e6b8b0-073d-4aaf-f0dc-624a86ddbf4a"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(1).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":71,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 1.827417 | valid loss: 1.832966\n","Epoch:  1 | train loss: 1.790593 | valid loss: 1.779500\n","Epoch:  2 | train loss: 1.729102 | valid loss: 1.709224\n","Epoch:  3 | train loss: 1.650572 | valid loss: 1.648628\n","Epoch:  4 | train loss: 1.571727 | valid loss: 1.592131\n","Epoch:  5 | train loss: 1.534660 | valid loss: 1.524141\n","Epoch:  6 | train loss: 1.416258 | valid loss: 1.425306\n","Epoch:  7 | train loss: 1.355164 | valid loss: 1.300818\n","Epoch:  8 | train loss: 0.977971 | valid loss: 1.168928\n","Epoch:  9 | train loss: 0.972772 | valid loss: 1.043411\n","Epoch:  10 | train loss: 0.910582 | valid loss: 0.930949\n","Epoch:  11 | train loss: 0.761050 | valid loss: 0.834912\n","Epoch:  12 | train loss: 0.653880 | valid loss: 0.756271\n","Epoch:  13 | train loss: 0.714167 | valid loss: 0.694708\n","Epoch:  14 | train loss: 0.576556 | valid loss: 0.646658\n","Epoch:  15 | train loss: 0.616378 | valid loss: 0.613562\n","Epoch:  16 | train loss: 0.567814 | valid loss: 0.589647\n","Epoch:  17 | train loss: 0.578065 | valid loss: 0.573194\n","Epoch:  18 | train loss: 0.561221 | valid loss: 0.562003\n","Epoch:  19 | train loss: 0.549650 | valid loss: 0.554258\n","Epoch:  20 | train loss: 0.578931 | valid loss: 0.549433\n","Epoch:  21 | train loss: 0.536666 | valid loss: 0.545724\n","Epoch:  22 | train loss: 0.564556 | valid loss: 0.542873\n","Epoch:  23 | train loss: 0.527701 | valid loss: 0.541206\n","Epoch:  24 | train loss: 0.558896 | valid loss: 0.540118\n","Epoch:  25 | train loss: 0.545491 | valid loss: 0.538923\n","Epoch:  26 | train loss: 0.554661 | valid loss: 0.537836\n","Epoch:  27 | train loss: 0.557942 | valid loss: 0.537537\n","Epoch:  28 | train loss: 0.518479 | valid loss: 0.537290\n","Epoch:  29 | train loss: 0.547907 | valid loss: 0.536759\n","Epoch:  30 | train loss: 0.522076 | valid loss: 0.537250\n","Epoch:  31 | train loss: 0.519114 | valid loss: 0.536651\n","Epoch:  32 | train loss: 0.541005 | valid loss: 0.536860\n","Epoch:  33 | train loss: 0.551035 | valid loss: 0.536661\n","Epoch:  34 | train loss: 0.541592 | valid loss: 0.535646\n","Epoch:  35 | train loss: 0.502211 | valid loss: 0.535550\n","Epoch:  36 | train loss: 0.557612 | valid loss: 0.535187\n","Epoch:  37 | train loss: 0.522452 | valid loss: 0.535652\n","Epoch:  38 | train loss: 0.547374 | valid loss: 0.535269\n","Epoch:  39 | train loss: 0.542645 | valid loss: 0.535623\n","Epoch:  40 | train loss: 0.559356 | valid loss: 0.535276\n","Epoch:  41 | train loss: 0.549415 | valid loss: 0.535422\n","Epoch:  42 | train loss: 0.557993 | valid loss: 0.535537\n","Epoch:  43 | train loss: 0.549074 | valid loss: 0.535601\n","Epoch:  44 | train loss: 0.480763 | valid loss: 0.535604\n","Epoch:  45 | train loss: 0.542864 | valid loss: 0.535746\n","Epoch:  46 | train loss: 0.522382 | valid loss: 0.535427\n","Epoch:  47 | train loss: 0.549048 | valid loss: 0.536261\n","Epoch:  48 | train loss: 0.543981 | valid loss: 0.535497\n","Epoch:  49 | train loss: 0.530007 | valid loss: 0.535582\n","Epoch:  50 | train loss: 0.510571 | valid loss: 0.534942\n","Epoch:  51 | train loss: 0.545492 | valid loss: 0.535833\n","Epoch:  52 | train loss: 0.502643 | valid loss: 0.536472\n","Epoch:  53 | train loss: 0.535156 | valid loss: 0.535688\n","Epoch:  54 | train loss: 0.548968 | valid loss: 0.535718\n","Epoch:  55 | train loss: 0.550194 | valid loss: 0.535636\n","Epoch:  56 | train loss: 0.554257 | valid loss: 0.535835\n","Epoch:  57 | train loss: 0.559897 | valid loss: 0.535463\n","Epoch:  58 | train loss: 0.567253 | valid loss: 0.535798\n","Epoch:  59 | train loss: 0.526125 | valid loss: 0.535253\n","Epoch:  60 | train loss: 0.536913 | valid loss: 0.535351\n","Epoch:  61 | train loss: 0.534236 | valid loss: 0.535366\n","Epoch:  62 | train loss: 0.562345 | valid loss: 0.535871\n","Epoch:  63 | train loss: 0.548574 | valid loss: 0.535309\n","Epoch:  64 | train loss: 0.572474 | valid loss: 0.535229\n","Epoch:  65 | train loss: 0.572236 | valid loss: 0.535886\n","Epoch:  66 | train loss: 0.556814 | valid loss: 0.535257\n","Epoch:  67 | train loss: 0.519864 | valid loss: 0.535660\n","Epoch:  68 | train loss: 0.522482 | valid loss: 0.535313\n","Epoch:  69 | train loss: 0.533560 | valid loss: 0.535347\n","Epoch:  70 | train loss: 0.512133 | valid loss: 0.535737\n","Epoch:  71 | train loss: 0.553214 | valid loss: 0.535289\n","Epoch:  72 | train loss: 0.514240 | valid loss: 0.535003\n","Epoch:  73 | train loss: 0.544527 | valid loss: 0.536011\n","Epoch:  74 | train loss: 0.557964 | valid loss: 0.535561\n","Epoch:  75 | train loss: 0.535803 | valid loss: 0.535627\n","Epoch:  76 | train loss: 0.520390 | valid loss: 0.535497\n","Epoch:  77 | train loss: 0.548817 | valid loss: 0.535637\n","Epoch:  78 | train loss: 0.548751 | valid loss: 0.535819\n","Epoch:  79 | train loss: 0.553820 | valid loss: 0.535275\n","Epoch:  80 | train loss: 0.563758 | valid loss: 0.535314\n","Epoch:  81 | train loss: 0.510496 | valid loss: 0.535349\n","Epoch:  82 | train loss: 0.546268 | valid loss: 0.535341\n","Epoch:  83 | train loss: 0.574796 | valid loss: 0.536335\n","Epoch:  84 | train loss: 0.551101 | valid loss: 0.535879\n","Epoch:  85 | train loss: 0.535699 | valid loss: 0.535766\n","Epoch:  86 | train loss: 0.547798 | valid loss: 0.535634\n","Epoch:  87 | train loss: 0.533390 | valid loss: 0.535645\n","Epoch:  88 | train loss: 0.555935 | valid loss: 0.535228\n","Epoch:  89 | train loss: 0.551985 | valid loss: 0.535375\n","Epoch:  90 | train loss: 0.551722 | valid loss: 0.535505\n","Epoch:  91 | train loss: 0.539058 | valid loss: 0.535433\n","Epoch:  92 | train loss: 0.535274 | valid loss: 0.535356\n","Epoch:  93 | train loss: 0.510528 | valid loss: 0.535556\n","Epoch:  94 | train loss: 0.538697 | valid loss: 0.535381\n","Epoch:  95 | train loss: 0.560730 | valid loss: 0.536295\n","Epoch:  96 | train loss: 0.517310 | valid loss: 0.535434\n","Epoch:  97 | train loss: 0.510961 | valid loss: 0.535126\n","Epoch:  98 | train loss: 0.557980 | valid loss: 0.535243\n","Epoch:  99 | train loss: 0.584411 | valid loss: 0.535944\n","Epoch:  100 | train loss: 0.577344 | valid loss: 0.535753\n","Epoch:  101 | train loss: 0.545157 | valid loss: 0.535549\n","Epoch:  102 | train loss: 0.538807 | valid loss: 0.535158\n","Epoch:  103 | train loss: 0.545706 | valid loss: 0.535458\n","Epoch:  104 | train loss: 0.509793 | valid loss: 0.535319\n","Epoch:  105 | train loss: 0.538490 | valid loss: 0.535347\n","Epoch:  106 | train loss: 0.526389 | valid loss: 0.535089\n","Epoch:  107 | train loss: 0.562669 | valid loss: 0.535968\n","Epoch:  108 | train loss: 0.522201 | valid loss: 0.535072\n","Epoch:  109 | train loss: 0.541888 | valid loss: 0.535217\n","Epoch:  110 | train loss: 0.503504 | valid loss: 0.535301\n","Epoch:  111 | train loss: 0.477827 | valid loss: 0.535342\n","Epoch:  112 | train loss: 0.550304 | valid loss: 0.535741\n","Epoch:  113 | train loss: 0.543439 | valid loss: 0.535171\n","Epoch:  114 | train loss: 0.548139 | valid loss: 0.535630\n","Epoch:  115 | train loss: 0.557270 | valid loss: 0.535300\n","Epoch:  116 | train loss: 0.548913 | valid loss: 0.535554\n","Epoch:  117 | train loss: 0.541541 | valid loss: 0.535294\n","Epoch:  118 | train loss: 0.567615 | valid loss: 0.535388\n","Epoch:  119 | train loss: 0.530268 | valid loss: 0.535167\n","Epoch:  120 | train loss: 0.554978 | valid loss: 0.535880\n","Epoch:  121 | train loss: 0.564101 | valid loss: 0.535630\n","Epoch:  122 | train loss: 0.517792 | valid loss: 0.535562\n","Epoch:  123 | train loss: 0.558900 | valid loss: 0.535266\n","Epoch:  124 | train loss: 0.502161 | valid loss: 0.535285\n","Epoch:  125 | train loss: 0.530629 | valid loss: 0.535343\n","Epoch:  126 | train loss: 0.539923 | valid loss: 0.535404\n","Epoch:  127 | train loss: 0.538102 | valid loss: 0.535312\n","Epoch:  128 | train loss: 0.523885 | valid loss: 0.535456\n","Epoch:  129 | train loss: 0.575227 | valid loss: 0.535290\n","Epoch:  130 | train loss: 0.562186 | valid loss: 0.535171\n","Epoch:  131 | train loss: 0.537271 | valid loss: 0.536111\n","Epoch:  132 | train loss: 0.546694 | valid loss: 0.535836\n","Epoch:  133 | train loss: 0.543050 | valid loss: 0.536786\n","Epoch:  134 | train loss: 0.559940 | valid loss: 0.535513\n","Epoch:  135 | train loss: 0.486275 | valid loss: 0.535113\n","Epoch:  136 | train loss: 0.537059 | valid loss: 0.535827\n","Epoch:  137 | train loss: 0.520003 | valid loss: 0.535394\n","Epoch:  138 | train loss: 0.552701 | valid loss: 0.535211\n","Epoch:  139 | train loss: 0.565951 | valid loss: 0.535759\n","Epoch:  140 | train loss: 0.523303 | valid loss: 0.535466\n","Epoch:  141 | train loss: 0.524519 | valid loss: 0.535107\n","Epoch:  142 | train loss: 0.524349 | valid loss: 0.535057\n","Epoch:  143 | train loss: 0.542716 | valid loss: 0.534906\n","Epoch:  144 | train loss: 0.525699 | valid loss: 0.535099\n","Epoch:  145 | train loss: 0.537639 | valid loss: 0.535086\n","Epoch:  146 | train loss: 0.507412 | valid loss: 0.535555\n","Epoch:  147 | train loss: 0.540954 | valid loss: 0.535765\n","Epoch:  148 | train loss: 0.515014 | valid loss: 0.535201\n","Epoch:  149 | train loss: 0.545933 | valid loss: 0.537283\n","Epoch:  150 | train loss: 0.538051 | valid loss: 0.535797\n","Epoch:  151 | train loss: 0.553238 | valid loss: 0.535399\n","Epoch:  152 | train loss: 0.504688 | valid loss: 0.535096\n","Epoch:  153 | train loss: 0.524832 | valid loss: 0.535051\n","Epoch:  154 | train loss: 0.539904 | valid loss: 0.535566\n","Epoch:  155 | train loss: 0.559933 | valid loss: 0.535214\n","Epoch:  156 | train loss: 0.548589 | valid loss: 0.535247\n","Epoch:  157 | train loss: 0.547904 | valid loss: 0.534840\n","Epoch:  158 | train loss: 0.527170 | valid loss: 0.534941\n","Epoch:  159 | train loss: 0.551961 | valid loss: 0.534437\n","Epoch:  160 | train loss: 0.528282 | valid loss: 0.535185\n","Epoch:  161 | train loss: 0.554579 | valid loss: 0.535063\n","Epoch:  162 | train loss: 0.559958 | valid loss: 0.535252\n","Epoch:  163 | train loss: 0.508267 | valid loss: 0.535412\n","Epoch:  164 | train loss: 0.571450 | valid loss: 0.535062\n","Epoch:  165 | train loss: 0.538645 | valid loss: 0.535253\n","Epoch:  166 | train loss: 0.544880 | valid loss: 0.535509\n","Epoch:  167 | train loss: 0.561364 | valid loss: 0.535218\n","Epoch:  168 | train loss: 0.530066 | valid loss: 0.534771\n","Epoch:  169 | train loss: 0.549059 | valid loss: 0.534902\n","Epoch:  170 | train loss: 0.505564 | valid loss: 0.535095\n","Epoch:  171 | train loss: 0.544311 | valid loss: 0.535319\n","Epoch:  172 | train loss: 0.550357 | valid loss: 0.535487\n","Epoch:  173 | train loss: 0.526543 | valid loss: 0.535883\n","Epoch:  174 | train loss: 0.544388 | valid loss: 0.534918\n","Epoch:  175 | train loss: 0.554398 | valid loss: 0.534705\n","Epoch:  176 | train loss: 0.571119 | valid loss: 0.535517\n","Epoch:  177 | train loss: 0.556006 | valid loss: 0.535358\n","Epoch:  178 | train loss: 0.507023 | valid loss: 0.534941\n","Epoch:  179 | train loss: 0.546854 | valid loss: 0.535292\n","Epoch:  180 | train loss: 0.564492 | valid loss: 0.535013\n","Epoch:  181 | train loss: 0.505637 | valid loss: 0.535124\n","Epoch:  182 | train loss: 0.542720 | valid loss: 0.534892\n","Epoch:  183 | train loss: 0.571232 | valid loss: 0.534741\n","Epoch:  184 | train loss: 0.531337 | valid loss: 0.535861\n","Epoch:  185 | train loss: 0.556461 | valid loss: 0.535138\n","Epoch:  186 | train loss: 0.526657 | valid loss: 0.535544\n","Epoch:  187 | train loss: 0.533921 | valid loss: 0.535136\n","Epoch:  188 | train loss: 0.545658 | valid loss: 0.535204\n","Epoch:  189 | train loss: 0.554361 | valid loss: 0.534861\n","Epoch:  190 | train loss: 0.549038 | valid loss: 0.535044\n","Epoch:  191 | train loss: 0.535716 | valid loss: 0.534792\n","Epoch:  192 | train loss: 0.534010 | valid loss: 0.535093\n","Epoch:  193 | train loss: 0.539200 | valid loss: 0.535649\n","Epoch:  194 | train loss: 0.507781 | valid loss: 0.535302\n","Epoch:  195 | train loss: 0.565831 | valid loss: 0.535071\n","Epoch:  196 | train loss: 0.561125 | valid loss: 0.535801\n","Epoch:  197 | train loss: 0.517160 | valid loss: 0.534991\n","Epoch:  198 | train loss: 0.548286 | valid loss: 0.535230\n","Epoch:  199 | train loss: 0.545327 | valid loss: 0.535267\n","Epoch:  200 | train loss: 0.543708 | valid loss: 0.534759\n","Epoch:  201 | train loss: 0.534570 | valid loss: 0.534754\n","Epoch:  202 | train loss: 0.540311 | valid loss: 0.534851\n","Epoch:  203 | train loss: 0.559753 | valid loss: 0.535162\n","Epoch:  204 | train loss: 0.548340 | valid loss: 0.534910\n","Epoch:  205 | train loss: 0.560379 | valid loss: 0.535508\n","Epoch:  206 | train loss: 0.544998 | valid loss: 0.535010\n","Epoch:  207 | train loss: 0.486978 | valid loss: 0.534993\n","Epoch:  208 | train loss: 0.549609 | valid loss: 0.534771\n","Epoch:  209 | train loss: 0.575217 | valid loss: 0.534879\n","Epoch:  210 | train loss: 0.527915 | valid loss: 0.534880\n","Epoch:  211 | train loss: 0.559354 | valid loss: 0.534732\n","Epoch:  212 | train loss: 0.537685 | valid loss: 0.534772\n","Epoch:  213 | train loss: 0.544271 | valid loss: 0.534980\n","Epoch:  214 | train loss: 0.525976 | valid loss: 0.535216\n","Epoch:  215 | train loss: 0.548449 | valid loss: 0.535149\n","Epoch:  216 | train loss: 0.533604 | valid loss: 0.534883\n","Epoch:  217 | train loss: 0.547064 | valid loss: 0.534859\n","Epoch:  218 | train loss: 0.550956 | valid loss: 0.535273\n","Epoch:  219 | train loss: 0.520466 | valid loss: 0.534898\n","Epoch:  220 | train loss: 0.555901 | valid loss: 0.534848\n","Epoch:  221 | train loss: 0.545929 | valid loss: 0.534675\n","Epoch:  222 | train loss: 0.556988 | valid loss: 0.534605\n","Epoch:  223 | train loss: 0.500940 | valid loss: 0.534851\n","Epoch:  224 | train loss: 0.559855 | valid loss: 0.534752\n","Epoch:  225 | train loss: 0.474787 | valid loss: 0.535114\n","Epoch:  226 | train loss: 0.546849 | valid loss: 0.535003\n","Epoch:  227 | train loss: 0.558987 | valid loss: 0.534742\n","Epoch:  228 | train loss: 0.513622 | valid loss: 0.534596\n","Epoch:  229 | train loss: 0.532256 | valid loss: 0.534843\n","Epoch:  230 | train loss: 0.519043 | valid loss: 0.534603\n","Epoch:  231 | train loss: 0.543176 | valid loss: 0.535249\n","Epoch:  232 | train loss: 0.568551 | valid loss: 0.534507\n","Epoch:  233 | train loss: 0.543035 | valid loss: 0.534619\n","Epoch:  234 | train loss: 0.541173 | valid loss: 0.534477\n","Epoch:  235 | train loss: 0.544689 | valid loss: 0.534675\n","Epoch:  236 | train loss: 0.542331 | valid loss: 0.534837\n","Epoch:  237 | train loss: 0.528861 | valid loss: 0.534754\n","Epoch:  238 | train loss: 0.531303 | valid loss: 0.534508\n","Epoch:  239 | train loss: 0.527787 | valid loss: 0.534666\n","Epoch:  240 | train loss: 0.540375 | valid loss: 0.534688\n","Epoch:  241 | train loss: 0.545348 | valid loss: 0.534900\n","Epoch:  242 | train loss: 0.545363 | valid loss: 0.534640\n","Epoch:  243 | train loss: 0.540497 | valid loss: 0.534536\n","Epoch:  244 | train loss: 0.547997 | valid loss: 0.534416\n","Epoch:  245 | train loss: 0.512712 | valid loss: 0.534519\n","Epoch:  246 | train loss: 0.562949 | valid loss: 0.534587\n","Epoch:  247 | train loss: 0.573139 | valid loss: 0.534510\n","Epoch:  248 | train loss: 0.546699 | valid loss: 0.534617\n","Epoch:  249 | train loss: 0.525198 | valid loss: 0.533888\n","Epoch:  250 | train loss: 0.512234 | valid loss: 0.534690\n","Epoch:  251 | train loss: 0.537244 | valid loss: 0.534562\n","Epoch:  252 | train loss: 0.536715 | valid loss: 0.534441\n","Epoch:  253 | train loss: 0.519010 | valid loss: 0.534690\n","Epoch:  254 | train loss: 0.549822 | valid loss: 0.534745\n","Epoch:  255 | train loss: 0.551710 | valid loss: 0.534607\n","Epoch:  256 | train loss: 0.550475 | valid loss: 0.534665\n","Epoch:  257 | train loss: 0.531031 | valid loss: 0.534233\n","Epoch:  258 | train loss: 0.524718 | valid loss: 0.534202\n","Epoch:  259 | train loss: 0.542491 | valid loss: 0.534274\n","Epoch:  260 | train loss: 0.547929 | valid loss: 0.534221\n","Epoch:  261 | train loss: 0.540765 | valid loss: 0.534296\n","Epoch:  262 | train loss: 0.559520 | valid loss: 0.534188\n","Epoch:  263 | train loss: 0.531101 | valid loss: 0.534053\n","Epoch:  264 | train loss: 0.567871 | valid loss: 0.534464\n","Epoch:  265 | train loss: 0.574576 | valid loss: 0.534510\n","Epoch:  266 | train loss: 0.542873 | valid loss: 0.534044\n","Epoch:  267 | train loss: 0.530284 | valid loss: 0.533533\n","Epoch:  268 | train loss: 0.549510 | valid loss: 0.534048\n","Epoch:  269 | train loss: 0.543925 | valid loss: 0.534684\n","Epoch:  270 | train loss: 0.543947 | valid loss: 0.534415\n","Epoch:  271 | train loss: 0.508202 | valid loss: 0.534195\n","Epoch:  272 | train loss: 0.527493 | valid loss: 0.534342\n","Epoch:  273 | train loss: 0.554242 | valid loss: 0.534403\n","Epoch:  274 | train loss: 0.503047 | valid loss: 0.534133\n","Epoch:  275 | train loss: 0.549901 | valid loss: 0.534122\n","Epoch:  276 | train loss: 0.565814 | valid loss: 0.534633\n","Epoch:  277 | train loss: 0.545578 | valid loss: 0.534502\n","Epoch:  278 | train loss: 0.545929 | valid loss: 0.534449\n","Epoch:  279 | train loss: 0.552467 | valid loss: 0.534285\n","Epoch:  280 | train loss: 0.550713 | valid loss: 0.534040\n","Epoch:  281 | train loss: 0.542799 | valid loss: 0.534476\n","Epoch:  282 | train loss: 0.510802 | valid loss: 0.534430\n","Epoch:  283 | train loss: 0.490346 | valid loss: 0.534106\n","Epoch:  284 | train loss: 0.510144 | valid loss: 0.534428\n","Epoch:  285 | train loss: 0.527006 | valid loss: 0.534169\n","Epoch:  286 | train loss: 0.535263 | valid loss: 0.534357\n","Epoch:  287 | train loss: 0.542309 | valid loss: 0.534078\n","Epoch:  288 | train loss: 0.471952 | valid loss: 0.533280\n","Epoch:  289 | train loss: 0.527416 | valid loss: 0.533850\n","Epoch:  290 | train loss: 0.509747 | valid loss: 0.533794\n","Epoch:  291 | train loss: 0.543963 | valid loss: 0.533442\n","Epoch:  292 | train loss: 0.550178 | valid loss: 0.533687\n","Epoch:  293 | train loss: 0.528860 | valid loss: 0.533004\n","Epoch:  294 | train loss: 0.530366 | valid loss: 0.533468\n","Epoch:  295 | train loss: 0.570117 | valid loss: 0.533174\n","Epoch:  296 | train loss: 0.549943 | valid loss: 0.533269\n","Epoch:  297 | train loss: 0.541325 | valid loss: 0.532987\n","Epoch:  298 | train loss: 0.516971 | valid loss: 0.533172\n","Epoch:  299 | train loss: 0.541099 | valid loss: 0.533016\n","Epoch:  300 | train loss: 0.521988 | valid loss: 0.533155\n","Epoch:  301 | train loss: 0.536243 | valid loss: 0.532900\n","Epoch:  302 | train loss: 0.556805 | valid loss: 0.533051\n","Epoch:  303 | train loss: 0.530240 | valid loss: 0.533598\n","Epoch:  304 | train loss: 0.530510 | valid loss: 0.533329\n","Epoch:  305 | train loss: 0.561666 | valid loss: 0.532845\n","Epoch:  306 | train loss: 0.545690 | valid loss: 0.533174\n","Epoch:  307 | train loss: 0.515300 | valid loss: 0.533075\n","Epoch:  308 | train loss: 0.532953 | valid loss: 0.532766\n","Epoch:  309 | train loss: 0.518069 | valid loss: 0.532452\n","Epoch:  310 | train loss: 0.554967 | valid loss: 0.532795\n","Epoch:  311 | train loss: 0.544556 | valid loss: 0.532746\n","Epoch:  312 | train loss: 0.545878 | valid loss: 0.532705\n","Epoch:  313 | train loss: 0.511405 | valid loss: 0.533420\n","Epoch:  314 | train loss: 0.545017 | valid loss: 0.533114\n","Epoch:  315 | train loss: 0.542910 | valid loss: 0.532763\n","Epoch:  316 | train loss: 0.492152 | valid loss: 0.532731\n","Epoch:  317 | train loss: 0.540610 | valid loss: 0.532998\n","Epoch:  318 | train loss: 0.557368 | valid loss: 0.532421\n","Epoch:  319 | train loss: 0.558422 | valid loss: 0.532511\n","Epoch:  320 | train loss: 0.538828 | valid loss: 0.532316\n","Epoch:  321 | train loss: 0.548307 | valid loss: 0.532369\n","Epoch:  322 | train loss: 0.540304 | valid loss: 0.532826\n","Epoch:  323 | train loss: 0.550614 | valid loss: 0.532371\n","Epoch:  324 | train loss: 0.556468 | valid loss: 0.532478\n","Epoch:  325 | train loss: 0.548336 | valid loss: 0.532474\n","Epoch:  326 | train loss: 0.513894 | valid loss: 0.532344\n","Epoch:  327 | train loss: 0.529884 | valid loss: 0.532161\n","Epoch:  328 | train loss: 0.542332 | valid loss: 0.532580\n","Epoch:  329 | train loss: 0.568700 | valid loss: 0.532587\n","Epoch:  330 | train loss: 0.546536 | valid loss: 0.532400\n","Epoch:  331 | train loss: 0.505031 | valid loss: 0.532348\n","Epoch:  332 | train loss: 0.562874 | valid loss: 0.532587\n","Epoch:  333 | train loss: 0.520918 | valid loss: 0.532213\n","Epoch:  334 | train loss: 0.573363 | valid loss: 0.532621\n","Epoch:  335 | train loss: 0.554236 | valid loss: 0.532163\n","Epoch:  336 | train loss: 0.546870 | valid loss: 0.532208\n","Epoch:  337 | train loss: 0.524178 | valid loss: 0.532323\n","Epoch:  338 | train loss: 0.541305 | valid loss: 0.532243\n","Epoch:  339 | train loss: 0.554126 | valid loss: 0.531901\n","Epoch:  340 | train loss: 0.523992 | valid loss: 0.531942\n","Epoch:  341 | train loss: 0.534026 | valid loss: 0.531847\n","Epoch:  342 | train loss: 0.570588 | valid loss: 0.531827\n","Epoch:  343 | train loss: 0.515545 | valid loss: 0.531779\n","Epoch:  344 | train loss: 0.492771 | valid loss: 0.531740\n","Epoch:  345 | train loss: 0.553475 | valid loss: 0.531865\n","Epoch:  346 | train loss: 0.540107 | valid loss: 0.531858\n","Epoch:  347 | train loss: 0.566164 | valid loss: 0.532020\n","Epoch:  348 | train loss: 0.536465 | valid loss: 0.531934\n","Epoch:  349 | train loss: 0.542386 | valid loss: 0.532161\n","Epoch:  350 | train loss: 0.542793 | valid loss: 0.531757\n","Epoch:  351 | train loss: 0.531020 | valid loss: 0.531549\n","Epoch:  352 | train loss: 0.548958 | valid loss: 0.531435\n","Epoch:  353 | train loss: 0.506796 | valid loss: 0.532204\n","Epoch:  354 | train loss: 0.528484 | valid loss: 0.531516\n","Epoch:  355 | train loss: 0.551184 | valid loss: 0.531688\n","Epoch:  356 | train loss: 0.533767 | valid loss: 0.531409\n","Epoch:  357 | train loss: 0.527133 | valid loss: 0.531808\n","Epoch:  358 | train loss: 0.556021 | valid loss: 0.531441\n","Epoch:  359 | train loss: 0.538988 | valid loss: 0.531147\n","Epoch:  360 | train loss: 0.536814 | valid loss: 0.531141\n","Epoch:  361 | train loss: 0.555830 | valid loss: 0.531470\n","Epoch:  362 | train loss: 0.537735 | valid loss: 0.530979\n","Epoch:  363 | train loss: 0.555920 | valid loss: 0.531224\n","Epoch:  364 | train loss: 0.471652 | valid loss: 0.531469\n","Epoch:  365 | train loss: 0.500550 | valid loss: 0.531430\n","Epoch:  366 | train loss: 0.519930 | valid loss: 0.531234\n","Epoch:  367 | train loss: 0.549160 | valid loss: 0.530634\n","Epoch:  368 | train loss: 0.545668 | valid loss: 0.531150\n","Epoch:  369 | train loss: 0.533625 | valid loss: 0.530857\n","Epoch:  370 | train loss: 0.551387 | valid loss: 0.530878\n","Epoch:  371 | train loss: 0.521167 | valid loss: 0.530902\n","Epoch:  372 | train loss: 0.546739 | valid loss: 0.530953\n","Epoch:  373 | train loss: 0.534451 | valid loss: 0.530602\n","Epoch:  374 | train loss: 0.522883 | valid loss: 0.530658\n","Epoch:  375 | train loss: 0.510022 | valid loss: 0.530848\n","Epoch:  376 | train loss: 0.526605 | valid loss: 0.530737\n","Epoch:  377 | train loss: 0.504370 | valid loss: 0.530277\n","Epoch:  378 | train loss: 0.534023 | valid loss: 0.530410\n","Epoch:  379 | train loss: 0.538857 | valid loss: 0.530234\n","Epoch:  380 | train loss: 0.521200 | valid loss: 0.530405\n","Epoch:  381 | train loss: 0.514595 | valid loss: 0.530810\n","Epoch:  382 | train loss: 0.504341 | valid loss: 0.530322\n","Epoch:  383 | train loss: 0.541799 | valid loss: 0.530120\n","Epoch:  384 | train loss: 0.549036 | valid loss: 0.530692\n","Epoch:  385 | train loss: 0.544013 | valid loss: 0.530403\n","Epoch:  386 | train loss: 0.542772 | valid loss: 0.530250\n","Epoch:  387 | train loss: 0.538744 | valid loss: 0.530222\n","Epoch:  388 | train loss: 0.537185 | valid loss: 0.530087\n","Epoch:  389 | train loss: 0.517889 | valid loss: 0.529926\n","Epoch:  390 | train loss: 0.547939 | valid loss: 0.530116\n","Epoch:  391 | train loss: 0.549601 | valid loss: 0.529993\n","Epoch:  392 | train loss: 0.568844 | valid loss: 0.529818\n","Epoch:  393 | train loss: 0.556598 | valid loss: 0.529501\n","Epoch:  394 | train loss: 0.540457 | valid loss: 0.529735\n","Epoch:  395 | train loss: 0.474197 | valid loss: 0.529635\n","Epoch:  396 | train loss: 0.534252 | valid loss: 0.529726\n","Epoch:  397 | train loss: 0.537307 | valid loss: 0.529854\n","Epoch:  398 | train loss: 0.532146 | valid loss: 0.529693\n","Epoch:  399 | train loss: 0.552056 | valid loss: 0.529242\n","Epoch:  400 | train loss: 0.560598 | valid loss: 0.529600\n","Epoch:  401 | train loss: 0.551841 | valid loss: 0.529583\n","Epoch:  402 | train loss: 0.538474 | valid loss: 0.529436\n","Epoch:  403 | train loss: 0.557232 | valid loss: 0.529126\n","Epoch:  404 | train loss: 0.501335 | valid loss: 0.529842\n","Epoch:  405 | train loss: 0.514540 | valid loss: 0.528938\n","Epoch:  406 | train loss: 0.518047 | valid loss: 0.529055\n","Epoch:  407 | train loss: 0.487401 | valid loss: 0.528942\n","Epoch:  408 | train loss: 0.521269 | valid loss: 0.529300\n","Epoch:  409 | train loss: 0.546616 | valid loss: 0.529119\n","Epoch:  410 | train loss: 0.536528 | valid loss: 0.529209\n","Epoch:  411 | train loss: 0.542999 | valid loss: 0.528981\n","Epoch:  412 | train loss: 0.504785 | valid loss: 0.528519\n","Epoch:  413 | train loss: 0.552820 | valid loss: 0.528686\n","Epoch:  414 | train loss: 0.500246 | valid loss: 0.528801\n","Epoch:  415 | train loss: 0.512866 | valid loss: 0.528507\n","Epoch:  416 | train loss: 0.492179 | valid loss: 0.528439\n","Epoch:  417 | train loss: 0.536782 | valid loss: 0.528651\n","Epoch:  418 | train loss: 0.542721 | valid loss: 0.528755\n","Epoch:  419 | train loss: 0.535150 | valid loss: 0.528055\n","Epoch:  420 | train loss: 0.532827 | valid loss: 0.527978\n","Epoch:  421 | train loss: 0.551882 | valid loss: 0.527907\n","Epoch:  422 | train loss: 0.528507 | valid loss: 0.527850\n","Epoch:  423 | train loss: 0.496716 | valid loss: 0.528314\n","Epoch:  424 | train loss: 0.526859 | valid loss: 0.527969\n","Epoch:  425 | train loss: 0.561373 | valid loss: 0.528096\n","Epoch:  426 | train loss: 0.577774 | valid loss: 0.528288\n","Epoch:  427 | train loss: 0.554218 | valid loss: 0.527639\n","Epoch:  428 | train loss: 0.532041 | valid loss: 0.527479\n","Epoch:  429 | train loss: 0.517117 | valid loss: 0.527713\n","Epoch:  430 | train loss: 0.531236 | valid loss: 0.527458\n","Epoch:  431 | train loss: 0.556063 | valid loss: 0.527719\n","Epoch:  432 | train loss: 0.557978 | valid loss: 0.527285\n","Epoch:  433 | train loss: 0.547338 | valid loss: 0.527535\n","Epoch:  434 | train loss: 0.524190 | valid loss: 0.527316\n","Epoch:  435 | train loss: 0.532710 | valid loss: 0.527061\n","Epoch:  436 | train loss: 0.516094 | valid loss: 0.527329\n","Epoch:  437 | train loss: 0.525982 | valid loss: 0.527164\n","Epoch:  438 | train loss: 0.517510 | valid loss: 0.527081\n","Epoch:  439 | train loss: 0.550058 | valid loss: 0.526829\n","Epoch:  440 | train loss: 0.547098 | valid loss: 0.526792\n","Epoch:  441 | train loss: 0.521422 | valid loss: 0.526639\n","Epoch:  442 | train loss: 0.542954 | valid loss: 0.526779\n","Epoch:  443 | train loss: 0.551262 | valid loss: 0.526291\n","Epoch:  444 | train loss: 0.536465 | valid loss: 0.526216\n","Epoch:  445 | train loss: 0.530443 | valid loss: 0.526521\n","Epoch:  446 | train loss: 0.528543 | valid loss: 0.526612\n","Epoch:  447 | train loss: 0.518012 | valid loss: 0.525946\n","Epoch:  448 | train loss: 0.539194 | valid loss: 0.526041\n","Epoch:  449 | train loss: 0.540833 | valid loss: 0.526112\n","Epoch:  450 | train loss: 0.519135 | valid loss: 0.525595\n","Epoch:  451 | train loss: 0.544241 | valid loss: 0.525719\n","Epoch:  452 | train loss: 0.491404 | valid loss: 0.525940\n","Epoch:  453 | train loss: 0.510078 | valid loss: 0.526205\n","Epoch:  454 | train loss: 0.511356 | valid loss: 0.525693\n","Epoch:  455 | train loss: 0.537793 | valid loss: 0.525868\n","Epoch:  456 | train loss: 0.518466 | valid loss: 0.525432\n","Epoch:  457 | train loss: 0.519568 | valid loss: 0.525274\n","Epoch:  458 | train loss: 0.535656 | valid loss: 0.525000\n","Epoch:  459 | train loss: 0.520416 | valid loss: 0.524891\n","Epoch:  460 | train loss: 0.499522 | valid loss: 0.525345\n","Epoch:  461 | train loss: 0.512272 | valid loss: 0.525053\n","Epoch:  462 | train loss: 0.538646 | valid loss: 0.524803\n","Epoch:  463 | train loss: 0.546581 | valid loss: 0.524844\n","Epoch:  464 | train loss: 0.538632 | valid loss: 0.524601\n","Epoch:  465 | train loss: 0.478958 | valid loss: 0.524638\n","Epoch:  466 | train loss: 0.521517 | valid loss: 0.524851\n","Epoch:  467 | train loss: 0.556036 | valid loss: 0.524519\n","Epoch:  468 | train loss: 0.530294 | valid loss: 0.524956\n","Epoch:  469 | train loss: 0.549671 | valid loss: 0.524550\n","Epoch:  470 | train loss: 0.529572 | valid loss: 0.524320\n","Epoch:  471 | train loss: 0.544626 | valid loss: 0.523897\n","Epoch:  472 | train loss: 0.541158 | valid loss: 0.523735\n","Epoch:  473 | train loss: 0.546060 | valid loss: 0.524224\n","Epoch:  474 | train loss: 0.510651 | valid loss: 0.523669\n","Epoch:  475 | train loss: 0.522489 | valid loss: 0.523752\n","Epoch:  476 | train loss: 0.538783 | valid loss: 0.523853\n","Epoch:  477 | train loss: 0.546296 | valid loss: 0.523906\n","Epoch:  478 | train loss: 0.516864 | valid loss: 0.523503\n","Epoch:  479 | train loss: 0.456755 | valid loss: 0.523501\n","Epoch:  480 | train loss: 0.539984 | valid loss: 0.523333\n","Epoch:  481 | train loss: 0.538634 | valid loss: 0.522954\n","Epoch:  482 | train loss: 0.516078 | valid loss: 0.523550\n","Epoch:  483 | train loss: 0.540300 | valid loss: 0.523766\n","Epoch:  484 | train loss: 0.504300 | valid loss: 0.523004\n","Epoch:  485 | train loss: 0.504070 | valid loss: 0.522592\n","Epoch:  486 | train loss: 0.564439 | valid loss: 0.522648\n","Epoch:  487 | train loss: 0.569699 | valid loss: 0.522237\n","Epoch:  488 | train loss: 0.533370 | valid loss: 0.522334\n","Epoch:  489 | train loss: 0.500822 | valid loss: 0.522435\n","Epoch:  490 | train loss: 0.535355 | valid loss: 0.521990\n","Epoch:  491 | train loss: 0.554901 | valid loss: 0.521981\n","Epoch:  492 | train loss: 0.539781 | valid loss: 0.521750\n","Epoch:  493 | train loss: 0.528741 | valid loss: 0.521612\n","Epoch:  494 | train loss: 0.578906 | valid loss: 0.521554\n","Epoch:  495 | train loss: 0.555024 | valid loss: 0.521498\n","Epoch:  496 | train loss: 0.541850 | valid loss: 0.521327\n","Epoch:  497 | train loss: 0.549216 | valid loss: 0.521120\n","Epoch:  498 | train loss: 0.534239 | valid loss: 0.521208\n","Epoch:  499 | train loss: 0.536565 | valid loss: 0.521134\n","Epoch:  500 | train loss: 0.533680 | valid loss: 0.521179\n","Epoch:  501 | train loss: 0.538869 | valid loss: 0.520752\n","Epoch:  502 | train loss: 0.527625 | valid loss: 0.520645\n","Epoch:  503 | train loss: 0.537852 | valid loss: 0.521085\n","Epoch:  504 | train loss: 0.538092 | valid loss: 0.520467\n","Epoch:  505 | train loss: 0.479815 | valid loss: 0.520808\n","Epoch:  506 | train loss: 0.519144 | valid loss: 0.520240\n","Epoch:  507 | train loss: 0.510339 | valid loss: 0.520350\n","Epoch:  508 | train loss: 0.496306 | valid loss: 0.520208\n","Epoch:  509 | train loss: 0.518200 | valid loss: 0.519839\n","Epoch:  510 | train loss: 0.517241 | valid loss: 0.519672\n","Epoch:  511 | train loss: 0.518612 | valid loss: 0.519539\n","Epoch:  512 | train loss: 0.499726 | valid loss: 0.520119\n","Epoch:  513 | train loss: 0.502971 | valid loss: 0.519351\n","Epoch:  514 | train loss: 0.513071 | valid loss: 0.519203\n","Epoch:  515 | train loss: 0.495483 | valid loss: 0.519305\n","Epoch:  516 | train loss: 0.540278 | valid loss: 0.518939\n","Epoch:  517 | train loss: 0.507903 | valid loss: 0.518807\n","Epoch:  518 | train loss: 0.500074 | valid loss: 0.518683\n","Epoch:  519 | train loss: 0.524403 | valid loss: 0.518896\n","Epoch:  520 | train loss: 0.533454 | valid loss: 0.518516\n","Epoch:  521 | train loss: 0.524327 | valid loss: 0.518439\n","Epoch:  522 | train loss: 0.517735 | valid loss: 0.518170\n","Epoch:  523 | train loss: 0.559885 | valid loss: 0.518030\n","Epoch:  524 | train loss: 0.524342 | valid loss: 0.518105\n","Epoch:  525 | train loss: 0.535730 | valid loss: 0.518313\n","Epoch:  526 | train loss: 0.530862 | valid loss: 0.517871\n","Epoch:  527 | train loss: 0.533504 | valid loss: 0.517593\n","Epoch:  528 | train loss: 0.567375 | valid loss: 0.517470\n","Epoch:  529 | train loss: 0.519127 | valid loss: 0.517358\n","Epoch:  530 | train loss: 0.535554 | valid loss: 0.517174\n","Epoch:  531 | train loss: 0.522042 | valid loss: 0.517104\n","Epoch:  532 | train loss: 0.548150 | valid loss: 0.516912\n","Epoch:  533 | train loss: 0.533184 | valid loss: 0.516888\n","Epoch:  534 | train loss: 0.511344 | valid loss: 0.516586\n","Epoch:  535 | train loss: 0.515656 | valid loss: 0.516517\n","Epoch:  536 | train loss: 0.522379 | valid loss: 0.516665\n","Epoch:  537 | train loss: 0.505638 | valid loss: 0.516180\n","Epoch:  538 | train loss: 0.549044 | valid loss: 0.516408\n","Epoch:  539 | train loss: 0.510112 | valid loss: 0.516323\n","Epoch:  540 | train loss: 0.519704 | valid loss: 0.515838\n","Epoch:  541 | train loss: 0.564569 | valid loss: 0.516020\n","Epoch:  542 | train loss: 0.502349 | valid loss: 0.515672\n","Epoch:  543 | train loss: 0.511619 | valid loss: 0.515572\n","Epoch:  544 | train loss: 0.520372 | valid loss: 0.515154\n","Epoch:  545 | train loss: 0.539093 | valid loss: 0.515085\n","Epoch:  546 | train loss: 0.500744 | valid loss: 0.515016\n","Epoch:  547 | train loss: 0.465996 | valid loss: 0.514883\n","Epoch:  548 | train loss: 0.463792 | valid loss: 0.514847\n","Epoch:  549 | train loss: 0.550283 | valid loss: 0.514510\n","Epoch:  550 | train loss: 0.551547 | valid loss: 0.514303\n","Epoch:  551 | train loss: 0.499614 | valid loss: 0.514232\n","Epoch:  552 | train loss: 0.514777 | valid loss: 0.513997\n","Epoch:  553 | train loss: 0.522434 | valid loss: 0.513969\n","Epoch:  554 | train loss: 0.512089 | valid loss: 0.513887\n","Epoch:  555 | train loss: 0.548752 | valid loss: 0.514056\n","Epoch:  556 | train loss: 0.509111 | valid loss: 0.513678\n","Epoch:  557 | train loss: 0.534719 | valid loss: 0.513416\n","Epoch:  558 | train loss: 0.528986 | valid loss: 0.513176\n","Epoch:  559 | train loss: 0.458389 | valid loss: 0.512960\n","Epoch:  560 | train loss: 0.562734 | valid loss: 0.513257\n","Epoch:  561 | train loss: 0.477338 | valid loss: 0.512844\n","Epoch:  562 | train loss: 0.477062 | valid loss: 0.512896\n","Epoch:  563 | train loss: 0.514868 | valid loss: 0.512644\n","Epoch:  564 | train loss: 0.547474 | valid loss: 0.512791\n","Epoch:  565 | train loss: 0.534818 | valid loss: 0.512292\n","Epoch:  566 | train loss: 0.504632 | valid loss: 0.512177\n","Epoch:  567 | train loss: 0.516770 | valid loss: 0.512147\n","Epoch:  568 | train loss: 0.486878 | valid loss: 0.511659\n","Epoch:  569 | train loss: 0.480539 | valid loss: 0.511734\n","Epoch:  570 | train loss: 0.519498 | valid loss: 0.511512\n","Epoch:  571 | train loss: 0.549186 | valid loss: 0.511658\n","Epoch:  572 | train loss: 0.486219 | valid loss: 0.511259\n","Epoch:  573 | train loss: 0.512027 | valid loss: 0.510972\n","Epoch:  574 | train loss: 0.530780 | valid loss: 0.510745\n","Epoch:  575 | train loss: 0.504471 | valid loss: 0.510697\n","Epoch:  576 | train loss: 0.513601 | valid loss: 0.510616\n","Epoch:  577 | train loss: 0.483975 | valid loss: 0.510542\n","Epoch:  578 | train loss: 0.533149 | valid loss: 0.510223\n","Epoch:  579 | train loss: 0.510318 | valid loss: 0.510300\n","Epoch:  580 | train loss: 0.485922 | valid loss: 0.509926\n","Epoch:  581 | train loss: 0.545859 | valid loss: 0.509710\n","Epoch:  582 | train loss: 0.476150 | valid loss: 0.510006\n","Epoch:  583 | train loss: 0.522986 | valid loss: 0.509741\n","Epoch:  584 | train loss: 0.520128 | valid loss: 0.509248\n","Epoch:  585 | train loss: 0.545354 | valid loss: 0.509178\n","Epoch:  586 | train loss: 0.527404 | valid loss: 0.509152\n","Epoch:  587 | train loss: 0.512315 | valid loss: 0.509191\n","Epoch:  588 | train loss: 0.501353 | valid loss: 0.508843\n","Epoch:  589 | train loss: 0.508711 | valid loss: 0.508682\n","Epoch:  590 | train loss: 0.528291 | valid loss: 0.508443\n","Epoch:  591 | train loss: 0.507787 | valid loss: 0.508437\n","Epoch:  592 | train loss: 0.510566 | valid loss: 0.507946\n","Epoch:  593 | train loss: 0.558863 | valid loss: 0.507998\n","Epoch:  594 | train loss: 0.513738 | valid loss: 0.507706\n","Epoch:  595 | train loss: 0.488911 | valid loss: 0.507785\n","Epoch:  596 | train loss: 0.484247 | valid loss: 0.507717\n","Epoch:  597 | train loss: 0.505798 | valid loss: 0.507178\n","Epoch:  598 | train loss: 0.513438 | valid loss: 0.507256\n","Epoch:  599 | train loss: 0.471533 | valid loss: 0.507022\n","Epoch:  600 | train loss: 0.503692 | valid loss: 0.507107\n","Epoch:  601 | train loss: 0.531250 | valid loss: 0.506713\n","Epoch:  602 | train loss: 0.555782 | valid loss: 0.506556\n","Epoch:  603 | train loss: 0.505548 | valid loss: 0.506451\n","Epoch:  604 | train loss: 0.464338 | valid loss: 0.506388\n","Epoch:  605 | train loss: 0.520326 | valid loss: 0.506024\n","Epoch:  606 | train loss: 0.539803 | valid loss: 0.505980\n","Epoch:  607 | train loss: 0.563357 | valid loss: 0.505907\n","Epoch:  608 | train loss: 0.536184 | valid loss: 0.505606\n","Epoch:  609 | train loss: 0.510544 | valid loss: 0.505524\n","Epoch:  610 | train loss: 0.472247 | valid loss: 0.505331\n","Epoch:  611 | train loss: 0.504128 | valid loss: 0.505182\n","Epoch:  612 | train loss: 0.481096 | valid loss: 0.505076\n","Epoch:  613 | train loss: 0.489908 | valid loss: 0.504774\n","Epoch:  614 | train loss: 0.520643 | valid loss: 0.504728\n","Epoch:  615 | train loss: 0.503882 | valid loss: 0.504798\n","Epoch:  616 | train loss: 0.481931 | valid loss: 0.504306\n","Epoch:  617 | train loss: 0.533992 | valid loss: 0.504424\n","Epoch:  618 | train loss: 0.478685 | valid loss: 0.504367\n","Epoch:  619 | train loss: 0.536158 | valid loss: 0.503995\n","Epoch:  620 | train loss: 0.504550 | valid loss: 0.503686\n","Epoch:  621 | train loss: 0.557300 | valid loss: 0.503647\n","Epoch:  622 | train loss: 0.558719 | valid loss: 0.503509\n","Epoch:  623 | train loss: 0.517413 | valid loss: 0.503176\n","Epoch:  624 | train loss: 0.528562 | valid loss: 0.503180\n","Epoch:  625 | train loss: 0.497234 | valid loss: 0.502952\n","Epoch:  626 | train loss: 0.499104 | valid loss: 0.502621\n","Epoch:  627 | train loss: 0.495212 | valid loss: 0.502539\n","Epoch:  628 | train loss: 0.477446 | valid loss: 0.502586\n","Epoch:  629 | train loss: 0.482418 | valid loss: 0.502088\n","Epoch:  630 | train loss: 0.531729 | valid loss: 0.502199\n","Epoch:  631 | train loss: 0.527158 | valid loss: 0.501973\n","Epoch:  632 | train loss: 0.513131 | valid loss: 0.501749\n","Epoch:  633 | train loss: 0.493177 | valid loss: 0.501713\n","Epoch:  634 | train loss: 0.460847 | valid loss: 0.501617\n","Epoch:  635 | train loss: 0.484663 | valid loss: 0.501578\n","Epoch:  636 | train loss: 0.488140 | valid loss: 0.501180\n","Epoch:  637 | train loss: 0.472415 | valid loss: 0.501271\n","Epoch:  638 | train loss: 0.520542 | valid loss: 0.500879\n","Epoch:  639 | train loss: 0.479320 | valid loss: 0.500924\n","Epoch:  640 | train loss: 0.495831 | valid loss: 0.500538\n","Epoch:  641 | train loss: 0.496030 | valid loss: 0.500510\n","Epoch:  642 | train loss: 0.489220 | valid loss: 0.500149\n","Epoch:  643 | train loss: 0.560691 | valid loss: 0.500039\n","Epoch:  644 | train loss: 0.543269 | valid loss: 0.499935\n","Epoch:  645 | train loss: 0.459147 | valid loss: 0.499748\n","Epoch:  646 | train loss: 0.508384 | valid loss: 0.499688\n","Epoch:  647 | train loss: 0.528094 | valid loss: 0.499537\n","Epoch:  648 | train loss: 0.459889 | valid loss: 0.499161\n","Epoch:  649 | train loss: 0.513922 | valid loss: 0.499258\n","Epoch:  650 | train loss: 0.517146 | valid loss: 0.499083\n","Epoch:  651 | train loss: 0.538766 | valid loss: 0.498876\n","Epoch:  652 | train loss: 0.523984 | valid loss: 0.498732\n","Epoch:  653 | train loss: 0.501025 | valid loss: 0.498791\n","Epoch:  654 | train loss: 0.476022 | valid loss: 0.498350\n","Epoch:  655 | train loss: 0.521681 | valid loss: 0.498128\n","Epoch:  656 | train loss: 0.477685 | valid loss: 0.497923\n","Epoch:  657 | train loss: 0.492053 | valid loss: 0.497703\n","Epoch:  658 | train loss: 0.523755 | valid loss: 0.497906\n","Epoch:  659 | train loss: 0.507054 | valid loss: 0.497505\n","Epoch:  660 | train loss: 0.523932 | valid loss: 0.497450\n","Epoch:  661 | train loss: 0.498103 | valid loss: 0.497217\n","Epoch:  662 | train loss: 0.488235 | valid loss: 0.497044\n","Epoch:  663 | train loss: 0.537451 | valid loss: 0.497488\n","Epoch:  664 | train loss: 0.510611 | valid loss: 0.496964\n","Epoch:  665 | train loss: 0.521751 | valid loss: 0.496569\n","Epoch:  666 | train loss: 0.443354 | valid loss: 0.496433\n","Epoch:  667 | train loss: 0.519884 | valid loss: 0.496412\n","Epoch:  668 | train loss: 0.494761 | valid loss: 0.496094\n","Epoch:  669 | train loss: 0.528086 | valid loss: 0.496012\n","Epoch:  670 | train loss: 0.573989 | valid loss: 0.496021\n","Epoch:  671 | train loss: 0.424245 | valid loss: 0.495673\n","Epoch:  672 | train loss: 0.468810 | valid loss: 0.495760\n","Epoch:  673 | train loss: 0.447913 | valid loss: 0.495320\n","Epoch:  674 | train loss: 0.527526 | valid loss: 0.495317\n","Epoch:  675 | train loss: 0.443698 | valid loss: 0.494967\n","Epoch:  676 | train loss: 0.529418 | valid loss: 0.494902\n","Epoch:  677 | train loss: 0.523649 | valid loss: 0.494821\n","Epoch:  678 | train loss: 0.500457 | valid loss: 0.494535\n","Epoch:  679 | train loss: 0.500353 | valid loss: 0.494691\n","Epoch:  680 | train loss: 0.461973 | valid loss: 0.494332\n","Epoch:  681 | train loss: 0.438072 | valid loss: 0.494113\n","Epoch:  682 | train loss: 0.479183 | valid loss: 0.494010\n","Epoch:  683 | train loss: 0.494775 | valid loss: 0.493810\n","Epoch:  684 | train loss: 0.513470 | valid loss: 0.493664\n","Epoch:  685 | train loss: 0.469050 | valid loss: 0.493585\n","Epoch:  686 | train loss: 0.461401 | valid loss: 0.493309\n","Epoch:  687 | train loss: 0.503727 | valid loss: 0.493163\n","Epoch:  688 | train loss: 0.486652 | valid loss: 0.492968\n","Epoch:  689 | train loss: 0.452260 | valid loss: 0.493126\n","Epoch:  690 | train loss: 0.528462 | valid loss: 0.492751\n","Epoch:  691 | train loss: 0.494004 | valid loss: 0.492582\n","Epoch:  692 | train loss: 0.461188 | valid loss: 0.492737\n","Epoch:  693 | train loss: 0.500089 | valid loss: 0.492346\n","Epoch:  694 | train loss: 0.490568 | valid loss: 0.492218\n","Epoch:  695 | train loss: 0.486430 | valid loss: 0.491854\n","Epoch:  696 | train loss: 0.521844 | valid loss: 0.491935\n","Epoch:  697 | train loss: 0.545615 | valid loss: 0.491655\n","Epoch:  698 | train loss: 0.483138 | valid loss: 0.491928\n","Epoch:  699 | train loss: 0.508337 | valid loss: 0.491348\n","Epoch:  700 | train loss: 0.455165 | valid loss: 0.491235\n","Epoch:  701 | train loss: 0.460613 | valid loss: 0.491060\n","Epoch:  702 | train loss: 0.518384 | valid loss: 0.490972\n","Epoch:  703 | train loss: 0.516167 | valid loss: 0.490849\n","Epoch:  704 | train loss: 0.415490 | valid loss: 0.490577\n","Epoch:  705 | train loss: 0.526866 | valid loss: 0.490416\n","Epoch:  706 | train loss: 0.483864 | valid loss: 0.490500\n","Epoch:  707 | train loss: 0.509998 | valid loss: 0.490187\n","Epoch:  708 | train loss: 0.512209 | valid loss: 0.489986\n","Epoch:  709 | train loss: 0.476388 | valid loss: 0.489792\n","Epoch:  710 | train loss: 0.507391 | valid loss: 0.489849\n","Epoch:  711 | train loss: 0.484244 | valid loss: 0.489644\n","Epoch:  712 | train loss: 0.461350 | valid loss: 0.489428\n","Epoch:  713 | train loss: 0.467530 | valid loss: 0.489375\n","Epoch:  714 | train loss: 0.495866 | valid loss: 0.489232\n","Epoch:  715 | train loss: 0.481940 | valid loss: 0.488958\n","Epoch:  716 | train loss: 0.484546 | valid loss: 0.488834\n","Epoch:  717 | train loss: 0.456395 | valid loss: 0.488799\n","Epoch:  718 | train loss: 0.517664 | valid loss: 0.488700\n","Epoch:  719 | train loss: 0.501843 | valid loss: 0.488559\n","Epoch:  720 | train loss: 0.513256 | valid loss: 0.488319\n","Epoch:  721 | train loss: 0.482688 | valid loss: 0.488295\n","Epoch:  722 | train loss: 0.507092 | valid loss: 0.488163\n","Epoch:  723 | train loss: 0.501777 | valid loss: 0.487925\n","Epoch:  724 | train loss: 0.530559 | valid loss: 0.487897\n","Epoch:  725 | train loss: 0.510978 | valid loss: 0.487733\n","Epoch:  726 | train loss: 0.487921 | valid loss: 0.487465\n","Epoch:  727 | train loss: 0.509063 | valid loss: 0.487446\n","Epoch:  728 | train loss: 0.469969 | valid loss: 0.487384\n","Epoch:  729 | train loss: 0.500388 | valid loss: 0.487090\n","Epoch:  730 | train loss: 0.475132 | valid loss: 0.486816\n","Epoch:  731 | train loss: 0.422482 | valid loss: 0.486585\n","Epoch:  732 | train loss: 0.500780 | valid loss: 0.486601\n","Epoch:  733 | train loss: 0.484470 | valid loss: 0.486590\n","Epoch:  734 | train loss: 0.537767 | valid loss: 0.486316\n","Epoch:  735 | train loss: 0.461358 | valid loss: 0.486241\n","Epoch:  736 | train loss: 0.464541 | valid loss: 0.485899\n","Epoch:  737 | train loss: 0.483764 | valid loss: 0.485821\n","Epoch:  738 | train loss: 0.463970 | valid loss: 0.485705\n","Epoch:  739 | train loss: 0.502032 | valid loss: 0.485655\n","Epoch:  740 | train loss: 0.471941 | valid loss: 0.485354\n","Epoch:  741 | train loss: 0.449396 | valid loss: 0.485202\n","Epoch:  742 | train loss: 0.500701 | valid loss: 0.485111\n","Epoch:  743 | train loss: 0.462636 | valid loss: 0.485237\n","Epoch:  744 | train loss: 0.492624 | valid loss: 0.484994\n","Epoch:  745 | train loss: 0.430192 | valid loss: 0.484564\n","Epoch:  746 | train loss: 0.506283 | valid loss: 0.484578\n","Epoch:  747 | train loss: 0.490664 | valid loss: 0.484509\n","Epoch:  748 | train loss: 0.485144 | valid loss: 0.484349\n","Epoch:  749 | train loss: 0.509609 | valid loss: 0.484162\n","Epoch:  750 | train loss: 0.484955 | valid loss: 0.483883\n","Epoch:  751 | train loss: 0.526494 | valid loss: 0.484217\n","Epoch:  752 | train loss: 0.505563 | valid loss: 0.483836\n","Epoch:  753 | train loss: 0.499581 | valid loss: 0.483699\n","Epoch:  754 | train loss: 0.553548 | valid loss: 0.483659\n","Epoch:  755 | train loss: 0.447139 | valid loss: 0.483309\n","Epoch:  756 | train loss: 0.469063 | valid loss: 0.483144\n","Epoch:  757 | train loss: 0.540257 | valid loss: 0.483138\n","Epoch:  758 | train loss: 0.419392 | valid loss: 0.482888\n","Epoch:  759 | train loss: 0.532607 | valid loss: 0.482779\n","Epoch:  760 | train loss: 0.516534 | valid loss: 0.482710\n","Epoch:  761 | train loss: 0.468960 | valid loss: 0.482489\n","Epoch:  762 | train loss: 0.502787 | valid loss: 0.482551\n","Epoch:  763 | train loss: 0.505846 | valid loss: 0.482379\n","Epoch:  764 | train loss: 0.490647 | valid loss: 0.482004\n","Epoch:  765 | train loss: 0.450033 | valid loss: 0.482238\n","Epoch:  766 | train loss: 0.518514 | valid loss: 0.482142\n","Epoch:  767 | train loss: 0.569040 | valid loss: 0.481882\n","Epoch:  768 | train loss: 0.500180 | valid loss: 0.481590\n","Epoch:  769 | train loss: 0.442506 | valid loss: 0.481405\n","Epoch:  770 | train loss: 0.497057 | valid loss: 0.481329\n","Epoch:  771 | train loss: 0.487231 | valid loss: 0.481129\n","Epoch:  772 | train loss: 0.555616 | valid loss: 0.481125\n","Epoch:  773 | train loss: 0.525634 | valid loss: 0.480970\n","Epoch:  774 | train loss: 0.445816 | valid loss: 0.480835\n","Epoch:  775 | train loss: 0.515295 | valid loss: 0.480716\n","Epoch:  776 | train loss: 0.483959 | valid loss: 0.480760\n","Epoch:  777 | train loss: 0.458032 | valid loss: 0.480264\n","Epoch:  778 | train loss: 0.530484 | valid loss: 0.480215\n","Epoch:  779 | train loss: 0.479659 | valid loss: 0.480061\n","Epoch:  780 | train loss: 0.438337 | valid loss: 0.479926\n","Epoch:  781 | train loss: 0.467213 | valid loss: 0.480030\n","Epoch:  782 | train loss: 0.501067 | valid loss: 0.479950\n","Epoch:  783 | train loss: 0.513792 | valid loss: 0.479541\n","Epoch:  784 | train loss: 0.439108 | valid loss: 0.479493\n","Epoch:  785 | train loss: 0.452301 | valid loss: 0.479408\n","Epoch:  786 | train loss: 0.484382 | valid loss: 0.479131\n","Epoch:  787 | train loss: 0.483079 | valid loss: 0.479147\n","Epoch:  788 | train loss: 0.524951 | valid loss: 0.478901\n","Epoch:  789 | train loss: 0.486096 | valid loss: 0.478770\n","Epoch:  790 | train loss: 0.482162 | valid loss: 0.478745\n","Epoch:  791 | train loss: 0.494849 | valid loss: 0.478515\n","Epoch:  792 | train loss: 0.489142 | valid loss: 0.478445\n","Epoch:  793 | train loss: 0.501869 | valid loss: 0.478213\n","Epoch:  794 | train loss: 0.500710 | valid loss: 0.478128\n","Epoch:  795 | train loss: 0.492784 | valid loss: 0.478027\n","Epoch:  796 | train loss: 0.519585 | valid loss: 0.477989\n","Epoch:  797 | train loss: 0.500377 | valid loss: 0.477898\n","Epoch:  798 | train loss: 0.475403 | valid loss: 0.477740\n","Epoch:  799 | train loss: 0.467880 | valid loss: 0.477577\n","Epoch:  800 | train loss: 0.507338 | valid loss: 0.477441\n","Epoch:  801 | train loss: 0.457028 | valid loss: 0.477296\n","Epoch:  802 | train loss: 0.441428 | valid loss: 0.477006\n","Epoch:  803 | train loss: 0.417398 | valid loss: 0.477059\n","Epoch:  804 | train loss: 0.477031 | valid loss: 0.476969\n","Epoch:  805 | train loss: 0.495600 | valid loss: 0.476668\n","Epoch:  806 | train loss: 0.481909 | valid loss: 0.476598\n","Epoch:  807 | train loss: 0.455708 | valid loss: 0.476478\n","Epoch:  808 | train loss: 0.510242 | valid loss: 0.476222\n","Epoch:  809 | train loss: 0.530549 | valid loss: 0.476155\n","Epoch:  810 | train loss: 0.453862 | valid loss: 0.476057\n","Epoch:  811 | train loss: 0.488912 | valid loss: 0.476002\n","Epoch:  812 | train loss: 0.492375 | valid loss: 0.475758\n","Epoch:  813 | train loss: 0.495279 | valid loss: 0.475837\n","Epoch:  814 | train loss: 0.531550 | valid loss: 0.475474\n","Epoch:  815 | train loss: 0.530900 | valid loss: 0.475428\n","Epoch:  816 | train loss: 0.446008 | valid loss: 0.475311\n","Epoch:  817 | train loss: 0.463028 | valid loss: 0.475108\n","Epoch:  818 | train loss: 0.466360 | valid loss: 0.475130\n","Epoch:  819 | train loss: 0.529734 | valid loss: 0.474889\n","Epoch:  820 | train loss: 0.428356 | valid loss: 0.474939\n","Epoch:  821 | train loss: 0.497904 | valid loss: 0.474726\n","Epoch:  822 | train loss: 0.511339 | valid loss: 0.474510\n","Epoch:  823 | train loss: 0.525294 | valid loss: 0.474590\n","Epoch:  824 | train loss: 0.515601 | valid loss: 0.474364\n","Epoch:  825 | train loss: 0.430134 | valid loss: 0.474242\n","Epoch:  826 | train loss: 0.427958 | valid loss: 0.474019\n","Epoch:  827 | train loss: 0.452537 | valid loss: 0.473916\n","Epoch:  828 | train loss: 0.472727 | valid loss: 0.473885\n","Epoch:  829 | train loss: 0.533775 | valid loss: 0.473724\n","Epoch:  830 | train loss: 0.486585 | valid loss: 0.473621\n","Epoch:  831 | train loss: 0.524023 | valid loss: 0.473550\n","Epoch:  832 | train loss: 0.505795 | valid loss: 0.473399\n","Epoch:  833 | train loss: 0.479643 | valid loss: 0.473298\n","Epoch:  834 | train loss: 0.464167 | valid loss: 0.473108\n","Epoch:  835 | train loss: 0.495793 | valid loss: 0.473061\n","Epoch:  836 | train loss: 0.449668 | valid loss: 0.472911\n","Epoch:  837 | train loss: 0.485605 | valid loss: 0.472785\n","Epoch:  838 | train loss: 0.457644 | valid loss: 0.472640\n","Epoch:  839 | train loss: 0.457363 | valid loss: 0.472512\n","Epoch:  840 | train loss: 0.461733 | valid loss: 0.472375\n","Epoch:  841 | train loss: 0.504628 | valid loss: 0.472280\n","Epoch:  842 | train loss: 0.454418 | valid loss: 0.472253\n","Epoch:  843 | train loss: 0.506804 | valid loss: 0.472019\n","Epoch:  844 | train loss: 0.505675 | valid loss: 0.471866\n","Epoch:  845 | train loss: 0.417740 | valid loss: 0.472075\n","Epoch:  846 | train loss: 0.464794 | valid loss: 0.471734\n","Epoch:  847 | train loss: 0.447875 | valid loss: 0.471635\n","Epoch:  848 | train loss: 0.488741 | valid loss: 0.471399\n","Epoch:  849 | train loss: 0.498783 | valid loss: 0.471541\n","Epoch:  850 | train loss: 0.462602 | valid loss: 0.471252\n","Epoch:  851 | train loss: 0.504160 | valid loss: 0.471121\n","Epoch:  852 | train loss: 0.428672 | valid loss: 0.470971\n","Epoch:  853 | train loss: 0.454862 | valid loss: 0.471197\n","Epoch:  854 | train loss: 0.435728 | valid loss: 0.470956\n","Epoch:  855 | train loss: 0.496360 | valid loss: 0.470656\n","Epoch:  856 | train loss: 0.455747 | valid loss: 0.470599\n","Epoch:  857 | train loss: 0.487017 | valid loss: 0.470429\n","Epoch:  858 | train loss: 0.478439 | valid loss: 0.470366\n","Epoch:  859 | train loss: 0.498003 | valid loss: 0.470164\n","Epoch:  860 | train loss: 0.517723 | valid loss: 0.470020\n","Epoch:  861 | train loss: 0.491181 | valid loss: 0.469883\n","Epoch:  862 | train loss: 0.443595 | valid loss: 0.469781\n","Epoch:  863 | train loss: 0.529768 | valid loss: 0.469794\n","Epoch:  864 | train loss: 0.529734 | valid loss: 0.469575\n","Epoch:  865 | train loss: 0.444883 | valid loss: 0.469387\n","Epoch:  866 | train loss: 0.509466 | valid loss: 0.469249\n","Epoch:  867 | train loss: 0.475243 | valid loss: 0.469311\n","Epoch:  868 | train loss: 0.435540 | valid loss: 0.469106\n","Epoch:  869 | train loss: 0.455234 | valid loss: 0.469086\n","Epoch:  870 | train loss: 0.450874 | valid loss: 0.468918\n","Epoch:  871 | train loss: 0.473613 | valid loss: 0.468845\n","Epoch:  872 | train loss: 0.484118 | valid loss: 0.468802\n","Epoch:  873 | train loss: 0.446161 | valid loss: 0.468534\n","Epoch:  874 | train loss: 0.527338 | valid loss: 0.468373\n","Epoch:  875 | train loss: 0.463507 | valid loss: 0.468571\n","Epoch:  876 | train loss: 0.475305 | valid loss: 0.468320\n","Epoch:  877 | train loss: 0.479984 | valid loss: 0.468293\n","Epoch:  878 | train loss: 0.408091 | valid loss: 0.468263\n","Epoch:  879 | train loss: 0.514123 | valid loss: 0.467939\n","Epoch:  880 | train loss: 0.446633 | valid loss: 0.467893\n","Epoch:  881 | train loss: 0.491578 | valid loss: 0.467667\n","Epoch:  882 | train loss: 0.513894 | valid loss: 0.467608\n","Epoch:  883 | train loss: 0.413941 | valid loss: 0.467457\n","Epoch:  884 | train loss: 0.389098 | valid loss: 0.467405\n","Epoch:  885 | train loss: 0.453435 | valid loss: 0.467246\n","Epoch:  886 | train loss: 0.514404 | valid loss: 0.467138\n","Epoch:  887 | train loss: 0.505058 | valid loss: 0.467129\n","Epoch:  888 | train loss: 0.474452 | valid loss: 0.466968\n","Epoch:  889 | train loss: 0.386792 | valid loss: 0.466938\n","Epoch:  890 | train loss: 0.477834 | valid loss: 0.466862\n","Epoch:  891 | train loss: 0.499006 | valid loss: 0.466528\n","Epoch:  892 | train loss: 0.512716 | valid loss: 0.466555\n","Epoch:  893 | train loss: 0.466486 | valid loss: 0.466572\n","Epoch:  894 | train loss: 0.532407 | valid loss: 0.466278\n","Epoch:  895 | train loss: 0.468767 | valid loss: 0.466193\n","Epoch:  896 | train loss: 0.474560 | valid loss: 0.466291\n","Epoch:  897 | train loss: 0.493629 | valid loss: 0.465958\n","Epoch:  898 | train loss: 0.461365 | valid loss: 0.465987\n","Epoch:  899 | train loss: 0.519316 | valid loss: 0.465937\n","Epoch:  900 | train loss: 0.490473 | valid loss: 0.465638\n","Epoch:  901 | train loss: 0.475450 | valid loss: 0.465657\n","Epoch:  902 | train loss: 0.423022 | valid loss: 0.465648\n","Epoch:  903 | train loss: 0.485925 | valid loss: 0.465364\n","Epoch:  904 | train loss: 0.483040 | valid loss: 0.465341\n","Epoch:  905 | train loss: 0.505887 | valid loss: 0.465211\n","Epoch:  906 | train loss: 0.458399 | valid loss: 0.465080\n","Epoch:  907 | train loss: 0.476102 | valid loss: 0.464998\n","Epoch:  908 | train loss: 0.479279 | valid loss: 0.464866\n","Epoch:  909 | train loss: 0.460705 | valid loss: 0.464875\n","Epoch:  910 | train loss: 0.423649 | valid loss: 0.464786\n","Epoch:  911 | train loss: 0.451981 | valid loss: 0.464540\n","Epoch:  912 | train loss: 0.492867 | valid loss: 0.464530\n","Epoch:  913 | train loss: 0.530804 | valid loss: 0.464370\n","Epoch:  914 | train loss: 0.443823 | valid loss: 0.464272\n","Epoch:  915 | train loss: 0.513346 | valid loss: 0.464246\n","Epoch:  916 | train loss: 0.515718 | valid loss: 0.464314\n","Epoch:  917 | train loss: 0.509099 | valid loss: 0.463897\n","Epoch:  918 | train loss: 0.406597 | valid loss: 0.463716\n","Epoch:  919 | train loss: 0.468152 | valid loss: 0.463625\n","Epoch:  920 | train loss: 0.371249 | valid loss: 0.463598\n","Epoch:  921 | train loss: 0.367848 | valid loss: 0.463560\n","Epoch:  922 | train loss: 0.495187 | valid loss: 0.463430\n","Epoch:  923 | train loss: 0.442036 | valid loss: 0.463256\n","Epoch:  924 | train loss: 0.438835 | valid loss: 0.463163\n","Epoch:  925 | train loss: 0.510885 | valid loss: 0.463386\n","Epoch:  926 | train loss: 0.446885 | valid loss: 0.462980\n","Epoch:  927 | train loss: 0.398012 | valid loss: 0.462924\n","Epoch:  928 | train loss: 0.371315 | valid loss: 0.462774\n","Epoch:  929 | train loss: 0.479926 | valid loss: 0.462710\n","Epoch:  930 | train loss: 0.391354 | valid loss: 0.462556\n","Epoch:  931 | train loss: 0.439393 | valid loss: 0.462556\n","Epoch:  932 | train loss: 0.458833 | valid loss: 0.462461\n","Epoch:  933 | train loss: 0.516289 | valid loss: 0.462257\n","Epoch:  934 | train loss: 0.419855 | valid loss: 0.462270\n","Epoch:  935 | train loss: 0.516948 | valid loss: 0.462101\n","Epoch:  936 | train loss: 0.473976 | valid loss: 0.462129\n","Epoch:  937 | train loss: 0.443829 | valid loss: 0.461934\n","Epoch:  938 | train loss: 0.477870 | valid loss: 0.461814\n","Epoch:  939 | train loss: 0.459046 | valid loss: 0.461799\n","Epoch:  940 | train loss: 0.468106 | valid loss: 0.461612\n","Epoch:  941 | train loss: 0.442443 | valid loss: 0.461520\n","Epoch:  942 | train loss: 0.452579 | valid loss: 0.461409\n","Epoch:  943 | train loss: 0.469843 | valid loss: 0.461377\n","Epoch:  944 | train loss: 0.482998 | valid loss: 0.461240\n","Epoch:  945 | train loss: 0.479284 | valid loss: 0.461077\n","Epoch:  946 | train loss: 0.474300 | valid loss: 0.461073\n","Epoch:  947 | train loss: 0.475027 | valid loss: 0.460922\n","Epoch:  948 | train loss: 0.435767 | valid loss: 0.460837\n","Epoch:  949 | train loss: 0.456070 | valid loss: 0.460715\n","Epoch:  950 | train loss: 0.472328 | valid loss: 0.460624\n","Epoch:  951 | train loss: 0.436187 | valid loss: 0.460576\n","Epoch:  952 | train loss: 0.480170 | valid loss: 0.460520\n","Epoch:  953 | train loss: 0.455402 | valid loss: 0.460359\n","Epoch:  954 | train loss: 0.486287 | valid loss: 0.460318\n","Epoch:  955 | train loss: 0.460081 | valid loss: 0.460208\n","Epoch:  956 | train loss: 0.504797 | valid loss: 0.460097\n","Epoch:  957 | train loss: 0.459604 | valid loss: 0.460024\n","Epoch:  958 | train loss: 0.463762 | valid loss: 0.459850\n","Epoch:  959 | train loss: 0.458565 | valid loss: 0.459776\n","Epoch:  960 | train loss: 0.389555 | valid loss: 0.459709\n","Epoch:  961 | train loss: 0.320881 | valid loss: 0.459718\n","Epoch:  962 | train loss: 0.451386 | valid loss: 0.459556\n","Epoch:  963 | train loss: 0.491429 | valid loss: 0.459446\n","Epoch:  964 | train loss: 0.487872 | valid loss: 0.459323\n","Epoch:  965 | train loss: 0.515204 | valid loss: 0.459317\n","Epoch:  966 | train loss: 0.486706 | valid loss: 0.459246\n","Epoch:  967 | train loss: 0.416600 | valid loss: 0.458899\n","Epoch:  968 | train loss: 0.415643 | valid loss: 0.458958\n","Epoch:  969 | train loss: 0.466165 | valid loss: 0.458772\n","Epoch:  970 | train loss: 0.458900 | valid loss: 0.458790\n","Epoch:  971 | train loss: 0.484492 | valid loss: 0.458713\n","Epoch:  972 | train loss: 0.512351 | valid loss: 0.458722\n","Epoch:  973 | train loss: 0.488569 | valid loss: 0.458503\n","Epoch:  974 | train loss: 0.441698 | valid loss: 0.458423\n","Epoch:  975 | train loss: 0.396128 | valid loss: 0.458333\n","Epoch:  976 | train loss: 0.418462 | valid loss: 0.458278\n","Epoch:  977 | train loss: 0.473790 | valid loss: 0.458082\n","Epoch:  978 | train loss: 0.452515 | valid loss: 0.458046\n","Epoch:  979 | train loss: 0.464076 | valid loss: 0.457993\n","Epoch:  980 | train loss: 0.481734 | valid loss: 0.457791\n","Epoch:  981 | train loss: 0.438894 | valid loss: 0.457926\n","Epoch:  982 | train loss: 0.440435 | valid loss: 0.457757\n","Epoch:  983 | train loss: 0.460087 | valid loss: 0.457647\n","Epoch:  984 | train loss: 0.476337 | valid loss: 0.457545\n","Epoch:  985 | train loss: 0.508152 | valid loss: 0.457516\n","Epoch:  986 | train loss: 0.478588 | valid loss: 0.457319\n","Epoch:  987 | train loss: 0.478818 | valid loss: 0.457192\n","Epoch:  988 | train loss: 0.438131 | valid loss: 0.457190\n","Epoch:  989 | train loss: 0.453788 | valid loss: 0.456973\n","Epoch:  990 | train loss: 0.441193 | valid loss: 0.456947\n","Epoch:  991 | train loss: 0.521608 | valid loss: 0.456832\n","Epoch:  992 | train loss: 0.424941 | valid loss: 0.456697\n","Epoch:  993 | train loss: 0.411485 | valid loss: 0.456791\n","Epoch:  994 | train loss: 0.459560 | valid loss: 0.456603\n","Epoch:  995 | train loss: 0.440317 | valid loss: 0.456440\n","Epoch:  996 | train loss: 0.463302 | valid loss: 0.456378\n","Epoch:  997 | train loss: 0.444545 | valid loss: 0.456380\n","Epoch:  998 | train loss: 0.486084 | valid loss: 0.456191\n","Epoch:  999 | train loss: 0.480759 | valid loss: 0.456098\n","Epoch:  1000 | train loss: 0.499298 | valid loss: 0.456032\n","Epoch:  1001 | train loss: 0.490554 | valid loss: 0.456089\n","Epoch:  1002 | train loss: 0.460476 | valid loss: 0.455909\n","Epoch:  1003 | train loss: 0.462439 | valid loss: 0.455876\n","Epoch:  1004 | train loss: 0.478214 | valid loss: 0.455645\n","Epoch:  1005 | train loss: 0.388556 | valid loss: 0.455640\n","Epoch:  1006 | train loss: 0.441812 | valid loss: 0.455589\n","Epoch:  1007 | train loss: 0.437687 | valid loss: 0.455415\n","Epoch:  1008 | train loss: 0.489444 | valid loss: 0.455487\n","Epoch:  1009 | train loss: 0.399463 | valid loss: 0.455168\n","Epoch:  1010 | train loss: 0.428456 | valid loss: 0.455147\n","Epoch:  1011 | train loss: 0.446099 | valid loss: 0.455142\n","Epoch:  1012 | train loss: 0.439305 | valid loss: 0.454923\n","Epoch:  1013 | train loss: 0.511475 | valid loss: 0.454929\n","Epoch:  1014 | train loss: 0.399884 | valid loss: 0.454978\n","Epoch:  1015 | train loss: 0.425321 | valid loss: 0.454947\n","Epoch:  1016 | train loss: 0.456109 | valid loss: 0.454669\n","Epoch:  1017 | train loss: 0.421726 | valid loss: 0.454578\n","Epoch:  1018 | train loss: 0.455822 | valid loss: 0.454604\n","Epoch:  1019 | train loss: 0.474015 | valid loss: 0.454474\n","Epoch:  1020 | train loss: 0.360881 | valid loss: 0.454333\n","Epoch:  1021 | train loss: 0.540229 | valid loss: 0.454264\n","Epoch:  1022 | train loss: 0.413551 | valid loss: 0.454036\n","Epoch:  1023 | train loss: 0.407162 | valid loss: 0.454035\n","Epoch:  1024 | train loss: 0.470594 | valid loss: 0.453871\n","Epoch:  1025 | train loss: 0.456092 | valid loss: 0.453870\n","Epoch:  1026 | train loss: 0.458838 | valid loss: 0.453691\n","Epoch:  1027 | train loss: 0.470133 | valid loss: 0.453632\n","Epoch:  1028 | train loss: 0.481766 | valid loss: 0.453635\n","Epoch:  1029 | train loss: 0.491578 | valid loss: 0.453520\n","Epoch:  1030 | train loss: 0.480613 | valid loss: 0.453414\n","Epoch:  1031 | train loss: 0.470707 | valid loss: 0.453364\n","Epoch:  1032 | train loss: 0.461196 | valid loss: 0.453263\n","Epoch:  1033 | train loss: 0.417853 | valid loss: 0.453087\n","Epoch:  1034 | train loss: 0.405215 | valid loss: 0.453045\n","Epoch:  1035 | train loss: 0.471880 | valid loss: 0.453024\n","Epoch:  1036 | train loss: 0.426408 | valid loss: 0.452935\n","Epoch:  1037 | train loss: 0.535067 | valid loss: 0.452773\n","Epoch:  1038 | train loss: 0.421894 | valid loss: 0.452675\n","Epoch:  1039 | train loss: 0.456528 | valid loss: 0.452700\n","Epoch:  1040 | train loss: 0.415942 | valid loss: 0.452524\n","Epoch:  1041 | train loss: 0.429006 | valid loss: 0.452381\n","Epoch:  1042 | train loss: 0.431391 | valid loss: 0.452418\n","Epoch:  1043 | train loss: 0.550794 | valid loss: 0.452293\n","Epoch:  1044 | train loss: 0.461020 | valid loss: 0.452357\n","Epoch:  1045 | train loss: 0.477056 | valid loss: 0.452027\n","Epoch:  1046 | train loss: 0.476940 | valid loss: 0.452145\n","Epoch:  1047 | train loss: 0.481696 | valid loss: 0.451927\n","Epoch:  1048 | train loss: 0.507633 | valid loss: 0.451817\n","Epoch:  1049 | train loss: 0.489972 | valid loss: 0.451827\n","Epoch:  1050 | train loss: 0.452244 | valid loss: 0.451713\n","Epoch:  1051 | train loss: 0.358432 | valid loss: 0.451576\n","Epoch:  1052 | train loss: 0.504250 | valid loss: 0.451563\n","Epoch:  1053 | train loss: 0.398193 | valid loss: 0.451423\n","Epoch:  1054 | train loss: 0.443390 | valid loss: 0.451362\n","Epoch:  1055 | train loss: 0.428304 | valid loss: 0.451440\n","Epoch:  1056 | train loss: 0.390338 | valid loss: 0.451135\n","Epoch:  1057 | train loss: 0.497995 | valid loss: 0.451073\n","Epoch:  1058 | train loss: 0.445614 | valid loss: 0.450908\n","Epoch:  1059 | train loss: 0.529249 | valid loss: 0.450940\n","Epoch:  1060 | train loss: 0.461781 | valid loss: 0.450927\n","Epoch:  1061 | train loss: 0.486732 | valid loss: 0.450706\n","Epoch:  1062 | train loss: 0.416012 | valid loss: 0.450533\n","Epoch:  1063 | train loss: 0.434320 | valid loss: 0.450671\n","Epoch:  1064 | train loss: 0.468629 | valid loss: 0.450449\n","Epoch:  1065 | train loss: 0.495266 | valid loss: 0.450375\n","Epoch:  1066 | train loss: 0.400963 | valid loss: 0.450345\n","Epoch:  1067 | train loss: 0.438109 | valid loss: 0.450266\n","Epoch:  1068 | train loss: 0.496031 | valid loss: 0.450114\n","Epoch:  1069 | train loss: 0.464029 | valid loss: 0.450091\n","Epoch:  1070 | train loss: 0.497083 | valid loss: 0.449826\n","Epoch:  1071 | train loss: 0.479053 | valid loss: 0.449799\n","Epoch:  1072 | train loss: 0.505801 | valid loss: 0.449943\n","Epoch:  1073 | train loss: 0.447304 | valid loss: 0.449647\n","Epoch:  1074 | train loss: 0.433936 | valid loss: 0.449652\n","Epoch:  1075 | train loss: 0.482368 | valid loss: 0.449479\n","Epoch:  1076 | train loss: 0.502133 | valid loss: 0.449403\n","Epoch:  1077 | train loss: 0.422016 | valid loss: 0.449428\n","Epoch:  1078 | train loss: 0.512430 | valid loss: 0.449233\n","Epoch:  1079 | train loss: 0.447772 | valid loss: 0.449233\n","Epoch:  1080 | train loss: 0.477503 | valid loss: 0.449054\n","Epoch:  1081 | train loss: 0.509484 | valid loss: 0.449097\n","Epoch:  1082 | train loss: 0.473433 | valid loss: 0.448907\n","Epoch:  1083 | train loss: 0.444578 | valid loss: 0.448912\n","Epoch:  1084 | train loss: 0.436069 | valid loss: 0.448776\n","Epoch:  1085 | train loss: 0.407413 | valid loss: 0.448770\n","Epoch:  1086 | train loss: 0.455279 | valid loss: 0.448520\n","Epoch:  1087 | train loss: 0.436406 | valid loss: 0.448537\n","Epoch:  1088 | train loss: 0.462200 | valid loss: 0.448475\n","Epoch:  1089 | train loss: 0.413533 | valid loss: 0.448361\n","Epoch:  1090 | train loss: 0.453804 | valid loss: 0.448242\n","Epoch:  1091 | train loss: 0.405317 | valid loss: 0.448256\n","Epoch:  1092 | train loss: 0.410297 | valid loss: 0.448035\n","Epoch:  1093 | train loss: 0.483791 | valid loss: 0.448065\n","Epoch:  1094 | train loss: 0.435586 | valid loss: 0.447809\n","Epoch:  1095 | train loss: 0.473669 | valid loss: 0.447793\n","Epoch:  1096 | train loss: 0.462721 | valid loss: 0.447627\n","Epoch:  1097 | train loss: 0.494500 | valid loss: 0.447788\n","Epoch:  1098 | train loss: 0.405318 | valid loss: 0.447489\n","Epoch:  1099 | train loss: 0.450681 | valid loss: 0.447371\n","Epoch:  1100 | train loss: 0.418347 | valid loss: 0.447238\n","Epoch:  1101 | train loss: 0.399832 | valid loss: 0.447166\n","Epoch:  1102 | train loss: 0.478059 | valid loss: 0.447123\n","Epoch:  1103 | train loss: 0.459822 | valid loss: 0.446961\n","Epoch:  1104 | train loss: 0.485780 | valid loss: 0.446941\n","Epoch:  1105 | train loss: 0.483263 | valid loss: 0.446840\n","Epoch:  1106 | train loss: 0.462550 | valid loss: 0.446772\n","Epoch:  1107 | train loss: 0.460521 | valid loss: 0.446814\n","Epoch:  1108 | train loss: 0.452288 | valid loss: 0.446721\n","Epoch:  1109 | train loss: 0.472849 | valid loss: 0.446775\n","Epoch:  1110 | train loss: 0.469192 | valid loss: 0.446442\n","Epoch:  1111 | train loss: 0.447182 | valid loss: 0.446313\n","Epoch:  1112 | train loss: 0.439476 | valid loss: 0.446361\n","Epoch:  1113 | train loss: 0.533854 | valid loss: 0.446133\n","Epoch:  1114 | train loss: 0.484887 | valid loss: 0.446250\n","Epoch:  1115 | train loss: 0.425290 | valid loss: 0.445984\n","Epoch:  1116 | train loss: 0.495884 | valid loss: 0.445838\n","Epoch:  1117 | train loss: 0.492856 | valid loss: 0.445800\n","Epoch:  1118 | train loss: 0.410212 | valid loss: 0.445791\n","Epoch:  1119 | train loss: 0.452776 | valid loss: 0.445752\n","Epoch:  1120 | train loss: 0.486833 | valid loss: 0.445589\n","Epoch:  1121 | train loss: 0.437876 | valid loss: 0.445603\n","Epoch:  1122 | train loss: 0.473795 | valid loss: 0.445424\n","Epoch:  1123 | train loss: 0.495847 | valid loss: 0.445328\n","Epoch:  1124 | train loss: 0.430227 | valid loss: 0.445233\n","Epoch:  1125 | train loss: 0.420877 | valid loss: 0.445180\n","Epoch:  1126 | train loss: 0.426281 | valid loss: 0.445122\n","Epoch:  1127 | train loss: 0.537899 | valid loss: 0.445006\n","Epoch:  1128 | train loss: 0.508635 | valid loss: 0.444949\n","Epoch:  1129 | train loss: 0.416138 | valid loss: 0.444775\n","Epoch:  1130 | train loss: 0.384656 | valid loss: 0.444801\n","Epoch:  1131 | train loss: 0.451397 | valid loss: 0.444778\n","Epoch:  1132 | train loss: 0.497690 | valid loss: 0.444537\n","Epoch:  1133 | train loss: 0.436198 | valid loss: 0.444541\n","Epoch:  1134 | train loss: 0.466306 | valid loss: 0.444587\n","Epoch:  1135 | train loss: 0.452305 | valid loss: 0.444384\n","Epoch:  1136 | train loss: 0.461322 | valid loss: 0.444292\n","Epoch:  1137 | train loss: 0.410552 | valid loss: 0.444219\n","Epoch:  1138 | train loss: 0.458290 | valid loss: 0.444175\n","Epoch:  1139 | train loss: 0.459833 | valid loss: 0.443813\n","Epoch:  1140 | train loss: 0.457048 | valid loss: 0.443701\n","Epoch:  1141 | train loss: 0.437406 | valid loss: 0.443805\n","Epoch:  1142 | train loss: 0.449009 | valid loss: 0.443546\n","Epoch:  1143 | train loss: 0.479210 | valid loss: 0.443563\n","Epoch:  1144 | train loss: 0.433151 | valid loss: 0.443466\n","Epoch:  1145 | train loss: 0.446160 | valid loss: 0.443434\n","Epoch:  1146 | train loss: 0.419542 | valid loss: 0.443339\n","Epoch:  1147 | train loss: 0.471698 | valid loss: 0.443268\n","Epoch:  1148 | train loss: 0.524935 | valid loss: 0.443177\n","Epoch:  1149 | train loss: 0.491718 | valid loss: 0.442982\n","Epoch:  1150 | train loss: 0.419628 | valid loss: 0.442975\n","Epoch:  1151 | train loss: 0.444071 | valid loss: 0.442825\n","Epoch:  1152 | train loss: 0.416414 | valid loss: 0.442816\n","Epoch:  1153 | train loss: 0.390654 | valid loss: 0.442747\n","Epoch:  1154 | train loss: 0.433701 | valid loss: 0.442722\n","Epoch:  1155 | train loss: 0.477855 | valid loss: 0.442492\n","Epoch:  1156 | train loss: 0.513167 | valid loss: 0.442423\n","Epoch:  1157 | train loss: 0.452807 | valid loss: 0.442379\n","Epoch:  1158 | train loss: 0.444089 | valid loss: 0.442179\n","Epoch:  1159 | train loss: 0.482076 | valid loss: 0.442203\n","Epoch:  1160 | train loss: 0.403136 | valid loss: 0.441959\n","Epoch:  1161 | train loss: 0.444014 | valid loss: 0.441927\n","Epoch:  1162 | train loss: 0.440955 | valid loss: 0.441827\n","Epoch:  1163 | train loss: 0.466513 | valid loss: 0.441709\n","Epoch:  1164 | train loss: 0.472116 | valid loss: 0.441729\n","Epoch:  1165 | train loss: 0.371791 | valid loss: 0.441503\n","Epoch:  1166 | train loss: 0.349525 | valid loss: 0.441524\n","Epoch:  1167 | train loss: 0.469111 | valid loss: 0.441459\n","Epoch:  1168 | train loss: 0.465341 | valid loss: 0.441419\n","Epoch:  1169 | train loss: 0.453634 | valid loss: 0.441324\n","Epoch:  1170 | train loss: 0.428011 | valid loss: 0.441221\n","Epoch:  1171 | train loss: 0.477202 | valid loss: 0.441309\n","Epoch:  1172 | train loss: 0.390861 | valid loss: 0.440929\n","Epoch:  1173 | train loss: 0.453949 | valid loss: 0.440864\n","Epoch:  1174 | train loss: 0.439894 | valid loss: 0.440780\n","Epoch:  1175 | train loss: 0.410657 | valid loss: 0.440640\n","Epoch:  1176 | train loss: 0.423266 | valid loss: 0.440509\n","Epoch:  1177 | train loss: 0.450222 | valid loss: 0.440542\n","Epoch:  1178 | train loss: 0.546939 | valid loss: 0.440381\n","Epoch:  1179 | train loss: 0.484081 | valid loss: 0.440550\n","Epoch:  1180 | train loss: 0.455519 | valid loss: 0.440263\n","Epoch:  1181 | train loss: 0.424646 | valid loss: 0.440151\n","Epoch:  1182 | train loss: 0.429439 | valid loss: 0.439969\n","Epoch:  1183 | train loss: 0.415757 | valid loss: 0.439950\n","Epoch:  1184 | train loss: 0.430344 | valid loss: 0.439941\n","Epoch:  1185 | train loss: 0.466991 | valid loss: 0.439667\n","Epoch:  1186 | train loss: 0.371797 | valid loss: 0.439653\n","Epoch:  1187 | train loss: 0.471769 | valid loss: 0.439631\n","Epoch:  1188 | train loss: 0.453239 | valid loss: 0.439456\n","Epoch:  1189 | train loss: 0.398176 | valid loss: 0.439503\n","Epoch:  1190 | train loss: 0.500185 | valid loss: 0.439276\n","Epoch:  1191 | train loss: 0.399620 | valid loss: 0.439493\n","Epoch:  1192 | train loss: 0.443574 | valid loss: 0.439163\n","Epoch:  1193 | train loss: 0.448199 | valid loss: 0.438935\n","Epoch:  1194 | train loss: 0.445193 | valid loss: 0.438981\n","Epoch:  1195 | train loss: 0.453819 | valid loss: 0.438696\n","Epoch:  1196 | train loss: 0.535525 | valid loss: 0.438773\n","Epoch:  1197 | train loss: 0.461648 | valid loss: 0.438753\n","Epoch:  1198 | train loss: 0.477192 | valid loss: 0.438576\n","Epoch:  1199 | train loss: 0.452397 | valid loss: 0.438539\n","Epoch:  1200 | train loss: 0.426795 | valid loss: 0.438392\n","Epoch:  1201 | train loss: 0.449833 | valid loss: 0.438274\n","Epoch:  1202 | train loss: 0.503111 | valid loss: 0.438107\n","Epoch:  1203 | train loss: 0.425646 | valid loss: 0.438007\n","Epoch:  1204 | train loss: 0.500135 | valid loss: 0.437966\n","Epoch:  1205 | train loss: 0.487352 | valid loss: 0.437854\n","Epoch:  1206 | train loss: 0.438946 | valid loss: 0.437836\n","Epoch:  1207 | train loss: 0.368152 | valid loss: 0.437644\n","Epoch:  1208 | train loss: 0.405263 | valid loss: 0.437535\n","Epoch:  1209 | train loss: 0.392401 | valid loss: 0.437547\n","Epoch:  1210 | train loss: 0.430218 | valid loss: 0.437416\n","Epoch:  1211 | train loss: 0.380765 | valid loss: 0.437293\n","Epoch:  1212 | train loss: 0.415017 | valid loss: 0.437208\n","Epoch:  1213 | train loss: 0.385870 | valid loss: 0.437169\n","Epoch:  1214 | train loss: 0.450323 | valid loss: 0.436986\n","Epoch:  1215 | train loss: 0.495729 | valid loss: 0.436896\n","Epoch:  1216 | train loss: 0.408908 | valid loss: 0.436954\n","Epoch:  1217 | train loss: 0.410901 | valid loss: 0.436707\n","Epoch:  1218 | train loss: 0.461015 | valid loss: 0.436524\n","Epoch:  1219 | train loss: 0.439607 | valid loss: 0.436609\n","Epoch:  1220 | train loss: 0.406756 | valid loss: 0.436364\n","Epoch:  1221 | train loss: 0.406649 | valid loss: 0.436322\n","Epoch:  1222 | train loss: 0.409045 | valid loss: 0.436181\n","Epoch:  1223 | train loss: 0.403555 | valid loss: 0.436022\n","Epoch:  1224 | train loss: 0.475561 | valid loss: 0.435940\n","Epoch:  1225 | train loss: 0.443543 | valid loss: 0.435832\n","Epoch:  1226 | train loss: 0.429466 | valid loss: 0.435915\n","Epoch:  1227 | train loss: 0.467664 | valid loss: 0.435841\n","Epoch:  1228 | train loss: 0.427886 | valid loss: 0.435587\n","Epoch:  1229 | train loss: 0.381251 | valid loss: 0.435589\n","Epoch:  1230 | train loss: 0.447110 | valid loss: 0.435398\n","Epoch:  1231 | train loss: 0.398656 | valid loss: 0.435232\n","Epoch:  1232 | train loss: 0.450691 | valid loss: 0.435283\n","Epoch:  1233 | train loss: 0.393435 | valid loss: 0.435285\n","Epoch:  1234 | train loss: 0.434330 | valid loss: 0.434973\n","Epoch:  1235 | train loss: 0.476032 | valid loss: 0.434910\n","Epoch:  1236 | train loss: 0.379632 | valid loss: 0.434670\n","Epoch:  1237 | train loss: 0.470715 | valid loss: 0.434682\n","Epoch:  1238 | train loss: 0.368586 | valid loss: 0.434572\n","Epoch:  1239 | train loss: 0.398603 | valid loss: 0.434510\n","Epoch:  1240 | train loss: 0.452557 | valid loss: 0.434336\n","Epoch:  1241 | train loss: 0.492217 | valid loss: 0.434437\n","Epoch:  1242 | train loss: 0.478977 | valid loss: 0.434191\n","Epoch:  1243 | train loss: 0.445614 | valid loss: 0.434146\n","Epoch:  1244 | train loss: 0.429763 | valid loss: 0.434237\n","Epoch:  1245 | train loss: 0.378793 | valid loss: 0.433851\n","Epoch:  1246 | train loss: 0.427120 | valid loss: 0.433985\n","Epoch:  1247 | train loss: 0.398283 | valid loss: 0.433784\n","Epoch:  1248 | train loss: 0.506180 | valid loss: 0.433655\n","Epoch:  1249 | train loss: 0.388499 | valid loss: 0.433440\n","Epoch:  1250 | train loss: 0.437731 | valid loss: 0.433540\n","Epoch:  1251 | train loss: 0.379225 | valid loss: 0.433122\n","Epoch:  1252 | train loss: 0.438356 | valid loss: 0.433141\n","Epoch:  1253 | train loss: 0.439135 | valid loss: 0.432898\n","Epoch:  1254 | train loss: 0.421634 | valid loss: 0.432833\n","Epoch:  1255 | train loss: 0.359312 | valid loss: 0.432744\n","Epoch:  1256 | train loss: 0.435237 | valid loss: 0.432849\n","Epoch:  1257 | train loss: 0.310428 | valid loss: 0.432593\n","Epoch:  1258 | train loss: 0.410243 | valid loss: 0.432473\n","Epoch:  1259 | train loss: 0.418616 | valid loss: 0.432414\n","Epoch:  1260 | train loss: 0.486726 | valid loss: 0.432213\n","Epoch:  1261 | train loss: 0.485718 | valid loss: 0.432200\n","Epoch:  1262 | train loss: 0.465543 | valid loss: 0.432111\n","Epoch:  1263 | train loss: 0.372275 | valid loss: 0.431866\n","Epoch:  1264 | train loss: 0.431742 | valid loss: 0.431730\n","Epoch:  1265 | train loss: 0.456951 | valid loss: 0.431639\n","Epoch:  1266 | train loss: 0.399653 | valid loss: 0.431622\n","Epoch:  1267 | train loss: 0.454699 | valid loss: 0.431413\n","Epoch:  1268 | train loss: 0.421607 | valid loss: 0.431307\n","Epoch:  1269 | train loss: 0.468369 | valid loss: 0.431377\n","Epoch:  1270 | train loss: 0.445580 | valid loss: 0.431488\n","Epoch:  1271 | train loss: 0.411817 | valid loss: 0.431044\n","Epoch:  1272 | train loss: 0.415092 | valid loss: 0.430838\n","Epoch:  1273 | train loss: 0.482445 | valid loss: 0.430903\n","Epoch:  1274 | train loss: 0.430169 | valid loss: 0.430692\n","Epoch:  1275 | train loss: 0.469390 | valid loss: 0.430773\n","Epoch:  1276 | train loss: 0.375099 | valid loss: 0.430821\n","Epoch:  1277 | train loss: 0.470295 | valid loss: 0.430500\n","Epoch:  1278 | train loss: 0.401203 | valid loss: 0.430346\n","Epoch:  1279 | train loss: 0.414489 | valid loss: 0.430158\n","Epoch:  1280 | train loss: 0.479138 | valid loss: 0.430079\n","Epoch:  1281 | train loss: 0.432886 | valid loss: 0.430042\n","Epoch:  1282 | train loss: 0.494618 | valid loss: 0.429812\n","Epoch:  1283 | train loss: 0.393154 | valid loss: 0.429606\n","Epoch:  1284 | train loss: 0.501559 | valid loss: 0.429631\n","Epoch:  1285 | train loss: 0.448777 | valid loss: 0.429553\n","Epoch:  1286 | train loss: 0.403288 | valid loss: 0.429273\n","Epoch:  1287 | train loss: 0.451226 | valid loss: 0.429281\n","Epoch:  1288 | train loss: 0.460790 | valid loss: 0.429302\n","Epoch:  1289 | train loss: 0.436163 | valid loss: 0.429164\n","Epoch:  1290 | train loss: 0.491915 | valid loss: 0.428797\n","Epoch:  1291 | train loss: 0.449769 | valid loss: 0.428819\n","Epoch:  1292 | train loss: 0.491660 | valid loss: 0.428617\n","Epoch:  1293 | train loss: 0.443688 | valid loss: 0.428619\n","Epoch:  1294 | train loss: 0.456677 | valid loss: 0.428416\n","Epoch:  1295 | train loss: 0.460251 | valid loss: 0.428233\n","Epoch:  1296 | train loss: 0.412960 | valid loss: 0.428251\n","Epoch:  1297 | train loss: 0.439147 | valid loss: 0.428054\n","Epoch:  1298 | train loss: 0.445783 | valid loss: 0.428051\n","Epoch:  1299 | train loss: 0.425432 | valid loss: 0.427823\n","Epoch:  1300 | train loss: 0.426141 | valid loss: 0.427769\n","Epoch:  1301 | train loss: 0.488197 | valid loss: 0.427639\n","Epoch:  1302 | train loss: 0.513145 | valid loss: 0.427518\n","Epoch:  1303 | train loss: 0.449363 | valid loss: 0.427445\n","Epoch:  1304 | train loss: 0.398577 | valid loss: 0.427271\n","Epoch:  1305 | train loss: 0.512636 | valid loss: 0.427295\n","Epoch:  1306 | train loss: 0.357676 | valid loss: 0.427168\n","Epoch:  1307 | train loss: 0.411401 | valid loss: 0.426989\n","Epoch:  1308 | train loss: 0.385078 | valid loss: 0.426768\n","Epoch:  1309 | train loss: 0.409219 | valid loss: 0.426761\n","Epoch:  1310 | train loss: 0.501401 | valid loss: 0.426885\n","Epoch:  1311 | train loss: 0.467385 | valid loss: 0.426435\n","Epoch:  1312 | train loss: 0.366344 | valid loss: 0.426382\n","Epoch:  1313 | train loss: 0.461816 | valid loss: 0.426191\n","Epoch:  1314 | train loss: 0.429957 | valid loss: 0.426155\n","Epoch:  1315 | train loss: 0.399492 | valid loss: 0.426007\n","Epoch:  1316 | train loss: 0.439263 | valid loss: 0.425852\n","Epoch:  1317 | train loss: 0.445250 | valid loss: 0.425679\n","Epoch:  1318 | train loss: 0.438406 | valid loss: 0.425597\n","Epoch:  1319 | train loss: 0.450564 | valid loss: 0.425729\n","Epoch:  1320 | train loss: 0.342298 | valid loss: 0.425430\n","Epoch:  1321 | train loss: 0.427558 | valid loss: 0.425582\n","Epoch:  1322 | train loss: 0.450960 | valid loss: 0.425185\n","Epoch:  1323 | train loss: 0.429277 | valid loss: 0.425039\n","Epoch:  1324 | train loss: 0.411004 | valid loss: 0.425047\n","Epoch:  1325 | train loss: 0.458797 | valid loss: 0.424797\n","Epoch:  1326 | train loss: 0.384317 | valid loss: 0.424682\n","Epoch:  1327 | train loss: 0.415453 | valid loss: 0.424635\n","Epoch:  1328 | train loss: 0.417934 | valid loss: 0.424402\n","Epoch:  1329 | train loss: 0.423789 | valid loss: 0.424296\n","Epoch:  1330 | train loss: 0.405530 | valid loss: 0.424201\n","Epoch:  1331 | train loss: 0.465979 | valid loss: 0.424084\n","Epoch:  1332 | train loss: 0.414433 | valid loss: 0.424000\n","Epoch:  1333 | train loss: 0.434680 | valid loss: 0.423817\n","Epoch:  1334 | train loss: 0.451999 | valid loss: 0.423819\n","Epoch:  1335 | train loss: 0.443564 | valid loss: 0.423721\n","Epoch:  1336 | train loss: 0.481949 | valid loss: 0.423548\n","Epoch:  1337 | train loss: 0.424392 | valid loss: 0.423286\n","Epoch:  1338 | train loss: 0.384377 | valid loss: 0.423278\n","Epoch:  1339 | train loss: 0.377011 | valid loss: 0.423245\n","Epoch:  1340 | train loss: 0.405479 | valid loss: 0.423083\n","Epoch:  1341 | train loss: 0.362582 | valid loss: 0.422870\n","Epoch:  1342 | train loss: 0.394024 | valid loss: 0.422847\n","Epoch:  1343 | train loss: 0.420451 | valid loss: 0.422696\n","Epoch:  1344 | train loss: 0.434376 | valid loss: 0.422586\n","Epoch:  1345 | train loss: 0.401389 | valid loss: 0.422707\n","Epoch:  1346 | train loss: 0.387416 | valid loss: 0.422562\n","Epoch:  1347 | train loss: 0.429405 | valid loss: 0.422250\n","Epoch:  1348 | train loss: 0.438047 | valid loss: 0.422102\n","Epoch:  1349 | train loss: 0.425354 | valid loss: 0.421886\n","Epoch:  1350 | train loss: 0.419701 | valid loss: 0.421828\n","Epoch:  1351 | train loss: 0.446270 | valid loss: 0.421813\n","Epoch:  1352 | train loss: 0.368120 | valid loss: 0.421587\n","Epoch:  1353 | train loss: 0.463653 | valid loss: 0.421429\n","Epoch:  1354 | train loss: 0.410994 | valid loss: 0.421306\n","Epoch:  1355 | train loss: 0.466775 | valid loss: 0.421367\n","Epoch:  1356 | train loss: 0.402482 | valid loss: 0.421143\n","Epoch:  1357 | train loss: 0.459733 | valid loss: 0.420987\n","Epoch:  1358 | train loss: 0.405806 | valid loss: 0.420938\n","Epoch:  1359 | train loss: 0.474002 | valid loss: 0.420737\n","Epoch:  1360 | train loss: 0.477979 | valid loss: 0.420685\n","Epoch:  1361 | train loss: 0.354651 | valid loss: 0.420641\n","Epoch:  1362 | train loss: 0.461823 | valid loss: 0.420330\n","Epoch:  1363 | train loss: 0.418740 | valid loss: 0.420381\n","Epoch:  1364 | train loss: 0.471873 | valid loss: 0.420063\n","Epoch:  1365 | train loss: 0.425901 | valid loss: 0.420000\n","Epoch:  1366 | train loss: 0.401053 | valid loss: 0.419853\n","Epoch:  1367 | train loss: 0.390337 | valid loss: 0.419691\n","Epoch:  1368 | train loss: 0.388889 | valid loss: 0.419867\n","Epoch:  1369 | train loss: 0.450815 | valid loss: 0.419502\n","Epoch:  1370 | train loss: 0.478574 | valid loss: 0.419248\n","Epoch:  1371 | train loss: 0.414334 | valid loss: 0.419216\n","Epoch:  1372 | train loss: 0.429621 | valid loss: 0.419017\n","Epoch:  1373 | train loss: 0.405165 | valid loss: 0.419088\n","Epoch:  1374 | train loss: 0.452162 | valid loss: 0.418830\n","Epoch:  1375 | train loss: 0.421616 | valid loss: 0.418794\n","Epoch:  1376 | train loss: 0.420292 | valid loss: 0.418651\n","Epoch:  1377 | train loss: 0.438647 | valid loss: 0.418529\n","Epoch:  1378 | train loss: 0.446050 | valid loss: 0.418384\n","Epoch:  1379 | train loss: 0.446162 | valid loss: 0.418326\n","Epoch:  1380 | train loss: 0.403448 | valid loss: 0.418104\n","Epoch:  1381 | train loss: 0.476836 | valid loss: 0.418080\n","Epoch:  1382 | train loss: 0.405069 | valid loss: 0.417867\n","Epoch:  1383 | train loss: 0.430806 | valid loss: 0.417612\n","Epoch:  1384 | train loss: 0.413160 | valid loss: 0.417454\n","Epoch:  1385 | train loss: 0.430887 | valid loss: 0.417500\n","Epoch:  1386 | train loss: 0.466236 | valid loss: 0.417271\n","Epoch:  1387 | train loss: 0.473043 | valid loss: 0.417110\n","Epoch:  1388 | train loss: 0.446346 | valid loss: 0.417211\n","Epoch:  1389 | train loss: 0.451889 | valid loss: 0.416840\n","Epoch:  1390 | train loss: 0.454131 | valid loss: 0.416698\n","Epoch:  1391 | train loss: 0.355900 | valid loss: 0.416543\n","Epoch:  1392 | train loss: 0.439822 | valid loss: 0.416403\n","Epoch:  1393 | train loss: 0.402795 | valid loss: 0.416261\n","Epoch:  1394 | train loss: 0.491637 | valid loss: 0.416192\n","Epoch:  1395 | train loss: 0.459161 | valid loss: 0.416281\n","Epoch:  1396 | train loss: 0.360897 | valid loss: 0.415902\n","Epoch:  1397 | train loss: 0.419169 | valid loss: 0.415899\n","Epoch:  1398 | train loss: 0.433434 | valid loss: 0.415726\n","Epoch:  1399 | train loss: 0.384895 | valid loss: 0.415584\n","Epoch:  1400 | train loss: 0.446571 | valid loss: 0.415607\n","Epoch:  1401 | train loss: 0.404048 | valid loss: 0.415367\n","Epoch:  1402 | train loss: 0.432702 | valid loss: 0.415132\n","Epoch:  1403 | train loss: 0.456021 | valid loss: 0.415057\n","Epoch:  1404 | train loss: 0.424159 | valid loss: 0.414971\n","Epoch:  1405 | train loss: 0.397007 | valid loss: 0.414838\n","Epoch:  1406 | train loss: 0.339569 | valid loss: 0.414650\n","Epoch:  1407 | train loss: 0.415414 | valid loss: 0.414637\n","Epoch:  1408 | train loss: 0.379476 | valid loss: 0.414452\n","Epoch:  1409 | train loss: 0.424851 | valid loss: 0.414251\n","Epoch:  1410 | train loss: 0.478983 | valid loss: 0.414094\n","Epoch:  1411 | train loss: 0.433922 | valid loss: 0.413894\n","Epoch:  1412 | train loss: 0.398783 | valid loss: 0.414057\n","Epoch:  1413 | train loss: 0.456947 | valid loss: 0.413754\n","Epoch:  1414 | train loss: 0.425434 | valid loss: 0.413597\n","Epoch:  1415 | train loss: 0.458134 | valid loss: 0.413388\n","Epoch:  1416 | train loss: 0.403158 | valid loss: 0.413322\n","Epoch:  1417 | train loss: 0.398047 | valid loss: 0.413206\n","Epoch:  1418 | train loss: 0.461903 | valid loss: 0.412999\n","Epoch:  1419 | train loss: 0.426683 | valid loss: 0.412895\n","Epoch:  1420 | train loss: 0.434468 | valid loss: 0.412776\n","Epoch:  1421 | train loss: 0.447075 | valid loss: 0.412565\n","Epoch:  1422 | train loss: 0.429419 | valid loss: 0.412507\n","Epoch:  1423 | train loss: 0.324924 | valid loss: 0.412518\n","Epoch:  1424 | train loss: 0.362212 | valid loss: 0.412156\n","Epoch:  1425 | train loss: 0.444679 | valid loss: 0.412104\n","Epoch:  1426 | train loss: 0.437820 | valid loss: 0.412010\n","Epoch:  1427 | train loss: 0.409905 | valid loss: 0.411846\n","Epoch:  1428 | train loss: 0.464576 | valid loss: 0.411655\n","Epoch:  1429 | train loss: 0.398015 | valid loss: 0.411588\n","Epoch:  1430 | train loss: 0.402065 | valid loss: 0.411509\n","Epoch:  1431 | train loss: 0.432052 | valid loss: 0.411423\n","Epoch:  1432 | train loss: 0.401648 | valid loss: 0.411114\n","Epoch:  1433 | train loss: 0.378855 | valid loss: 0.410878\n","Epoch:  1434 | train loss: 0.392057 | valid loss: 0.410814\n","Epoch:  1435 | train loss: 0.425703 | valid loss: 0.410721\n","Epoch:  1436 | train loss: 0.391741 | valid loss: 0.410552\n","Epoch:  1437 | train loss: 0.422914 | valid loss: 0.410344\n","Epoch:  1438 | train loss: 0.475667 | valid loss: 0.410407\n","Epoch:  1439 | train loss: 0.422314 | valid loss: 0.410266\n","Epoch:  1440 | train loss: 0.390210 | valid loss: 0.410016\n","Epoch:  1441 | train loss: 0.403837 | valid loss: 0.409803\n","Epoch:  1442 | train loss: 0.408323 | valid loss: 0.409999\n","Epoch:  1443 | train loss: 0.368277 | valid loss: 0.409562\n","Epoch:  1444 | train loss: 0.457224 | valid loss: 0.409310\n","Epoch:  1445 | train loss: 0.465852 | valid loss: 0.409328\n","Epoch:  1446 | train loss: 0.415040 | valid loss: 0.409065\n","Epoch:  1447 | train loss: 0.423079 | valid loss: 0.409065\n","Epoch:  1448 | train loss: 0.479710 | valid loss: 0.408844\n","Epoch:  1449 | train loss: 0.363055 | valid loss: 0.408687\n","Epoch:  1450 | train loss: 0.409769 | valid loss: 0.408599\n","Epoch:  1451 | train loss: 0.389773 | valid loss: 0.408447\n","Epoch:  1452 | train loss: 0.449841 | valid loss: 0.408278\n","Epoch:  1453 | train loss: 0.441957 | valid loss: 0.408129\n","Epoch:  1454 | train loss: 0.420054 | valid loss: 0.408224\n","Epoch:  1455 | train loss: 0.397253 | valid loss: 0.407862\n","Epoch:  1456 | train loss: 0.433379 | valid loss: 0.407835\n","Epoch:  1457 | train loss: 0.390734 | valid loss: 0.407659\n","Epoch:  1458 | train loss: 0.444417 | valid loss: 0.407406\n","Epoch:  1459 | train loss: 0.406342 | valid loss: 0.407279\n","Epoch:  1460 | train loss: 0.477093 | valid loss: 0.407326\n","Epoch:  1461 | train loss: 0.366852 | valid loss: 0.407277\n","Epoch:  1462 | train loss: 0.433823 | valid loss: 0.406789\n","Epoch:  1463 | train loss: 0.430090 | valid loss: 0.406826\n","Epoch:  1464 | train loss: 0.383317 | valid loss: 0.406498\n","Epoch:  1465 | train loss: 0.439706 | valid loss: 0.406372\n","Epoch:  1466 | train loss: 0.439498 | valid loss: 0.406492\n","Epoch:  1467 | train loss: 0.425691 | valid loss: 0.406245\n","Epoch:  1468 | train loss: 0.376754 | valid loss: 0.406005\n","Epoch:  1469 | train loss: 0.449857 | valid loss: 0.405800\n","Epoch:  1470 | train loss: 0.376826 | valid loss: 0.405707\n","Epoch:  1471 | train loss: 0.382245 | valid loss: 0.405433\n","Epoch:  1472 | train loss: 0.432167 | valid loss: 0.405393\n","Epoch:  1473 | train loss: 0.398069 | valid loss: 0.405215\n","Epoch:  1474 | train loss: 0.459791 | valid loss: 0.405100\n","Epoch:  1475 | train loss: 0.356914 | valid loss: 0.404886\n","Epoch:  1476 | train loss: 0.442367 | valid loss: 0.404748\n","Epoch:  1477 | train loss: 0.417678 | valid loss: 0.404705\n","Epoch:  1478 | train loss: 0.391014 | valid loss: 0.404501\n","Epoch:  1479 | train loss: 0.397867 | valid loss: 0.404438\n","Epoch:  1480 | train loss: 0.373803 | valid loss: 0.404281\n","Epoch:  1481 | train loss: 0.452025 | valid loss: 0.404141\n","Epoch:  1482 | train loss: 0.431083 | valid loss: 0.403928\n","Epoch:  1483 | train loss: 0.491890 | valid loss: 0.403785\n","Epoch:  1484 | train loss: 0.466689 | valid loss: 0.403602\n","Epoch:  1485 | train loss: 0.485149 | valid loss: 0.403610\n","Epoch:  1486 | train loss: 0.452850 | valid loss: 0.403408\n","Epoch:  1487 | train loss: 0.425038 | valid loss: 0.403180\n","Epoch:  1488 | train loss: 0.345807 | valid loss: 0.403077\n","Epoch:  1489 | train loss: 0.375442 | valid loss: 0.402957\n","Epoch:  1490 | train loss: 0.388201 | valid loss: 0.402705\n","Epoch:  1491 | train loss: 0.403047 | valid loss: 0.402599\n","Epoch:  1492 | train loss: 0.414655 | valid loss: 0.402586\n","Epoch:  1493 | train loss: 0.414378 | valid loss: 0.402452\n","Epoch:  1494 | train loss: 0.374298 | valid loss: 0.402493\n","Epoch:  1495 | train loss: 0.458450 | valid loss: 0.402010\n","Epoch:  1496 | train loss: 0.371598 | valid loss: 0.401905\n","Epoch:  1497 | train loss: 0.390976 | valid loss: 0.401889\n","Epoch:  1498 | train loss: 0.453620 | valid loss: 0.401651\n","Epoch:  1499 | train loss: 0.419973 | valid loss: 0.401605\n","Epoch:  1500 | train loss: 0.363066 | valid loss: 0.401338\n","Epoch:  1501 | train loss: 0.455572 | valid loss: 0.401093\n","Epoch:  1502 | train loss: 0.376149 | valid loss: 0.401144\n","Epoch:  1503 | train loss: 0.349511 | valid loss: 0.400786\n","Epoch:  1504 | train loss: 0.410872 | valid loss: 0.400736\n","Epoch:  1505 | train loss: 0.384555 | valid loss: 0.400619\n","Epoch:  1506 | train loss: 0.384982 | valid loss: 0.400395\n","Epoch:  1507 | train loss: 0.443135 | valid loss: 0.400265\n","Epoch:  1508 | train loss: 0.392117 | valid loss: 0.400141\n","Epoch:  1509 | train loss: 0.393196 | valid loss: 0.399886\n","Epoch:  1510 | train loss: 0.418947 | valid loss: 0.399834\n","Epoch:  1511 | train loss: 0.399267 | valid loss: 0.399761\n","Epoch:  1512 | train loss: 0.374629 | valid loss: 0.399595\n","Epoch:  1513 | train loss: 0.400361 | valid loss: 0.399316\n","Epoch:  1514 | train loss: 0.360042 | valid loss: 0.399412\n","Epoch:  1515 | train loss: 0.342735 | valid loss: 0.399265\n","Epoch:  1516 | train loss: 0.435085 | valid loss: 0.398944\n","Epoch:  1517 | train loss: 0.377160 | valid loss: 0.398798\n","Epoch:  1518 | train loss: 0.470082 | valid loss: 0.398788\n","Epoch:  1519 | train loss: 0.371699 | valid loss: 0.398350\n","Epoch:  1520 | train loss: 0.357495 | valid loss: 0.398280\n","Epoch:  1521 | train loss: 0.406663 | valid loss: 0.398117\n","Epoch:  1522 | train loss: 0.379068 | valid loss: 0.398037\n","Epoch:  1523 | train loss: 0.448503 | valid loss: 0.397802\n","Epoch:  1524 | train loss: 0.395867 | valid loss: 0.397934\n","Epoch:  1525 | train loss: 0.396230 | valid loss: 0.397622\n","Epoch:  1526 | train loss: 0.434261 | valid loss: 0.397585\n","Epoch:  1527 | train loss: 0.393779 | valid loss: 0.397240\n","Epoch:  1528 | train loss: 0.440697 | valid loss: 0.397163\n","Epoch:  1529 | train loss: 0.379267 | valid loss: 0.396960\n","Epoch:  1530 | train loss: 0.396978 | valid loss: 0.396814\n","Epoch:  1531 | train loss: 0.395305 | valid loss: 0.396816\n","Epoch:  1532 | train loss: 0.410447 | valid loss: 0.396450\n","Epoch:  1533 | train loss: 0.367312 | valid loss: 0.396695\n","Epoch:  1534 | train loss: 0.450824 | valid loss: 0.396106\n","Epoch:  1535 | train loss: 0.414144 | valid loss: 0.396174\n","Epoch:  1536 | train loss: 0.413266 | valid loss: 0.395946\n","Epoch:  1537 | train loss: 0.402633 | valid loss: 0.395770\n","Epoch:  1538 | train loss: 0.448612 | valid loss: 0.395879\n","Epoch:  1539 | train loss: 0.430803 | valid loss: 0.395516\n","Epoch:  1540 | train loss: 0.380422 | valid loss: 0.395368\n","Epoch:  1541 | train loss: 0.433141 | valid loss: 0.395307\n","Epoch:  1542 | train loss: 0.445854 | valid loss: 0.395404\n","Epoch:  1543 | train loss: 0.416734 | valid loss: 0.394773\n","Epoch:  1544 | train loss: 0.398004 | valid loss: 0.394793\n","Epoch:  1545 | train loss: 0.420227 | valid loss: 0.394566\n","Epoch:  1546 | train loss: 0.459056 | valid loss: 0.394288\n","Epoch:  1547 | train loss: 0.306164 | valid loss: 0.394044\n","Epoch:  1548 | train loss: 0.421428 | valid loss: 0.393920\n","Epoch:  1549 | train loss: 0.346372 | valid loss: 0.393858\n","Epoch:  1550 | train loss: 0.356629 | valid loss: 0.393812\n","Epoch:  1551 | train loss: 0.383001 | valid loss: 0.393528\n","Epoch:  1552 | train loss: 0.466589 | valid loss: 0.393374\n","Epoch:  1553 | train loss: 0.406485 | valid loss: 0.393218\n","Epoch:  1554 | train loss: 0.409087 | valid loss: 0.393077\n","Epoch:  1555 | train loss: 0.396271 | valid loss: 0.393056\n","Epoch:  1556 | train loss: 0.439131 | valid loss: 0.392930\n","Epoch:  1557 | train loss: 0.362242 | valid loss: 0.392754\n","Epoch:  1558 | train loss: 0.400286 | valid loss: 0.392461\n","Epoch:  1559 | train loss: 0.428784 | valid loss: 0.392334\n","Epoch:  1560 | train loss: 0.364802 | valid loss: 0.392160\n","Epoch:  1561 | train loss: 0.409777 | valid loss: 0.392091\n","Epoch:  1562 | train loss: 0.329243 | valid loss: 0.391815\n","Epoch:  1563 | train loss: 0.437637 | valid loss: 0.391738\n","Epoch:  1564 | train loss: 0.420211 | valid loss: 0.391539\n","Epoch:  1565 | train loss: 0.418338 | valid loss: 0.391464\n","Epoch:  1566 | train loss: 0.429813 | valid loss: 0.391293\n","Epoch:  1567 | train loss: 0.429695 | valid loss: 0.391157\n","Epoch:  1568 | train loss: 0.384416 | valid loss: 0.391012\n","Epoch:  1569 | train loss: 0.381010 | valid loss: 0.390707\n","Epoch:  1570 | train loss: 0.374568 | valid loss: 0.390617\n","Epoch:  1571 | train loss: 0.318354 | valid loss: 0.390553\n","Epoch:  1572 | train loss: 0.430729 | valid loss: 0.390375\n","Epoch:  1573 | train loss: 0.406691 | valid loss: 0.390256\n","Epoch:  1574 | train loss: 0.292738 | valid loss: 0.390114\n","Epoch:  1575 | train loss: 0.416272 | valid loss: 0.389955\n","Epoch:  1576 | train loss: 0.446695 | valid loss: 0.389719\n","Epoch:  1577 | train loss: 0.431049 | valid loss: 0.389719\n","Epoch:  1578 | train loss: 0.389144 | valid loss: 0.389487\n","Epoch:  1579 | train loss: 0.353595 | valid loss: 0.389393\n","Epoch:  1580 | train loss: 0.422441 | valid loss: 0.389268\n","Epoch:  1581 | train loss: 0.428439 | valid loss: 0.388999\n","Epoch:  1582 | train loss: 0.414368 | valid loss: 0.388807\n","Epoch:  1583 | train loss: 0.414024 | valid loss: 0.388782\n","Epoch:  1584 | train loss: 0.379521 | valid loss: 0.388534\n","Epoch:  1585 | train loss: 0.388459 | valid loss: 0.388509\n","Epoch:  1586 | train loss: 0.455379 | valid loss: 0.388140\n","Epoch:  1587 | train loss: 0.490881 | valid loss: 0.388084\n","Epoch:  1588 | train loss: 0.420853 | valid loss: 0.387937\n","Epoch:  1589 | train loss: 0.453967 | valid loss: 0.387744\n","Epoch:  1590 | train loss: 0.382935 | valid loss: 0.387635\n","Epoch:  1591 | train loss: 0.381739 | valid loss: 0.387539\n","Epoch:  1592 | train loss: 0.348991 | valid loss: 0.387252\n","Epoch:  1593 | train loss: 0.403472 | valid loss: 0.387264\n","Epoch:  1594 | train loss: 0.389626 | valid loss: 0.387076\n","Epoch:  1595 | train loss: 0.411364 | valid loss: 0.386904\n","Epoch:  1596 | train loss: 0.395051 | valid loss: 0.386699\n","Epoch:  1597 | train loss: 0.423509 | valid loss: 0.386578\n","Epoch:  1598 | train loss: 0.391173 | valid loss: 0.386474\n","Epoch:  1599 | train loss: 0.442448 | valid loss: 0.386253\n","Epoch:  1600 | train loss: 0.471338 | valid loss: 0.386124\n","Epoch:  1601 | train loss: 0.401818 | valid loss: 0.385873\n","Epoch:  1602 | train loss: 0.424629 | valid loss: 0.385859\n","Epoch:  1603 | train loss: 0.433742 | valid loss: 0.385700\n","Epoch:  1604 | train loss: 0.431250 | valid loss: 0.385453\n","Epoch:  1605 | train loss: 0.424462 | valid loss: 0.385306\n","Epoch:  1606 | train loss: 0.344632 | valid loss: 0.385232\n","Epoch:  1607 | train loss: 0.355191 | valid loss: 0.384973\n","Epoch:  1608 | train loss: 0.400767 | valid loss: 0.384923\n","Epoch:  1609 | train loss: 0.364376 | valid loss: 0.384698\n","Epoch:  1610 | train loss: 0.354847 | valid loss: 0.384583\n","Epoch:  1611 | train loss: 0.460580 | valid loss: 0.384600\n","Epoch:  1612 | train loss: 0.352135 | valid loss: 0.384275\n","Epoch:  1613 | train loss: 0.428459 | valid loss: 0.384340\n","Epoch:  1614 | train loss: 0.373952 | valid loss: 0.383965\n","Epoch:  1615 | train loss: 0.327297 | valid loss: 0.383797\n","Epoch:  1616 | train loss: 0.406336 | valid loss: 0.383690\n","Epoch:  1617 | train loss: 0.385509 | valid loss: 0.383500\n","Epoch:  1618 | train loss: 0.379827 | valid loss: 0.383394\n","Epoch:  1619 | train loss: 0.416705 | valid loss: 0.383232\n","Epoch:  1620 | train loss: 0.414320 | valid loss: 0.383116\n","Epoch:  1621 | train loss: 0.393038 | valid loss: 0.382945\n","Epoch:  1622 | train loss: 0.367333 | valid loss: 0.382943\n","Epoch:  1623 | train loss: 0.343500 | valid loss: 0.382585\n","Epoch:  1624 | train loss: 0.341145 | valid loss: 0.382457\n","Epoch:  1625 | train loss: 0.367467 | valid loss: 0.382444\n","Epoch:  1626 | train loss: 0.354406 | valid loss: 0.382123\n","Epoch:  1627 | train loss: 0.410891 | valid loss: 0.381994\n","Epoch:  1628 | train loss: 0.385715 | valid loss: 0.381842\n","Epoch:  1629 | train loss: 0.407526 | valid loss: 0.381710\n","Epoch:  1630 | train loss: 0.363976 | valid loss: 0.381721\n","Epoch:  1631 | train loss: 0.398704 | valid loss: 0.381403\n","Epoch:  1632 | train loss: 0.382954 | valid loss: 0.381259\n","Epoch:  1633 | train loss: 0.364144 | valid loss: 0.381142\n","Epoch:  1634 | train loss: 0.422921 | valid loss: 0.380939\n","Epoch:  1635 | train loss: 0.429262 | valid loss: 0.380848\n","Epoch:  1636 | train loss: 0.343489 | valid loss: 0.380695\n","Epoch:  1637 | train loss: 0.424050 | valid loss: 0.380507\n","Epoch:  1638 | train loss: 0.375879 | valid loss: 0.380368\n","Epoch:  1639 | train loss: 0.397574 | valid loss: 0.380148\n","Epoch:  1640 | train loss: 0.406273 | valid loss: 0.380051\n","Epoch:  1641 | train loss: 0.465617 | valid loss: 0.380030\n","Epoch:  1642 | train loss: 0.367804 | valid loss: 0.379748\n","Epoch:  1643 | train loss: 0.370868 | valid loss: 0.379734\n","Epoch:  1644 | train loss: 0.407353 | valid loss: 0.379481\n","Epoch:  1645 | train loss: 0.423285 | valid loss: 0.379410\n","Epoch:  1646 | train loss: 0.405902 | valid loss: 0.379175\n","Epoch:  1647 | train loss: 0.341640 | valid loss: 0.378995\n","Epoch:  1648 | train loss: 0.392231 | valid loss: 0.378939\n","Epoch:  1649 | train loss: 0.416594 | valid loss: 0.378612\n","Epoch:  1650 | train loss: 0.428402 | valid loss: 0.378633\n","Epoch:  1651 | train loss: 0.404719 | valid loss: 0.378419\n","Epoch:  1652 | train loss: 0.352167 | valid loss: 0.378233\n","Epoch:  1653 | train loss: 0.327579 | valid loss: 0.378072\n","Epoch:  1654 | train loss: 0.342750 | valid loss: 0.377956\n","Epoch:  1655 | train loss: 0.380495 | valid loss: 0.377883\n","Epoch:  1656 | train loss: 0.433578 | valid loss: 0.377631\n","Epoch:  1657 | train loss: 0.353236 | valid loss: 0.377480\n","Epoch:  1658 | train loss: 0.391778 | valid loss: 0.377327\n","Epoch:  1659 | train loss: 0.419524 | valid loss: 0.377202\n","Epoch:  1660 | train loss: 0.382994 | valid loss: 0.376939\n","Epoch:  1661 | train loss: 0.363105 | valid loss: 0.376901\n","Epoch:  1662 | train loss: 0.376534 | valid loss: 0.376763\n","Epoch:  1663 | train loss: 0.409018 | valid loss: 0.376505\n","Epoch:  1664 | train loss: 0.375670 | valid loss: 0.376404\n","Epoch:  1665 | train loss: 0.362754 | valid loss: 0.376325\n","Epoch:  1666 | train loss: 0.413868 | valid loss: 0.376111\n","Epoch:  1667 | train loss: 0.367613 | valid loss: 0.375946\n","Epoch:  1668 | train loss: 0.398909 | valid loss: 0.375845\n","Epoch:  1669 | train loss: 0.420102 | valid loss: 0.375652\n","Epoch:  1670 | train loss: 0.376957 | valid loss: 0.375519\n","Epoch:  1671 | train loss: 0.346362 | valid loss: 0.375341\n","Epoch:  1672 | train loss: 0.373276 | valid loss: 0.375239\n","Epoch:  1673 | train loss: 0.399265 | valid loss: 0.375043\n","Epoch:  1674 | train loss: 0.378283 | valid loss: 0.374941\n","Epoch:  1675 | train loss: 0.375109 | valid loss: 0.374758\n","Epoch:  1676 | train loss: 0.425681 | valid loss: 0.374585\n","Epoch:  1677 | train loss: 0.386282 | valid loss: 0.374383\n","Epoch:  1678 | train loss: 0.407804 | valid loss: 0.374272\n","Epoch:  1679 | train loss: 0.374645 | valid loss: 0.374137\n","Epoch:  1680 | train loss: 0.331924 | valid loss: 0.373872\n","Epoch:  1681 | train loss: 0.400751 | valid loss: 0.373915\n","Epoch:  1682 | train loss: 0.346197 | valid loss: 0.373786\n","Epoch:  1683 | train loss: 0.379401 | valid loss: 0.373479\n","Epoch:  1684 | train loss: 0.367364 | valid loss: 0.373298\n","Epoch:  1685 | train loss: 0.399573 | valid loss: 0.373147\n","Epoch:  1686 | train loss: 0.467934 | valid loss: 0.373005\n","Epoch:  1687 | train loss: 0.335703 | valid loss: 0.372977\n","Epoch:  1688 | train loss: 0.391034 | valid loss: 0.372786\n","Epoch:  1689 | train loss: 0.422206 | valid loss: 0.372597\n","Epoch:  1690 | train loss: 0.385507 | valid loss: 0.372431\n","Epoch:  1691 | train loss: 0.389257 | valid loss: 0.372264\n","Epoch:  1692 | train loss: 0.407819 | valid loss: 0.372127\n","Epoch:  1693 | train loss: 0.365706 | valid loss: 0.371947\n","Epoch:  1694 | train loss: 0.422389 | valid loss: 0.371927\n","Epoch:  1695 | train loss: 0.352251 | valid loss: 0.371741\n","Epoch:  1696 | train loss: 0.388799 | valid loss: 0.371574\n","Epoch:  1697 | train loss: 0.350657 | valid loss: 0.371270\n","Epoch:  1698 | train loss: 0.361431 | valid loss: 0.371265\n","Epoch:  1699 | train loss: 0.429179 | valid loss: 0.371078\n","Epoch:  1700 | train loss: 0.384150 | valid loss: 0.370924\n","Epoch:  1701 | train loss: 0.404991 | valid loss: 0.370709\n","Epoch:  1702 | train loss: 0.425508 | valid loss: 0.370721\n","Epoch:  1703 | train loss: 0.390582 | valid loss: 0.370382\n","Epoch:  1704 | train loss: 0.359591 | valid loss: 0.370329\n","Epoch:  1705 | train loss: 0.349952 | valid loss: 0.370161\n","Epoch:  1706 | train loss: 0.394402 | valid loss: 0.369982\n","Epoch:  1707 | train loss: 0.343881 | valid loss: 0.369854\n","Epoch:  1708 | train loss: 0.342815 | valid loss: 0.369782\n","Epoch:  1709 | train loss: 0.362311 | valid loss: 0.369479\n","Epoch:  1710 | train loss: 0.382088 | valid loss: 0.369275\n","Epoch:  1711 | train loss: 0.414617 | valid loss: 0.369265\n","Epoch:  1712 | train loss: 0.365278 | valid loss: 0.369098\n","Epoch:  1713 | train loss: 0.361568 | valid loss: 0.368945\n","Epoch:  1714 | train loss: 0.389557 | valid loss: 0.368741\n","Epoch:  1715 | train loss: 0.380891 | valid loss: 0.368671\n","Epoch:  1716 | train loss: 0.323842 | valid loss: 0.368626\n","Epoch:  1717 | train loss: 0.394260 | valid loss: 0.368279\n","Epoch:  1718 | train loss: 0.315038 | valid loss: 0.368192\n","Epoch:  1719 | train loss: 0.407073 | valid loss: 0.368002\n","Epoch:  1720 | train loss: 0.341817 | valid loss: 0.367810\n","Epoch:  1721 | train loss: 0.340604 | valid loss: 0.367760\n","Epoch:  1722 | train loss: 0.395809 | valid loss: 0.367635\n","Epoch:  1723 | train loss: 0.332084 | valid loss: 0.367407\n","Epoch:  1724 | train loss: 0.364600 | valid loss: 0.367404\n","Epoch:  1725 | train loss: 0.354082 | valid loss: 0.367101\n","Epoch:  1726 | train loss: 0.426365 | valid loss: 0.367060\n","Epoch:  1727 | train loss: 0.348296 | valid loss: 0.366727\n","Epoch:  1728 | train loss: 0.371283 | valid loss: 0.366649\n","Epoch:  1729 | train loss: 0.331696 | valid loss: 0.366559\n","Epoch:  1730 | train loss: 0.322368 | valid loss: 0.366310\n","Epoch:  1731 | train loss: 0.378062 | valid loss: 0.366441\n","Epoch:  1732 | train loss: 0.395725 | valid loss: 0.366112\n","Epoch:  1733 | train loss: 0.383315 | valid loss: 0.365877\n","Epoch:  1734 | train loss: 0.374015 | valid loss: 0.365646\n","Epoch:  1735 | train loss: 0.393967 | valid loss: 0.365587\n","Epoch:  1736 | train loss: 0.338830 | valid loss: 0.365538\n","Epoch:  1737 | train loss: 0.325891 | valid loss: 0.365205\n","Epoch:  1738 | train loss: 0.318704 | valid loss: 0.365191\n","Epoch:  1739 | train loss: 0.375395 | valid loss: 0.364862\n","Epoch:  1740 | train loss: 0.414698 | valid loss: 0.364887\n","Epoch:  1741 | train loss: 0.437819 | valid loss: 0.364823\n","Epoch:  1742 | train loss: 0.481189 | valid loss: 0.364603\n","Epoch:  1743 | train loss: 0.423552 | valid loss: 0.364476\n","Epoch:  1744 | train loss: 0.309398 | valid loss: 0.364259\n","Epoch:  1745 | train loss: 0.331147 | valid loss: 0.364257\n","Epoch:  1746 | train loss: 0.398787 | valid loss: 0.363961\n","Epoch:  1747 | train loss: 0.390790 | valid loss: 0.363845\n","Epoch:  1748 | train loss: 0.436284 | valid loss: 0.363615\n","Epoch:  1749 | train loss: 0.408564 | valid loss: 0.363733\n","Epoch:  1750 | train loss: 0.357216 | valid loss: 0.363369\n","Epoch:  1751 | train loss: 0.365735 | valid loss: 0.363334\n","Epoch:  1752 | train loss: 0.377365 | valid loss: 0.362977\n","Epoch:  1753 | train loss: 0.419741 | valid loss: 0.362926\n","Epoch:  1754 | train loss: 0.323055 | valid loss: 0.362761\n","Epoch:  1755 | train loss: 0.423944 | valid loss: 0.362657\n","Epoch:  1756 | train loss: 0.401267 | valid loss: 0.362508\n","Epoch:  1757 | train loss: 0.338822 | valid loss: 0.362337\n","Epoch:  1758 | train loss: 0.331407 | valid loss: 0.362147\n","Epoch:  1759 | train loss: 0.386090 | valid loss: 0.362028\n","Epoch:  1760 | train loss: 0.402569 | valid loss: 0.362084\n","Epoch:  1761 | train loss: 0.399294 | valid loss: 0.361738\n","Epoch:  1762 | train loss: 0.358863 | valid loss: 0.361593\n","Epoch:  1763 | train loss: 0.355470 | valid loss: 0.361512\n","Epoch:  1764 | train loss: 0.398700 | valid loss: 0.361402\n","Epoch:  1765 | train loss: 0.365242 | valid loss: 0.361213\n","Epoch:  1766 | train loss: 0.343685 | valid loss: 0.360982\n","Epoch:  1767 | train loss: 0.336054 | valid loss: 0.360938\n","Epoch:  1768 | train loss: 0.374798 | valid loss: 0.360849\n","Epoch:  1769 | train loss: 0.397688 | valid loss: 0.360527\n","Epoch:  1770 | train loss: 0.361510 | valid loss: 0.360397\n","Epoch:  1771 | train loss: 0.399999 | valid loss: 0.360185\n","Epoch:  1772 | train loss: 0.377911 | valid loss: 0.360212\n","Epoch:  1773 | train loss: 0.402248 | valid loss: 0.359981\n","Epoch:  1774 | train loss: 0.404941 | valid loss: 0.359755\n","Epoch:  1775 | train loss: 0.389499 | valid loss: 0.359766\n","Epoch:  1776 | train loss: 0.340733 | valid loss: 0.359538\n","Epoch:  1777 | train loss: 0.378365 | valid loss: 0.359377\n","Epoch:  1778 | train loss: 0.386985 | valid loss: 0.359341\n","Epoch:  1779 | train loss: 0.395874 | valid loss: 0.359115\n","Epoch:  1780 | train loss: 0.390265 | valid loss: 0.358877\n","Epoch:  1781 | train loss: 0.349475 | valid loss: 0.358853\n","Epoch:  1782 | train loss: 0.347757 | valid loss: 0.358692\n","Epoch:  1783 | train loss: 0.421761 | valid loss: 0.358416\n","Epoch:  1784 | train loss: 0.356070 | valid loss: 0.358357\n","Epoch:  1785 | train loss: 0.544841 | valid loss: 0.358285\n","Epoch:  1786 | train loss: 0.384486 | valid loss: 0.358093\n","Epoch:  1787 | train loss: 0.363606 | valid loss: 0.357906\n","Epoch:  1788 | train loss: 0.375557 | valid loss: 0.357828\n","Epoch:  1789 | train loss: 0.404794 | valid loss: 0.357637\n","Epoch:  1790 | train loss: 0.395646 | valid loss: 0.357465\n","Epoch:  1791 | train loss: 0.312085 | valid loss: 0.357269\n","Epoch:  1792 | train loss: 0.360127 | valid loss: 0.357191\n","Epoch:  1793 | train loss: 0.341283 | valid loss: 0.357037\n","Epoch:  1794 | train loss: 0.325811 | valid loss: 0.356852\n","Epoch:  1795 | train loss: 0.336938 | valid loss: 0.356703\n","Epoch:  1796 | train loss: 0.379608 | valid loss: 0.356551\n","Epoch:  1797 | train loss: 0.344911 | valid loss: 0.356438\n","Epoch:  1798 | train loss: 0.343065 | valid loss: 0.356361\n","Epoch:  1799 | train loss: 0.350059 | valid loss: 0.356163\n","Epoch:  1800 | train loss: 0.369029 | valid loss: 0.355958\n","Epoch:  1801 | train loss: 0.407479 | valid loss: 0.355954\n","Epoch:  1802 | train loss: 0.407329 | valid loss: 0.355714\n","Epoch:  1803 | train loss: 0.383056 | valid loss: 0.355713\n","Epoch:  1804 | train loss: 0.372579 | valid loss: 0.355402\n","Epoch:  1805 | train loss: 0.391871 | valid loss: 0.355293\n","Epoch:  1806 | train loss: 0.372188 | valid loss: 0.355060\n","Epoch:  1807 | train loss: 0.339490 | valid loss: 0.355116\n","Epoch:  1808 | train loss: 0.306568 | valid loss: 0.354792\n","Epoch:  1809 | train loss: 0.372911 | valid loss: 0.354662\n","Epoch:  1810 | train loss: 0.344290 | valid loss: 0.354540\n","Epoch:  1811 | train loss: 0.407281 | valid loss: 0.354398\n","Epoch:  1812 | train loss: 0.446311 | valid loss: 0.354256\n","Epoch:  1813 | train loss: 0.496192 | valid loss: 0.354071\n","Epoch:  1814 | train loss: 0.354742 | valid loss: 0.353984\n","Epoch:  1815 | train loss: 0.411229 | valid loss: 0.353781\n","Epoch:  1816 | train loss: 0.301237 | valid loss: 0.353598\n","Epoch:  1817 | train loss: 0.331349 | valid loss: 0.353480\n","Epoch:  1818 | train loss: 0.425351 | valid loss: 0.353443\n","Epoch:  1819 | train loss: 0.364083 | valid loss: 0.353287\n","Epoch:  1820 | train loss: 0.387328 | valid loss: 0.353040\n","Epoch:  1821 | train loss: 0.399479 | valid loss: 0.352911\n","Epoch:  1822 | train loss: 0.337389 | valid loss: 0.352805\n","Epoch:  1823 | train loss: 0.418608 | valid loss: 0.352598\n","Epoch:  1824 | train loss: 0.364082 | valid loss: 0.352552\n","Epoch:  1825 | train loss: 0.411460 | valid loss: 0.352380\n","Epoch:  1826 | train loss: 0.397799 | valid loss: 0.352251\n","Epoch:  1827 | train loss: 0.273352 | valid loss: 0.352007\n","Epoch:  1828 | train loss: 0.342502 | valid loss: 0.351971\n","Epoch:  1829 | train loss: 0.384322 | valid loss: 0.351847\n","Epoch:  1830 | train loss: 0.342177 | valid loss: 0.351757\n","Epoch:  1831 | train loss: 0.360668 | valid loss: 0.351564\n","Epoch:  1832 | train loss: 0.347955 | valid loss: 0.351462\n","Epoch:  1833 | train loss: 0.310681 | valid loss: 0.351199\n","Epoch:  1834 | train loss: 0.376329 | valid loss: 0.351122\n","Epoch:  1835 | train loss: 0.368438 | valid loss: 0.350943\n","Epoch:  1836 | train loss: 0.403767 | valid loss: 0.350740\n","Epoch:  1837 | train loss: 0.348455 | valid loss: 0.350811\n","Epoch:  1838 | train loss: 0.378342 | valid loss: 0.350569\n","Epoch:  1839 | train loss: 0.334409 | valid loss: 0.350432\n","Epoch:  1840 | train loss: 0.376097 | valid loss: 0.350236\n","Epoch:  1841 | train loss: 0.336991 | valid loss: 0.350149\n","Epoch:  1842 | train loss: 0.267013 | valid loss: 0.349925\n","Epoch:  1843 | train loss: 0.343590 | valid loss: 0.349783\n","Epoch:  1844 | train loss: 0.363587 | valid loss: 0.349684\n","Epoch:  1845 | train loss: 0.386115 | valid loss: 0.349470\n","Epoch:  1846 | train loss: 0.402989 | valid loss: 0.349457\n","Epoch:  1847 | train loss: 0.405799 | valid loss: 0.349304\n","Epoch:  1848 | train loss: 0.392584 | valid loss: 0.349161\n","Epoch:  1849 | train loss: 0.266716 | valid loss: 0.349027\n","Epoch:  1850 | train loss: 0.341263 | valid loss: 0.348849\n","Epoch:  1851 | train loss: 0.314531 | valid loss: 0.348775\n","Epoch:  1852 | train loss: 0.358785 | valid loss: 0.348688\n","Epoch:  1853 | train loss: 0.310659 | valid loss: 0.348386\n","Epoch:  1854 | train loss: 0.359477 | valid loss: 0.348214\n","Epoch:  1855 | train loss: 0.375482 | valid loss: 0.348072\n","Epoch:  1856 | train loss: 0.356102 | valid loss: 0.347964\n","Epoch:  1857 | train loss: 0.383449 | valid loss: 0.347897\n","Epoch:  1858 | train loss: 0.330115 | valid loss: 0.347902\n","Epoch:  1859 | train loss: 0.385049 | valid loss: 0.347646\n","Epoch:  1860 | train loss: 0.356368 | valid loss: 0.347458\n","Epoch:  1861 | train loss: 0.401708 | valid loss: 0.347239\n","Epoch:  1862 | train loss: 0.356354 | valid loss: 0.347173\n","Epoch:  1863 | train loss: 0.391807 | valid loss: 0.346980\n","Epoch:  1864 | train loss: 0.327460 | valid loss: 0.346835\n","Epoch:  1865 | train loss: 0.377897 | valid loss: 0.346766\n","Epoch:  1866 | train loss: 0.364864 | valid loss: 0.346601\n","Epoch:  1867 | train loss: 0.326309 | valid loss: 0.346519\n","Epoch:  1868 | train loss: 0.405206 | valid loss: 0.346406\n","Epoch:  1869 | train loss: 0.408753 | valid loss: 0.346155\n","Epoch:  1870 | train loss: 0.318353 | valid loss: 0.345992\n","Epoch:  1871 | train loss: 0.383523 | valid loss: 0.345962\n","Epoch:  1872 | train loss: 0.358156 | valid loss: 0.345834\n","Epoch:  1873 | train loss: 0.357308 | valid loss: 0.345626\n","Epoch:  1874 | train loss: 0.386213 | valid loss: 0.345552\n","Epoch:  1875 | train loss: 0.385971 | valid loss: 0.345337\n","Epoch:  1876 | train loss: 0.390208 | valid loss: 0.345152\n","Epoch:  1877 | train loss: 0.360816 | valid loss: 0.345132\n","Epoch:  1878 | train loss: 0.357009 | valid loss: 0.345014\n","Epoch:  1879 | train loss: 0.381752 | valid loss: 0.344778\n","Epoch:  1880 | train loss: 0.415363 | valid loss: 0.344741\n","Epoch:  1881 | train loss: 0.352007 | valid loss: 0.344525\n","Epoch:  1882 | train loss: 0.377419 | valid loss: 0.344465\n","Epoch:  1883 | train loss: 0.353890 | valid loss: 0.344343\n","Epoch:  1884 | train loss: 0.374527 | valid loss: 0.344264\n","Epoch:  1885 | train loss: 0.335329 | valid loss: 0.344089\n","Epoch:  1886 | train loss: 0.430904 | valid loss: 0.344012\n","Epoch:  1887 | train loss: 0.338119 | valid loss: 0.343808\n","Epoch:  1888 | train loss: 0.311203 | valid loss: 0.343830\n","Epoch:  1889 | train loss: 0.389138 | valid loss: 0.343582\n","Epoch:  1890 | train loss: 0.328941 | valid loss: 0.343370\n","Epoch:  1891 | train loss: 0.377986 | valid loss: 0.343277\n","Epoch:  1892 | train loss: 0.409021 | valid loss: 0.343190\n","Epoch:  1893 | train loss: 0.336356 | valid loss: 0.343184\n","Epoch:  1894 | train loss: 0.355307 | valid loss: 0.342838\n","Epoch:  1895 | train loss: 0.327739 | valid loss: 0.342753\n","Epoch:  1896 | train loss: 0.363438 | valid loss: 0.342598\n","Epoch:  1897 | train loss: 0.330728 | valid loss: 0.342355\n","Epoch:  1898 | train loss: 0.354013 | valid loss: 0.342307\n","Epoch:  1899 | train loss: 0.407683 | valid loss: 0.342156\n","Epoch:  1900 | train loss: 0.591567 | valid loss: 0.341987\n","Epoch:  1901 | train loss: 0.366717 | valid loss: 0.341998\n","Epoch:  1902 | train loss: 0.380440 | valid loss: 0.341812\n","Epoch:  1903 | train loss: 0.404361 | valid loss: 0.341674\n","Epoch:  1904 | train loss: 0.272601 | valid loss: 0.341497\n","Epoch:  1905 | train loss: 0.376086 | valid loss: 0.341436\n","Epoch:  1906 | train loss: 0.319764 | valid loss: 0.341202\n","Epoch:  1907 | train loss: 0.344363 | valid loss: 0.341146\n","Epoch:  1908 | train loss: 0.383890 | valid loss: 0.341020\n","Epoch:  1909 | train loss: 0.388002 | valid loss: 0.340858\n","Epoch:  1910 | train loss: 0.365858 | valid loss: 0.340911\n","Epoch:  1911 | train loss: 0.347787 | valid loss: 0.340634\n","Epoch:  1912 | train loss: 0.321368 | valid loss: 0.340519\n","Epoch:  1913 | train loss: 0.372296 | valid loss: 0.340323\n","Epoch:  1914 | train loss: 0.334495 | valid loss: 0.340372\n","Epoch:  1915 | train loss: 0.349297 | valid loss: 0.340138\n","Epoch:  1916 | train loss: 0.294921 | valid loss: 0.339910\n","Epoch:  1917 | train loss: 0.331265 | valid loss: 0.339852\n","Epoch:  1918 | train loss: 0.298656 | valid loss: 0.339645\n","Epoch:  1919 | train loss: 0.374078 | valid loss: 0.339524\n","Epoch:  1920 | train loss: 0.348990 | valid loss: 0.339475\n","Epoch:  1921 | train loss: 0.350869 | valid loss: 0.339311\n","Epoch:  1922 | train loss: 0.346891 | valid loss: 0.339201\n","Epoch:  1923 | train loss: 0.270043 | valid loss: 0.339097\n","Epoch:  1924 | train loss: 0.348460 | valid loss: 0.338958\n","Epoch:  1925 | train loss: 0.386060 | valid loss: 0.339028\n","Epoch:  1926 | train loss: 0.322451 | valid loss: 0.338666\n","Epoch:  1927 | train loss: 0.358836 | valid loss: 0.338666\n","Epoch:  1928 | train loss: 0.314538 | valid loss: 0.338609\n","Epoch:  1929 | train loss: 0.350587 | valid loss: 0.338301\n","Epoch:  1930 | train loss: 0.350060 | valid loss: 0.338243\n","Epoch:  1931 | train loss: 0.327161 | valid loss: 0.338132\n","Epoch:  1932 | train loss: 0.332852 | valid loss: 0.337958\n","Epoch:  1933 | train loss: 0.348076 | valid loss: 0.337854\n","Epoch:  1934 | train loss: 0.305555 | valid loss: 0.337683\n","Epoch:  1935 | train loss: 0.345852 | valid loss: 0.337518\n","Epoch:  1936 | train loss: 0.391324 | valid loss: 0.337404\n","Epoch:  1937 | train loss: 0.371421 | valid loss: 0.337311\n","Epoch:  1938 | train loss: 0.348035 | valid loss: 0.337124\n","Epoch:  1939 | train loss: 0.351038 | valid loss: 0.337059\n","Epoch:  1940 | train loss: 0.363299 | valid loss: 0.336914\n","Epoch:  1941 | train loss: 0.342364 | valid loss: 0.336772\n","Epoch:  1942 | train loss: 0.320680 | valid loss: 0.336587\n","Epoch:  1943 | train loss: 0.386241 | valid loss: 0.336701\n","Epoch:  1944 | train loss: 0.348531 | valid loss: 0.336380\n","Epoch:  1945 | train loss: 0.379341 | valid loss: 0.336296\n","Epoch:  1946 | train loss: 0.365425 | valid loss: 0.336222\n","Epoch:  1947 | train loss: 0.304190 | valid loss: 0.336141\n","Epoch:  1948 | train loss: 0.306178 | valid loss: 0.335936\n","Epoch:  1949 | train loss: 0.361368 | valid loss: 0.335830\n","Epoch:  1950 | train loss: 0.372081 | valid loss: 0.335839\n","Epoch:  1951 | train loss: 0.355318 | valid loss: 0.335563\n","Epoch:  1952 | train loss: 0.367537 | valid loss: 0.335588\n","Epoch:  1953 | train loss: 0.345801 | valid loss: 0.335391\n","Epoch:  1954 | train loss: 0.405853 | valid loss: 0.335394\n","Epoch:  1955 | train loss: 0.354756 | valid loss: 0.335105\n","Epoch:  1956 | train loss: 0.352792 | valid loss: 0.335132\n","Epoch:  1957 | train loss: 0.359918 | valid loss: 0.334825\n","Epoch:  1958 | train loss: 0.295589 | valid loss: 0.334683\n","Epoch:  1959 | train loss: 0.365873 | valid loss: 0.334571\n","Epoch:  1960 | train loss: 0.347358 | valid loss: 0.334499\n","Epoch:  1961 | train loss: 0.327323 | valid loss: 0.334377\n","Epoch:  1962 | train loss: 0.321064 | valid loss: 0.334296\n","Epoch:  1963 | train loss: 0.342032 | valid loss: 0.334210\n","Epoch:  1964 | train loss: 0.420485 | valid loss: 0.333935\n","Epoch:  1965 | train loss: 0.384154 | valid loss: 0.333895\n","Epoch:  1966 | train loss: 0.549283 | valid loss: 0.333755\n","Epoch:  1967 | train loss: 0.405687 | valid loss: 0.333653\n","Epoch:  1968 | train loss: 0.334911 | valid loss: 0.333450\n","Epoch:  1969 | train loss: 0.330916 | valid loss: 0.333417\n","Epoch:  1970 | train loss: 0.333248 | valid loss: 0.333171\n","Epoch:  1971 | train loss: 0.309553 | valid loss: 0.333341\n","Epoch:  1972 | train loss: 0.362863 | valid loss: 0.333091\n","Epoch:  1973 | train loss: 0.360637 | valid loss: 0.332826\n","Epoch:  1974 | train loss: 0.364411 | valid loss: 0.332731\n","Epoch:  1975 | train loss: 0.344737 | valid loss: 0.332602\n","Epoch:  1976 | train loss: 0.301444 | valid loss: 0.332502\n","Epoch:  1977 | train loss: 0.348698 | valid loss: 0.332436\n","Epoch:  1978 | train loss: 0.338906 | valid loss: 0.332216\n","Epoch:  1979 | train loss: 0.330067 | valid loss: 0.332175\n","Epoch:  1980 | train loss: 0.297317 | valid loss: 0.332134\n","Epoch:  1981 | train loss: 0.349242 | valid loss: 0.331914\n","Epoch:  1982 | train loss: 0.364485 | valid loss: 0.331740\n","Epoch:  1983 | train loss: 0.588842 | valid loss: 0.331689\n","Epoch:  1984 | train loss: 0.375517 | valid loss: 0.331616\n","Epoch:  1985 | train loss: 0.325580 | valid loss: 0.331439\n","Epoch:  1986 | train loss: 0.333789 | valid loss: 0.331416\n","Epoch:  1987 | train loss: 0.320446 | valid loss: 0.331191\n","Epoch:  1988 | train loss: 0.370439 | valid loss: 0.331009\n","Epoch:  1989 | train loss: 0.330239 | valid loss: 0.330885\n","Epoch:  1990 | train loss: 0.374093 | valid loss: 0.330876\n","Epoch:  1991 | train loss: 0.324931 | valid loss: 0.330764\n","Epoch:  1992 | train loss: 0.314154 | valid loss: 0.330615\n","Epoch:  1993 | train loss: 0.355677 | valid loss: 0.330494\n","Epoch:  1994 | train loss: 0.351566 | valid loss: 0.330472\n","Epoch:  1995 | train loss: 0.378248 | valid loss: 0.330268\n","Epoch:  1996 | train loss: 0.324408 | valid loss: 0.330099\n","Epoch:  1997 | train loss: 0.329562 | valid loss: 0.330089\n","Epoch:  1998 | train loss: 0.294645 | valid loss: 0.329947\n","Epoch:  1999 | train loss: 0.326045 | valid loss: 0.329798\n","Epoch:  2000 | train loss: 0.372670 | valid loss: 0.329703\n","Epoch:  2001 | train loss: 0.336453 | valid loss: 0.329561\n","Epoch:  2002 | train loss: 0.330579 | valid loss: 0.329380\n","Epoch:  2003 | train loss: 0.296476 | valid loss: 0.329357\n","Epoch:  2004 | train loss: 0.359213 | valid loss: 0.329142\n","Epoch:  2005 | train loss: 0.337294 | valid loss: 0.329146\n","Epoch:  2006 | train loss: 0.359671 | valid loss: 0.328968\n","Epoch:  2007 | train loss: 0.322140 | valid loss: 0.328872\n","Epoch:  2008 | train loss: 0.327606 | valid loss: 0.328803\n","Epoch:  2009 | train loss: 0.421358 | valid loss: 0.328635\n","Epoch:  2010 | train loss: 0.362421 | valid loss: 0.328604\n","Epoch:  2011 | train loss: 0.354552 | valid loss: 0.328436\n","Epoch:  2012 | train loss: 0.315486 | valid loss: 0.328238\n","Epoch:  2013 | train loss: 0.337802 | valid loss: 0.328206\n","Epoch:  2014 | train loss: 0.323774 | valid loss: 0.328146\n","Epoch:  2015 | train loss: 0.336937 | valid loss: 0.327963\n","Epoch:  2016 | train loss: 0.336203 | valid loss: 0.327876\n","Epoch:  2017 | train loss: 0.323075 | valid loss: 0.327726\n","Epoch:  2018 | train loss: 0.352069 | valid loss: 0.327733\n","Epoch:  2019 | train loss: 0.326473 | valid loss: 0.327481\n","Epoch:  2020 | train loss: 0.277717 | valid loss: 0.327558\n","Epoch:  2021 | train loss: 0.348407 | valid loss: 0.327256\n","Epoch:  2022 | train loss: 0.352643 | valid loss: 0.327209\n","Epoch:  2023 | train loss: 0.301480 | valid loss: 0.327138\n","Epoch:  2024 | train loss: 0.368149 | valid loss: 0.326976\n","Epoch:  2025 | train loss: 0.307278 | valid loss: 0.326762\n","Epoch:  2026 | train loss: 0.297964 | valid loss: 0.326767\n","Epoch:  2027 | train loss: 0.368335 | valid loss: 0.326675\n","Epoch:  2028 | train loss: 0.319884 | valid loss: 0.326651\n","Epoch:  2029 | train loss: 0.290100 | valid loss: 0.326359\n","Epoch:  2030 | train loss: 0.370062 | valid loss: 0.326435\n","Epoch:  2031 | train loss: 0.368922 | valid loss: 0.326154\n","Epoch:  2032 | train loss: 0.338792 | valid loss: 0.326076\n","Epoch:  2033 | train loss: 0.339089 | valid loss: 0.325856\n","Epoch:  2034 | train loss: 0.328119 | valid loss: 0.325810\n","Epoch:  2035 | train loss: 0.303788 | valid loss: 0.325888\n","Epoch:  2036 | train loss: 0.347921 | valid loss: 0.325630\n","Epoch:  2037 | train loss: 0.320216 | valid loss: 0.325461\n","Epoch:  2038 | train loss: 0.393554 | valid loss: 0.325380\n","Epoch:  2039 | train loss: 0.345077 | valid loss: 0.325327\n","Epoch:  2040 | train loss: 0.298936 | valid loss: 0.325190\n","Epoch:  2041 | train loss: 0.357277 | valid loss: 0.325077\n","Epoch:  2042 | train loss: 0.351015 | valid loss: 0.325244\n","Epoch:  2043 | train loss: 0.338184 | valid loss: 0.324918\n","Epoch:  2044 | train loss: 0.344159 | valid loss: 0.324858\n","Epoch:  2045 | train loss: 0.328904 | valid loss: 0.324664\n","Epoch:  2046 | train loss: 0.320877 | valid loss: 0.324498\n","Epoch:  2047 | train loss: 0.315675 | valid loss: 0.324567\n","Epoch:  2048 | train loss: 0.303841 | valid loss: 0.324398\n","Epoch:  2049 | train loss: 0.366503 | valid loss: 0.324252\n","Epoch:  2050 | train loss: 0.307408 | valid loss: 0.324144\n","Epoch:  2051 | train loss: 0.368314 | valid loss: 0.324011\n","Epoch:  2052 | train loss: 0.344763 | valid loss: 0.323832\n","Epoch:  2053 | train loss: 0.361481 | valid loss: 0.323785\n","Epoch:  2054 | train loss: 0.367802 | valid loss: 0.323703\n","Epoch:  2055 | train loss: 0.378611 | valid loss: 0.323554\n","Epoch:  2056 | train loss: 0.283868 | valid loss: 0.323560\n","Epoch:  2057 | train loss: 0.370149 | valid loss: 0.323434\n","Epoch:  2058 | train loss: 0.379802 | valid loss: 0.323369\n","Epoch:  2059 | train loss: 0.344313 | valid loss: 0.323143\n","Epoch:  2060 | train loss: 0.352256 | valid loss: 0.323156\n","Epoch:  2061 | train loss: 0.349176 | valid loss: 0.322927\n","Epoch:  2062 | train loss: 0.348897 | valid loss: 0.322810\n","Epoch:  2063 | train loss: 0.329091 | valid loss: 0.322730\n","Epoch:  2064 | train loss: 0.309505 | valid loss: 0.322659\n","Epoch:  2065 | train loss: 0.320461 | valid loss: 0.322407\n","Epoch:  2066 | train loss: 0.323481 | valid loss: 0.322375\n","Epoch:  2067 | train loss: 0.291228 | valid loss: 0.322335\n","Epoch:  2068 | train loss: 0.383448 | valid loss: 0.322353\n","Epoch:  2069 | train loss: 0.335732 | valid loss: 0.322164\n","Epoch:  2070 | train loss: 0.338966 | valid loss: 0.321952\n","Epoch:  2071 | train loss: 0.351576 | valid loss: 0.321891\n","Epoch:  2072 | train loss: 0.335497 | valid loss: 0.321848\n","Epoch:  2073 | train loss: 0.282778 | valid loss: 0.321710\n","Epoch:  2074 | train loss: 0.387552 | valid loss: 0.321569\n","Epoch:  2075 | train loss: 0.309320 | valid loss: 0.321497\n","Epoch:  2076 | train loss: 0.338571 | valid loss: 0.321348\n","Epoch:  2077 | train loss: 0.299088 | valid loss: 0.321275\n","Epoch:  2078 | train loss: 0.346676 | valid loss: 0.321219\n","Epoch:  2079 | train loss: 0.337700 | valid loss: 0.321013\n","Epoch:  2080 | train loss: 0.285249 | valid loss: 0.320908\n","Epoch:  2081 | train loss: 0.304759 | valid loss: 0.320877\n","Epoch:  2082 | train loss: 0.335844 | valid loss: 0.320791\n","Epoch:  2083 | train loss: 0.296384 | valid loss: 0.320700\n","Epoch:  2084 | train loss: 0.386492 | valid loss: 0.320580\n","Epoch:  2085 | train loss: 0.341302 | valid loss: 0.320428\n","Epoch:  2086 | train loss: 0.282449 | valid loss: 0.320302\n","Epoch:  2087 | train loss: 0.357387 | valid loss: 0.320317\n","Epoch:  2088 | train loss: 0.300276 | valid loss: 0.320199\n","Epoch:  2089 | train loss: 0.344312 | valid loss: 0.320072\n","Epoch:  2090 | train loss: 0.365034 | valid loss: 0.319882\n","Epoch:  2091 | train loss: 0.333648 | valid loss: 0.319833\n","Epoch:  2092 | train loss: 0.284952 | valid loss: 0.319805\n","Epoch:  2093 | train loss: 0.308151 | valid loss: 0.319565\n","Epoch:  2094 | train loss: 0.350109 | valid loss: 0.319573\n","Epoch:  2095 | train loss: 0.303270 | valid loss: 0.319534\n","Epoch:  2096 | train loss: 0.339967 | valid loss: 0.319282\n","Epoch:  2097 | train loss: 0.376854 | valid loss: 0.319231\n","Epoch:  2098 | train loss: 0.326549 | valid loss: 0.319159\n","Epoch:  2099 | train loss: 0.328437 | valid loss: 0.319064\n","Epoch:  2100 | train loss: 0.317029 | valid loss: 0.318909\n","Epoch:  2101 | train loss: 0.280210 | valid loss: 0.318780\n","Epoch:  2102 | train loss: 0.362022 | valid loss: 0.318657\n","Epoch:  2103 | train loss: 0.297348 | valid loss: 0.318702\n","Epoch:  2104 | train loss: 0.398674 | valid loss: 0.318629\n","Epoch:  2105 | train loss: 0.323757 | valid loss: 0.318417\n","Epoch:  2106 | train loss: 0.277943 | valid loss: 0.318369\n","Epoch:  2107 | train loss: 0.340231 | valid loss: 0.318387\n","Epoch:  2108 | train loss: 0.381559 | valid loss: 0.318085\n","Epoch:  2109 | train loss: 0.323383 | valid loss: 0.318002\n","Epoch:  2110 | train loss: 0.377878 | valid loss: 0.318068\n","Epoch:  2111 | train loss: 0.399600 | valid loss: 0.317900\n","Epoch:  2112 | train loss: 0.371060 | valid loss: 0.317856\n","Epoch:  2113 | train loss: 0.344326 | valid loss: 0.317613\n","Epoch:  2114 | train loss: 0.307096 | valid loss: 0.317495\n","Epoch:  2115 | train loss: 0.353114 | valid loss: 0.317554\n","Epoch:  2116 | train loss: 0.342137 | valid loss: 0.317360\n","Epoch:  2117 | train loss: 0.371561 | valid loss: 0.317263\n","Epoch:  2118 | train loss: 0.345540 | valid loss: 0.317083\n","Epoch:  2119 | train loss: 0.338313 | valid loss: 0.316970\n","Epoch:  2120 | train loss: 0.346828 | valid loss: 0.317048\n","Epoch:  2121 | train loss: 0.309962 | valid loss: 0.316898\n","Epoch:  2122 | train loss: 0.338319 | valid loss: 0.316899\n","Epoch:  2123 | train loss: 0.332474 | valid loss: 0.316520\n","Epoch:  2124 | train loss: 0.303572 | valid loss: 0.316489\n","Epoch:  2125 | train loss: 0.394788 | valid loss: 0.316406\n","Epoch:  2126 | train loss: 0.349693 | valid loss: 0.316325\n","Epoch:  2127 | train loss: 0.396867 | valid loss: 0.316124\n","Epoch:  2128 | train loss: 0.318021 | valid loss: 0.316178\n","Epoch:  2129 | train loss: 0.366099 | valid loss: 0.316062\n","Epoch:  2130 | train loss: 0.247068 | valid loss: 0.315910\n","Epoch:  2131 | train loss: 0.349173 | valid loss: 0.315706\n","Epoch:  2132 | train loss: 0.268391 | valid loss: 0.315754\n","Epoch:  2133 | train loss: 0.356088 | valid loss: 0.315596\n","Epoch:  2134 | train loss: 0.351083 | valid loss: 0.315537\n","Epoch:  2135 | train loss: 0.352590 | valid loss: 0.315515\n","Epoch:  2136 | train loss: 0.370989 | valid loss: 0.315318\n","Epoch:  2137 | train loss: 0.356832 | valid loss: 0.315233\n","Epoch:  2138 | train loss: 0.350675 | valid loss: 0.315099\n","Epoch:  2139 | train loss: 0.370493 | valid loss: 0.315096\n","Epoch:  2140 | train loss: 0.306161 | valid loss: 0.314931\n","Epoch:  2141 | train loss: 0.298224 | valid loss: 0.314804\n","Epoch:  2142 | train loss: 0.311063 | valid loss: 0.314734\n","Epoch:  2143 | train loss: 0.286734 | valid loss: 0.314691\n","Epoch:  2144 | train loss: 0.301935 | valid loss: 0.314627\n","Epoch:  2145 | train loss: 0.361524 | valid loss: 0.314471\n","Epoch:  2146 | train loss: 0.341233 | valid loss: 0.314388\n","Epoch:  2147 | train loss: 0.330097 | valid loss: 0.314253\n","Epoch:  2148 | train loss: 0.341342 | valid loss: 0.314169\n","Epoch:  2149 | train loss: 0.312522 | valid loss: 0.314091\n","Epoch:  2150 | train loss: 0.341022 | valid loss: 0.314007\n","Epoch:  2151 | train loss: 0.317119 | valid loss: 0.313950\n","Epoch:  2152 | train loss: 0.311733 | valid loss: 0.313821\n","Epoch:  2153 | train loss: 0.376473 | valid loss: 0.313727\n","Epoch:  2154 | train loss: 0.294900 | valid loss: 0.313661\n","Epoch:  2155 | train loss: 0.367653 | valid loss: 0.313518\n","Epoch:  2156 | train loss: 0.344905 | valid loss: 0.313338\n","Epoch:  2157 | train loss: 0.278593 | valid loss: 0.313415\n","Epoch:  2158 | train loss: 0.286410 | valid loss: 0.313152\n","Epoch:  2159 | train loss: 0.322168 | valid loss: 0.313188\n","Epoch:  2160 | train loss: 0.269832 | valid loss: 0.313024\n","Epoch:  2161 | train loss: 0.315575 | valid loss: 0.312874\n","Epoch:  2162 | train loss: 0.261159 | valid loss: 0.312878\n","Epoch:  2163 | train loss: 0.359419 | valid loss: 0.312750\n","Epoch:  2164 | train loss: 0.369298 | valid loss: 0.312715\n","Epoch:  2165 | train loss: 0.313334 | valid loss: 0.312626\n","Epoch:  2166 | train loss: 0.338916 | valid loss: 0.312566\n","Epoch:  2167 | train loss: 0.391033 | valid loss: 0.312357\n","Epoch:  2168 | train loss: 0.298266 | valid loss: 0.312327\n","Epoch:  2169 | train loss: 0.307540 | valid loss: 0.312170\n","Epoch:  2170 | train loss: 0.351845 | valid loss: 0.312134\n","Epoch:  2171 | train loss: 0.372827 | valid loss: 0.312047\n","Epoch:  2172 | train loss: 0.350709 | valid loss: 0.311971\n","Epoch:  2173 | train loss: 0.330538 | valid loss: 0.311785\n","Epoch:  2174 | train loss: 0.353334 | valid loss: 0.311876\n","Epoch:  2175 | train loss: 0.327993 | valid loss: 0.311749\n","Epoch:  2176 | train loss: 0.335310 | valid loss: 0.311647\n","Epoch:  2177 | train loss: 0.334656 | valid loss: 0.311500\n","Epoch:  2178 | train loss: 0.295784 | valid loss: 0.311341\n","Epoch:  2179 | train loss: 0.337350 | valid loss: 0.311309\n","Epoch:  2180 | train loss: 0.373314 | valid loss: 0.311246\n","Epoch:  2181 | train loss: 0.282739 | valid loss: 0.311175\n","Epoch:  2182 | train loss: 0.300121 | valid loss: 0.311051\n","Epoch:  2183 | train loss: 0.269387 | valid loss: 0.311044\n","Epoch:  2184 | train loss: 0.306118 | valid loss: 0.310936\n","Epoch:  2185 | train loss: 0.270747 | valid loss: 0.310768\n","Epoch:  2186 | train loss: 0.260264 | valid loss: 0.310767\n","Epoch:  2187 | train loss: 0.372839 | valid loss: 0.310658\n","Epoch:  2188 | train loss: 0.346169 | valid loss: 0.310602\n","Epoch:  2189 | train loss: 0.286062 | valid loss: 0.310400\n","Epoch:  2190 | train loss: 0.302593 | valid loss: 0.310345\n","Epoch:  2191 | train loss: 0.274155 | valid loss: 0.310296\n","Epoch:  2192 | train loss: 0.327728 | valid loss: 0.310127\n","Epoch:  2193 | train loss: 0.318536 | valid loss: 0.310077\n","Epoch:  2194 | train loss: 0.307513 | valid loss: 0.309977\n","Epoch:  2195 | train loss: 0.354522 | valid loss: 0.310015\n","Epoch:  2196 | train loss: 0.400458 | valid loss: 0.309855\n","Epoch:  2197 | train loss: 0.317633 | valid loss: 0.309681\n","Epoch:  2198 | train loss: 0.252458 | valid loss: 0.309568\n","Epoch:  2199 | train loss: 0.360220 | valid loss: 0.309567\n","Epoch:  2200 | train loss: 0.329332 | valid loss: 0.309539\n","Epoch:  2201 | train loss: 0.298523 | valid loss: 0.309383\n","Epoch:  2202 | train loss: 0.291388 | valid loss: 0.309295\n","Epoch:  2203 | train loss: 0.343616 | valid loss: 0.309323\n","Epoch:  2204 | train loss: 0.309114 | valid loss: 0.309144\n","Epoch:  2205 | train loss: 0.230976 | valid loss: 0.309156\n","Epoch:  2206 | train loss: 0.325071 | valid loss: 0.308869\n","Epoch:  2207 | train loss: 0.277115 | valid loss: 0.308748\n","Epoch:  2208 | train loss: 0.365712 | valid loss: 0.308776\n","Epoch:  2209 | train loss: 0.324485 | valid loss: 0.308715\n","Epoch:  2210 | train loss: 0.309411 | valid loss: 0.308628\n","Epoch:  2211 | train loss: 0.339695 | valid loss: 0.308488\n","Epoch:  2212 | train loss: 0.385127 | valid loss: 0.308386\n","Epoch:  2213 | train loss: 0.242568 | valid loss: 0.308355\n","Epoch:  2214 | train loss: 0.250020 | valid loss: 0.308185\n","Epoch:  2215 | train loss: 0.362647 | valid loss: 0.308254\n","Epoch:  2216 | train loss: 0.292456 | valid loss: 0.308189\n","Epoch:  2217 | train loss: 0.272672 | valid loss: 0.307983\n","Epoch:  2218 | train loss: 0.285583 | valid loss: 0.307943\n","Epoch:  2219 | train loss: 0.361977 | valid loss: 0.307834\n","Epoch:  2220 | train loss: 0.269561 | valid loss: 0.307738\n","Epoch:  2221 | train loss: 0.348370 | valid loss: 0.307679\n","Epoch:  2222 | train loss: 0.337401 | valid loss: 0.307688\n","Epoch:  2223 | train loss: 0.291428 | valid loss: 0.307547\n","Epoch:  2224 | train loss: 0.309608 | valid loss: 0.307369\n","Epoch:  2225 | train loss: 0.380151 | valid loss: 0.307290\n","Epoch:  2226 | train loss: 0.316933 | valid loss: 0.307203\n","Epoch:  2227 | train loss: 0.284364 | valid loss: 0.307158\n","Epoch:  2228 | train loss: 0.292344 | valid loss: 0.307040\n","Epoch:  2229 | train loss: 0.309378 | valid loss: 0.306947\n","Epoch:  2230 | train loss: 0.371118 | valid loss: 0.306925\n","Epoch:  2231 | train loss: 0.303405 | valid loss: 0.306898\n","Epoch:  2232 | train loss: 0.525459 | valid loss: 0.306713\n","Epoch:  2233 | train loss: 0.370696 | valid loss: 0.306704\n","Epoch:  2234 | train loss: 0.323398 | valid loss: 0.306480\n","Epoch:  2235 | train loss: 0.263841 | valid loss: 0.306515\n","Epoch:  2236 | train loss: 0.274806 | valid loss: 0.306432\n","Epoch:  2237 | train loss: 0.287358 | valid loss: 0.306315\n","Epoch:  2238 | train loss: 0.376629 | valid loss: 0.306266\n","Epoch:  2239 | train loss: 0.384439 | valid loss: 0.306160\n","Epoch:  2240 | train loss: 0.300419 | valid loss: 0.306077\n","Epoch:  2241 | train loss: 0.341933 | valid loss: 0.306163\n","Epoch:  2242 | train loss: 0.354307 | valid loss: 0.305883\n","Epoch:  2243 | train loss: 0.288988 | valid loss: 0.305794\n","Epoch:  2244 | train loss: 0.297569 | valid loss: 0.305711\n","Epoch:  2245 | train loss: 0.333431 | valid loss: 0.305655\n","Epoch:  2246 | train loss: 0.349290 | valid loss: 0.305620\n","Epoch:  2247 | train loss: 0.317206 | valid loss: 0.305515\n","Epoch:  2248 | train loss: 0.323088 | valid loss: 0.305411\n","Epoch:  2249 | train loss: 0.306679 | valid loss: 0.305356\n","Epoch:  2250 | train loss: 0.321070 | valid loss: 0.305328\n","Epoch:  2251 | train loss: 0.253635 | valid loss: 0.305120\n","Epoch:  2252 | train loss: 0.344439 | valid loss: 0.305109\n","Epoch:  2253 | train loss: 0.276036 | valid loss: 0.305146\n","Epoch:  2254 | train loss: 0.327879 | valid loss: 0.305049\n","Epoch:  2255 | train loss: 0.271605 | valid loss: 0.304842\n","Epoch:  2256 | train loss: 0.311986 | valid loss: 0.304785\n","Epoch:  2257 | train loss: 0.326179 | valid loss: 0.304603\n","Epoch:  2258 | train loss: 0.339716 | valid loss: 0.304591\n","Epoch:  2259 | train loss: 0.319207 | valid loss: 0.304660\n","Epoch:  2260 | train loss: 0.300970 | valid loss: 0.304416\n","Epoch:  2261 | train loss: 0.285311 | valid loss: 0.304312\n","Epoch:  2262 | train loss: 0.275279 | valid loss: 0.304254\n","Epoch:  2263 | train loss: 0.302330 | valid loss: 0.304213\n","Epoch:  2264 | train loss: 0.300397 | valid loss: 0.304115\n","Epoch:  2265 | train loss: 0.253270 | valid loss: 0.304056\n","Epoch:  2266 | train loss: 0.307954 | valid loss: 0.303837\n","Epoch:  2267 | train loss: 0.303651 | valid loss: 0.303748\n","Epoch:  2268 | train loss: 0.233151 | valid loss: 0.303709\n","Epoch:  2269 | train loss: 0.326979 | valid loss: 0.303613\n","Epoch:  2270 | train loss: 0.273791 | valid loss: 0.303557\n","Epoch:  2271 | train loss: 0.322814 | valid loss: 0.303533\n","Epoch:  2272 | train loss: 0.305275 | valid loss: 0.303408\n","Epoch:  2273 | train loss: 0.288990 | valid loss: 0.303294\n","Epoch:  2274 | train loss: 0.353057 | valid loss: 0.303278\n","Epoch:  2275 | train loss: 0.357615 | valid loss: 0.303223\n","Epoch:  2276 | train loss: 0.276772 | valid loss: 0.303140\n","Epoch:  2277 | train loss: 0.318215 | valid loss: 0.303027\n","Epoch:  2278 | train loss: 0.373828 | valid loss: 0.303021\n","Epoch:  2279 | train loss: 0.329568 | valid loss: 0.303014\n","Epoch:  2280 | train loss: 0.310579 | valid loss: 0.302940\n","Epoch:  2281 | train loss: 0.351398 | valid loss: 0.302740\n","Epoch:  2282 | train loss: 0.314072 | valid loss: 0.302660\n","Epoch:  2283 | train loss: 0.308186 | valid loss: 0.302594\n","Epoch:  2284 | train loss: 0.338747 | valid loss: 0.302526\n","Epoch:  2285 | train loss: 0.326997 | valid loss: 0.302346\n","Epoch:  2286 | train loss: 0.315748 | valid loss: 0.302359\n","Epoch:  2287 | train loss: 0.279566 | valid loss: 0.302429\n","Epoch:  2288 | train loss: 0.356681 | valid loss: 0.302218\n","Epoch:  2289 | train loss: 0.307109 | valid loss: 0.302080\n","Epoch:  2290 | train loss: 0.343627 | valid loss: 0.302054\n","Epoch:  2291 | train loss: 0.373618 | valid loss: 0.302064\n","Epoch:  2292 | train loss: 0.242545 | valid loss: 0.301873\n","Epoch:  2293 | train loss: 0.292048 | valid loss: 0.301881\n","Epoch:  2294 | train loss: 0.350540 | valid loss: 0.301831\n","Epoch:  2295 | train loss: 0.298795 | valid loss: 0.301825\n","Epoch:  2296 | train loss: 0.310695 | valid loss: 0.301500\n","Epoch:  2297 | train loss: 0.302021 | valid loss: 0.301449\n","Epoch:  2298 | train loss: 0.286692 | valid loss: 0.301380\n","Epoch:  2299 | train loss: 0.305043 | valid loss: 0.301430\n","Epoch:  2300 | train loss: 0.296225 | valid loss: 0.301408\n","Epoch:  2301 | train loss: 0.263288 | valid loss: 0.301165\n","Epoch:  2302 | train loss: 0.482195 | valid loss: 0.301177\n","Epoch:  2303 | train loss: 0.300722 | valid loss: 0.301090\n","Epoch:  2304 | train loss: 0.394280 | valid loss: 0.300932\n","Epoch:  2305 | train loss: 0.309832 | valid loss: 0.300923\n","Epoch:  2306 | train loss: 0.267327 | valid loss: 0.300812\n","Epoch:  2307 | train loss: 0.271706 | valid loss: 0.300840\n","Epoch:  2308 | train loss: 0.304474 | valid loss: 0.300585\n","Epoch:  2309 | train loss: 0.273221 | valid loss: 0.300645\n","Epoch:  2310 | train loss: 0.302622 | valid loss: 0.300540\n","Epoch:  2311 | train loss: 0.326124 | valid loss: 0.300538\n","Epoch:  2312 | train loss: 0.336788 | valid loss: 0.300462\n","Epoch:  2313 | train loss: 0.329398 | valid loss: 0.300208\n","Epoch:  2314 | train loss: 0.307145 | valid loss: 0.300292\n","Epoch:  2315 | train loss: 0.351926 | valid loss: 0.300192\n","Epoch:  2316 | train loss: 0.294757 | valid loss: 0.299991\n","Epoch:  2317 | train loss: 0.371968 | valid loss: 0.300027\n","Epoch:  2318 | train loss: 0.314391 | valid loss: 0.299838\n","Epoch:  2319 | train loss: 0.309672 | valid loss: 0.299821\n","Epoch:  2320 | train loss: 0.303405 | valid loss: 0.299680\n","Epoch:  2321 | train loss: 0.321636 | valid loss: 0.299599\n","Epoch:  2322 | train loss: 0.363075 | valid loss: 0.299654\n","Epoch:  2323 | train loss: 0.304211 | valid loss: 0.299681\n","Epoch:  2324 | train loss: 0.300068 | valid loss: 0.299547\n","Epoch:  2325 | train loss: 0.290760 | valid loss: 0.299593\n","Epoch:  2326 | train loss: 0.291790 | valid loss: 0.299359\n","Epoch:  2327 | train loss: 0.375979 | valid loss: 0.299235\n","Epoch:  2328 | train loss: 0.368689 | valid loss: 0.299204\n","Epoch:  2329 | train loss: 0.334248 | valid loss: 0.299056\n","Epoch:  2330 | train loss: 0.296626 | valid loss: 0.299044\n","Epoch:  2331 | train loss: 0.353131 | valid loss: 0.298928\n","Epoch:  2332 | train loss: 0.351103 | valid loss: 0.298972\n","Epoch:  2333 | train loss: 0.265175 | valid loss: 0.298793\n","Epoch:  2334 | train loss: 0.305472 | valid loss: 0.298673\n","Epoch:  2335 | train loss: 0.317446 | valid loss: 0.298660\n","Epoch:  2336 | train loss: 0.331909 | valid loss: 0.298599\n","Epoch:  2337 | train loss: 0.335047 | valid loss: 0.298499\n","Epoch:  2338 | train loss: 0.290099 | valid loss: 0.298358\n","Epoch:  2339 | train loss: 0.339079 | valid loss: 0.298332\n","Epoch:  2340 | train loss: 0.392184 | valid loss: 0.298401\n","Epoch:  2341 | train loss: 0.265866 | valid loss: 0.298360\n","Epoch:  2342 | train loss: 0.312501 | valid loss: 0.298061\n","Epoch:  2343 | train loss: 0.290678 | valid loss: 0.298095\n","Epoch:  2344 | train loss: 0.363485 | valid loss: 0.298166\n","Epoch:  2345 | train loss: 0.327336 | valid loss: 0.298004\n","Epoch:  2346 | train loss: 0.378438 | valid loss: 0.297880\n","Epoch:  2347 | train loss: 0.301128 | valid loss: 0.297720\n","Epoch:  2348 | train loss: 0.330302 | valid loss: 0.297722\n","Epoch:  2349 | train loss: 0.338437 | valid loss: 0.297656\n","Epoch:  2350 | train loss: 0.291357 | valid loss: 0.297597\n","Epoch:  2351 | train loss: 0.326976 | valid loss: 0.297436\n","Epoch:  2352 | train loss: 0.257862 | valid loss: 0.297398\n","Epoch:  2353 | train loss: 0.311134 | valid loss: 0.297333\n","Epoch:  2354 | train loss: 0.275101 | valid loss: 0.297263\n","Epoch:  2355 | train loss: 0.318322 | valid loss: 0.297122\n","Epoch:  2356 | train loss: 0.335576 | valid loss: 0.297176\n","Epoch:  2357 | train loss: 0.341059 | valid loss: 0.297011\n","Epoch:  2358 | train loss: 0.280421 | valid loss: 0.297015\n","Epoch:  2359 | train loss: 0.321820 | valid loss: 0.296955\n","Epoch:  2360 | train loss: 0.338357 | valid loss: 0.296735\n","Epoch:  2361 | train loss: 0.299554 | valid loss: 0.296640\n","Epoch:  2362 | train loss: 0.307899 | valid loss: 0.296649\n","Epoch:  2363 | train loss: 0.256729 | valid loss: 0.296582\n","Epoch:  2364 | train loss: 0.238058 | valid loss: 0.296508\n","Epoch:  2365 | train loss: 0.315819 | valid loss: 0.296504\n","Epoch:  2366 | train loss: 0.337079 | valid loss: 0.296432\n","Epoch:  2367 | train loss: 0.355601 | valid loss: 0.296193\n","Epoch:  2368 | train loss: 0.352408 | valid loss: 0.296456\n","Epoch:  2369 | train loss: 0.330837 | valid loss: 0.296162\n","Epoch:  2370 | train loss: 0.373414 | valid loss: 0.296114\n","Epoch:  2371 | train loss: 0.320282 | valid loss: 0.296085\n","Epoch:  2372 | train loss: 0.295920 | valid loss: 0.296048\n","Epoch:  2373 | train loss: 0.335648 | valid loss: 0.295912\n","Epoch:  2374 | train loss: 0.307204 | valid loss: 0.296012\n","Epoch:  2375 | train loss: 0.515295 | valid loss: 0.295757\n","Epoch:  2376 | train loss: 0.251352 | valid loss: 0.295700\n","Epoch:  2377 | train loss: 0.250323 | valid loss: 0.295630\n","Epoch:  2378 | train loss: 0.344257 | valid loss: 0.295690\n","Epoch:  2379 | train loss: 0.316515 | valid loss: 0.295464\n","Epoch:  2380 | train loss: 0.242791 | valid loss: 0.295347\n","Epoch:  2381 | train loss: 0.281685 | valid loss: 0.295342\n","Epoch:  2382 | train loss: 0.308630 | valid loss: 0.295119\n","Epoch:  2383 | train loss: 0.295697 | valid loss: 0.295261\n","Epoch:  2384 | train loss: 0.292317 | valid loss: 0.295095\n","Epoch:  2385 | train loss: 0.307146 | valid loss: 0.295196\n","Epoch:  2386 | train loss: 0.273616 | valid loss: 0.295112\n","Epoch:  2387 | train loss: 0.324033 | valid loss: 0.294915\n","Epoch:  2388 | train loss: 0.272375 | valid loss: 0.294913\n","Epoch:  2389 | train loss: 0.359140 | valid loss: 0.294837\n","Epoch:  2390 | train loss: 0.327262 | valid loss: 0.294686\n","Epoch:  2391 | train loss: 0.241710 | valid loss: 0.294649\n","Epoch:  2392 | train loss: 0.297515 | valid loss: 0.294637\n","Epoch:  2393 | train loss: 0.315639 | valid loss: 0.294526\n","Epoch:  2394 | train loss: 0.323105 | valid loss: 0.294530\n","Epoch:  2395 | train loss: 0.240220 | valid loss: 0.294397\n","Epoch:  2396 | train loss: 0.278385 | valid loss: 0.294314\n","Epoch:  2397 | train loss: 0.277531 | valid loss: 0.294167\n","Epoch:  2398 | train loss: 0.286623 | valid loss: 0.294195\n","Epoch:  2399 | train loss: 0.289847 | valid loss: 0.294151\n","Epoch:  2400 | train loss: 0.319354 | valid loss: 0.294052\n","Epoch:  2401 | train loss: 0.368570 | valid loss: 0.294004\n","Epoch:  2402 | train loss: 0.351924 | valid loss: 0.293947\n","Epoch:  2403 | train loss: 0.312512 | valid loss: 0.293866\n","Epoch:  2404 | train loss: 0.311397 | valid loss: 0.293804\n","Epoch:  2405 | train loss: 0.377522 | valid loss: 0.293663\n","Epoch:  2406 | train loss: 0.298025 | valid loss: 0.293709\n","Epoch:  2407 | train loss: 0.258646 | valid loss: 0.293695\n","Epoch:  2408 | train loss: 0.279974 | valid loss: 0.293481\n","Epoch:  2409 | train loss: 0.303944 | valid loss: 0.293464\n","Epoch:  2410 | train loss: 0.344469 | valid loss: 0.293557\n","Epoch:  2411 | train loss: 0.300079 | valid loss: 0.293259\n","Epoch:  2412 | train loss: 0.270633 | valid loss: 0.293072\n","Epoch:  2413 | train loss: 0.300087 | valid loss: 0.293249\n","Epoch:  2414 | train loss: 0.336923 | valid loss: 0.292878\n","Epoch:  2415 | train loss: 0.243143 | valid loss: 0.293121\n","Epoch:  2416 | train loss: 0.290207 | valid loss: 0.292972\n","Epoch:  2417 | train loss: 0.272875 | valid loss: 0.292934\n","Epoch:  2418 | train loss: 0.285876 | valid loss: 0.292828\n","Epoch:  2419 | train loss: 0.326971 | valid loss: 0.292811\n","Epoch:  2420 | train loss: 0.356327 | valid loss: 0.292835\n","Epoch:  2421 | train loss: 0.301708 | valid loss: 0.292761\n","Epoch:  2422 | train loss: 0.291059 | valid loss: 0.292568\n","Epoch:  2423 | train loss: 0.449388 | valid loss: 0.292585\n","Epoch:  2424 | train loss: 0.276772 | valid loss: 0.292403\n","Epoch:  2425 | train loss: 0.342714 | valid loss: 0.292455\n","Epoch:  2426 | train loss: 0.294049 | valid loss: 0.292389\n","Epoch:  2427 | train loss: 0.292415 | valid loss: 0.292219\n","Epoch:  2428 | train loss: 0.311384 | valid loss: 0.292056\n","Epoch:  2429 | train loss: 0.303778 | valid loss: 0.292126\n","Epoch:  2430 | train loss: 0.303340 | valid loss: 0.292134\n","Epoch:  2431 | train loss: 0.259234 | valid loss: 0.291986\n","Epoch:  2432 | train loss: 0.329551 | valid loss: 0.291971\n","Epoch:  2433 | train loss: 0.338165 | valid loss: 0.291970\n","Epoch:  2434 | train loss: 0.289052 | valid loss: 0.291782\n","Epoch:  2435 | train loss: 0.292500 | valid loss: 0.291752\n","Epoch:  2436 | train loss: 0.296369 | valid loss: 0.291770\n","Epoch:  2437 | train loss: 0.267625 | valid loss: 0.291653\n","Epoch:  2438 | train loss: 0.263439 | valid loss: 0.291479\n","Epoch:  2439 | train loss: 0.322865 | valid loss: 0.291472\n","Epoch:  2440 | train loss: 0.334124 | valid loss: 0.291434\n","Epoch:  2441 | train loss: 0.282742 | valid loss: 0.291289\n","Epoch:  2442 | train loss: 0.295167 | valid loss: 0.291159\n","Epoch:  2443 | train loss: 0.282198 | valid loss: 0.291160\n","Epoch:  2444 | train loss: 0.344591 | valid loss: 0.291184\n","Epoch:  2445 | train loss: 0.336774 | valid loss: 0.290958\n","Epoch:  2446 | train loss: 0.305233 | valid loss: 0.291077\n","Epoch:  2447 | train loss: 0.309488 | valid loss: 0.291044\n","Epoch:  2448 | train loss: 0.314862 | valid loss: 0.290966\n","Epoch:  2449 | train loss: 0.288791 | valid loss: 0.290938\n","Epoch:  2450 | train loss: 0.249254 | valid loss: 0.290811\n","Epoch:  2451 | train loss: 0.347260 | valid loss: 0.290737\n","Epoch:  2452 | train loss: 0.238036 | valid loss: 0.290734\n","Epoch:  2453 | train loss: 0.356768 | valid loss: 0.290599\n","Epoch:  2454 | train loss: 0.271598 | valid loss: 0.290605\n","Epoch:  2455 | train loss: 0.251960 | valid loss: 0.290414\n","Epoch:  2456 | train loss: 0.231838 | valid loss: 0.290396\n","Epoch:  2457 | train loss: 0.348321 | valid loss: 0.290353\n","Epoch:  2458 | train loss: 0.339514 | valid loss: 0.290258\n","Epoch:  2459 | train loss: 0.316816 | valid loss: 0.290183\n","Epoch:  2460 | train loss: 0.364461 | valid loss: 0.290173\n","Epoch:  2461 | train loss: 0.275996 | valid loss: 0.290099\n","Epoch:  2462 | train loss: 0.302445 | valid loss: 0.290010\n","Epoch:  2463 | train loss: 0.344884 | valid loss: 0.289941\n","Epoch:  2464 | train loss: 0.258918 | valid loss: 0.289896\n","Epoch:  2465 | train loss: 0.296975 | valid loss: 0.289892\n","Epoch:  2466 | train loss: 0.315313 | valid loss: 0.289774\n","Epoch:  2467 | train loss: 0.323328 | valid loss: 0.289732\n","Epoch:  2468 | train loss: 0.332402 | valid loss: 0.289734\n","Epoch:  2469 | train loss: 0.268323 | valid loss: 0.289592\n","Epoch:  2470 | train loss: 0.311190 | valid loss: 0.289561\n","Epoch:  2471 | train loss: 0.313499 | valid loss: 0.289533\n","Epoch:  2472 | train loss: 0.272408 | valid loss: 0.289530\n","Epoch:  2473 | train loss: 0.305101 | valid loss: 0.289399\n","Epoch:  2474 | train loss: 0.360624 | valid loss: 0.289288\n","Epoch:  2475 | train loss: 0.357541 | valid loss: 0.289106\n","Epoch:  2476 | train loss: 0.298137 | valid loss: 0.289150\n","Epoch:  2477 | train loss: 0.351847 | valid loss: 0.289053\n","Epoch:  2478 | train loss: 0.252295 | valid loss: 0.288940\n","Epoch:  2479 | train loss: 0.283539 | valid loss: 0.288933\n","Epoch:  2480 | train loss: 0.343237 | valid loss: 0.288845\n","Epoch:  2481 | train loss: 0.282193 | valid loss: 0.289032\n","Epoch:  2482 | train loss: 0.343067 | valid loss: 0.288790\n","Epoch:  2483 | train loss: 0.273342 | valid loss: 0.288661\n","Epoch:  2484 | train loss: 0.376448 | valid loss: 0.288723\n","Epoch:  2485 | train loss: 0.301134 | valid loss: 0.288675\n","Epoch:  2486 | train loss: 0.267840 | valid loss: 0.288452\n","Epoch:  2487 | train loss: 0.295481 | valid loss: 0.288455\n","Epoch:  2488 | train loss: 0.333360 | valid loss: 0.288361\n","Epoch:  2489 | train loss: 0.308578 | valid loss: 0.288196\n","Epoch:  2490 | train loss: 0.283480 | valid loss: 0.288108\n","Epoch:  2491 | train loss: 0.293164 | valid loss: 0.288124\n","Epoch:  2492 | train loss: 0.366091 | valid loss: 0.288169\n","Epoch:  2493 | train loss: 0.290279 | valid loss: 0.288143\n","Epoch:  2494 | train loss: 0.322282 | valid loss: 0.288055\n","Epoch:  2495 | train loss: 0.320079 | valid loss: 0.287933\n","Epoch:  2496 | train loss: 0.243499 | valid loss: 0.287856\n","Epoch:  2497 | train loss: 0.263038 | valid loss: 0.287954\n","Epoch:  2498 | train loss: 0.336222 | valid loss: 0.287676\n","Epoch:  2499 | train loss: 0.336224 | valid loss: 0.287729\n","Epoch:  2500 | train loss: 0.298826 | valid loss: 0.287612\n","Epoch:  2501 | train loss: 0.245833 | valid loss: 0.287696\n","Epoch:  2502 | train loss: 0.263485 | valid loss: 0.287491\n","Epoch:  2503 | train loss: 0.330639 | valid loss: 0.287411\n","Epoch:  2504 | train loss: 0.266427 | valid loss: 0.287404\n","Epoch:  2505 | train loss: 0.253521 | valid loss: 0.287294\n","Epoch:  2506 | train loss: 0.388741 | valid loss: 0.287332\n","Epoch:  2507 | train loss: 0.313892 | valid loss: 0.287190\n","Epoch:  2508 | train loss: 0.309470 | valid loss: 0.287162\n","Epoch:  2509 | train loss: 0.271243 | valid loss: 0.286969\n","Epoch:  2510 | train loss: 0.292269 | valid loss: 0.287010\n","Epoch:  2511 | train loss: 0.204543 | valid loss: 0.286959\n","Epoch:  2512 | train loss: 0.232487 | valid loss: 0.286908\n","Epoch:  2513 | train loss: 0.276754 | valid loss: 0.286938\n","Epoch:  2514 | train loss: 0.363753 | valid loss: 0.286845\n","Epoch:  2515 | train loss: 0.262774 | valid loss: 0.286634\n","Epoch:  2516 | train loss: 0.303118 | valid loss: 0.286580\n","Epoch:  2517 | train loss: 0.362643 | valid loss: 0.286462\n","Epoch:  2518 | train loss: 0.322744 | valid loss: 0.286523\n","Epoch:  2519 | train loss: 0.308541 | valid loss: 0.286478\n","Epoch:  2520 | train loss: 0.362868 | valid loss: 0.286538\n","Epoch:  2521 | train loss: 0.309049 | valid loss: 0.286241\n","Epoch:  2522 | train loss: 0.275811 | valid loss: 0.286221\n","Epoch:  2523 | train loss: 0.315689 | valid loss: 0.286147\n","Epoch:  2524 | train loss: 0.333327 | valid loss: 0.286154\n","Epoch:  2525 | train loss: 0.306105 | valid loss: 0.286136\n","Epoch:  2526 | train loss: 0.280087 | valid loss: 0.285964\n","Epoch:  2527 | train loss: 0.297533 | valid loss: 0.285931\n","Epoch:  2528 | train loss: 0.312488 | valid loss: 0.285984\n","Epoch:  2529 | train loss: 0.318436 | valid loss: 0.285998\n","Epoch:  2530 | train loss: 0.430518 | valid loss: 0.285761\n","Epoch:  2531 | train loss: 0.312458 | valid loss: 0.285729\n","Epoch:  2532 | train loss: 0.298081 | valid loss: 0.285629\n","Epoch:  2533 | train loss: 0.309889 | valid loss: 0.285570\n","Epoch:  2534 | train loss: 0.263827 | valid loss: 0.285506\n","Epoch:  2535 | train loss: 0.261341 | valid loss: 0.285341\n","Epoch:  2536 | train loss: 0.258764 | valid loss: 0.285388\n","Epoch:  2537 | train loss: 0.260287 | valid loss: 0.285360\n","Epoch:  2538 | train loss: 0.351513 | valid loss: 0.285230\n","Epoch:  2539 | train loss: 0.293255 | valid loss: 0.285209\n","Epoch:  2540 | train loss: 0.329813 | valid loss: 0.285119\n","Epoch:  2541 | train loss: 0.281514 | valid loss: 0.285081\n","Epoch:  2542 | train loss: 0.322789 | valid loss: 0.285029\n","Epoch:  2543 | train loss: 0.275530 | valid loss: 0.284923\n","Epoch:  2544 | train loss: 0.325863 | valid loss: 0.285107\n","Epoch:  2545 | train loss: 0.264904 | valid loss: 0.284913\n","Epoch:  2546 | train loss: 0.321179 | valid loss: 0.284708\n","Epoch:  2547 | train loss: 0.296269 | valid loss: 0.284736\n","Epoch:  2548 | train loss: 0.350095 | valid loss: 0.284738\n","Epoch:  2549 | train loss: 0.318421 | valid loss: 0.284539\n","Epoch:  2550 | train loss: 0.297323 | valid loss: 0.284541\n","Epoch:  2551 | train loss: 0.223996 | valid loss: 0.284572\n","Epoch:  2552 | train loss: 0.267525 | valid loss: 0.284505\n","Epoch:  2553 | train loss: 0.286330 | valid loss: 0.284350\n","Epoch:  2554 | train loss: 0.259947 | valid loss: 0.284316\n","Epoch:  2555 | train loss: 0.303826 | valid loss: 0.284157\n","Epoch:  2556 | train loss: 0.285326 | valid loss: 0.284203\n","Epoch:  2557 | train loss: 0.246141 | valid loss: 0.284074\n","Epoch:  2558 | train loss: 0.279525 | valid loss: 0.284247\n","Epoch:  2559 | train loss: 0.284763 | valid loss: 0.283943\n","Epoch:  2560 | train loss: 0.205327 | valid loss: 0.283924\n","Epoch:  2561 | train loss: 0.308950 | valid loss: 0.283919\n","Epoch:  2562 | train loss: 0.240376 | valid loss: 0.283893\n","Epoch:  2563 | train loss: 0.294461 | valid loss: 0.283829\n","Epoch:  2564 | train loss: 0.367185 | valid loss: 0.283804\n","Epoch:  2565 | train loss: 0.204263 | valid loss: 0.283673\n","Epoch:  2566 | train loss: 0.240556 | valid loss: 0.283663\n","Epoch:  2567 | train loss: 0.351534 | valid loss: 0.283577\n","Epoch:  2568 | train loss: 0.312907 | valid loss: 0.283417\n","Epoch:  2569 | train loss: 0.285045 | valid loss: 0.283470\n","Epoch:  2570 | train loss: 0.279690 | valid loss: 0.283390\n","Epoch:  2571 | train loss: 0.209126 | valid loss: 0.283331\n","Epoch:  2572 | train loss: 0.325892 | valid loss: 0.283243\n","Epoch:  2573 | train loss: 0.282221 | valid loss: 0.283256\n","Epoch:  2574 | train loss: 0.321067 | valid loss: 0.283131\n","Epoch:  2575 | train loss: 0.372681 | valid loss: 0.283107\n","Epoch:  2576 | train loss: 0.326041 | valid loss: 0.283252\n","Epoch:  2577 | train loss: 0.330655 | valid loss: 0.283050\n","Epoch:  2578 | train loss: 0.242279 | valid loss: 0.282910\n","Epoch:  2579 | train loss: 0.311572 | valid loss: 0.282849\n","Epoch:  2580 | train loss: 0.263772 | valid loss: 0.282902\n","Epoch:  2581 | train loss: 0.269394 | valid loss: 0.282815\n","Epoch:  2582 | train loss: 0.300218 | valid loss: 0.282542\n","Epoch:  2583 | train loss: 0.275826 | valid loss: 0.282644\n","Epoch:  2584 | train loss: 0.372866 | valid loss: 0.282612\n","Epoch:  2585 | train loss: 0.303977 | valid loss: 0.282562\n","Epoch:  2586 | train loss: 0.268169 | valid loss: 0.282484\n","Epoch:  2587 | train loss: 0.224494 | valid loss: 0.282426\n","Epoch:  2588 | train loss: 0.334889 | valid loss: 0.282279\n","Epoch:  2589 | train loss: 0.273314 | valid loss: 0.282373\n","Epoch:  2590 | train loss: 0.275476 | valid loss: 0.282308\n","Epoch:  2591 | train loss: 0.327718 | valid loss: 0.282163\n","Epoch:  2592 | train loss: 0.327308 | valid loss: 0.282072\n","Epoch:  2593 | train loss: 0.336719 | valid loss: 0.282046\n","Epoch:  2594 | train loss: 0.274562 | valid loss: 0.281918\n","Epoch:  2595 | train loss: 0.285132 | valid loss: 0.282009\n","Epoch:  2596 | train loss: 0.227009 | valid loss: 0.281885\n","Epoch:  2597 | train loss: 0.343491 | valid loss: 0.281892\n","Epoch:  2598 | train loss: 0.302233 | valid loss: 0.281692\n","Epoch:  2599 | train loss: 0.314913 | valid loss: 0.281692\n","Epoch:  2600 | train loss: 0.274280 | valid loss: 0.281599\n","Epoch:  2601 | train loss: 0.330019 | valid loss: 0.281661\n","Epoch:  2602 | train loss: 0.246339 | valid loss: 0.281680\n","Epoch:  2603 | train loss: 0.218141 | valid loss: 0.281374\n","Epoch:  2604 | train loss: 0.322294 | valid loss: 0.281579\n","Epoch:  2605 | train loss: 0.359138 | valid loss: 0.281365\n","Epoch:  2606 | train loss: 0.312397 | valid loss: 0.281256\n","Epoch:  2607 | train loss: 0.279535 | valid loss: 0.281245\n","Epoch:  2608 | train loss: 0.203295 | valid loss: 0.281285\n","Epoch:  2609 | train loss: 0.312557 | valid loss: 0.281163\n","Epoch:  2610 | train loss: 0.337021 | valid loss: 0.281024\n","Epoch:  2611 | train loss: 0.296261 | valid loss: 0.281092\n","Epoch:  2612 | train loss: 0.260711 | valid loss: 0.280961\n","Epoch:  2613 | train loss: 0.328489 | valid loss: 0.280797\n","Epoch:  2614 | train loss: 0.266416 | valid loss: 0.280808\n","Epoch:  2615 | train loss: 0.286735 | valid loss: 0.280728\n","Epoch:  2616 | train loss: 0.308919 | valid loss: 0.280666\n","Epoch:  2617 | train loss: 0.326418 | valid loss: 0.280793\n","Epoch:  2618 | train loss: 0.289730 | valid loss: 0.280770\n","Epoch:  2619 | train loss: 0.270675 | valid loss: 0.280732\n","Epoch:  2620 | train loss: 0.324476 | valid loss: 0.280576\n","Epoch:  2621 | train loss: 0.311165 | valid loss: 0.280472\n","Epoch:  2622 | train loss: 0.265471 | valid loss: 0.280484\n","Epoch:  2623 | train loss: 0.299755 | valid loss: 0.280432\n","Epoch:  2624 | train loss: 0.277039 | valid loss: 0.280425\n","Epoch:  2625 | train loss: 0.358067 | valid loss: 0.280233\n","Epoch:  2626 | train loss: 0.284198 | valid loss: 0.280289\n","Epoch:  2627 | train loss: 0.268475 | valid loss: 0.280134\n","Epoch:  2628 | train loss: 0.232159 | valid loss: 0.280183\n","Epoch:  2629 | train loss: 0.394091 | valid loss: 0.280154\n","Epoch:  2630 | train loss: 0.252679 | valid loss: 0.280013\n","Epoch:  2631 | train loss: 0.290884 | valid loss: 0.280025\n","Epoch:  2632 | train loss: 0.338207 | valid loss: 0.279907\n","Epoch:  2633 | train loss: 0.309328 | valid loss: 0.279802\n","Epoch:  2634 | train loss: 0.258027 | valid loss: 0.279838\n","Epoch:  2635 | train loss: 0.335795 | valid loss: 0.279776\n","Epoch:  2636 | train loss: 0.254504 | valid loss: 0.279659\n","Epoch:  2637 | train loss: 0.234433 | valid loss: 0.279618\n","Epoch:  2638 | train loss: 0.286679 | valid loss: 0.279732\n","Epoch:  2639 | train loss: 0.254499 | valid loss: 0.279546\n","Epoch:  2640 | train loss: 0.380271 | valid loss: 0.279588\n","Epoch:  2641 | train loss: 0.342569 | valid loss: 0.279421\n","Epoch:  2642 | train loss: 0.297088 | valid loss: 0.279379\n","Epoch:  2643 | train loss: 0.258429 | valid loss: 0.279308\n","Epoch:  2644 | train loss: 0.294107 | valid loss: 0.279347\n","Epoch:  2645 | train loss: 0.363020 | valid loss: 0.279254\n","Epoch:  2646 | train loss: 0.275387 | valid loss: 0.279140\n","Epoch:  2647 | train loss: 0.318459 | valid loss: 0.278968\n","Epoch:  2648 | train loss: 0.310178 | valid loss: 0.278977\n","Epoch:  2649 | train loss: 0.372991 | valid loss: 0.278933\n","Epoch:  2650 | train loss: 0.306516 | valid loss: 0.279013\n","Epoch:  2651 | train loss: 0.310853 | valid loss: 0.278909\n","Epoch:  2652 | train loss: 0.328677 | valid loss: 0.278846\n","Epoch:  2653 | train loss: 0.321242 | valid loss: 0.278859\n","Epoch:  2654 | train loss: 0.321223 | valid loss: 0.278744\n","Epoch:  2655 | train loss: 0.305874 | valid loss: 0.278828\n","Epoch:  2656 | train loss: 0.296393 | valid loss: 0.278643\n","Epoch:  2657 | train loss: 0.293833 | valid loss: 0.278610\n","Epoch:  2658 | train loss: 0.238461 | valid loss: 0.278658\n","Epoch:  2659 | train loss: 0.230515 | valid loss: 0.278532\n","Epoch:  2660 | train loss: 0.315573 | valid loss: 0.278496\n","Epoch:  2661 | train loss: 0.290821 | valid loss: 0.278527\n","Epoch:  2662 | train loss: 0.300849 | valid loss: 0.278373\n","Epoch:  2663 | train loss: 0.319979 | valid loss: 0.278231\n","Epoch:  2664 | train loss: 0.318313 | valid loss: 0.278271\n","Epoch:  2665 | train loss: 0.300329 | valid loss: 0.278087\n","Epoch:  2666 | train loss: 0.270012 | valid loss: 0.278312\n","Epoch:  2667 | train loss: 0.354399 | valid loss: 0.278060\n","Epoch:  2668 | train loss: 0.336061 | valid loss: 0.277995\n","Epoch:  2669 | train loss: 0.296776 | valid loss: 0.278013\n","Epoch:  2670 | train loss: 0.211231 | valid loss: 0.278088\n","Epoch:  2671 | train loss: 0.249981 | valid loss: 0.278005\n","Epoch:  2672 | train loss: 0.226168 | valid loss: 0.277847\n","Epoch:  2673 | train loss: 0.296740 | valid loss: 0.277740\n","Epoch:  2674 | train loss: 0.296085 | valid loss: 0.277936\n","Epoch:  2675 | train loss: 0.349029 | valid loss: 0.277777\n","Epoch:  2676 | train loss: 0.269075 | valid loss: 0.277628\n","Epoch:  2677 | train loss: 0.308301 | valid loss: 0.277479\n","Epoch:  2678 | train loss: 0.222682 | valid loss: 0.277580\n","Epoch:  2679 | train loss: 0.239850 | valid loss: 0.277556\n","Epoch:  2680 | train loss: 0.321673 | valid loss: 0.277434\n","Epoch:  2681 | train loss: 0.326351 | valid loss: 0.277397\n","Epoch:  2682 | train loss: 0.265439 | valid loss: 0.277188\n","Epoch:  2683 | train loss: 0.298831 | valid loss: 0.277359\n","Epoch:  2684 | train loss: 0.220904 | valid loss: 0.277200\n","Epoch:  2685 | train loss: 0.396606 | valid loss: 0.277236\n","Epoch:  2686 | train loss: 0.293297 | valid loss: 0.277154\n","Epoch:  2687 | train loss: 0.293251 | valid loss: 0.277100\n","Epoch:  2688 | train loss: 0.312250 | valid loss: 0.277068\n","Epoch:  2689 | train loss: 0.250794 | valid loss: 0.276937\n","Epoch:  2690 | train loss: 0.280830 | valid loss: 0.276917\n","Epoch:  2691 | train loss: 0.256222 | valid loss: 0.276977\n","Epoch:  2692 | train loss: 0.295326 | valid loss: 0.276856\n","Epoch:  2693 | train loss: 0.231736 | valid loss: 0.276811\n","Epoch:  2694 | train loss: 0.273546 | valid loss: 0.276881\n","Epoch:  2695 | train loss: 0.247130 | valid loss: 0.276572\n","Epoch:  2696 | train loss: 0.301436 | valid loss: 0.276713\n","Epoch:  2697 | train loss: 0.261337 | valid loss: 0.276495\n","Epoch:  2698 | train loss: 0.316670 | valid loss: 0.276551\n","Epoch:  2699 | train loss: 0.366234 | valid loss: 0.276527\n","Epoch:  2700 | train loss: 0.304215 | valid loss: 0.276515\n","Epoch:  2701 | train loss: 0.264376 | valid loss: 0.276375\n","Epoch:  2702 | train loss: 0.353807 | valid loss: 0.276278\n","Epoch:  2703 | train loss: 0.318688 | valid loss: 0.276335\n","Epoch:  2704 | train loss: 0.262952 | valid loss: 0.276251\n","Epoch:  2705 | train loss: 0.277877 | valid loss: 0.276077\n","Epoch:  2706 | train loss: 0.320814 | valid loss: 0.276102\n","Epoch:  2707 | train loss: 0.286416 | valid loss: 0.275957\n","Epoch:  2708 | train loss: 0.334278 | valid loss: 0.276036\n","Epoch:  2709 | train loss: 0.285271 | valid loss: 0.275861\n","Epoch:  2710 | train loss: 0.323214 | valid loss: 0.275942\n","Epoch:  2711 | train loss: 0.299030 | valid loss: 0.275807\n","Epoch:  2712 | train loss: 0.271619 | valid loss: 0.275872\n","Epoch:  2713 | train loss: 0.290898 | valid loss: 0.275738\n","Epoch:  2714 | train loss: 0.289569 | valid loss: 0.275729\n","Epoch:  2715 | train loss: 0.350400 | valid loss: 0.275744\n","Epoch:  2716 | train loss: 0.340695 | valid loss: 0.275691\n","Epoch:  2717 | train loss: 0.275173 | valid loss: 0.275652\n","Epoch:  2718 | train loss: 0.298854 | valid loss: 0.275603\n","Epoch:  2719 | train loss: 0.310249 | valid loss: 0.275622\n","Epoch:  2720 | train loss: 0.322640 | valid loss: 0.275438\n","Epoch:  2721 | train loss: 0.377874 | valid loss: 0.275383\n","Epoch:  2722 | train loss: 0.216838 | valid loss: 0.275304\n","Epoch:  2723 | train loss: 0.247816 | valid loss: 0.275250\n","Epoch:  2724 | train loss: 0.330845 | valid loss: 0.275214\n","Epoch:  2725 | train loss: 0.283926 | valid loss: 0.275153\n","Epoch:  2726 | train loss: 0.279337 | valid loss: 0.275210\n","Epoch:  2727 | train loss: 0.244324 | valid loss: 0.274994\n","Epoch:  2728 | train loss: 0.279874 | valid loss: 0.275056\n","Epoch:  2729 | train loss: 0.250586 | valid loss: 0.274998\n","Epoch:  2730 | train loss: 0.312780 | valid loss: 0.274990\n","Epoch:  2731 | train loss: 0.282602 | valid loss: 0.274871\n","Epoch:  2732 | train loss: 0.345612 | valid loss: 0.274882\n","Epoch:  2733 | train loss: 0.292359 | valid loss: 0.274861\n","Epoch:  2734 | train loss: 0.355181 | valid loss: 0.274861\n","Epoch:  2735 | train loss: 0.320831 | valid loss: 0.274775\n","Epoch:  2736 | train loss: 0.272279 | valid loss: 0.274749\n","Epoch:  2737 | train loss: 0.305255 | valid loss: 0.274744\n","Epoch:  2738 | train loss: 0.347160 | valid loss: 0.274706\n","Epoch:  2739 | train loss: 0.246896 | valid loss: 0.274588\n","Epoch:  2740 | train loss: 0.289308 | valid loss: 0.274472\n","Epoch:  2741 | train loss: 0.227984 | valid loss: 0.274338\n","Epoch:  2742 | train loss: 0.311402 | valid loss: 0.274356\n","Epoch:  2743 | train loss: 0.400345 | valid loss: 0.274286\n","Epoch:  2744 | train loss: 0.292278 | valid loss: 0.274358\n","Epoch:  2745 | train loss: 0.345585 | valid loss: 0.274114\n","Epoch:  2746 | train loss: 0.320493 | valid loss: 0.274171\n","Epoch:  2747 | train loss: 0.296566 | valid loss: 0.274075\n","Epoch:  2748 | train loss: 0.226149 | valid loss: 0.274115\n","Epoch:  2749 | train loss: 0.252472 | valid loss: 0.274117\n","Epoch:  2750 | train loss: 0.284748 | valid loss: 0.274038\n","Epoch:  2751 | train loss: 0.270898 | valid loss: 0.274098\n","Epoch:  2752 | train loss: 0.229882 | valid loss: 0.274078\n","Epoch:  2753 | train loss: 0.284268 | valid loss: 0.273842\n","Epoch:  2754 | train loss: 0.339087 | valid loss: 0.273850\n","Epoch:  2755 | train loss: 0.308103 | valid loss: 0.273784\n","Epoch:  2756 | train loss: 0.322781 | valid loss: 0.273787\n","Epoch:  2757 | train loss: 0.308839 | valid loss: 0.273821\n","Epoch:  2758 | train loss: 0.327610 | valid loss: 0.273522\n","Epoch:  2759 | train loss: 0.318703 | valid loss: 0.273424\n","Epoch:  2760 | train loss: 0.290788 | valid loss: 0.273537\n","Epoch:  2761 | train loss: 0.254313 | valid loss: 0.273444\n","Epoch:  2762 | train loss: 0.251133 | valid loss: 0.273419\n","Epoch:  2763 | train loss: 0.286762 | valid loss: 0.273491\n","Epoch:  2764 | train loss: 0.249356 | valid loss: 0.273475\n","Epoch:  2765 | train loss: 0.335007 | valid loss: 0.273373\n","Epoch:  2766 | train loss: 0.289769 | valid loss: 0.273240\n","Epoch:  2767 | train loss: 0.270953 | valid loss: 0.273185\n","Epoch:  2768 | train loss: 0.332190 | valid loss: 0.273267\n","Epoch:  2769 | train loss: 0.292380 | valid loss: 0.273288\n","Epoch:  2770 | train loss: 0.297338 | valid loss: 0.273116\n","Epoch:  2771 | train loss: 0.265636 | valid loss: 0.273121\n","Epoch:  2772 | train loss: 0.250245 | valid loss: 0.273044\n","Epoch:  2773 | train loss: 0.290222 | valid loss: 0.272940\n","Epoch:  2774 | train loss: 0.254443 | valid loss: 0.272925\n","Epoch:  2775 | train loss: 0.313774 | valid loss: 0.273050\n","Epoch:  2776 | train loss: 0.238132 | valid loss: 0.272796\n","Epoch:  2777 | train loss: 0.369610 | valid loss: 0.272834\n","Epoch:  2778 | train loss: 0.265061 | valid loss: 0.272660\n","Epoch:  2779 | train loss: 0.241343 | valid loss: 0.272709\n","Epoch:  2780 | train loss: 0.265369 | valid loss: 0.272579\n","Epoch:  2781 | train loss: 0.294202 | valid loss: 0.272533\n","Epoch:  2782 | train loss: 0.312261 | valid loss: 0.272498\n","Epoch:  2783 | train loss: 0.235600 | valid loss: 0.272397\n","Epoch:  2784 | train loss: 0.239946 | valid loss: 0.272484\n","Epoch:  2785 | train loss: 0.279108 | valid loss: 0.272335\n","Epoch:  2786 | train loss: 0.294894 | valid loss: 0.272247\n","Epoch:  2787 | train loss: 0.271188 | valid loss: 0.272273\n","Epoch:  2788 | train loss: 0.278567 | valid loss: 0.272270\n","Epoch:  2789 | train loss: 0.319934 | valid loss: 0.272217\n","Epoch:  2790 | train loss: 0.326098 | valid loss: 0.272081\n","Epoch:  2791 | train loss: 0.226302 | valid loss: 0.272054\n","Epoch:  2792 | train loss: 0.304364 | valid loss: 0.271998\n","Epoch:  2793 | train loss: 0.296131 | valid loss: 0.271990\n","Epoch:  2794 | train loss: 0.366060 | valid loss: 0.272034\n","Epoch:  2795 | train loss: 0.246160 | valid loss: 0.271939\n","Epoch:  2796 | train loss: 0.287222 | valid loss: 0.271902\n","Epoch:  2797 | train loss: 0.296844 | valid loss: 0.271825\n","Epoch:  2798 | train loss: 0.281458 | valid loss: 0.271758\n","Epoch:  2799 | train loss: 0.287709 | valid loss: 0.271717\n","Epoch:  2800 | train loss: 0.285184 | valid loss: 0.271663\n","Epoch:  2801 | train loss: 0.272639 | valid loss: 0.271662\n","Epoch:  2802 | train loss: 0.351778 | valid loss: 0.271461\n","Epoch:  2803 | train loss: 0.244380 | valid loss: 0.271585\n","Epoch:  2804 | train loss: 0.327645 | valid loss: 0.271617\n","Epoch:  2805 | train loss: 0.288572 | valid loss: 0.271512\n","Epoch:  2806 | train loss: 0.245768 | valid loss: 0.271391\n","Epoch:  2807 | train loss: 0.321588 | valid loss: 0.271567\n","Epoch:  2808 | train loss: 0.349044 | valid loss: 0.271380\n","Epoch:  2809 | train loss: 0.316973 | valid loss: 0.271385\n","Epoch:  2810 | train loss: 0.271834 | valid loss: 0.271214\n","Epoch:  2811 | train loss: 0.291517 | valid loss: 0.271249\n","Epoch:  2812 | train loss: 0.291910 | valid loss: 0.271120\n","Epoch:  2813 | train loss: 0.282048 | valid loss: 0.271165\n","Epoch:  2814 | train loss: 0.259618 | valid loss: 0.271048\n","Epoch:  2815 | train loss: 0.315796 | valid loss: 0.271017\n","Epoch:  2816 | train loss: 0.450806 | valid loss: 0.270923\n","Epoch:  2817 | train loss: 0.291079 | valid loss: 0.271059\n","Epoch:  2818 | train loss: 0.272081 | valid loss: 0.270893\n","Epoch:  2819 | train loss: 0.292283 | valid loss: 0.270864\n","Epoch:  2820 | train loss: 0.347423 | valid loss: 0.270876\n","Epoch:  2821 | train loss: 0.255576 | valid loss: 0.270828\n","Epoch:  2822 | train loss: 0.286289 | valid loss: 0.270849\n","Epoch:  2823 | train loss: 0.295706 | valid loss: 0.270670\n","Epoch:  2824 | train loss: 0.236647 | valid loss: 0.270639\n","Epoch:  2825 | train loss: 0.301396 | valid loss: 0.270739\n","Epoch:  2826 | train loss: 0.319042 | valid loss: 0.270456\n","Epoch:  2827 | train loss: 0.295213 | valid loss: 0.270611\n","Epoch:  2828 | train loss: 0.219567 | valid loss: 0.270537\n","Epoch:  2829 | train loss: 0.227910 | valid loss: 0.270438\n","Epoch:  2830 | train loss: 0.317677 | valid loss: 0.270485\n","Epoch:  2831 | train loss: 0.363585 | valid loss: 0.270439\n","Epoch:  2832 | train loss: 0.311932 | valid loss: 0.270424\n","Epoch:  2833 | train loss: 0.268194 | valid loss: 0.270369\n","Epoch:  2834 | train loss: 0.251300 | valid loss: 0.270274\n","Epoch:  2835 | train loss: 0.253487 | valid loss: 0.270193\n","Epoch:  2836 | train loss: 0.311761 | valid loss: 0.270294\n","Epoch:  2837 | train loss: 0.252841 | valid loss: 0.269921\n","Epoch:  2838 | train loss: 0.425731 | valid loss: 0.269978\n","Epoch:  2839 | train loss: 0.324155 | valid loss: 0.270163\n","Epoch:  2840 | train loss: 0.318454 | valid loss: 0.270038\n","Epoch:  2841 | train loss: 0.242472 | valid loss: 0.269925\n","Epoch:  2842 | train loss: 0.265389 | valid loss: 0.269957\n","Epoch:  2843 | train loss: 0.270011 | valid loss: 0.269770\n","Epoch:  2844 | train loss: 0.290330 | valid loss: 0.269845\n","Epoch:  2845 | train loss: 0.358000 | valid loss: 0.269854\n","Epoch:  2846 | train loss: 0.217828 | valid loss: 0.269802\n","Epoch:  2847 | train loss: 0.317819 | valid loss: 0.269743\n","Epoch:  2848 | train loss: 0.305818 | valid loss: 0.269709\n","Epoch:  2849 | train loss: 0.299211 | valid loss: 0.269629\n","Epoch:  2850 | train loss: 0.326796 | valid loss: 0.269618\n","Epoch:  2851 | train loss: 0.327542 | valid loss: 0.269587\n","Epoch:  2852 | train loss: 0.252445 | valid loss: 0.269520\n","Epoch:  2853 | train loss: 0.306678 | valid loss: 0.269587\n","Epoch:  2854 | train loss: 0.351917 | valid loss: 0.269511\n","Epoch:  2855 | train loss: 0.294649 | valid loss: 0.269512\n","Epoch:  2856 | train loss: 0.312216 | valid loss: 0.269534\n","Epoch:  2857 | train loss: 0.231840 | valid loss: 0.269278\n","Epoch:  2858 | train loss: 0.302583 | valid loss: 0.269306\n","Epoch:  2859 | train loss: 0.269937 | valid loss: 0.269158\n","Epoch:  2860 | train loss: 0.273382 | valid loss: 0.269139\n","Epoch:  2861 | train loss: 0.300927 | valid loss: 0.269190\n","Epoch:  2862 | train loss: 0.274530 | valid loss: 0.269254\n","Epoch:  2863 | train loss: 0.258593 | valid loss: 0.269070\n","Epoch:  2864 | train loss: 0.298854 | valid loss: 0.269177\n","Epoch:  2865 | train loss: 0.216490 | valid loss: 0.269067\n","Epoch:  2866 | train loss: 0.230857 | valid loss: 0.269030\n","Epoch:  2867 | train loss: 0.269258 | valid loss: 0.268803\n","Epoch:  2868 | train loss: 0.265239 | valid loss: 0.268829\n","Epoch:  2869 | train loss: 0.332595 | valid loss: 0.268774\n","Epoch:  2870 | train loss: 0.293046 | valid loss: 0.268708\n","Epoch:  2871 | train loss: 0.307837 | valid loss: 0.268817\n","Epoch:  2872 | train loss: 0.311121 | valid loss: 0.268671\n","Epoch:  2873 | train loss: 0.313336 | valid loss: 0.268689\n","Epoch:  2874 | train loss: 0.302934 | valid loss: 0.268708\n","Epoch:  2875 | train loss: 0.171037 | valid loss: 0.268462\n","Epoch:  2876 | train loss: 0.208292 | valid loss: 0.268576\n","Epoch:  2877 | train loss: 0.287739 | valid loss: 0.268468\n","Epoch:  2878 | train loss: 0.377058 | valid loss: 0.268487\n","Epoch:  2879 | train loss: 0.408141 | valid loss: 0.268414\n","Epoch:  2880 | train loss: 0.289481 | valid loss: 0.268425\n","Epoch:  2881 | train loss: 0.292336 | valid loss: 0.268373\n","Epoch:  2882 | train loss: 0.317244 | valid loss: 0.268280\n","Epoch:  2883 | train loss: 0.265521 | valid loss: 0.268186\n","Epoch:  2884 | train loss: 0.312083 | valid loss: 0.268207\n","Epoch:  2885 | train loss: 0.280550 | valid loss: 0.268218\n","Epoch:  2886 | train loss: 0.318529 | valid loss: 0.268177\n","Epoch:  2887 | train loss: 0.329180 | valid loss: 0.268165\n","Epoch:  2888 | train loss: 0.213314 | valid loss: 0.268127\n","Epoch:  2889 | train loss: 0.369242 | valid loss: 0.268127\n","Epoch:  2890 | train loss: 0.221670 | valid loss: 0.267981\n","Epoch:  2891 | train loss: 0.268495 | valid loss: 0.267918\n","Epoch:  2892 | train loss: 0.343756 | valid loss: 0.268059\n","Epoch:  2893 | train loss: 0.254400 | valid loss: 0.267952\n","Epoch:  2894 | train loss: 0.272500 | valid loss: 0.267856\n","Epoch:  2895 | train loss: 0.288487 | valid loss: 0.267928\n","Epoch:  2896 | train loss: 0.360270 | valid loss: 0.267956\n","Epoch:  2897 | train loss: 0.246250 | valid loss: 0.267795\n","Epoch:  2898 | train loss: 0.355425 | valid loss: 0.267653\n","Epoch:  2899 | train loss: 0.304115 | valid loss: 0.267681\n","Epoch:  2900 | train loss: 0.257673 | valid loss: 0.267630\n","Epoch:  2901 | train loss: 0.330110 | valid loss: 0.267690\n","Epoch:  2902 | train loss: 0.263643 | valid loss: 0.267647\n","Epoch:  2903 | train loss: 0.284719 | valid loss: 0.267515\n","Epoch:  2904 | train loss: 0.315017 | valid loss: 0.267478\n","Epoch:  2905 | train loss: 0.270969 | valid loss: 0.267401\n","Epoch:  2906 | train loss: 0.267615 | valid loss: 0.267444\n","Epoch:  2907 | train loss: 0.293981 | valid loss: 0.267346\n","Epoch:  2908 | train loss: 0.271960 | valid loss: 0.267284\n","Epoch:  2909 | train loss: 0.293299 | valid loss: 0.267401\n","Epoch:  2910 | train loss: 0.265441 | valid loss: 0.267190\n","Epoch:  2911 | train loss: 0.250914 | valid loss: 0.267313\n","Epoch:  2912 | train loss: 0.243309 | valid loss: 0.267030\n","Epoch:  2913 | train loss: 0.244661 | valid loss: 0.267124\n","Epoch:  2914 | train loss: 0.266338 | valid loss: 0.267194\n","Epoch:  2915 | train loss: 0.286123 | valid loss: 0.267035\n","Epoch:  2916 | train loss: 0.310956 | valid loss: 0.267099\n","Epoch:  2917 | train loss: 0.359528 | valid loss: 0.266998\n","Epoch:  2918 | train loss: 0.287432 | valid loss: 0.267003\n","Epoch:  2919 | train loss: 0.287602 | valid loss: 0.266894\n","Epoch:  2920 | train loss: 0.376526 | valid loss: 0.266890\n","Epoch:  2921 | train loss: 0.268438 | valid loss: 0.266892\n","Epoch:  2922 | train loss: 0.248615 | valid loss: 0.266850\n","Epoch:  2923 | train loss: 0.279702 | valid loss: 0.266697\n","Epoch:  2924 | train loss: 0.284664 | valid loss: 0.266781\n","Epoch:  2925 | train loss: 0.288890 | valid loss: 0.266609\n","Epoch:  2926 | train loss: 0.253033 | valid loss: 0.266688\n","Epoch:  2927 | train loss: 0.264410 | valid loss: 0.266650\n","Epoch:  2928 | train loss: 0.205531 | valid loss: 0.266794\n","Epoch:  2929 | train loss: 0.266374 | valid loss: 0.266519\n","Epoch:  2930 | train loss: 0.241784 | valid loss: 0.266536\n","Epoch:  2931 | train loss: 0.202646 | valid loss: 0.266514\n","Epoch:  2932 | train loss: 0.252198 | valid loss: 0.266485\n","Epoch:  2933 | train loss: 0.272484 | valid loss: 0.266476\n","Epoch:  2934 | train loss: 0.278206 | valid loss: 0.266335\n","Epoch:  2935 | train loss: 0.215537 | valid loss: 0.266502\n","Epoch:  2936 | train loss: 0.293344 | valid loss: 0.266386\n","Epoch:  2937 | train loss: 0.222830 | valid loss: 0.266295\n","Epoch:  2938 | train loss: 0.281334 | valid loss: 0.266284\n","Epoch:  2939 | train loss: 0.325034 | valid loss: 0.266137\n","Epoch:  2940 | train loss: 0.223656 | valid loss: 0.266027\n","Epoch:  2941 | train loss: 0.262779 | valid loss: 0.266123\n","Epoch:  2942 | train loss: 0.353579 | valid loss: 0.265951\n","Epoch:  2943 | train loss: 0.256935 | valid loss: 0.265906\n","Epoch:  2944 | train loss: 0.256758 | valid loss: 0.265950\n","Epoch:  2945 | train loss: 0.291822 | valid loss: 0.265760\n","Epoch:  2946 | train loss: 0.428499 | valid loss: 0.265828\n","Epoch:  2947 | train loss: 0.267244 | valid loss: 0.265813\n","Epoch:  2948 | train loss: 0.325491 | valid loss: 0.265768\n","Epoch:  2949 | train loss: 0.265327 | valid loss: 0.265732\n","Epoch:  2950 | train loss: 0.279985 | valid loss: 0.265720\n","Epoch:  2951 | train loss: 0.342758 | valid loss: 0.265801\n","Epoch:  2952 | train loss: 0.313897 | valid loss: 0.265587\n","Epoch:  2953 | train loss: 0.272591 | valid loss: 0.265716\n","Epoch:  2954 | train loss: 0.270603 | valid loss: 0.265628\n","Epoch:  2955 | train loss: 0.312576 | valid loss: 0.265605\n","Epoch:  2956 | train loss: 0.278403 | valid loss: 0.265642\n","Epoch:  2957 | train loss: 0.254704 | valid loss: 0.265542\n","Epoch:  2958 | train loss: 0.308032 | valid loss: 0.265327\n","Epoch:  2959 | train loss: 0.249028 | valid loss: 0.265387\n","Epoch:  2960 | train loss: 0.289413 | valid loss: 0.265384\n","Epoch:  2961 | train loss: 0.275972 | valid loss: 0.265396\n","Epoch:  2962 | train loss: 0.312203 | valid loss: 0.265227\n","Epoch:  2963 | train loss: 0.312044 | valid loss: 0.265302\n","Epoch:  2964 | train loss: 0.297809 | valid loss: 0.265355\n","Epoch:  2965 | train loss: 0.317377 | valid loss: 0.265320\n","Epoch:  2966 | train loss: 0.230342 | valid loss: 0.265306\n","Epoch:  2967 | train loss: 0.272357 | valid loss: 0.265170\n","Epoch:  2968 | train loss: 0.290682 | valid loss: 0.265060\n","Epoch:  2969 | train loss: 0.341600 | valid loss: 0.265211\n","Epoch:  2970 | train loss: 0.272397 | valid loss: 0.265058\n","Epoch:  2971 | train loss: 0.247672 | valid loss: 0.265053\n","Epoch:  2972 | train loss: 0.296989 | valid loss: 0.264894\n","Epoch:  2973 | train loss: 0.271515 | valid loss: 0.264947\n","Epoch:  2974 | train loss: 0.278272 | valid loss: 0.265261\n","Epoch:  2975 | train loss: 0.309751 | valid loss: 0.264808\n","Epoch:  2976 | train loss: 0.329640 | valid loss: 0.264880\n","Epoch:  2977 | train loss: 0.265256 | valid loss: 0.264859\n","Epoch:  2978 | train loss: 0.293576 | valid loss: 0.264608\n","Epoch:  2979 | train loss: 0.308562 | valid loss: 0.264843\n","Epoch:  2980 | train loss: 0.267946 | valid loss: 0.264737\n","Epoch:  2981 | train loss: 0.239275 | valid loss: 0.264592\n","Epoch:  2982 | train loss: 0.218733 | valid loss: 0.264631\n","Epoch:  2983 | train loss: 0.252026 | valid loss: 0.264605\n","Epoch:  2984 | train loss: 0.264983 | valid loss: 0.264588\n","Epoch:  2985 | train loss: 0.330383 | valid loss: 0.264631\n","Epoch:  2986 | train loss: 0.223349 | valid loss: 0.264567\n","Epoch:  2987 | train loss: 0.347670 | valid loss: 0.264527\n","Epoch:  2988 | train loss: 0.225459 | valid loss: 0.264598\n","Epoch:  2989 | train loss: 0.304986 | valid loss: 0.264541\n","Epoch:  2990 | train loss: 0.265570 | valid loss: 0.264509\n","Epoch:  2991 | train loss: 0.283847 | valid loss: 0.264372\n","Epoch:  2992 | train loss: 0.222784 | valid loss: 0.264234\n","Epoch:  2993 | train loss: 0.335190 | valid loss: 0.264348\n","Epoch:  2994 | train loss: 0.252401 | valid loss: 0.264337\n","Epoch:  2995 | train loss: 0.224055 | valid loss: 0.264290\n","Epoch:  2996 | train loss: 0.223430 | valid loss: 0.264244\n","Epoch:  2997 | train loss: 0.306441 | valid loss: 0.264260\n","Epoch:  2998 | train loss: 0.267542 | valid loss: 0.264177\n","Epoch:  2999 | train loss: 0.404318 | valid loss: 0.264113\n","Epoch:  3000 | train loss: 0.275336 | valid loss: 0.264099\n","Epoch:  3001 | train loss: 0.251659 | valid loss: 0.264036\n","Epoch:  3002 | train loss: 0.249442 | valid loss: 0.264122\n","Epoch:  3003 | train loss: 0.278441 | valid loss: 0.264041\n","Epoch:  3004 | train loss: 0.338970 | valid loss: 0.263923\n","Epoch:  3005 | train loss: 0.239798 | valid loss: 0.263763\n","Epoch:  3006 | train loss: 0.272274 | valid loss: 0.263942\n","Epoch:  3007 | train loss: 0.277133 | valid loss: 0.263818\n","Epoch:  3008 | train loss: 0.264789 | valid loss: 0.263815\n","Epoch:  3009 | train loss: 0.232372 | valid loss: 0.263859\n","Epoch:  3010 | train loss: 0.281552 | valid loss: 0.263610\n","Epoch:  3011 | train loss: 0.252497 | valid loss: 0.263792\n","Epoch:  3012 | train loss: 0.222079 | valid loss: 0.263589\n","Epoch:  3013 | train loss: 0.324908 | valid loss: 0.263713\n","Epoch:  3014 | train loss: 0.284446 | valid loss: 0.263621\n","Epoch:  3015 | train loss: 0.365707 | valid loss: 0.263584\n","Epoch:  3016 | train loss: 0.335655 | valid loss: 0.263592\n","Epoch:  3017 | train loss: 0.187274 | valid loss: 0.263489\n","Epoch:  3018 | train loss: 0.282604 | valid loss: 0.263524\n","Epoch:  3019 | train loss: 0.319801 | valid loss: 0.263474\n","Epoch:  3020 | train loss: 0.243030 | valid loss: 0.263460\n","Epoch:  3021 | train loss: 0.361221 | valid loss: 0.263509\n","Epoch:  3022 | train loss: 0.256252 | valid loss: 0.263303\n","Epoch:  3023 | train loss: 0.286315 | valid loss: 0.263383\n","Epoch:  3024 | train loss: 0.276968 | valid loss: 0.263327\n","Epoch:  3025 | train loss: 0.313725 | valid loss: 0.263348\n","Epoch:  3026 | train loss: 0.281753 | valid loss: 0.263218\n","Epoch:  3027 | train loss: 0.262032 | valid loss: 0.263306\n","Epoch:  3028 | train loss: 0.277768 | valid loss: 0.263209\n","Epoch:  3029 | train loss: 0.342851 | valid loss: 0.263178\n","Epoch:  3030 | train loss: 0.204502 | valid loss: 0.263188\n","Epoch:  3031 | train loss: 0.282059 | valid loss: 0.263110\n","Epoch:  3032 | train loss: 0.333081 | valid loss: 0.263045\n","Epoch:  3033 | train loss: 0.272548 | valid loss: 0.263430\n","Epoch:  3034 | train loss: 0.391049 | valid loss: 0.262985\n","Epoch:  3035 | train loss: 0.243089 | valid loss: 0.263087\n","Epoch:  3036 | train loss: 0.297803 | valid loss: 0.263039\n","Epoch:  3037 | train loss: 0.286795 | valid loss: 0.262925\n","Epoch:  3038 | train loss: 0.280594 | valid loss: 0.262902\n","Epoch:  3039 | train loss: 0.270134 | valid loss: 0.262871\n","Epoch:  3040 | train loss: 0.291559 | valid loss: 0.262803\n","Epoch:  3041 | train loss: 0.303865 | valid loss: 0.262769\n","Epoch:  3042 | train loss: 0.276980 | valid loss: 0.262739\n","Epoch:  3043 | train loss: 0.290469 | valid loss: 0.262699\n","Epoch:  3044 | train loss: 0.339435 | valid loss: 0.262810\n","Epoch:  3045 | train loss: 0.375204 | valid loss: 0.262701\n","Epoch:  3046 | train loss: 0.270079 | valid loss: 0.262600\n","Epoch:  3047 | train loss: 0.294016 | valid loss: 0.262489\n","Epoch:  3048 | train loss: 0.285348 | valid loss: 0.262628\n","Epoch:  3049 | train loss: 0.378806 | valid loss: 0.262638\n","Epoch:  3050 | train loss: 0.264252 | valid loss: 0.262486\n","Epoch:  3051 | train loss: 0.257158 | valid loss: 0.262517\n","Epoch:  3052 | train loss: 0.299113 | valid loss: 0.262529\n","Epoch:  3053 | train loss: 0.270081 | valid loss: 0.262405\n","Epoch:  3054 | train loss: 0.314172 | valid loss: 0.262377\n","Epoch:  3055 | train loss: 0.278511 | valid loss: 0.262316\n","Epoch:  3056 | train loss: 0.228759 | valid loss: 0.262313\n","Epoch:  3057 | train loss: 0.274835 | valid loss: 0.262282\n","Epoch:  3058 | train loss: 0.287023 | valid loss: 0.262319\n","Epoch:  3059 | train loss: 0.247743 | valid loss: 0.262265\n","Epoch:  3060 | train loss: 0.277848 | valid loss: 0.262157\n","Epoch:  3061 | train loss: 0.251120 | valid loss: 0.262385\n","Epoch:  3062 | train loss: 0.320840 | valid loss: 0.262175\n","Epoch:  3063 | train loss: 0.278237 | valid loss: 0.262107\n","Epoch:  3064 | train loss: 0.282911 | valid loss: 0.262159\n","Epoch:  3065 | train loss: 0.231029 | valid loss: 0.261995\n","Epoch:  3066 | train loss: 0.271863 | valid loss: 0.262174\n","Epoch:  3067 | train loss: 0.282656 | valid loss: 0.262050\n","Epoch:  3068 | train loss: 0.327056 | valid loss: 0.262049\n","Epoch:  3069 | train loss: 0.336889 | valid loss: 0.261971\n","Epoch:  3070 | train loss: 0.277961 | valid loss: 0.262107\n","Epoch:  3071 | train loss: 0.273899 | valid loss: 0.261865\n","Epoch:  3072 | train loss: 0.210881 | valid loss: 0.261733\n","Epoch:  3073 | train loss: 0.296516 | valid loss: 0.261745\n","Epoch:  3074 | train loss: 0.221118 | valid loss: 0.261780\n","Epoch:  3075 | train loss: 0.323360 | valid loss: 0.261751\n","Epoch:  3076 | train loss: 0.493415 | valid loss: 0.261695\n","Epoch:  3077 | train loss: 0.278091 | valid loss: 0.261680\n","Epoch:  3078 | train loss: 0.354165 | valid loss: 0.261705\n","Epoch:  3079 | train loss: 0.267250 | valid loss: 0.261825\n","Epoch:  3080 | train loss: 0.302243 | valid loss: 0.261699\n","Epoch:  3081 | train loss: 0.288581 | valid loss: 0.261724\n","Epoch:  3082 | train loss: 0.195920 | valid loss: 0.261677\n","Epoch:  3083 | train loss: 0.274360 | valid loss: 0.261611\n","Epoch:  3084 | train loss: 0.273825 | valid loss: 0.261564\n","Epoch:  3085 | train loss: 0.316075 | valid loss: 0.261593\n","Epoch:  3086 | train loss: 0.249009 | valid loss: 0.261591\n","Epoch:  3087 | train loss: 0.319063 | valid loss: 0.261529\n","Epoch:  3088 | train loss: 0.187179 | valid loss: 0.261666\n","Epoch:  3089 | train loss: 0.292854 | valid loss: 0.261511\n","Epoch:  3090 | train loss: 0.310806 | valid loss: 0.261492\n","Epoch:  3091 | train loss: 0.271296 | valid loss: 0.261417\n","Epoch:  3092 | train loss: 0.264546 | valid loss: 0.261398\n","Epoch:  3093 | train loss: 0.255839 | valid loss: 0.261399\n","Epoch:  3094 | train loss: 0.311070 | valid loss: 0.261368\n","Epoch:  3095 | train loss: 0.274669 | valid loss: 0.261259\n","Epoch:  3096 | train loss: 0.294188 | valid loss: 0.261354\n","Epoch:  3097 | train loss: 0.302920 | valid loss: 0.261315\n","Epoch:  3098 | train loss: 0.322021 | valid loss: 0.261271\n","Epoch:  3099 | train loss: 0.266411 | valid loss: 0.261281\n","Epoch:  3100 | train loss: 0.261843 | valid loss: 0.261200\n","Epoch:  3101 | train loss: 0.258902 | valid loss: 0.261198\n","Epoch:  3102 | train loss: 0.209834 | valid loss: 0.260993\n","Epoch:  3103 | train loss: 0.235967 | valid loss: 0.260943\n","Epoch:  3104 | train loss: 0.329656 | valid loss: 0.261105\n","Epoch:  3105 | train loss: 0.346115 | valid loss: 0.261012\n","Epoch:  3106 | train loss: 0.260519 | valid loss: 0.260822\n","Epoch:  3107 | train loss: 0.282492 | valid loss: 0.261003\n","Epoch:  3108 | train loss: 0.291093 | valid loss: 0.260886\n","Epoch:  3109 | train loss: 0.301354 | valid loss: 0.260895\n","Epoch:  3110 | train loss: 0.230423 | valid loss: 0.260873\n","Epoch:  3111 | train loss: 0.225274 | valid loss: 0.260841\n","Epoch:  3112 | train loss: 0.406750 | valid loss: 0.260674\n","Epoch:  3113 | train loss: 0.246154 | valid loss: 0.260791\n","Epoch:  3114 | train loss: 0.250493 | valid loss: 0.260780\n","Epoch:  3115 | train loss: 0.290322 | valid loss: 0.260817\n","Epoch:  3116 | train loss: 0.264111 | valid loss: 0.260783\n","Epoch:  3117 | train loss: 0.323075 | valid loss: 0.260713\n","Epoch:  3118 | train loss: 0.273796 | valid loss: 0.260774\n","Epoch:  3119 | train loss: 0.253033 | valid loss: 0.260782\n","Epoch:  3120 | train loss: 0.338877 | valid loss: 0.260634\n","Epoch:  3121 | train loss: 0.299272 | valid loss: 0.260687\n","Epoch:  3122 | train loss: 0.452673 | valid loss: 0.260764\n","Epoch:  3123 | train loss: 0.234896 | valid loss: 0.260588\n","Epoch:  3124 | train loss: 0.246887 | valid loss: 0.260618\n","Epoch:  3125 | train loss: 0.260635 | valid loss: 0.260663\n","Epoch:  3126 | train loss: 0.228242 | valid loss: 0.260711\n","Epoch:  3127 | train loss: 0.279811 | valid loss: 0.260384\n","Epoch:  3128 | train loss: 0.247385 | valid loss: 0.260497\n","Epoch:  3129 | train loss: 0.377973 | valid loss: 0.260461\n","Epoch:  3130 | train loss: 0.358194 | valid loss: 0.260570\n","Epoch:  3131 | train loss: 0.457759 | valid loss: 0.260413\n","Epoch:  3132 | train loss: 0.226005 | valid loss: 0.260302\n","Epoch:  3133 | train loss: 0.280207 | valid loss: 0.260476\n","Epoch:  3134 | train loss: 0.254968 | valid loss: 0.260485\n","Epoch:  3135 | train loss: 0.301824 | valid loss: 0.260347\n","Epoch:  3136 | train loss: 0.326331 | valid loss: 0.260294\n","Epoch:  3137 | train loss: 0.318462 | valid loss: 0.260210\n","Epoch:  3138 | train loss: 0.296266 | valid loss: 0.260127\n","Epoch:  3139 | train loss: 0.268189 | valid loss: 0.260168\n","Epoch:  3140 | train loss: 0.170142 | valid loss: 0.260241\n","Epoch:  3141 | train loss: 0.326121 | valid loss: 0.260216\n","Epoch:  3142 | train loss: 0.252764 | valid loss: 0.260216\n","Epoch:  3143 | train loss: 0.442293 | valid loss: 0.260054\n","Epoch:  3144 | train loss: 0.297526 | valid loss: 0.260074\n","Epoch:  3145 | train loss: 0.269019 | valid loss: 0.260060\n","Epoch:  3146 | train loss: 0.325889 | valid loss: 0.260047\n","Epoch:  3147 | train loss: 0.243095 | valid loss: 0.259948\n","Epoch:  3148 | train loss: 0.282215 | valid loss: 0.259978\n","Epoch:  3149 | train loss: 0.321932 | valid loss: 0.260107\n","Epoch:  3150 | train loss: 0.289420 | valid loss: 0.259997\n","Epoch:  3151 | train loss: 0.253076 | valid loss: 0.259925\n","Epoch:  3152 | train loss: 0.277275 | valid loss: 0.259837\n","Epoch:  3153 | train loss: 0.336133 | valid loss: 0.259860\n","Epoch:  3154 | train loss: 0.272220 | valid loss: 0.259947\n","Epoch:  3155 | train loss: 0.308292 | valid loss: 0.259768\n","Epoch:  3156 | train loss: 0.318709 | valid loss: 0.259830\n","Epoch:  3157 | train loss: 0.264689 | valid loss: 0.259813\n","Epoch:  3158 | train loss: 0.304858 | valid loss: 0.259762\n","Epoch:  3159 | train loss: 0.312508 | valid loss: 0.259698\n","Epoch:  3160 | train loss: 0.299148 | valid loss: 0.259723\n","Epoch:  3161 | train loss: 0.306562 | valid loss: 0.259736\n","Epoch:  3162 | train loss: 0.241315 | valid loss: 0.259762\n","Epoch:  3163 | train loss: 0.251726 | valid loss: 0.259739\n","Epoch:  3164 | train loss: 0.311015 | valid loss: 0.259722\n","Epoch:  3165 | train loss: 0.233221 | valid loss: 0.259628\n","Epoch:  3166 | train loss: 0.306944 | valid loss: 0.259724\n","Epoch:  3167 | train loss: 0.207908 | valid loss: 0.259687\n","Epoch:  3168 | train loss: 0.254733 | valid loss: 0.259553\n","Epoch:  3169 | train loss: 0.332900 | valid loss: 0.259460\n","Epoch:  3170 | train loss: 0.226674 | valid loss: 0.259548\n","Epoch:  3171 | train loss: 0.291604 | valid loss: 0.259447\n","Epoch:  3172 | train loss: 0.213145 | valid loss: 0.259462\n","Epoch:  3173 | train loss: 0.242486 | valid loss: 0.259524\n","Epoch:  3174 | train loss: 0.197956 | valid loss: 0.259530\n","Epoch:  3175 | train loss: 0.294909 | valid loss: 0.259418\n","Epoch:  3176 | train loss: 0.315336 | valid loss: 0.259406\n","Epoch:  3177 | train loss: 0.257946 | valid loss: 0.259360\n","Epoch:  3178 | train loss: 0.304938 | valid loss: 0.259345\n","Epoch:  3179 | train loss: 0.233421 | valid loss: 0.259311\n","Epoch:  3180 | train loss: 0.217836 | valid loss: 0.259259\n","Epoch:  3181 | train loss: 0.254048 | valid loss: 0.259227\n","Epoch:  3182 | train loss: 0.243038 | valid loss: 0.259391\n","Epoch:  3183 | train loss: 0.220655 | valid loss: 0.259296\n","Epoch:  3184 | train loss: 0.325454 | valid loss: 0.259263\n","Epoch:  3185 | train loss: 0.262962 | valid loss: 0.259264\n","Epoch:  3186 | train loss: 0.283831 | valid loss: 0.259148\n","Epoch:  3187 | train loss: 0.187848 | valid loss: 0.259224\n","Epoch:  3188 | train loss: 0.304825 | valid loss: 0.259150\n","Epoch:  3189 | train loss: 0.280927 | valid loss: 0.259162\n","Epoch:  3190 | train loss: 0.276058 | valid loss: 0.259083\n","Epoch:  3191 | train loss: 0.300396 | valid loss: 0.259213\n","Epoch:  3192 | train loss: 0.269992 | valid loss: 0.259069\n","Epoch:  3193 | train loss: 0.235351 | valid loss: 0.258939\n","Epoch:  3194 | train loss: 0.335247 | valid loss: 0.259010\n","Epoch:  3195 | train loss: 0.269955 | valid loss: 0.259002\n","Epoch:  3196 | train loss: 0.273631 | valid loss: 0.259038\n","Epoch:  3197 | train loss: 0.255583 | valid loss: 0.259136\n","Epoch:  3198 | train loss: 0.291367 | valid loss: 0.259065\n","Epoch:  3199 | train loss: 0.228438 | valid loss: 0.258924\n","Epoch:  3200 | train loss: 0.242973 | valid loss: 0.258867\n","Epoch:  3201 | train loss: 0.263919 | valid loss: 0.258940\n","Epoch:  3202 | train loss: 0.249299 | valid loss: 0.258815\n","Epoch:  3203 | train loss: 0.273491 | valid loss: 0.258814\n","Epoch:  3204 | train loss: 0.212108 | valid loss: 0.258826\n","Epoch:  3205 | train loss: 0.205091 | valid loss: 0.258864\n","Epoch:  3206 | train loss: 0.277036 | valid loss: 0.258995\n","Epoch:  3207 | train loss: 0.239486 | valid loss: 0.258763\n","Epoch:  3208 | train loss: 0.278711 | valid loss: 0.258818\n","Epoch:  3209 | train loss: 0.248797 | valid loss: 0.258742\n","Epoch:  3210 | train loss: 0.272122 | valid loss: 0.258712\n","Epoch:  3211 | train loss: 0.279819 | valid loss: 0.258753\n","Epoch:  3212 | train loss: 0.266224 | valid loss: 0.258562\n","Epoch:  3213 | train loss: 0.290008 | valid loss: 0.258615\n","Epoch:  3214 | train loss: 0.303368 | valid loss: 0.258658\n","Epoch:  3215 | train loss: 0.284830 | valid loss: 0.258673\n","Epoch:  3216 | train loss: 0.249851 | valid loss: 0.258783\n","Epoch:  3217 | train loss: 0.149251 | valid loss: 0.258608\n","Epoch:  3218 | train loss: 0.234596 | valid loss: 0.258574\n","Epoch:  3219 | train loss: 0.249769 | valid loss: 0.258580\n","Epoch:  3220 | train loss: 0.263560 | valid loss: 0.258533\n","Epoch:  3221 | train loss: 0.265505 | valid loss: 0.258652\n","Epoch:  3222 | train loss: 0.276985 | valid loss: 0.258488\n","Epoch:  3223 | train loss: 0.265124 | valid loss: 0.258503\n","Epoch:  3224 | train loss: 0.247302 | valid loss: 0.258355\n","Epoch:  3225 | train loss: 0.284576 | valid loss: 0.258423\n","Epoch:  3226 | train loss: 0.259069 | valid loss: 0.258441\n","Epoch:  3227 | train loss: 0.239442 | valid loss: 0.258447\n","Epoch:  3228 | train loss: 0.236192 | valid loss: 0.258356\n","Epoch:  3229 | train loss: 0.214318 | valid loss: 0.258386\n","Epoch:  3230 | train loss: 0.252543 | valid loss: 0.258273\n","Epoch:  3231 | train loss: 0.210262 | valid loss: 0.258294\n","Epoch:  3232 | train loss: 0.271391 | valid loss: 0.258306\n","Epoch:  3233 | train loss: 0.343516 | valid loss: 0.258225\n","Epoch:  3234 | train loss: 0.226330 | valid loss: 0.258309\n","Epoch:  3235 | train loss: 0.302970 | valid loss: 0.258241\n","Epoch:  3236 | train loss: 0.255270 | valid loss: 0.258269\n","Epoch:  3237 | train loss: 0.213959 | valid loss: 0.258156\n","Epoch:  3238 | train loss: 0.240031 | valid loss: 0.258116\n","Epoch:  3239 | train loss: 0.304232 | valid loss: 0.258286\n","Epoch:  3240 | train loss: 0.259030 | valid loss: 0.258334\n","Epoch:  3241 | train loss: 0.238543 | valid loss: 0.258264\n","Epoch:  3242 | train loss: 0.240112 | valid loss: 0.258210\n","Epoch:  3243 | train loss: 0.216735 | valid loss: 0.258111\n","Epoch:  3244 | train loss: 0.217274 | valid loss: 0.258167\n","Epoch:  3245 | train loss: 0.256171 | valid loss: 0.258175\n","Epoch:  3246 | train loss: 0.286526 | valid loss: 0.258177\n","Epoch:  3247 | train loss: 0.235416 | valid loss: 0.258100\n","Epoch:  3248 | train loss: 0.247325 | valid loss: 0.258078\n","Epoch:  3249 | train loss: 0.310654 | valid loss: 0.258107\n","Epoch:  3250 | train loss: 0.273422 | valid loss: 0.257936\n","Epoch:  3251 | train loss: 0.289191 | valid loss: 0.258075\n","Epoch:  3252 | train loss: 0.248405 | valid loss: 0.258012\n","Epoch:  3253 | train loss: 0.237229 | valid loss: 0.257884\n","Epoch:  3254 | train loss: 0.273874 | valid loss: 0.257793\n","Epoch:  3255 | train loss: 0.303688 | valid loss: 0.258008\n","Epoch:  3256 | train loss: 0.242492 | valid loss: 0.257933\n","Epoch:  3257 | train loss: 0.309694 | valid loss: 0.257995\n","Epoch:  3258 | train loss: 0.319573 | valid loss: 0.257909\n","Epoch:  3259 | train loss: 0.295569 | valid loss: 0.257775\n","Epoch:  3260 | train loss: 0.257404 | valid loss: 0.257797\n","Epoch:  3261 | train loss: 0.258943 | valid loss: 0.257820\n","Epoch:  3262 | train loss: 0.293487 | valid loss: 0.257913\n","Epoch:  3263 | train loss: 0.340369 | valid loss: 0.257865\n","Epoch:  3264 | train loss: 0.324299 | valid loss: 0.257845\n","Epoch:  3265 | train loss: 0.267305 | valid loss: 0.257762\n","Epoch:  3266 | train loss: 0.310951 | valid loss: 0.257850\n","Epoch:  3267 | train loss: 0.269944 | valid loss: 0.257808\n","Epoch:  3268 | train loss: 0.462453 | valid loss: 0.257683\n","Epoch:  3269 | train loss: 0.353494 | valid loss: 0.257774\n","Epoch:  3270 | train loss: 0.239159 | valid loss: 0.257811\n","Epoch:  3271 | train loss: 0.320027 | valid loss: 0.257752\n","Epoch:  3272 | train loss: 0.268711 | valid loss: 0.257706\n","Epoch:  3273 | train loss: 0.294750 | valid loss: 0.257693\n","Epoch:  3274 | train loss: 0.261689 | valid loss: 0.257691\n","Epoch:  3275 | train loss: 0.212138 | valid loss: 0.257533\n","Epoch:  3276 | train loss: 0.284177 | valid loss: 0.257712\n","Epoch:  3277 | train loss: 0.243953 | valid loss: 0.257619\n","Epoch:  3278 | train loss: 0.323516 | valid loss: 0.257622\n","Epoch:  3279 | train loss: 0.267216 | valid loss: 0.257559\n","Epoch:  3280 | train loss: 0.276274 | valid loss: 0.257722\n","Epoch:  3281 | train loss: 0.219506 | valid loss: 0.257601\n","Epoch:  3282 | train loss: 0.280118 | valid loss: 0.257558\n","Epoch:  3283 | train loss: 0.289312 | valid loss: 0.257544\n","Epoch:  3284 | train loss: 0.243498 | valid loss: 0.257468\n","Epoch:  3285 | train loss: 0.182204 | valid loss: 0.257573\n","Epoch:  3286 | train loss: 0.226932 | valid loss: 0.257426\n","Epoch:  3287 | train loss: 0.263723 | valid loss: 0.257466\n","Epoch:  3288 | train loss: 0.291294 | valid loss: 0.257577\n","Epoch:  3289 | train loss: 0.328409 | valid loss: 0.257543\n","Epoch:  3290 | train loss: 0.334281 | valid loss: 0.257452\n","Epoch:  3291 | train loss: 0.339440 | valid loss: 0.257439\n","Epoch:  3292 | train loss: 0.265816 | valid loss: 0.257378\n","Epoch:  3293 | train loss: 0.211421 | valid loss: 0.257443\n","Epoch:  3294 | train loss: 0.259302 | valid loss: 0.257320\n","Epoch:  3295 | train loss: 0.289488 | valid loss: 0.257299\n","Epoch:  3296 | train loss: 0.200821 | valid loss: 0.257206\n","Epoch:  3297 | train loss: 0.274241 | valid loss: 0.257462\n","Epoch:  3298 | train loss: 0.181692 | valid loss: 0.257331\n","Epoch:  3299 | train loss: 0.284797 | valid loss: 0.257528\n","Epoch:  3300 | train loss: 0.214397 | valid loss: 0.257278\n","Epoch:  3301 | train loss: 0.354252 | valid loss: 0.257462\n","Epoch:  3302 | train loss: 0.262698 | valid loss: 0.257285\n","Epoch:  3303 | train loss: 0.376504 | valid loss: 0.257271\n","Epoch:  3304 | train loss: 0.301470 | valid loss: 0.257247\n","Epoch:  3305 | train loss: 0.265355 | valid loss: 0.257161\n","Epoch:  3306 | train loss: 0.314737 | valid loss: 0.257360\n","Epoch:  3307 | train loss: 0.248753 | valid loss: 0.257133\n","Epoch:  3308 | train loss: 0.280605 | valid loss: 0.257169\n","Epoch:  3309 | train loss: 0.206956 | valid loss: 0.257222\n","Epoch:  3310 | train loss: 0.237055 | valid loss: 0.257150\n","Epoch:  3311 | train loss: 0.207757 | valid loss: 0.257224\n","Epoch:  3312 | train loss: 0.254083 | valid loss: 0.257356\n","Epoch:  3313 | train loss: 0.191904 | valid loss: 0.257193\n","Epoch:  3314 | train loss: 0.346501 | valid loss: 0.257204\n","Epoch:  3315 | train loss: 0.251281 | valid loss: 0.257106\n","Epoch:  3316 | train loss: 0.269080 | valid loss: 0.257301\n","Epoch:  3317 | train loss: 0.254915 | valid loss: 0.257252\n","Epoch:  3318 | train loss: 0.326558 | valid loss: 0.257099\n","Epoch:  3319 | train loss: 0.256555 | valid loss: 0.257151\n","Epoch:  3320 | train loss: 0.208468 | valid loss: 0.257251\n","Epoch:  3321 | train loss: 0.314089 | valid loss: 0.257095\n","Epoch:  3322 | train loss: 0.288153 | valid loss: 0.257131\n","Epoch:  3323 | train loss: 0.210814 | valid loss: 0.257082\n","Epoch:  3324 | train loss: 0.278443 | valid loss: 0.257200\n","Epoch:  3325 | train loss: 0.371295 | valid loss: 0.257137\n","Epoch:  3326 | train loss: 0.324436 | valid loss: 0.257029\n","Epoch:  3327 | train loss: 0.258154 | valid loss: 0.257148\n","Epoch:  3328 | train loss: 0.277743 | valid loss: 0.256942\n","Epoch:  3329 | train loss: 0.206763 | valid loss: 0.257121\n","Epoch:  3330 | train loss: 0.266903 | valid loss: 0.256995\n","Epoch:  3331 | train loss: 0.231824 | valid loss: 0.256841\n","Epoch:  3332 | train loss: 0.314717 | valid loss: 0.256986\n","Epoch:  3333 | train loss: 0.288029 | valid loss: 0.256926\n","Epoch:  3334 | train loss: 0.206193 | valid loss: 0.256878\n","Epoch:  3335 | train loss: 0.220246 | valid loss: 0.256838\n","Epoch:  3336 | train loss: 0.295090 | valid loss: 0.256919\n","Epoch:  3337 | train loss: 0.239574 | valid loss: 0.256964\n","Epoch:  3338 | train loss: 0.546513 | valid loss: 0.256898\n","Epoch:  3339 | train loss: 0.325937 | valid loss: 0.256871\n","Epoch:  3340 | train loss: 0.311910 | valid loss: 0.257020\n","Epoch:  3341 | train loss: 0.306653 | valid loss: 0.256927\n","Epoch:  3342 | train loss: 0.348405 | valid loss: 0.256962\n","Epoch:  3343 | train loss: 0.218569 | valid loss: 0.256854\n","Epoch:  3344 | train loss: 0.295673 | valid loss: 0.256876\n","Epoch:  3345 | train loss: 0.302914 | valid loss: 0.256906\n","Epoch:  3346 | train loss: 0.273284 | valid loss: 0.256871\n","Epoch:  3347 | train loss: 0.257020 | valid loss: 0.256971\n","Epoch:  3348 | train loss: 0.231325 | valid loss: 0.256835\n","Epoch:  3349 | train loss: 0.208978 | valid loss: 0.256773\n","Epoch:  3350 | train loss: 0.254653 | valid loss: 0.256817\n","Epoch:  3351 | train loss: 0.209289 | valid loss: 0.256863\n","Epoch:  3352 | train loss: 0.321975 | valid loss: 0.256832\n","Epoch:  3353 | train loss: 0.267140 | valid loss: 0.256941\n","Epoch:  3354 | train loss: 0.265893 | valid loss: 0.256797\n","Epoch:  3355 | train loss: 0.178428 | valid loss: 0.256779\n","Epoch:  3356 | train loss: 0.328315 | valid loss: 0.256854\n","Epoch:  3357 | train loss: 0.307829 | valid loss: 0.257108\n","Epoch:  3358 | train loss: 0.234279 | valid loss: 0.256795\n","Epoch:  3359 | train loss: 0.242279 | valid loss: 0.256754\n","Epoch:  3360 | train loss: 0.348382 | valid loss: 0.256911\n","Epoch:  3361 | train loss: 0.333966 | valid loss: 0.256763\n","Epoch:  3362 | train loss: 0.215581 | valid loss: 0.256752\n","Epoch:  3363 | train loss: 0.324112 | valid loss: 0.256739\n","Epoch:  3364 | train loss: 0.267598 | valid loss: 0.256762\n","Epoch:  3365 | train loss: 0.259905 | valid loss: 0.256659\n","Epoch:  3366 | train loss: 0.313560 | valid loss: 0.256682\n","Epoch:  3367 | train loss: 0.282243 | valid loss: 0.256664\n","Epoch:  3368 | train loss: 0.318485 | valid loss: 0.256637\n","Epoch:  3369 | train loss: 0.252897 | valid loss: 0.256655\n","Epoch:  3370 | train loss: 0.268590 | valid loss: 0.256632\n","Epoch:  3371 | train loss: 0.260179 | valid loss: 0.256607\n","Epoch:  3372 | train loss: 0.233758 | valid loss: 0.256642\n","Epoch:  3373 | train loss: 0.255185 | valid loss: 0.256681\n","Epoch:  3374 | train loss: 0.347538 | valid loss: 0.256604\n","Epoch:  3375 | train loss: 0.262725 | valid loss: 0.256600\n","Epoch:  3376 | train loss: 0.271122 | valid loss: 0.256612\n","Epoch:  3377 | train loss: 0.280919 | valid loss: 0.256580\n","Epoch:  3378 | train loss: 0.203264 | valid loss: 0.256601\n","Epoch:  3379 | train loss: 0.312209 | valid loss: 0.256567\n","Epoch:  3380 | train loss: 0.308942 | valid loss: 0.256530\n","Epoch:  3381 | train loss: 0.256835 | valid loss: 0.256604\n","Epoch:  3382 | train loss: 0.282827 | valid loss: 0.256575\n","Epoch:  3383 | train loss: 0.232362 | valid loss: 0.256605\n","Epoch:  3384 | train loss: 0.215664 | valid loss: 0.256572\n","Epoch:  3385 | train loss: 0.287062 | valid loss: 0.256519\n","Epoch:  3386 | train loss: 0.250740 | valid loss: 0.256612\n","Epoch:  3387 | train loss: 0.280331 | valid loss: 0.256509\n","Epoch:  3388 | train loss: 0.259775 | valid loss: 0.256556\n","Epoch:  3389 | train loss: 0.296547 | valid loss: 0.256525\n","Epoch:  3390 | train loss: 0.253829 | valid loss: 0.256489\n","Epoch:  3391 | train loss: 0.298619 | valid loss: 0.256452\n","Epoch:  3392 | train loss: 0.264394 | valid loss: 0.256469\n","Epoch:  3393 | train loss: 0.318360 | valid loss: 0.256494\n","Epoch:  3394 | train loss: 0.248738 | valid loss: 0.256482\n","Epoch:  3395 | train loss: 0.318930 | valid loss: 0.256535\n","Epoch:  3396 | train loss: 0.193705 | valid loss: 0.256437\n","Epoch:  3397 | train loss: 0.274281 | valid loss: 0.256438\n","Epoch:  3398 | train loss: 0.270820 | valid loss: 0.256440\n","Epoch:  3399 | train loss: 0.243839 | valid loss: 0.256440\n","Epoch:  3400 | train loss: 0.184975 | valid loss: 0.256393\n","Epoch:  3401 | train loss: 0.215674 | valid loss: 0.256492\n","Epoch:  3402 | train loss: 0.213003 | valid loss: 0.256408\n","Epoch:  3403 | train loss: 0.257868 | valid loss: 0.256442\n","Epoch:  3404 | train loss: 0.304755 | valid loss: 0.256398\n","Epoch:  3405 | train loss: 0.336750 | valid loss: 0.256393\n","Epoch:  3406 | train loss: 0.233467 | valid loss: 0.256469\n","Epoch:  3407 | train loss: 0.332183 | valid loss: 0.256351\n","Epoch:  3408 | train loss: 0.279429 | valid loss: 0.256350\n","Epoch:  3409 | train loss: 0.224860 | valid loss: 0.256376\n","Epoch:  3410 | train loss: 0.300549 | valid loss: 0.256362\n","Epoch:  3411 | train loss: 0.284332 | valid loss: 0.256305\n","Epoch:  3412 | train loss: 0.308828 | valid loss: 0.256291\n","Epoch:  3413 | train loss: 0.205302 | valid loss: 0.256378\n","Epoch:  3414 | train loss: 0.285986 | valid loss: 0.256450\n","Epoch:  3415 | train loss: 0.320768 | valid loss: 0.256271\n","Epoch:  3416 | train loss: 0.273090 | valid loss: 0.256283\n","Epoch:  3417 | train loss: 0.378799 | valid loss: 0.256283\n","Epoch:  3418 | train loss: 0.256554 | valid loss: 0.256247\n","Epoch:  3419 | train loss: 0.248749 | valid loss: 0.256324\n","Epoch:  3420 | train loss: 0.278420 | valid loss: 0.256322\n","Epoch:  3421 | train loss: 0.240641 | valid loss: 0.256324\n","Epoch:  3422 | train loss: 0.283015 | valid loss: 0.256364\n","Epoch:  3423 | train loss: 0.250050 | valid loss: 0.256249\n","Epoch:  3424 | train loss: 0.262541 | valid loss: 0.256296\n","Epoch:  3425 | train loss: 0.238481 | valid loss: 0.256207\n","Epoch:  3426 | train loss: 0.312160 | valid loss: 0.256294\n","Epoch:  3427 | train loss: 0.281850 | valid loss: 0.256275\n","Epoch:  3428 | train loss: 0.260909 | valid loss: 0.256178\n","Epoch:  3429 | train loss: 0.248322 | valid loss: 0.256213\n","Epoch:  3430 | train loss: 0.343295 | valid loss: 0.256235\n","Epoch:  3431 | train loss: 0.244576 | valid loss: 0.256301\n","Epoch:  3432 | train loss: 0.248725 | valid loss: 0.256273\n","Epoch:  3433 | train loss: 0.235028 | valid loss: 0.256292\n","Epoch:  3434 | train loss: 0.234872 | valid loss: 0.256264\n","Epoch:  3435 | train loss: 0.420744 | valid loss: 0.256330\n","Epoch:  3436 | train loss: 0.318140 | valid loss: 0.256241\n","Epoch:  3437 | train loss: 0.246876 | valid loss: 0.256135\n","Epoch:  3438 | train loss: 0.252260 | valid loss: 0.256164\n","Epoch:  3439 | train loss: 0.257213 | valid loss: 0.256199\n","Epoch:  3440 | train loss: 0.270317 | valid loss: 0.256162\n","Epoch:  3441 | train loss: 0.226915 | valid loss: 0.256528\n","Epoch:  3442 | train loss: 0.280486 | valid loss: 0.256293\n","Epoch:  3443 | train loss: 0.295168 | valid loss: 0.256103\n","Epoch:  3444 | train loss: 0.323611 | valid loss: 0.256020\n","Epoch:  3445 | train loss: 0.291065 | valid loss: 0.256194\n","Epoch:  3446 | train loss: 0.299130 | valid loss: 0.256090\n","Epoch:  3447 | train loss: 0.338576 | valid loss: 0.256098\n","Epoch:  3448 | train loss: 0.248148 | valid loss: 0.256056\n","Epoch:  3449 | train loss: 0.299288 | valid loss: 0.256194\n","Epoch:  3450 | train loss: 0.279227 | valid loss: 0.256123\n","Epoch:  3451 | train loss: 0.212355 | valid loss: 0.256254\n","Epoch:  3452 | train loss: 0.325862 | valid loss: 0.256166\n","Epoch:  3453 | train loss: 0.284713 | valid loss: 0.256207\n","Epoch:  3454 | train loss: 0.247925 | valid loss: 0.256199\n","Epoch:  3455 | train loss: 0.293425 | valid loss: 0.256195\n","Epoch:  3456 | train loss: 0.336159 | valid loss: 0.256077\n","Epoch:  3457 | train loss: 0.328059 | valid loss: 0.256252\n","Epoch:  3458 | train loss: 0.226302 | valid loss: 0.256067\n","Epoch:  3459 | train loss: 0.248585 | valid loss: 0.256056\n","Epoch:  3460 | train loss: 0.254039 | valid loss: 0.256140\n","Epoch:  3461 | train loss: 0.246944 | valid loss: 0.256049\n","Epoch:  3462 | train loss: 0.263566 | valid loss: 0.256020\n","Epoch:  3463 | train loss: 0.247824 | valid loss: 0.256171\n","Epoch:  3464 | train loss: 0.304929 | valid loss: 0.256240\n","Epoch:  3465 | train loss: 0.353252 | valid loss: 0.256283\n","Epoch:  3466 | train loss: 0.286381 | valid loss: 0.256286\n","Epoch:  3467 | train loss: 0.224373 | valid loss: 0.256198\n","Epoch:  3468 | train loss: 0.297571 | valid loss: 0.256251\n","Epoch:  3469 | train loss: 0.352348 | valid loss: 0.256011\n","Epoch:  3470 | train loss: 0.277332 | valid loss: 0.256060\n","Epoch:  3471 | train loss: 0.208678 | valid loss: 0.256046\n","Epoch:  3472 | train loss: 0.362463 | valid loss: 0.256087\n","Epoch:  3473 | train loss: 0.254531 | valid loss: 0.255967\n","Epoch:  3474 | train loss: 0.234784 | valid loss: 0.256105\n","Epoch:  3475 | train loss: 0.232731 | valid loss: 0.256058\n","Epoch:  3476 | train loss: 0.276608 | valid loss: 0.256088\n","Epoch:  3477 | train loss: 0.251692 | valid loss: 0.256401\n","Epoch:  3478 | train loss: 0.265466 | valid loss: 0.256101\n","Epoch:  3479 | train loss: 0.298306 | valid loss: 0.256000\n","Epoch:  3480 | train loss: 0.270249 | valid loss: 0.256082\n","Epoch:  3481 | train loss: 0.285729 | valid loss: 0.256145\n","Epoch:  3482 | train loss: 0.345528 | valid loss: 0.256074\n","Epoch:  3483 | train loss: 0.240586 | valid loss: 0.256024\n","Epoch:  3484 | train loss: 0.317156 | valid loss: 0.256030\n","Epoch:  3485 | train loss: 0.235653 | valid loss: 0.256023\n","Epoch:  3486 | train loss: 0.255096 | valid loss: 0.256104\n","Epoch:  3487 | train loss: 0.203752 | valid loss: 0.256076\n","Epoch:  3488 | train loss: 0.250693 | valid loss: 0.256094\n","Epoch:  3489 | train loss: 0.259907 | valid loss: 0.256110\n","Epoch:  3490 | train loss: 0.252647 | valid loss: 0.255993\n","Epoch:  3491 | train loss: 0.257075 | valid loss: 0.256133\n","Epoch:  3492 | train loss: 0.272702 | valid loss: 0.256106\n","Epoch:  3493 | train loss: 0.222769 | valid loss: 0.255943\n","Epoch:  3494 | train loss: 0.254938 | valid loss: 0.256015\n","Epoch:  3495 | train loss: 0.234078 | valid loss: 0.256038\n","Epoch:  3496 | train loss: 0.231140 | valid loss: 0.255854\n","Epoch:  3497 | train loss: 0.247141 | valid loss: 0.256063\n","Epoch:  3498 | train loss: 0.302057 | valid loss: 0.256084\n","Epoch:  3499 | train loss: 0.276837 | valid loss: 0.255890\n","Epoch:  3500 | train loss: 0.314477 | valid loss: 0.255975\n","Epoch:  3501 | train loss: 0.277444 | valid loss: 0.255960\n","Epoch:  3502 | train loss: 0.307710 | valid loss: 0.256012\n","Epoch:  3503 | train loss: 0.232899 | valid loss: 0.256066\n","Epoch:  3504 | train loss: 0.278259 | valid loss: 0.255944\n","Epoch:  3505 | train loss: 0.302055 | valid loss: 0.255909\n","Epoch:  3506 | train loss: 0.251312 | valid loss: 0.255982\n","Epoch:  3507 | train loss: 0.241094 | valid loss: 0.255966\n","Epoch:  3508 | train loss: 0.302649 | valid loss: 0.255963\n","Epoch:  3509 | train loss: 0.251031 | valid loss: 0.256015\n","Epoch:  3510 | train loss: 0.278824 | valid loss: 0.255960\n","Epoch:  3511 | train loss: 0.224688 | valid loss: 0.255930\n","Epoch:  3512 | train loss: 0.321520 | valid loss: 0.255957\n","Epoch:  3513 | train loss: 0.219555 | valid loss: 0.255985\n","Epoch:  3514 | train loss: 0.242996 | valid loss: 0.255970\n","Epoch:  3515 | train loss: 0.282612 | valid loss: 0.255988\n","Epoch:  3516 | train loss: 0.246904 | valid loss: 0.255968\n","Epoch:  3517 | train loss: 0.314441 | valid loss: 0.255982\n","Epoch:  3518 | train loss: 0.252582 | valid loss: 0.256047\n","Epoch:  3519 | train loss: 0.243492 | valid loss: 0.255947\n","Epoch:  3520 | train loss: 0.226350 | valid loss: 0.255960\n","Epoch:  3521 | train loss: 0.348913 | valid loss: 0.256061\n","Epoch:  3522 | train loss: 0.215098 | valid loss: 0.256025\n","Epoch:  3523 | train loss: 0.316595 | valid loss: 0.256039\n","Epoch:  3524 | train loss: 0.226452 | valid loss: 0.255957\n","Epoch:  3525 | train loss: 0.275039 | valid loss: 0.255930\n","Epoch:  3526 | train loss: 0.244994 | valid loss: 0.255811\n","Epoch:  3527 | train loss: 0.267123 | valid loss: 0.255856\n","Epoch:  3528 | train loss: 0.254356 | valid loss: 0.255936\n","Epoch:  3529 | train loss: 0.324576 | valid loss: 0.255862\n","Epoch:  3530 | train loss: 0.289964 | valid loss: 0.256028\n","Epoch:  3531 | train loss: 0.222768 | valid loss: 0.255732\n","Epoch:  3532 | train loss: 0.232655 | valid loss: 0.255919\n","Epoch:  3533 | train loss: 0.314112 | valid loss: 0.255905\n","Epoch:  3534 | train loss: 0.233606 | valid loss: 0.255933\n","Epoch:  3535 | train loss: 0.252811 | valid loss: 0.255933\n","Epoch:  3536 | train loss: 0.239074 | valid loss: 0.255863\n","Epoch:  3537 | train loss: 0.234606 | valid loss: 0.255879\n","Epoch:  3538 | train loss: 0.417706 | valid loss: 0.256003\n","Epoch:  3539 | train loss: 0.244260 | valid loss: 0.255815\n","Epoch:  3540 | train loss: 0.242028 | valid loss: 0.255886\n","Epoch:  3541 | train loss: 0.262276 | valid loss: 0.255896\n","Epoch:  3542 | train loss: 0.309883 | valid loss: 0.255943\n","Epoch:  3543 | train loss: 0.199860 | valid loss: 0.255946\n","Epoch:  3544 | train loss: 0.182934 | valid loss: 0.256016\n","Epoch:  3545 | train loss: 0.236316 | valid loss: 0.255944\n","Epoch:  3546 | train loss: 0.327817 | valid loss: 0.255907\n","Epoch:  3547 | train loss: 0.341698 | valid loss: 0.255902\n","Epoch:  3548 | train loss: 0.266278 | valid loss: 0.255907\n","Epoch:  3549 | train loss: 0.318769 | valid loss: 0.256037\n","Epoch:  3550 | train loss: 0.290720 | valid loss: 0.255862\n","Epoch:  3551 | train loss: 0.187858 | valid loss: 0.255805\n","Epoch:  3552 | train loss: 0.243677 | valid loss: 0.255681\n","Epoch:  3553 | train loss: 0.235629 | valid loss: 0.255819\n","Epoch:  3554 | train loss: 0.206144 | valid loss: 0.255807\n","Epoch:  3555 | train loss: 0.240266 | valid loss: 0.255831\n","Epoch:  3556 | train loss: 0.281731 | valid loss: 0.255745\n","Epoch:  3557 | train loss: 0.302011 | valid loss: 0.255889\n","Epoch:  3558 | train loss: 0.249184 | valid loss: 0.255884\n","Epoch:  3559 | train loss: 0.366000 | valid loss: 0.255900\n","Epoch:  3560 | train loss: 0.296717 | valid loss: 0.255971\n","Epoch:  3561 | train loss: 0.249403 | valid loss: 0.256147\n","Epoch:  3562 | train loss: 0.280232 | valid loss: 0.255975\n","Epoch:  3563 | train loss: 0.295478 | valid loss: 0.255981\n","Epoch:  3564 | train loss: 0.243899 | valid loss: 0.255780\n","Epoch:  3565 | train loss: 0.253035 | valid loss: 0.255842\n","Epoch:  3566 | train loss: 0.286613 | valid loss: 0.255861\n","Epoch:  3567 | train loss: 0.246853 | valid loss: 0.255840\n","Epoch:  3568 | train loss: 0.250490 | valid loss: 0.255958\n","Epoch:  3569 | train loss: 0.341313 | valid loss: 0.255988\n","Epoch:  3570 | train loss: 0.296225 | valid loss: 0.255865\n","Epoch:  3571 | train loss: 0.226457 | valid loss: 0.255827\n","Epoch:  3572 | train loss: 0.268486 | valid loss: 0.255928\n","Epoch:  3573 | train loss: 0.273839 | valid loss: 0.255857\n","Epoch:  3574 | train loss: 0.283339 | valid loss: 0.255799\n","Epoch:  3575 | train loss: 0.289160 | valid loss: 0.255944\n","Epoch:  3576 | train loss: 0.226643 | valid loss: 0.255874\n","Epoch:  3577 | train loss: 0.293612 | valid loss: 0.255801\n","Epoch:  3578 | train loss: 0.256068 | valid loss: 0.255926\n","Epoch:  3579 | train loss: 0.328812 | valid loss: 0.255825\n","Epoch:  3580 | train loss: 0.244521 | valid loss: 0.255888\n","Epoch:  3581 | train loss: 0.167329 | valid loss: 0.255913\n","Epoch:  3582 | train loss: 0.229658 | valid loss: 0.255842\n","Epoch:  3583 | train loss: 0.198675 | valid loss: 0.255755\n","Epoch:  3584 | train loss: 0.267575 | valid loss: 0.255796\n","Epoch:  3585 | train loss: 0.307478 | valid loss: 0.255890\n","Epoch:  3586 | train loss: 0.313328 | valid loss: 0.255856\n","Epoch:  3587 | train loss: 0.221672 | valid loss: 0.255835\n","Epoch:  3588 | train loss: 0.325390 | valid loss: 0.255803\n","Epoch:  3589 | train loss: 0.248510 | valid loss: 0.255779\n","Epoch:  3590 | train loss: 0.300890 | valid loss: 0.255896\n","Epoch:  3591 | train loss: 0.287441 | valid loss: 0.255830\n","Epoch:  3592 | train loss: 0.291530 | valid loss: 0.255901\n","Epoch:  3593 | train loss: 0.497709 | valid loss: 0.255722\n","Epoch:  3594 | train loss: 0.284095 | valid loss: 0.255862\n","Epoch:  3595 | train loss: 0.301002 | valid loss: 0.255950\n","Epoch:  3596 | train loss: 0.331493 | valid loss: 0.255835\n","Epoch:  3597 | train loss: 0.317427 | valid loss: 0.255844\n","Epoch:  3598 | train loss: 0.272871 | valid loss: 0.255859\n","Epoch:  3599 | train loss: 0.240151 | valid loss: 0.255883\n","Epoch:  3600 | train loss: 0.274078 | valid loss: 0.255872\n","Epoch:  3601 | train loss: 0.244575 | valid loss: 0.255819\n","Epoch:  3602 | train loss: 0.326550 | valid loss: 0.255851\n","Epoch:  3603 | train loss: 0.307766 | valid loss: 0.255787\n","Epoch:  3604 | train loss: 0.304581 | valid loss: 0.255888\n","Epoch:  3605 | train loss: 0.195001 | valid loss: 0.255748\n","Epoch:  3606 | train loss: 0.190190 | valid loss: 0.255823\n","Epoch:  3607 | train loss: 0.406909 | valid loss: 0.255899\n","Epoch:  3608 | train loss: 0.186192 | valid loss: 0.255786\n","Epoch:  3609 | train loss: 0.245437 | valid loss: 0.255758\n","Epoch:  3610 | train loss: 0.293615 | valid loss: 0.255766\n","Epoch:  3611 | train loss: 0.245902 | valid loss: 0.255813\n","Epoch:  3612 | train loss: 0.198576 | valid loss: 0.255772\n","Epoch:  3613 | train loss: 0.288053 | valid loss: 0.255778\n","Epoch:  3614 | train loss: 0.262068 | valid loss: 0.255712\n","Epoch:  3615 | train loss: 0.349520 | valid loss: 0.255779\n","Epoch:  3616 | train loss: 0.291651 | valid loss: 0.255918\n","Epoch:  3617 | train loss: 0.282784 | valid loss: 0.255807\n","Epoch:  3618 | train loss: 0.236107 | valid loss: 0.255840\n","Epoch:  3619 | train loss: 0.380021 | valid loss: 0.255848\n","Epoch:  3620 | train loss: 0.251912 | valid loss: 0.255804\n","Epoch:  3621 | train loss: 0.224789 | valid loss: 0.255791\n","Epoch:  3622 | train loss: 0.211224 | valid loss: 0.255841\n","Epoch:  3623 | train loss: 0.348893 | valid loss: 0.255842\n","Epoch:  3624 | train loss: 0.246137 | valid loss: 0.255775\n","Epoch:  3625 | train loss: 0.304130 | valid loss: 0.255894\n","Epoch:  3626 | train loss: 0.271973 | valid loss: 0.255788\n","Epoch:  3627 | train loss: 0.275607 | valid loss: 0.255790\n","Epoch:  3628 | train loss: 0.279353 | valid loss: 0.255824\n","Epoch:  3629 | train loss: 0.321077 | valid loss: 0.255757\n","Epoch:  3630 | train loss: 0.208876 | valid loss: 0.255870\n","Epoch:  3631 | train loss: 0.212029 | valid loss: 0.255824\n","Epoch:  3632 | train loss: 0.251037 | valid loss: 0.255793\n","Epoch:  3633 | train loss: 0.300254 | valid loss: 0.255915\n","Epoch:  3634 | train loss: 0.195665 | valid loss: 0.255790\n","Epoch:  3635 | train loss: 0.226139 | valid loss: 0.255882\n","Epoch:  3636 | train loss: 0.309210 | valid loss: 0.256125\n","Epoch:  3637 | train loss: 0.270207 | valid loss: 0.255776\n","Epoch:  3638 | train loss: 0.206454 | valid loss: 0.255731\n","Epoch:  3639 | train loss: 0.225544 | valid loss: 0.255789\n","Epoch:  3640 | train loss: 0.243045 | valid loss: 0.255762\n","Epoch:  3641 | train loss: 0.192505 | valid loss: 0.255857\n","Epoch:  3642 | train loss: 0.237649 | valid loss: 0.255883\n","Epoch:  3643 | train loss: 0.274786 | valid loss: 0.255804\n","Epoch:  3644 | train loss: 0.275159 | valid loss: 0.255814\n","Epoch:  3645 | train loss: 0.292554 | valid loss: 0.255748\n","Epoch:  3646 | train loss: 0.209431 | valid loss: 0.255797\n","Epoch:  3647 | train loss: 0.260003 | valid loss: 0.255857\n","Epoch:  3648 | train loss: 0.303075 | valid loss: 0.255986\n","Epoch:  3649 | train loss: 0.222327 | valid loss: 0.255772\n","Epoch:  3650 | train loss: 0.269652 | valid loss: 0.255850\n","Epoch:  3651 | train loss: 0.231104 | valid loss: 0.255787\n","Epoch:  3652 | train loss: 0.285947 | valid loss: 0.255960\n","Epoch:  3653 | train loss: 0.254932 | valid loss: 0.255938\n","Epoch:  3654 | train loss: 0.224716 | valid loss: 0.255838\n","Epoch:  3655 | train loss: 0.243106 | valid loss: 0.255859\n","Epoch:  3656 | train loss: 0.281505 | valid loss: 0.255850\n","Epoch:  3657 | train loss: 0.205761 | valid loss: 0.255873\n","Epoch:  3658 | train loss: 0.312022 | valid loss: 0.255851\n","Epoch:  3659 | train loss: 0.270215 | valid loss: 0.255841\n","Epoch:  3660 | train loss: 0.316894 | valid loss: 0.255793\n","Epoch:  3661 | train loss: 0.272221 | valid loss: 0.255876\n","Epoch:  3662 | train loss: 0.247680 | valid loss: 0.255899\n","Epoch:  3663 | train loss: 0.257114 | valid loss: 0.255951\n","Epoch:  3664 | train loss: 0.296134 | valid loss: 0.255782\n","Epoch:  3665 | train loss: 0.254142 | valid loss: 0.255919\n","Epoch:  3666 | train loss: 0.308097 | valid loss: 0.255809\n","Epoch:  3667 | train loss: 0.213354 | valid loss: 0.255976\n","Epoch:  3668 | train loss: 0.268389 | valid loss: 0.256006\n","Epoch:  3669 | train loss: 0.268369 | valid loss: 0.255913\n","Epoch:  3670 | train loss: 0.376590 | valid loss: 0.255956\n","Epoch:  3671 | train loss: 0.241296 | valid loss: 0.255833\n","Epoch:  3672 | train loss: 0.284516 | valid loss: 0.255883\n","Epoch:  3673 | train loss: 0.227435 | valid loss: 0.255791\n","Epoch:  3674 | train loss: 0.325192 | valid loss: 0.255746\n","Epoch:  3675 | train loss: 0.296315 | valid loss: 0.255815\n","Epoch:  3676 | train loss: 0.224117 | valid loss: 0.255800\n","Epoch:  3677 | train loss: 0.305295 | valid loss: 0.255773\n","Epoch:  3678 | train loss: 0.274541 | valid loss: 0.255829\n","Epoch:  3679 | train loss: 0.331546 | valid loss: 0.255846\n","Epoch:  3680 | train loss: 0.211272 | valid loss: 0.255722\n","Epoch:  3681 | train loss: 0.289513 | valid loss: 0.255859\n","Epoch:  3682 | train loss: 0.234301 | valid loss: 0.255828\n","Epoch:  3683 | train loss: 0.255063 | valid loss: 0.255801\n","Epoch:  3684 | train loss: 0.248537 | valid loss: 0.255843\n","Epoch:  3685 | train loss: 0.276651 | valid loss: 0.255796\n","Epoch:  3686 | train loss: 0.274564 | valid loss: 0.255848\n","Epoch:  3687 | train loss: 0.241706 | valid loss: 0.255856\n","Epoch:  3688 | train loss: 0.225783 | valid loss: 0.255710\n","Epoch:  3689 | train loss: 0.261204 | valid loss: 0.255839\n","Epoch:  3690 | train loss: 0.262423 | valid loss: 0.255729\n","Epoch:  3691 | train loss: 0.317324 | valid loss: 0.255829\n","Epoch:  3692 | train loss: 0.247417 | valid loss: 0.255821\n","Epoch:  3693 | train loss: 0.272929 | valid loss: 0.255857\n","Epoch:  3694 | train loss: 0.188641 | valid loss: 0.255889\n","Epoch:  3695 | train loss: 0.298557 | valid loss: 0.255866\n","Epoch:  3696 | train loss: 0.284364 | valid loss: 0.255820\n","Epoch:  3697 | train loss: 0.315525 | valid loss: 0.255819\n","Epoch:  3698 | train loss: 0.328954 | valid loss: 0.255887\n","Epoch:  3699 | train loss: 0.275630 | valid loss: 0.255607\n","Epoch:  3700 | train loss: 0.312760 | valid loss: 0.255795\n","Epoch:  3701 | train loss: 0.345505 | valid loss: 0.255863\n","Epoch:  3702 | train loss: 0.299851 | valid loss: 0.255760\n","Epoch:  3703 | train loss: 0.207047 | valid loss: 0.255784\n","Epoch:  3704 | train loss: 0.241258 | valid loss: 0.255741\n","Epoch:  3705 | train loss: 0.215863 | valid loss: 0.255779\n","Epoch:  3706 | train loss: 0.298883 | valid loss: 0.255846\n","Epoch:  3707 | train loss: 0.224482 | valid loss: 0.255775\n","Epoch:  3708 | train loss: 0.306835 | valid loss: 0.255755\n","Epoch:  3709 | train loss: 0.260112 | valid loss: 0.255944\n","Epoch:  3710 | train loss: 0.227791 | valid loss: 0.255814\n","Epoch:  3711 | train loss: 0.313242 | valid loss: 0.255910\n","Epoch:  3712 | train loss: 0.293453 | valid loss: 0.255841\n","Epoch:  3713 | train loss: 0.287113 | valid loss: 0.255805\n","Epoch:  3714 | train loss: 0.363820 | valid loss: 0.255788\n","Epoch:  3715 | train loss: 0.210456 | valid loss: 0.255849\n","Epoch:  3716 | train loss: 0.218954 | valid loss: 0.255883\n","Epoch:  3717 | train loss: 0.319305 | valid loss: 0.255783\n","Epoch:  3718 | train loss: 0.373423 | valid loss: 0.255890\n","Epoch:  3719 | train loss: 0.293071 | valid loss: 0.255820\n","Epoch:  3720 | train loss: 0.315523 | valid loss: 0.255817\n","Epoch:  3721 | train loss: 0.271886 | valid loss: 0.255843\n","Epoch:  3722 | train loss: 0.222384 | valid loss: 0.255845\n","Epoch:  3723 | train loss: 0.301606 | valid loss: 0.255864\n","Epoch:  3724 | train loss: 0.337328 | valid loss: 0.255888\n","Epoch:  3725 | train loss: 0.241785 | valid loss: 0.255829\n","Epoch:  3726 | train loss: 0.294597 | valid loss: 0.255746\n","Epoch:  3727 | train loss: 0.195260 | valid loss: 0.255819\n","Epoch:  3728 | train loss: 0.244074 | valid loss: 0.255815\n","Epoch:  3729 | train loss: 0.231965 | valid loss: 0.255883\n","Epoch:  3730 | train loss: 0.316162 | valid loss: 0.255872\n","Epoch:  3731 | train loss: 0.286262 | valid loss: 0.255805\n","Epoch:  3732 | train loss: 0.362866 | valid loss: 0.255783\n","Epoch:  3733 | train loss: 0.299226 | valid loss: 0.255877\n","Epoch:  3734 | train loss: 0.276697 | valid loss: 0.255708\n","Epoch:  3735 | train loss: 0.288138 | valid loss: 0.255890\n","Epoch:  3736 | train loss: 0.237812 | valid loss: 0.255717\n","Epoch:  3737 | train loss: 0.300856 | valid loss: 0.255770\n","Epoch:  3738 | train loss: 0.233526 | valid loss: 0.255831\n","Epoch:  3739 | train loss: 0.322894 | valid loss: 0.255744\n","Epoch:  3740 | train loss: 0.295491 | valid loss: 0.255875\n","Epoch:  3741 | train loss: 0.285855 | valid loss: 0.255888\n","Epoch:  3742 | train loss: 0.252947 | valid loss: 0.255766\n","Epoch:  3743 | train loss: 0.293898 | valid loss: 0.255866\n","Epoch:  3744 | train loss: 0.252833 | valid loss: 0.255749\n","Epoch:  3745 | train loss: 0.293411 | valid loss: 0.255827\n","Epoch:  3746 | train loss: 0.215884 | valid loss: 0.255775\n","Epoch:  3747 | train loss: 0.289466 | valid loss: 0.255902\n","Epoch:  3748 | train loss: 0.212113 | valid loss: 0.255821\n","Epoch:  3749 | train loss: 0.255872 | valid loss: 0.255878\n","Epoch:  3750 | train loss: 0.241826 | valid loss: 0.255781\n","Epoch:  3751 | train loss: 0.235148 | valid loss: 0.255768\n","Epoch:  3752 | train loss: 0.249352 | valid loss: 0.255805\n","Epoch:  3753 | train loss: 0.308002 | valid loss: 0.255769\n","Epoch:  3754 | train loss: 0.253413 | valid loss: 0.255832\n","Epoch:  3755 | train loss: 0.298012 | valid loss: 0.255976\n","Epoch:  3756 | train loss: 0.307626 | valid loss: 0.255818\n","Epoch:  3757 | train loss: 0.274429 | valid loss: 0.255836\n","Epoch:  3758 | train loss: 0.300500 | valid loss: 0.255764\n","Epoch:  3759 | train loss: 0.195274 | valid loss: 0.255810\n","Epoch:  3760 | train loss: 0.226024 | valid loss: 0.255891\n","Epoch:  3761 | train loss: 0.263137 | valid loss: 0.255709\n","Epoch:  3762 | train loss: 0.336470 | valid loss: 0.255840\n","Epoch:  3763 | train loss: 0.264850 | valid loss: 0.255846\n","Epoch:  3764 | train loss: 0.299555 | valid loss: 0.255734\n","Epoch:  3765 | train loss: 0.272405 | valid loss: 0.255814\n","Epoch:  3766 | train loss: 0.249729 | valid loss: 0.255768\n","Epoch:  3767 | train loss: 0.309323 | valid loss: 0.255861\n","Epoch:  3768 | train loss: 0.305805 | valid loss: 0.255819\n","Epoch:  3769 | train loss: 0.318001 | valid loss: 0.255807\n","Epoch:  3770 | train loss: 0.263395 | valid loss: 0.255727\n","Epoch:  3771 | train loss: 0.254996 | valid loss: 0.255766\n","Epoch:  3772 | train loss: 0.373633 | valid loss: 0.255766\n","Epoch:  3773 | train loss: 0.247658 | valid loss: 0.255861\n","Epoch:  3774 | train loss: 0.293531 | valid loss: 0.255744\n","Epoch:  3775 | train loss: 0.372568 | valid loss: 0.255792\n","Epoch:  3776 | train loss: 0.425506 | valid loss: 0.255751\n","Epoch:  3777 | train loss: 0.222151 | valid loss: 0.255872\n","Epoch:  3778 | train loss: 0.282189 | valid loss: 0.255844\n","Epoch:  3779 | train loss: 0.321937 | valid loss: 0.255820\n","Epoch:  3780 | train loss: 0.292231 | valid loss: 0.255811\n","Epoch:  3781 | train loss: 0.281535 | valid loss: 0.255737\n","Epoch:  3782 | train loss: 0.238066 | valid loss: 0.255857\n","Epoch:  3783 | train loss: 0.293935 | valid loss: 0.255785\n","Epoch:  3784 | train loss: 0.246572 | valid loss: 0.255975\n","Epoch:  3785 | train loss: 0.293410 | valid loss: 0.255810\n","Epoch:  3786 | train loss: 0.288711 | valid loss: 0.255773\n","Epoch:  3787 | train loss: 0.259406 | valid loss: 0.255757\n","Epoch:  3788 | train loss: 0.267247 | valid loss: 0.255732\n","Epoch:  3789 | train loss: 0.279798 | valid loss: 0.255660\n","Epoch:  3790 | train loss: 0.266950 | valid loss: 0.255771\n","Epoch:  3791 | train loss: 0.277198 | valid loss: 0.255807\n","Epoch:  3792 | train loss: 0.238651 | valid loss: 0.255792\n","Epoch:  3793 | train loss: 0.242769 | valid loss: 0.255791\n","Epoch:  3794 | train loss: 0.219037 | valid loss: 0.255827\n","Epoch:  3795 | train loss: 0.272838 | valid loss: 0.255839\n","Epoch:  3796 | train loss: 0.289539 | valid loss: 0.255710\n","Epoch:  3797 | train loss: 0.220404 | valid loss: 0.255857\n","Epoch:  3798 | train loss: 0.302630 | valid loss: 0.255889\n","Epoch:  3799 | train loss: 0.214423 | valid loss: 0.255681\n","Epoch:  3800 | train loss: 0.285465 | valid loss: 0.255808\n","Epoch:  3801 | train loss: 0.242401 | valid loss: 0.255823\n","Epoch:  3802 | train loss: 0.213997 | valid loss: 0.255755\n","Epoch:  3803 | train loss: 0.240339 | valid loss: 0.255951\n","Epoch:  3804 | train loss: 0.228824 | valid loss: 0.255813\n","Epoch:  3805 | train loss: 0.247031 | valid loss: 0.256017\n","Epoch:  3806 | train loss: 0.324129 | valid loss: 0.255842\n","Epoch:  3807 | train loss: 0.245148 | valid loss: 0.255866\n","Epoch:  3808 | train loss: 0.281757 | valid loss: 0.255718\n","Epoch:  3809 | train loss: 0.310726 | valid loss: 0.255759\n","Epoch:  3810 | train loss: 0.268552 | valid loss: 0.255837\n","Epoch:  3811 | train loss: 0.312769 | valid loss: 0.255827\n","Epoch:  3812 | train loss: 0.358725 | valid loss: 0.255880\n","Epoch:  3813 | train loss: 0.314239 | valid loss: 0.255800\n","Epoch:  3814 | train loss: 0.317414 | valid loss: 0.255816\n","Epoch:  3815 | train loss: 0.268017 | valid loss: 0.255841\n","Epoch:  3816 | train loss: 0.234077 | valid loss: 0.255843\n","Epoch:  3817 | train loss: 0.325733 | valid loss: 0.255929\n","Epoch:  3818 | train loss: 0.257468 | valid loss: 0.255847\n","Epoch:  3819 | train loss: 0.352117 | valid loss: 0.255933\n","Epoch:  3820 | train loss: 0.269879 | valid loss: 0.255856\n","Epoch:  3821 | train loss: 0.276207 | valid loss: 0.255969\n","Epoch:  3822 | train loss: 0.330209 | valid loss: 0.255782\n","Epoch:  3823 | train loss: 0.323459 | valid loss: 0.255859\n","Epoch:  3824 | train loss: 0.229473 | valid loss: 0.255724\n","Epoch:  3825 | train loss: 0.267380 | valid loss: 0.255833\n","Epoch:  3826 | train loss: 0.242200 | valid loss: 0.255824\n","Epoch:  3827 | train loss: 0.308249 | valid loss: 0.255741\n","Epoch:  3828 | train loss: 0.271290 | valid loss: 0.255818\n","Epoch:  3829 | train loss: 0.206503 | valid loss: 0.255801\n","Epoch:  3830 | train loss: 0.284393 | valid loss: 0.255860\n","Epoch:  3831 | train loss: 0.227280 | valid loss: 0.255827\n","Epoch:  3832 | train loss: 0.248758 | valid loss: 0.255819\n","Epoch:  3833 | train loss: 0.331829 | valid loss: 0.255840\n","Epoch:  3834 | train loss: 0.304855 | valid loss: 0.255702\n","Epoch:  3835 | train loss: 0.299079 | valid loss: 0.255855\n","Epoch:  3836 | train loss: 0.271301 | valid loss: 0.255739\n","Epoch:  3837 | train loss: 0.254835 | valid loss: 0.255801\n","Epoch:  3838 | train loss: 0.254977 | valid loss: 0.255796\n","Epoch:  3839 | train loss: 0.460849 | valid loss: 0.255821\n","Epoch:  3840 | train loss: 0.284330 | valid loss: 0.255860\n","Epoch:  3841 | train loss: 0.255154 | valid loss: 0.255805\n","Epoch:  3842 | train loss: 0.264364 | valid loss: 0.255872\n","Epoch:  3843 | train loss: 0.263400 | valid loss: 0.255856\n","Epoch:  3844 | train loss: 0.320741 | valid loss: 0.255778\n","Epoch:  3845 | train loss: 0.251794 | valid loss: 0.255832\n","Epoch:  3846 | train loss: 0.243827 | valid loss: 0.255837\n","Epoch:  3847 | train loss: 0.230919 | valid loss: 0.255799\n","Epoch:  3848 | train loss: 0.281677 | valid loss: 0.255894\n","Epoch:  3849 | train loss: 0.248900 | valid loss: 0.255815\n","Epoch:  3850 | train loss: 0.260381 | valid loss: 0.255865\n","Epoch:  3851 | train loss: 0.261296 | valid loss: 0.255846\n","Epoch:  3852 | train loss: 0.245522 | valid loss: 0.255744\n","Epoch:  3853 | train loss: 0.216391 | valid loss: 0.255797\n","Epoch:  3854 | train loss: 0.259086 | valid loss: 0.255819\n","Epoch:  3855 | train loss: 0.276133 | valid loss: 0.255675\n","Epoch:  3856 | train loss: 0.264804 | valid loss: 0.255741\n","Epoch:  3857 | train loss: 0.248124 | valid loss: 0.255778\n","Epoch:  3858 | train loss: 0.336226 | valid loss: 0.255828\n","Epoch:  3859 | train loss: 0.216497 | valid loss: 0.255771\n","Epoch:  3860 | train loss: 0.268894 | valid loss: 0.255791\n","Epoch:  3861 | train loss: 0.239853 | valid loss: 0.255836\n","Epoch:  3862 | train loss: 0.249870 | valid loss: 0.255793\n","Epoch:  3863 | train loss: 0.208210 | valid loss: 0.255805\n","Epoch:  3864 | train loss: 0.186007 | valid loss: 0.255880\n","Epoch:  3865 | train loss: 0.325494 | valid loss: 0.255770\n","Epoch:  3866 | train loss: 0.240386 | valid loss: 0.255824\n","Epoch:  3867 | train loss: 0.263981 | valid loss: 0.255893\n","Epoch:  3868 | train loss: 0.224232 | valid loss: 0.255890\n","Epoch:  3869 | train loss: 0.279087 | valid loss: 0.255688\n","Epoch:  3870 | train loss: 0.313032 | valid loss: 0.255822\n","Epoch:  3871 | train loss: 0.252353 | valid loss: 0.255830\n","Epoch:  3872 | train loss: 0.288570 | valid loss: 0.255846\n","Epoch:  3873 | train loss: 0.197916 | valid loss: 0.255850\n","Epoch:  3874 | train loss: 0.256630 | valid loss: 0.255705\n","Epoch:  3875 | train loss: 0.260062 | valid loss: 0.255822\n","Epoch:  3876 | train loss: 0.212410 | valid loss: 0.255706\n","Epoch:  3877 | train loss: 0.235590 | valid loss: 0.255771\n","Epoch:  3878 | train loss: 0.303980 | valid loss: 0.255779\n","Epoch:  3879 | train loss: 0.235263 | valid loss: 0.255732\n","Epoch:  3880 | train loss: 0.196395 | valid loss: 0.255829\n","Epoch:  3881 | train loss: 0.254199 | valid loss: 0.255753\n","Epoch:  3882 | train loss: 0.242760 | valid loss: 0.255879\n","Epoch:  3883 | train loss: 0.345080 | valid loss: 0.255826\n","Epoch:  3884 | train loss: 0.228854 | valid loss: 0.255886\n","Epoch:  3885 | train loss: 0.287230 | valid loss: 0.255833\n","Epoch:  3886 | train loss: 0.259642 | valid loss: 0.255894\n","Epoch:  3887 | train loss: 0.250583 | valid loss: 0.255784\n","Epoch:  3888 | train loss: 0.284732 | valid loss: 0.255851\n","Epoch:  3889 | train loss: 0.224383 | valid loss: 0.255889\n","Epoch:  3890 | train loss: 0.286311 | valid loss: 0.255788\n","Epoch:  3891 | train loss: 0.305596 | valid loss: 0.255777\n","Epoch:  3892 | train loss: 0.246149 | valid loss: 0.255759\n","Epoch:  3893 | train loss: 0.192717 | valid loss: 0.255949\n","Epoch:  3894 | train loss: 0.255764 | valid loss: 0.255846\n","Epoch:  3895 | train loss: 0.234116 | valid loss: 0.255847\n","Epoch:  3896 | train loss: 0.225623 | valid loss: 0.255860\n","Epoch:  3897 | train loss: 0.263882 | valid loss: 0.255818\n","Epoch:  3898 | train loss: 0.272731 | valid loss: 0.255857\n","Epoch:  3899 | train loss: 0.220600 | valid loss: 0.255980\n","Epoch:  3900 | train loss: 0.305477 | valid loss: 0.255883\n","Epoch:  3901 | train loss: 0.280522 | valid loss: 0.255878\n","Epoch:  3902 | train loss: 0.315353 | valid loss: 0.255966\n","Epoch:  3903 | train loss: 0.218837 | valid loss: 0.255825\n","Epoch:  3904 | train loss: 0.192006 | valid loss: 0.255916\n","Epoch:  3905 | train loss: 0.266019 | valid loss: 0.255873\n","Epoch:  3906 | train loss: 0.270514 | valid loss: 0.255868\n","Epoch:  3907 | train loss: 0.277026 | valid loss: 0.255777\n","Epoch:  3908 | train loss: 0.176867 | valid loss: 0.255790\n","Epoch:  3909 | train loss: 0.290426 | valid loss: 0.255762\n","Epoch:  3910 | train loss: 0.283453 | valid loss: 0.255816\n","Epoch:  3911 | train loss: 0.220858 | valid loss: 0.255809\n","Epoch:  3912 | train loss: 0.243521 | valid loss: 0.255786\n","Epoch:  3913 | train loss: 0.196078 | valid loss: 0.255838\n","Epoch:  3914 | train loss: 0.262114 | valid loss: 0.255889\n","Epoch:  3915 | train loss: 0.280988 | valid loss: 0.255843\n","Epoch:  3916 | train loss: 0.214891 | valid loss: 0.255766\n","Epoch:  3917 | train loss: 0.257587 | valid loss: 0.255725\n","Epoch:  3918 | train loss: 0.331049 | valid loss: 0.255851\n","Epoch:  3919 | train loss: 0.220022 | valid loss: 0.255788\n","Epoch:  3920 | train loss: 0.286337 | valid loss: 0.255814\n","Epoch:  3921 | train loss: 0.207000 | valid loss: 0.256002\n","Epoch:  3922 | train loss: 0.275919 | valid loss: 0.255873\n","Epoch:  3923 | train loss: 0.334287 | valid loss: 0.255847\n","Epoch:  3924 | train loss: 0.322782 | valid loss: 0.255925\n","Epoch:  3925 | train loss: 0.276438 | valid loss: 0.255804\n","Epoch:  3926 | train loss: 0.369746 | valid loss: 0.255789\n","Epoch:  3927 | train loss: 0.307901 | valid loss: 0.255849\n","Epoch:  3928 | train loss: 0.220759 | valid loss: 0.255883\n","Epoch:  3929 | train loss: 0.288324 | valid loss: 0.255857\n","Epoch:  3930 | train loss: 0.329632 | valid loss: 0.255953\n","Epoch:  3931 | train loss: 0.360331 | valid loss: 0.255838\n","Epoch:  3932 | train loss: 0.303140 | valid loss: 0.255905\n","Epoch:  3933 | train loss: 0.312178 | valid loss: 0.255797\n","Epoch:  3934 | train loss: 0.232136 | valid loss: 0.255803\n","Epoch:  3935 | train loss: 0.263404 | valid loss: 0.255760\n","Epoch:  3936 | train loss: 0.291757 | valid loss: 0.256015\n","Epoch:  3937 | train loss: 0.261391 | valid loss: 0.255926\n","Epoch:  3938 | train loss: 0.273877 | valid loss: 0.255910\n","Epoch:  3939 | train loss: 0.202181 | valid loss: 0.255817\n","Epoch:  3940 | train loss: 0.205995 | valid loss: 0.255984\n","Epoch:  3941 | train loss: 0.333884 | valid loss: 0.255872\n","Epoch:  3942 | train loss: 0.286675 | valid loss: 0.255641\n","Epoch:  3943 | train loss: 0.332541 | valid loss: 0.255759\n","Epoch:  3944 | train loss: 0.254070 | valid loss: 0.255787\n","Epoch:  3945 | train loss: 0.282034 | valid loss: 0.255808\n","Epoch:  3946 | train loss: 0.238241 | valid loss: 0.255705\n","Epoch:  3947 | train loss: 0.277065 | valid loss: 0.255809\n","Epoch:  3948 | train loss: 0.280474 | valid loss: 0.255727\n","Epoch:  3949 | train loss: 0.236296 | valid loss: 0.255943\n","Epoch:  3950 | train loss: 0.208909 | valid loss: 0.255805\n","Epoch:  3951 | train loss: 0.254615 | valid loss: 0.255843\n","Epoch:  3952 | train loss: 0.231000 | valid loss: 0.255862\n","Epoch:  3953 | train loss: 0.231727 | valid loss: 0.255903\n","Epoch:  3954 | train loss: 0.235136 | valid loss: 0.255744\n","Epoch:  3955 | train loss: 0.294506 | valid loss: 0.255886\n","Epoch:  3956 | train loss: 0.232722 | valid loss: 0.255801\n","Epoch:  3957 | train loss: 0.302417 | valid loss: 0.255890\n","Epoch:  3958 | train loss: 0.216043 | valid loss: 0.255960\n","Epoch:  3959 | train loss: 0.303573 | valid loss: 0.255863\n","Epoch:  3960 | train loss: 0.287689 | valid loss: 0.255855\n","Epoch:  3961 | train loss: 0.222519 | valid loss: 0.255832\n","Epoch:  3962 | train loss: 0.263145 | valid loss: 0.255820\n","Epoch:  3963 | train loss: 0.273771 | valid loss: 0.255853\n","Epoch:  3964 | train loss: 0.226128 | valid loss: 0.255923\n","Epoch:  3965 | train loss: 0.212540 | valid loss: 0.255850\n","Epoch:  3966 | train loss: 0.279829 | valid loss: 0.255909\n","Epoch:  3967 | train loss: 0.248185 | valid loss: 0.255844\n","Epoch:  3968 | train loss: 0.284389 | valid loss: 0.255881\n","Epoch:  3969 | train loss: 0.271341 | valid loss: 0.255829\n","Epoch:  3970 | train loss: 0.234714 | valid loss: 0.255748\n","Epoch:  3971 | train loss: 0.244229 | valid loss: 0.255756\n","Epoch:  3972 | train loss: 0.306102 | valid loss: 0.255816\n","Epoch:  3973 | train loss: 0.266948 | valid loss: 0.255834\n","Epoch:  3974 | train loss: 0.226694 | valid loss: 0.255792\n","Epoch:  3975 | train loss: 0.265349 | valid loss: 0.255871\n","Epoch:  3976 | train loss: 0.277004 | valid loss: 0.255781\n","Epoch:  3977 | train loss: 0.225252 | valid loss: 0.255860\n","Epoch:  3978 | train loss: 0.222268 | valid loss: 0.255934\n","Epoch:  3979 | train loss: 0.338619 | valid loss: 0.255795\n","Epoch:  3980 | train loss: 0.211221 | valid loss: 0.255879\n","Epoch:  3981 | train loss: 0.343339 | valid loss: 0.255846\n","Epoch:  3982 | train loss: 0.167739 | valid loss: 0.255845\n","Epoch:  3983 | train loss: 0.234730 | valid loss: 0.256011\n","Epoch:  3984 | train loss: 0.252021 | valid loss: 0.255885\n","Epoch:  3985 | train loss: 0.332658 | valid loss: 0.255853\n","Epoch:  3986 | train loss: 0.263799 | valid loss: 0.255886\n","Epoch:  3987 | train loss: 0.313027 | valid loss: 0.255861\n","Epoch:  3988 | train loss: 0.270923 | valid loss: 0.255920\n","Epoch:  3989 | train loss: 0.233256 | valid loss: 0.255960\n","Epoch:  3990 | train loss: 0.313409 | valid loss: 0.255864\n","Epoch:  3991 | train loss: 0.267018 | valid loss: 0.255888\n","Epoch:  3992 | train loss: 0.301198 | valid loss: 0.255936\n","Epoch:  3993 | train loss: 0.310931 | valid loss: 0.255886\n","Epoch:  3994 | train loss: 0.273671 | valid loss: 0.255922\n","Epoch:  3995 | train loss: 0.326788 | valid loss: 0.255894\n","Epoch:  3996 | train loss: 0.298919 | valid loss: 0.255867\n","Epoch:  3997 | train loss: 0.250775 | valid loss: 0.255771\n","Epoch:  3998 | train loss: 0.261657 | valid loss: 0.255907\n","Epoch:  3999 | train loss: 0.290545 | valid loss: 0.255865\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knquGLo3aq2i","executionInfo":{"status":"ok","timestamp":1629654817591,"user_tz":-60,"elapsed":48,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"c4db273d-ea7a-489d-e22e-3ae4e8373ff2"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Train time: 535.2902278900146\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"ROgLm0LRyo7l","executionInfo":{"status":"ok","timestamp":1629654818604,"user_tz":-60,"elapsed":1028,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"1f45da00-e0bb-4873-a294-d041cc21cd14"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":73},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAcEAAAGxCAYAAAAamQ0pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVf7H8feZmUwaEDoICBERkKo0QUVRFEFEdrGsBVF/1l1dO4pdFBQVewVdy1pWFAvSFZQmvffea+gBQjLlnt8fkwnJ5E5LZjKTyff1PDwkd+7ce2aS3M+cc09RWmuEEEKIisgS6wIIIYQQsSIhKIQQosKSEBRCCFFhSQgKIYSosCQEhRBCVFi2WBcg0mrWrKkzMzNjXQwhhBBxZNGiRQe01rV8tydcCGZmZrJw4cJYF0MIIUQcUUptM9suzaFCCCEqLAlBIYQQFZaEoBBCiApLQlAIIUSFlTAhqJTqo5QaefTo0VgXRQghRDmRML1DtdZjgbEdOnS4K9ZlEUKIUGRnZ5OVlYXT6Yx1Ucq1pKQkateuTZUqVcJ+bsKEoBBClCfZ2dns27eP+vXrk5qailIq1kUql7TWnDx5kl27dgGEHYQJ0xwqhBDlSVZWFvXr1yctLU0CsBSUUqSlpVG/fn2ysrLCfr6EoBBCxIDT6SQ1NTXWxUgYqampJWpWlhAUQogYkRpg5JT0vZQQFEIIUWFJCAohhKiwJASFEELETLdu3bj//vtjdn4ZIiGEECIs3bp1o1WrVrz//vulPtZPP/1EUlJSBEpVMlITNJO1Bo7tjXUphBCi3Aq1p2b16tWpXLlylEvjn4SgCeeHXVn186uxLoYQQsSd2267jenTp/PBBx+glEIpxRdffIFSigkTJtCpUyfsdjuTJ09m06ZN9O3bl7p165Kenk67du0YN25ckeP5NodmZmYyZMgQ7rnnHqpUqUKDBg14/fXXo/Z6pDnUhENbOJaTG+tiCCEqmMFjV7F6d3aZnrNFvSo836dlyPu/8847rF+/nubNm/Pyyy8DsGrVKgCeeOIJ3njjDZo0aULlypXZvXs3vXr1YsiQIaSmpjJq1Cj69evH8uXLad68ud9zvPXWWwwePJiBAwcyceJEHnjgAS688EK6dOlSuhdrQmqCJtzKCm6Zy08IIXxlZGRgt9tJS0ujbt261K1bF6vVCsALL7xAjx49aNy4MbVq1aJt27bce++9tG7dmiZNmvD000/Trl07Ro8eHfAcPXr04P7776dJkyb8+9//pkmTJkydOjUqr0dqgibc2MBwxboYQogKJpwaWTzq0KFDke9PnDjB4MGDGTduHHv27MHpdJKbm0ubNm0CHsf38Xr16pVoSrRQSAiacGNBSQgKIURY0tPTi3z/2GOPMWnSJIYPH85ZZ51FWloaAwYMwOFwBDyOb29RpRSGYUS8vCAhaMqtpCYohBD+2O123G530P1mzZrFgAEDuOaaawDIzc1l06ZNNG3aNNpFDJncEzThxio1QSGE8CMzM5P58+ezdetWDhw44LeW1rRpU37++WcWL17MihUr6N+/P7m58dXpUELQhKGsUhMUQgg/HnvsMex2Oy1atKBWrVps377ddL8333yT2rVr07VrV3r16kXnzp3p2rVrGZc2MKW1jnUZIqpDhw564cKFpTrG9pdasy+5ER0fHxd8ZyGEKIE1a9Zw9tlnx7oYCSXQe6qUWqS17uC7XWqCJtxYsWipCQohRKKTEDRhKBsWHfymrxBCiPJNQtCEW1mxyD1BIYRIeBKCJgxlxYLUBIUQItFJCJrwNIdKTVAIIRKdhKAJQ1mxyj1BIYRIeBKCJqRjjBBCVAwSgiYMZZN7gkIIUQFICJowlBWb3BMUQoiEJyFowrBITVAIIaLFdzV53+/NtGrVihdeeCHiZZFVJExorFilJiiEEGXip59+KrZ8UlmREDRhWGxYic7aVUIIIYqqXr16zM4tzaEmtLJJTVAIIUyMHDmSOnXqFFtP8KabbuLqq69m06ZN9O3bl7p165Kenk67du0YNy7wYgS+zaFZWVn07duX1NRUGjVqxGeffRaV1wJSEzSlLVasck9QCFHWJg6CvSvK9px1W0OvYSHvft111/HAAw/w+++/07NnTwCOHz/OmDFj+Pzzzzl+/Di9evViyJAhpKamMmrUKPr168fy5ctp3rx5SOe47bbb2LZtG1OmTCEtLY2HH36YrVu3luTVBSUhaEJbkrBJCAohRDHVqlXjyiuv5JtvvikIwV9++QWbzcbVV19NSkoKbdu2Ldj/6aefZuzYsYwePZpnnnkm6PHXr1/PxIkTmTVrFhdccAEAX375JY0bN47K65EQNKGV1ASFEDEQRo0slvr378+tt95KTk4OaWlpfPPNN1xzzTWkpKRw4sQJBg8ezLhx49izZw9Op5Pc3FzatGkT0rHXrFmDxWKhU6dOBdsaNWpEvXr1ovJaJARNaItNQlAIIfzo3bs3NpuNMWPG0L17d6ZMmcLkyZMBz6rzkyZNYvjw4Zx11lmkpaUxYMAAHA5HWOdQSkWj6MVICJpRVqxaeocKIYSZ5ORkrrvuOr755hsOHDhA3bp16datGwCzZs1iwIABXHPNNQDk5uayadMmmjZtGtKxmzdvjmEYzJ8/n/PPPx+A7du3s3v37qi8FglBE8piQaFjXQwhhIhb/fv3p3v37mzZsoUbb7wRi8Uz2KBp06b8/PPP9O3bl6SkJAYPHkxubm7Ix23WrBk9e/bknnvuYeTIkaSmpvLII4+QmpoaldchQyTMKAsWCUEhhPCra9eu1K9fn9WrV9O/f/+C7W+++Sa1a9ema9eu9OrVi86dO9O1a9ewjv3FF19wxhlncOmll9KnTx9uuukmMjMzI/wKPJTWiXWx79Chg164cGGpjjH700c5f+en8PwRKKN2aSFExbJmzRrOPvvsWBcjoQR6T5VSi7TWHXy3S03QjPK8LVruCwohREKTEDSh8tu2DUNCUAghEpmEoAmlrAC43DJ1mhBCJDIJQTPemqBbaoJCCJHIJARNWPI7w0hNUAgRTXLLJXJK+l5KCJpR3ppgYvWcFULEj/T0dHbt2oXD4SDReumXJa01DoeDXbt2kZ6eHvbzZbC8CW/HGLf0DhVCREmDBg04cOAA27Ztw+WSVqfSsNlsZGRkULNmzfCfG4XylHvK4ukY45bmUCFElFgsFmrXrk3t2rVjXZQKTZpDTSglHWOEEKIikBA04Q1BqQkKIURikxA0IYPlhRCiYpAQNFFwT1BCUAghEpqEoAnvnNmGWxbWFUKIRCYhaCZ/2jS0hKAQQiQyCUEz3qqgDGAVQoiEJiFopmApJQlBIYRIZBKCZrwhKB1jhBAioUkImlHet0XuCQohRCKTEDQjNUEhhKgQJATNFIyRkHuCQgiRyCQETej8IRJamkOFECKhSQiaUAU1QWkOFUKIRCYhaErGCQohREUgIWgmf+5QGScohBCJTULQlLcmKPcEhRAikUkImslfSknuCQohRGKTEDTjHSeINIcKIUQikxA04V1ZHkOaQ4UQIpFJCJrQBRNoS3OoEEIkMglBM96aoISgEEIkNAlBEwWD5SUEhRAioUkImimoCUrHGCGESGQSgmYKQlA6xgghRCKTEDShCjrGxLggQgghokpC0EzBBNpSExRCiEQmIWhGBssLIUSFICFoRpZSEkKICkFC0JT3bZEQFEKIRCYhaEJZZIiEEEJUBBKCZmTGGCGEqBAkBE14Z4zRhtQEhRAikUkImlFyT1AIISoCCUEz0hwqhBAVgoSgiYLmUOkYI4QQCU1C0IzUBIUQokKQEDRjkRAUQoiKQELQhMK7nqA0hwohRCKTEDRjkd6hQghREUgImlDet0XGCQohREKTEDRj8TaHSk1QCCESmYSgCYUVkKWUhBAi0dliXYBAlFLpwIeAA5imtf6mTE5skaWUhBCiIijzmqBS6jOlVJZSaqXP9p5KqXVKqY1KqUH5m/sBo7XWdwFXl2Ep8/+XEBRCiEQWi+bQL4CehTcopazAB0AvoAVwo1KqBdAA2JG/m7usCihLKQkhRMVQ5iGotZ4BHPLZ3AnYqLXerLV2AN8BfYGdeIIQApRVKXW3UmqhUmrh/v37S19IZc0vrNQEhRAikcVLx5j6nKrxgSf86gM/AdcopT4Cxvp7stZ6pNa6g9a6Q61atUpdGO/coRKCQgiR2OK6Y4zW+gRwe1mfV1lkxhghhKgI4qUmuAs4vdD3DfK3xUZBc6iEoBBCJLJ4CcEFwFlKqTOUUnbgBuDXWBXGUtAcWmZ9cYQQQsRALIZI/A+YAzRTSu1USt2htXYB9wOTgTXA91rrVWVdtgKW/MHyUhMUQoiEVub3BLXWN/rZPgGYUMbFMWWVpZSEEKJCiJfm0Lhiye8Yo2XGGCGESGgSgiaUNIcKIUSFICFowlIQgtIxRgghEpmEoAmrTJsmhBAVgoSgCe9geS0dY4QQIqFJCJrwNofKUkpCCJHYJARNeOcOlY4xQgiR2CQETXh7h8p6gkIIkdgSJgSVUn2UUiOPHj0agWN53hYlNUEhhEhoCROCWuuxWuu7MzIySn0sWUpJCCEqhoQJwUhS3lUkkJqgEEIkMglBMxapCQohREUgIWhCKTC0QkkICiFEQpMQNKEAAyWtoUIIkeAkBE0opTwhiMwdKoQQiUxC0IQCNErmDhVCiAQnIWjCopSEoBBCVAASgiaUAgMLMmOMEEIkNglBPzRI71AhhEhwEoImCmqC0hoqhBAJTULQhCL/nqA0hwohREKTEDShlDSHCiFERSAhaMJTB7RI71AhhEhwEoImTg2WlxAUQohEljAhGNH1BPEMlpfmUCGESGwJE4KRXU9QZowRQoiKIGFCMJJONYdKTVAIIRKZhKAf0hwqhBCJT0LQD+kYI4QQiU9C0A+NBSX3BIUQIqFJCPrhiT9pDhVCiEQmIeiHDJYXQojEJyHoh86fQVQIIUTikhD0wzNOUJpDhRAikUkI+mFITVAIIRKehKAfUhMUQojEJyHoh2ewvNQEhRAikUkI+qFlsLwQQiQ8CUE/3FqhDXesiyGEECKKJAT90Ch2HjoR62IIIYSIIglBPzy9Q4UQQiQyCUE/PCEovUOFECKRJUwIRnJlefA0h1qkY4wQQiS0hAnBSK4sDzJYXgghKoKECcFI01ikJiiEEAlOQtAPDVITFEKIBCch6IeBRUJQCCESnISgH4Z0jBFCiIQnIeiH9A4VQojEJyHoh0ahlISgEEIkMglBPwwtQySEECLRSQj64WkOlRljhBAikUkI+mGgSLHJ2yOEEIlMrvJ+VEq1k2qLdSmEEEJEk4SgHwZWLFrWExRCiEQmIeiHW9mwIiEohBCJTELQDzcWqQkKIUSCCzkElVI/KKXuLvR9M6XUdUqpWtEpWmwZyopFaoJCCJHQwqkJXgQsBVBK1QDmAZ8Cq5RSraNQtpgysGKVmqAQQiS0cEKwMrAn/+trgC1AdeATYGiEyxVz+064cbmcsS6GEEKIKAonBLcDZ+Z/fS3wldbaDXwBdI5wuWLOpS1YZbC8EEIktHBGwn0GvK+UmghcAtxb6BhpkS5YrLmxYpN7gkIIkdBCDkGt9WtKKYArgMe01pvzH+oEbItC2WLKhUWGSAghRIILa04UrfVrwGs+m+sA30WsRHHCUxOU5lAhhEhkIYegUuoH4Het9cj875sBbYDPtdb7o1S+kCml+gB9mjRpEpHjuaQ5VMSxwyccVEu3x7oYQpR7kRoi0SoKZQuL1nqs1vrujIyMiBzPLc2hIk79uS6Lc1/6nZkbzD97/rF2H+v3HSvjUglRPkVqiMTLES5XzAWqCWqt+X7hDnKdEpKi7C3edhiAJduPmD7+f18spMdbM8qySEKUWzJEwg+XtmJVGozi9wWnr9/P46OXM2zi2hiUrLiDx/MwDFkAuKLQ8qMWImLCCUHvEInX8QyR+CV/e0IOkXBhBWDU/C1Ftuc63ew/lgfA9kM5HM9zsTHLvOnJ4TJYsye7yDbD0BzLDX8Q/pEcB02fmcjczQeLbN+XnUv7IVN4948NYR9TCCEqupBDML9n6H+BdlSAIRLu/LdmxlpPC/DxPBdDx6/myndmMnD0cgCcboM7v1zAZW/OQGvNSYebmRv2M2nlXnYcymHw2FX0emcmu46cxDA0d365gOtGzKH1C79x9GTRINyYdYxOQ6ew5cAJ0/Is3XEEh8vgw2mbimz3BvJvq/aV6HWOnLGJzEHjcbmlJ2x54RmpJISIBBki4UceSQDYDE/IvD5pLV/OKZr1Wdl5rMvvgOAyNE/+tJxflu4ueLx53coArN97jNcnrWXKmqyCx7JPOun+xjQqJduYNvASrnh7Jm5Dc8nwaWwd1hvw1DofHrWUp648m/wxmmiftrC7/7sQACN/+8wN+2nXsBrpyaH9aN+e4qlB5rkMbFbzz0TP/rKS5qdV5ubzGoV0TBFd0hwqROSUeu30/GBMOCdIAWDjLk8NyzcAgYIABDjr6Ym0rFelyONr93oef/KnFezNzi3yWNfX/gTgwHEHAO5C9/RGL9rJte0bMG3dfiau3Iuhtd8A2n00t+D5Ow/ncMt/5gPwv7s6Uy09ieZ1T5Vp2ros2jWqRpWUpIJt3vC0BKhefDXX89olBIUQiSacpZSSlVKvKqXWKKU2K6XGKKWui2bhYqlW9WoA5OYcZ/zyPUH29li1O9t0u28A+rr3q0VFvp+0ci8AlvxcmlyoqdPhMm+2dGvNyl1HC76/8ZO59Hx7Jr8u241haCat3Mttny/g5k/mkZWdy+uT13oey89eaWITQlRE4dQEhwNXAR8CeUAL4DOl1A3AP7TWriiUL2YcllQA0snlvm8XR/Vck1btLfL9lDX7eG3SWto1rFawbeoaTxDO23IIgI1Zx5mx/tQ4McPQ3Pt18XKu25vNvqO5DJ2wBoAVu47S6eWpBY8nWSX9yiv5yQlReuH0Dr0OuFlr/brW+l2t9b1AEyATGBSNwsWSw+Lp8JquAtfiouXDaZvIKTQOsXBz7KJth/j7B3/x4rjVBdu2HswxPY7WRZttzR73x21oMgeNL/h+20HzTjul5XIbLN9pPuZNCCGiKZwQTAGyCm/QWu8DHgZuj2Sh4kGVKp6ZZ9KJTQgCPPC/Jabbr/loDsfyQqt4fzhtEzsOmQcknLonaBaGvk2veX6aYkvr7SkbuPr9v4o05wbicBks3HooKmUpz35fva/IhxaRmHIcLvYFucUiQhdOCE4H7jDZvhNPD9GE0rNLOwDqqvJ/sfU2oZrx3hM8nucic9B4vpl3qsapKZtuiKt2e8Iv61hof9ivTlrLtR/PYbWfe7Dl1cwN++n/6bygEx/4+7m8J2NFK4TrR8zhvEK3NETphBOCg4B7lVIjlVItlFIWpVQK8CCwKjrFix13ei3ydBKZam/wnRPA3vxepv+ZdWpyAN/aYaS75h896eSVCWtwGf5ro2bW7vWE38ETeZEtUIz96+vFzNp4gOOOhLq9LiJs5a7E+vAXa+GsJ7hGKXUxMBJYCbjwhOhBoG90ihdDysI8ozl32iZyp21iweY8bWOu0YKWlq3s11VZrxvQ1zq74PGx7s70sc7Foa0sMprxH3cvTmInTyeRpNxYMDCwkKeT2Kjrk016LF5dMe78BPJ2trh0+LRiYw0jXTN8ffJavp67Peh+mYPG07v1aXxwc7v8MnpKuWZPNnWqpNC0TuWIlivWZBygEGUn3MHyy4HO+csotQSOAfO01gn30aRlvQx6ufrzm/WJItuTlYuLrZ4ZY2qqbM6m6EW8j3UuAHblpot1NV2sqwnFCiOT9fp0dusaZHCCjboeu3RNFhjNyyQoC48XzHO52Wwyc43L7dln6Y4j/Lk2i3embmD+092pXTmlYJ9lO46wek82PVrUIc1uI9Vu9XtOpyvw1T4rO7egJ+v4FXv4IH+7dzjHyxPW8vKEtQWTC5R7YXb39B3WIr1FhQhfwBBUSk3Gs3zSkvz/12mPdcC6MihfzFgtivX6dJrk/pc0crGgsWHgRnGSZKqQQ4pycFynkkoeldVJ6qjDHNXp1FGHOKIro4Fc7CTjxK6ctFRbOUkyvSzzWaKb0NWygnRyOdOyh9aWrdTU2dTmsGfibh8rjEwO6SqMN87jD3c7DlCFSF72/vm1Z6ziwRMOLh0+3XSff4yYw6SHLuJvH/xVsG3V7mx2pp7k3q8W8eSVzXl41DLAM0FAszqVmfzwRX7P6XsRf/C7pQz9eyv6nlMfgDV7zXu1qkQf1BhiTVBqjEKUXrCa4GLgHGAAns4vOUqpFXgC0RuOy7XWCdtVyYWNbCoV255LctGLlYa1umHB18Vo+IvWAHzl7gHA69xQbDcLBk3ULqpwguut00lXJ+ltnU9ry1YATy00f8KXFUYmK4wzeMV1M8dKOYf5vmzP/bVDJxx+9znhcDNxZdGJA5wug58W7yTrWF5BAHoFGpph5nieiwe/W1oQgr5R9+Zv67iqbb2ErfF4X1dZdUgK1ysT15But/FA97NiXRQhIiZgCGqtn/R+rZSqgycQvf8eAs4CtFJqg9a6RTQLWlEYWFivTwdgoas5APflz7VdiRyaqN30ts7lFuvvtLZspbVlKzfZPFOwfeTqw+uuf2CE1d8pPC9PKLp81FtTNtC+UdWwjnHfN4vpe069oLPU+D7+7h8b+WruNtqeHt75yotwa7hlXSEeMd0zZ76EoEgk4XSM2QdMzv8HgFIqFWib/09E2XHSWKqbsNTVhKGu/qSRy23WSXSxrKardSX/tI3lZutUPnb14Xt3Nw6QEfUy7TqcE3DM0mM/LOO28zNpVT8Dh8vAbrMwfsUexq/Yw42dTg/7fE63TtiaYCI66XCTkmRJ/CZsUW4FrTIopcYppYq3BwJa65Na67la6xGRL1rsLXj6slgXIaAcUvjQ/TducT5Fy9z/8InrSo7odB5PGsWc5Pv5w/4I7VV0b91qHbgJdfSinVz13iymr99P02cmMmbproLHvB1tfM3eeACtdUEv0MKO57nCaizMznVy++fzORHi5ALlWpwFzZEcB2c/N4n3/tgY66II4Vco7Wa9KLRorlJqlFKqRqHvLUqpKqbPLOdqVU6OdRGK+elf55tuP0EqQ139ucjxDt3zXmec0ZnGlr38mDyYqfZH6WJZRcg9LsIQ6hGnrfNMNvTgd0sLtv2waKfpvjd9Oo83flsf4Fj7/T7m67bP5vPnuv0Fq3aUB8E6vJSXDjEHjnvuMxf+4CNEvAklBH0/Xl4JRdrZagHlf1qVELxzwzm8d+O53NqlZEsKrX2pJ+uG9Cyy7d0bzw3rGCk2/0MOvDbp+jzsvI9WuZ/yhvNazrTs4X/2oYyyv8QFlhVEMgyPh1jD2rDveFjHff/PjWFXbFxug6HjVxcsNAyw4/BJIHBtNV54X285ybiQJdrrEYklUj0ootcTI46k2W30aVuPwX1b8fUd55nuk2zzvBWXnV18JrmUJCvJPiHWoFpq5Aua7zhpvOfuR7PcL3jOeSsNVRbf2F/hR/sLXGxZRllenmZtPBC1Y+864gm6mRsO8MnMLTzzywoAFm8/XFAbKQ/iqzFTiIohUuGVsB/2Ci+U2/WsmgVfW0yuWIueuYx1Q3qxdVhvPr21g99jfnd3Z9PtvoH4nwDHCEcedv7rvoKL897iaef/UUcd5kv7q4yxP8sd1gkkEZ/3y0INhZ5vzQBOLUzsvdfY78PZ5abpsCSks4mItPX7jnG4HLSaRFKoIXi7Uqpz/lyhEIehp5Tqo5QaefRoaCsRhGrELe0BqJeRQkpSoVpc/vWnc+PqBZtqVArtHmLnxjVMtydZi/44upvUJislF+/Q+0TP5gVfX9e+AVe2rmt6fAdJfOO+jEvy3uQJ511U5xjPJn3NH/ZHudoyG1ucheHcABN/F3Ysz8XynUfi75eyhLTWnPfyFL6aszXofvGt4oZ0rtPtdwHseNbjrRn0fndmrItRpkIJwT+BJ4DZQDaQDryqlHpQKdUViItBW1rrsVrruzMyoj8sAE7NXxnJ61D9qsGbRhvWKD4ovl7VU9OWPXNVC9NelYU5sTHKfQmXON5ghKs3Bop37e+zLvlWbrD+ETdh+O7U0FdFeHjUUt6ecqozzdIdoa1P6HQbvDJhDUdPOk0fP5LjYOAPy8gJMqn1tHVZHM0xP0aoCtfs9mXn8eyY8Oalj7/IifeQjp7mz06i59szYl2MEtl9NGHnPjEVNAS11t211tXxLKB7M/AanuB7Fs/ySmuiWsI4VdCJoZR/5wp4qW9LRt/bhfdvOjdgR5kpj1wMQJ+29Uwf75RZnYzUpJA7lLiw8YrrZro53uRp5/+RTTrDkj5lRvJD3G/9mSqE15kllpRSrMpfWmnT/uN+Q83XuOW7GTFjM8Mmmv8avzt1Iz8s2sn/5u/we4zDJxzc9vkC7vl6YfgFNxHqr5Q0h8Y3s/l3RfwJZZxgR6VUW631Zq31D1rrQVrrHlrrmkBj4Hrg1aiXNMZ8LziW/O+9E0+fYzKLSbdmtfwer0ntU0Mvb+mSSYfM6lRNs3O1n4C7omWdgue85y8olXlZg9FY+MZ9GefmjeA2x0A2GvV5LOkH5iXfz/+ShtBQ7QvreLG29WAOA39YFnxHwJ3fYpXnNG+6crjdgGdicH8c+QfZvL90F73Ei7TEe0Ui8YTSHDoMuLHwBqXULfmTa78ErNVaPxWNwsUzS6Hu7L8/fBFf3dGp2D7/ubVjsSERXun5qyuEGlgjbvHfScbwWQap5JcexTTjXAY4n6Rn3jCmGu3oYl3NjOSHGZH0Jh3VWuK1icv3NWcdK94rdMn2w7R4bhIHC/UYtZgMS3C5Dbbkf4pfu8cz/+mvy3ZHsriAZz3FZ39ZSa7TXWR73N/q8zF88jpaPDcp1sUQokRCmTatNfCM9xulVFvgc2AzcDbQJ7+muM3P88u12pVTqFslhef6FJ0a1Ztdhtac5Wc9O6tFYbUEH9dXWg2qee4TeodlmPVcDdda3ZD7nQ/wkrM/t9kmc6v1N65IXshKI5Ov3Jczxn2+ZxLxcmTE9M3kONz8sTaLVyet48DxPM5t6KnB/7xkF6t2H+W3hwxrTGAAACAASURBVC9m2MS1fDprC/ddcmZIkV/S0Hpnyga+mruNs+pUYkCXzEJN7MFWljcXq9bR9/+UGWFE+RVKTbAyUHjKh/7AWqAZnubQv4AnTZ6XEOw2C3Of6s4VLYv2uGzboCo3dDydt64/J6TjeMcPRsqMgZcUfF2/aipLn7ucO7ueAUT2XtE+qvOq60Y65H3E087/w4abV5M+YX7yfbxs+yR/WrbYV102ZIV+//LnJbsKxg8u2X6qmXP9vuPMWL+fT2dtAeCDPzexaNvhkI8b9uB+w9OMahhF3z8j9m9nZCXa6xEJJZQr8w6gfqHvLwVG568r6MLTUeYS02cmMJvVwrBr2pBZM/iCty/2bcn4By4ssq1hDc/z0gMsOgtw+wWZvHND8aBtWCON0zI8vUI1UDXNXhB+ha/FH9zUjllPlP7Hk0MK37gvo6djGP/Ie5bfjXb8zTqbH5MHM83+CA9Yf6KBCn06s1gyAtS0Ak3JprVmzNJd5Ll8mi/zr/L7svP4dt52s6f6OZ7nf98PLfG6lFK4pN+OKA9CCcHfgIEASqnGeFaM+L3Q41uA8JcDqEAGdMmkSe2iTabD+rVm5C3tTZtSJzzQlS9u7wjA831aFqyv56tg/Tmfi3rhi6pG06BaGlVSPC3fT195dklfRsFZ5+mzedT5LzrmfcijjnvZrWvwSNJoZiU/yHf2l7jOOo10TpbyPJHnnTot0BRugQJo2rr9PPjd0oJ5TSet3FssEJ/6eUXB19m5p3qo7j5ykh5vTQ+44ob3J+pOuKqgEPErlBB8GbhAKbULmAdswzNm0Os0ILzVUwXpyTZ6tDQf1N6iXhW6Nasd9Bj+mj3N7gl6j1c/gtO0nSCVH42LuMn5DBfkvsPrzuupzWFeTxrJwuR/8m7Se3S3LIqbGWnmb/UMvj8YYEaMz//aWuT7M/Jr+qdXTy0YdrH3aC5zNx/k3q8XMWziWt9DADBj/X7avPAbs/Oni/t67jbW7zvODwv9D7WI1LAbkRiyc50hz80rSi5oxxit9W6lVEfgQTzjA9/VRase3QH/U/6LqPO9aN5z8ZkFKzR4H3uuTwuqp9u5vEXxWWgiYRe1+MD9Nz5w96Wd2sAN1j+5yjqXq61zOKLTmeTuyO9Ge/4yWpWrDjU7DuUA0LFR9SLNe3vzBxTvPFy8xrtk+2Hm5892s2jbYc5vcmq6Pd9aumdb0ecHaq4tjxLr1ZSdNi/8RpJVsWHolbEuSqkYhuaFsau49fxMzqxluipfTIXUW0NrvV1r/ajW+g6tte8ArLOB0ZEvmiipJrUrcceFnk4yVVKTAKhZKZkXrm5JktXCx/3bR/HsisW6KY+77uGcvJHc6XiU6UZbrrTO4z/2N1iSfA+fJL3B9dY/qUlkp7iLBld+0+RPS3YxZ9NBwHNRf2jUUr/P+fuHswuCzJJfLQ8UBL4Vd2kNTUyPjFrKpJV7w3qO08+am+XJxv3H+e+cbdzz1aJYF8VU0JqgUupjYFH+vxVa6yJTcWitb4lS2UQQj13RlIdHLTNd93DgFc1o0yCDiwpN+u3Vs1Vdlj3fA7ehaffS78UejxQHSUwx2jPFaE8SLjpZ1nCZZTGXWxdxuXURhk2xVJ/JFHd7fjfas0HXJ54HWH+3wLwp06zi5htkpzrBBH6e57klu/DF7zsnDp1w8NOSXfy0ZBdbh/WOdXFEIaGME7wbcABJgFMptYpTobgIWK61rljTjseJv5/bgL+f28D0sZQkq98ONQAZ+TVEMz/+83yu+Wi238dLwomNv4zW/GW0ZrBrAGer7VxmWcRl1sU8njSKxxnFVqMOfxrnMNVox1zjbFwh/XqWvbGFBs77yytvU6d3ZqGAPT59evXG/8TYoTEL5f3H8rBbLWSk+f/9KyufztxM29Or0jGzevCdSymaHzbjXbx/OAvlKjMZOAcYgWee0Hb5/64BqpEfjFrrdlErpUgwijW6EWvcjXjP3Y86HKK7dQmXWxZyi/V3brdNJlunMd1owxyjJRPdHTlMleCHjRGztRK9OVbQSclbEwxwSfDWEr1TufkbYlBeMtKsmB2HTsFmUWx8Ofb3uYaM98wXKzWzii2UjjG9lFJXA28AWcADWusnAJRSZwDt8YSiKOfS7VZOONxlPr5rH9X51t2db93dSeckF1pWcollCZdbF9HHOpeXbJ+xUDdjirsdvxvt2apPK9sCBpDncvP46OXFtnsHwPuuFl+kOdTPMX2nwUs0LrnpKeJIqB1jfgVaAuOBP5RSI5VSNbTWW7TWoyvi3KGJyBKJ+dZK6QSpTDY6Msh1N+3zPqZv3ot84O5LZU7ydNK3TEt+lN/tA3nINpoz1a7gB4wy/82hHhafTxSFvyu4T1jwWNFJ2cv7KhHlu/TRc+eXkVltpLyJ12b+kOfy0lo7tNYv4wnDSsAGpdSDUSuZKBPnnXHqfog1DkKwKMUy3YQ3XddzpeMVLsx7h+edt5JDMg9Yf2Zq8kAm2Z/g39afaKwiP8F1KMyaQqF4kGldtGZYmL8JtIP9NMp5RlZYU9aUr1VZSivef0/DmtBSKVUJaABMAzYCbyqlon9XWUSN97NZ+0bVsAb4bf10QAdu7NSwbArlx05diy/dV9DXMYTOee/zvPNWsknj0aTR/JH8GOPsT3Gf9ReqEPt13LxBtu3gCY7mOAsFW/H32HtvyssIEJiBlPeaoxCxEMp6gkOUUmOUUpvxrCz/K55OMX8ANwGhLeEt4lP+xfnxK5oF3O2yFnV4pV9rv493aVwjkqUKKotqfOm+gusdz3Ne7vu86LwFF1YGJn3PguR/8WnS61xhWYDCfJ3AaPPW/P47ZxtXvT/Tz/0/3+nuPP8HumWWdSyXaeuyIlLGshJuM5hhaBZtOxSl0iSOeG1eLG9CqQk+hWc5pc+Bxlrr2lrrK/IX1x2ltY7NVUZExKlZS07VIkpSn+jdJnadVfZRnc/cvfib4yWuzHuZ79zdON+ymhH2t5hqf4zbrROpTeirQUTCl3NOrSy249DJgprg0AlrgoaYd+5Qs1rjDSPmsnZvYs9S+PGMTVzz0RxmbzJvao6FPUdP8uLY1TKvaynE6zsXSgj+iWe6tMHAGqXUAqXUx0qpu5VS7ZVSsR/wI0rMbBC3V6XkwJ2HbYXuIV59Tr1IFqvEVutMnnfdzrl5I3jI8S9ySOH5pK+YmfwQr9g+oYGKTS3qs7+2FHx92+cLuOU/8/jf/FOD7w1DFxsn6F2xvrDNB/w39SZKY6h3gvM9RwJNNh45D49aypTVge/TPfr9Mj77awsLtsZPDTUeK4KTVu7lq7m+S8vG929m0BDUWnfXWlcHmgADgKl41hF8GVgAHFdKLY5qKUXU9GzlmcS7QbXUgiD01goDDajfOqx3kbFekV4vsbTysPOLcSFXOYbSL+8F5hnNudH2J9PtD/Nh0tsxXwdx5oaitZyPpm9id/58pCWtbPg+7cDxPFbtjt3UdCW9R1nWl8yfl+zizv8G7rEZj8M6ApUoO9eJ0+RDVLTd+/Uinv1lZZmftzRCnpJDa70Zz2ryP3i3KaUygQ7IOMFy644Lz+CGTg2L1PrqVU3hjgvP4MZOp3PZmzNCOk6gQeCx5ZnLdIDzSeo4D3Gr7Tdusk7lyuT5LDGaMMJ1FZOMjsT60+qvS0/1bi08bVp2rpMqKaE1tvguAHzFWzM4eMJRbgeDx1/slB9tXviNy86uzae3dvS7z4k8F1aLIiUp8JqmEROnP9BSfXzXWm+VcYLlm1KqWLOnQvHsVS1oUrsyI25pz/N9WgQ8RvO6lQP2ZHzt2jaRKGqp7aM6r7luoEveezzjvJ0aHOVj+9tMsg/iastsLDHqRAOwbt+p+3yFQ/DR733nqw9doCWj4lq8fp6KM8E6xkxZE7jpv+Xzk7nw1T8jWSRT8d5pOT4nZxQx8c9uTXhp3Goqp5z6tbjCZ83DvwZdyvHcU2uczXriEs+q9gGO2yCCaxhGwklS+Np9Od+4u9PPMosHbT/yrv19/mWM4R1XPyYZHdGl+3xYKoWvbd6lnMDzyb08KmkFIK56P8ZRUSLpwPG8WBch5uLrRo6IqTsuPIOtw3oHbB6pXzWVZnUrF3zfoFoalZJtAe//xGtTqcbCj8ZFXOx4i/sd/yYJFx/Z32F+8n1cYVkQs3IV7oFYuCdo1rGiF6x4fV9F2UjQXC5zEoIiIgJdjn3zMV6aR700FsYZXbjc8TqPOu6lKscZYX+LUfYXaa62l3l5nv5lRZHvj+Y4yXW6uWT4tCLbC69M4YpBJ4hQlTSqYzH4f/amA2QOGs+uI8UXSy6p9fuiM6QlmhXlaIxFjdfQlhAUEeE772jjmukFX/teys4o9JiZNg0yCr6+tr35UlHRYOTXDFvmfcYLzgE0UzsYb3+SV2yfUIey6xq/41DRC3DbF3/jbpMFSVfvzi74+tkxq6JerpIqT82h3mErC/0MhSj8uzxtXRbfLzRfY7KwHm+F1rksntz2eexaQsqahKCIitsuyPT7mG8o3tX1jCLf9z+vEW3zgzC1rHquFeIgiS/cPemW9yafu3tyjXUGM5Mf5GHbaFKIzT2UGev3F9s2bvmegq8nrdxT7PFIWLX7KEdznMF3jKBINvM6XAYrd0VumEjhWL7t8wWmK4iUlYBrVIqQSQiKqPOtJfo2c/ku/tu1aU0evrwpAE1qV4pq2WwBJg0/QmWGuG6hh+M1/jTO5UHbT0xPfpielvnEW+NOSZoOHS6DzEHjyRw0njyX27Tm1fvdWfxj5JxIFDFskXiHXxi7iqvem1Wkg1HAc8ZTZ5wEEe+LRSdMCCql+iilRh49GrvBweIU5edrgCRr0S2F/zZu7NSQ0zJS6dasNr/cdwEDujQqVTns1sC/4qEsH7VVn8Y9zke4Nu85DunKfGx/m7H2p2mhtpaqbJFUkgVA/io0LVmzZybx6cwtpvuVdJq2kt8LDL6P29DkOIr2ln1x7GoyB40vsm3pds/UxkdPhlabPbXuo3kh4qkrUpxmSjHxPrF7woSg1nqs1vrujIyM4DuL6Cs8F2mhv4EnejandX3/P6PC+55zetVS/wFVTQs80Dyc8Fiom9PHMZRPXb1obdnKz/bneND6I8nEdjzekRxHwAui1pozn5rA53+Zh5zX0AlrAj4ezI5DOWit+WnxTvJc7uBPCCbAa3rk+6W0eG5ykW2fBXl9QphJmBAU8aVwttSslFzw9T+7nRkw2ILV3ML1zZ3nBXzcd9HbYFzYGOK6hXa5H/Ob0YGHk35ksv0JLraUfFB7aWTnOjnnxd+DDox3G5rBY1eHdMwnRi8vVqMKxd7sXH5bvY9Hvl/G21M2hP18h8tg28ETIdW2xiwNbf3IsqosPTxqaYneMxF7EoIiYm47PxPwzCNaOFsa1QjcG7TwDf5HezT1u9/URy8Ou0zBzh1uCHodogr/dj7AzY4ncWPhS/urfJT0FqdxsETHK6l5m4P3WvWtJT4/ZiX9P53HrsPmwwBGhdDj0R9vJ5r9hcY0htps99TPK7j49Wkcy5+MIZYdP3x/K4KV5eclu6JXGD/KS3OoV7wWV0JQRMyzV7WgQbVUhl/XNui+i5+9nHoZKcW2Vw4wT+aZtSpRp0qy38fDFWy6t1D8ZbSml2MYrzmvp5tlGX8kP8r91p9Jomxmd7kryMTPUPTi43IbfDlnG7M2HuCZMCY6bvHcpIKv9x4NvrpDSd7WWfmTip9wxHBmnHi9UouokRAUEWO1KGY9cSl92tYL2s29erqd6pXsIR33u7s789o1ngH24XafDxRy6UGWigqVgyQ+dP+Ny/JeZ7bRkseSfmC8/Um6WOJj7F7hGWje/H19yM8r3Jsvx3HqHl+g8Dy1PmU4JcT0OaHUdPYfi86QFd+yxOPsPNGuKUfkvm45ICEooiKSHcI6N67B9R1Pj9wB80X6sraLWtzhHMg9jodIxcH/7EN5J+l9qpMd/MlRVHhC7g+nbQrjeebbA/1svaf6c93+Ivu5DR20BnmqK33IRaTj0Cmm251ug4VbD0XsZxxq4DzzywqO5ZbNuEqz92nx9sOMmB76zziQZs9MCr5TCOLv40NRMoG2iIpo/eL7uwAvefZyzn3p97DLEY1yTjY6Mc1xDv+0/cq/rGO4KHk5Q103M9p9UZTOGFg4q6EPHnuq9hruuK6Dxx28nN/DtMg9QTTDJq7hEz9DMBZvP8zgsatxuHXB/qU1fPI6RszYXOrjvD1lvd97p2a+nrs9YJN+Sb3/xwZ2HDrJq0GmHOz34eyInxsg1+mm+xvTGXZNa7qeVatEx4jXe5hSExRREUpNMB6amKI1hikPO2+7ruVKxyts1PUYnjSCr5Je4XQVeAXzaDDCuPp8/tfWgq//7ueC6n3Hhk9eR/tCHzwe+X4p2YVWGFm640jB19PWFZ/xxuu5MStZtuOI3xUNHC6DT2duZtLKvaaPz91cvDPS6j0lq337BvDbUzbww6KdYR0jnPc7VMN/W1+sw1JZZsrm/SfYdeQkQ8efGkbz9dxt/Lbq1M/E8PNhK86HCUoIiugo64Az+/NbP6RXzAfqbtQNuN7xHM84b+dcy0am2Adyn/UXbGXUcQaKzjEajhVBpht7/8+NRYZmFL5vCPDgd0uB4L8Lvo97M8T7M31rynqGjF/DvV8Xnz8V4IaRc4ttM8shp9tgTYjhWHi5sCJlDeX3KYrp9MiopdE7eABmtfNnfllZZE7bY37es2C8TdexIiEooiojNXjTUDgfnL2XoJ//dT5/FBoyYfW5OL16TWvstuC/3mWRkRoLX7svp3vecH432jMw6XvG2J+ltSp9c10o/mESEmVJo9mQdTz0/Qv9PrgNzbfzwl/Jw6w29urEtfR6Zyab9wcvy6CfVpBdRvf2wvFToaEYsZiGrDQfKv01cw+fvI5rP57Dip2xme1LQlBExRUt69KmQQZj7rsgosf1/hHWrJRM41qVeP3aNnx0czsy0pKKDM3wrolYkj/ZUMKzJPZRnfudD3KP42FqqGx+sT/L87YvySD0gIgHkfrgcCTHYTq5tTfAtIaRMzaHPOWZV+ag8Wzef6LY9iX5zbOXvjGdp39eUexxX9khnveyN6cX+b6soilS5+k4dArv/xF4coNo5q13Wr5YLfArISiiIiMtiV/vv5DMIMsmldZ1HU6nV+vTgPCXXfJ3Mb+pU0MAHu/ZrFRl82ey0ZEeea/xg/tibrdNZkryQLpZlkTlXNEQqabu6z6ew1XvzSq2fd6WU01j2w8VD7NQ7M0u3hO1cKm/8VO7LMnFfmMYtdxYmL/lUMBVRvYfy2P4b6ENnfG+h+sKzSf76qS1pSlezEkIiphpWD0NgDR75JdL8tYYfYPu5vMackOh4RZml/PHrmjG/Zc04a6ujSNeLq9s0hnkupu7HQ/jxMoX9td5M+nDmA+niAbf9RG9vE2kge49+oZS1rFcth4oWTCG64eF4XWIKWuhBvb1I+Zw79eLI3JO79/Tqt2nfmYf+Rl243IbHM1xhvyhafyK6CwHFoyEoIiZV69tw8f923NWncohP6e0TXFD/96afu1O1RitJjNoV0q28dgVzUiK8DymZn4zOnJx3tu84+rHVZY5TEl+jH6WGSjieKX4MuprZHYPqdPQqXQbPi3sY4VS5sM+86++MzX8+U8TlW/ghhLAT/+8krYv/obLMEJ6zugwe+FGioSgiJlKyTZ6tqoLwOxBlzLhga4hP9ffH1TvNp6mUe81TynFI5f7n4+0VYAVLfz5uH/7sJ8TiBMbb7mupbfjFbbqurxp/5jv7ENiMpwiFNsOhrY2XyALItwb8PsFwec7DRaEC7Ye8vt75dvzNS7EYNyd9z00O7Xvh5Zflno68bjCGKcaCxKCIi7Uq5pKi3pVgu4X9BO9yd/bA93PKvJ9q/pVaFwznUG9mvP+Te0ChuTWYb2LbWvfqFrQcpbEBt2Aax0v8KzzNtqqTfxuf5z7rL9gJ756KZZ0DF5hvrUuM2v2ZIfc5Pf4j6Vf4X3yKv8fOlaFMcwknhaP9c7HGgvev9VF2w7HrAyhkBAU5VKwWUUChWWa3cYfj3WjfaPqVEq2hR1q0Zyz0cDCV+4eXJz3FlOMdgxM+p4J9ifpbAltGaTyIpSu9l/P3V6qFS2KnTPIvakfF++M6coV4XIaBrnOwDXUCSYdYtyGZp7JBANmvIEeyvvi7/198qfgPXFjSUJQlCtD/taaM2ulc1pGqunjJbmIhXuLqyw+6HuHU9zmGIgdJ9/Zh/BG0kfUIDZjqSLtYIy6w5eWN7uHjIv9h5IOQ6bQ/NlJ/GPEnKBhWNhH0zaGPHZ07PKiIeoNupLUduOoglyEhKAoVy5uWoupj3YLOpYvGjPWeJdxMhuI3atVXS5uWrI5FQOZZpxLD8drvO/qSx/LbKYmP8YN1j9i3nFmeynvCw4q49rBwq2RbZL7dJb/VewL/3pMDLPH45EcR1iBBp4hJYu3B399N+YHXzgTF+w45Pk5F35N09ZlMXB0yZufj5500uudmQVDS8waBQxDh/0+lJSEoEgoJfq0GSQvpz3WjflPd6dGuicEzRbiVQqe7n226fN7tKhTgkKdkksyw13/4ErHK6zTpzMs6VNG2wfTXIU/k0qk/P3Dv2J27pKYtHJvROYuHzF9E5NXmc9haibY1HO+znnxd/72QXTe2zlBmkADhY73z0op+G6+eRO1byuMvw+if67NYs2ebN7LH6Bv9jf70vjVNH92Eg5X9D/sySoSIqF4/6B8c+rlv7fG34iHYLVG74D/z27ryJQ1+6hTpfhiwApFUz9DPWzWU8e/tHlt/libFfB8/mzUDfiH41musczkqaRvmJQ8iC9dl/OG6zqyqVSiY5bUwRA6tsSTOZsP0umM6kH3C/YhasqaLKasKdnPL1Rr9x5j28FTYyFDvX9nJpza1OMh1O4Upb8nHsrzvRO5O9xG1GZw8pKaoEgoBYu6+my/6byG/KNjQ9PntD09gya1g4dI3YwU+nduZP6gzwlXvNCDd2881/NQoUROSSrtn5ziR+MiuucNZ5SrG/2tU/gz+VH+af21zFazL6/2mcwiEw2hTP8VrIZTuLYZ6v27wsHp9dPiXSZ7mgs0iXUo9wB9m1l9P4i6DV3QvArxs86ghKBISOEM6E6z25jyyMXBdwx0Pp/vK6ckFVw4Cjefnl4tze8xru8Q+rRvR6jME6676eMYyjZdhyeSvmOq/VHOt/hf9b2ii8T4xlD8snR30H0ezl8NYuWuo/R4azrH84p+gDFrcg9Iw8WvTwtt19JU5AKU67qP5xTd1efxvdm5dH3tz2LrM+44fOrnUlb3AQuTEBQJJZ56oBkFIXhq26M9/M9H+tLfWoV9jtU6k36OF7nV8QQaxbf2l/k06XXOVKHXAMQpv60umwkKxq/Yww0j5/D65HWs33e82OQBYYdgGVmx80jwnYI4cNzTlO5tISk82XnrFyYX2XdTGczLKiEoEsqpDIz9RSR/tigsStGyXhW6NasV8P5Gsq3kc6hON9rSw/EarzhvpJNlLZPtTzDU9h9qUfqLlii5QJ/J5m4uFHw+O0YzA/0d+3CO/0kZvMUzdOBJBYqeJ/iLOOazXJXTXfSNKItexNIxRiSksv4gbXax89YElYLxQaaEu7GT+f3KcORhZ4S7Dz+4L+YB20/cbJ3K362z+Nx9BZ+6ruQwwWfkEWXL3+9pNGuC/lpLTpo0RUZj9hvvMRVw8HjgDlaeWYN0VBfHlpqgSCixbg59vGczGtXw3Pfr0bIu7RtV40GfadvMpCZFbiWNQ1ThBddtXO54jRlGG+6z/crU5Me4xzqWVMqmc4jwCPb7OG3dfs9+Ph+jLCYTu8dSSf6ufO9zen3tXcYqxJf4Q5Qn1pYQFAmpJJeQ+y45k+Z1Q1/Rwsy/ujVh+sBLAMhITeLHf55PoxrB11SMxnRdW/Vp3Ot8mJ55w1hunMmTSf9jRvJD3GUdJ2FYRnYdMV9GKphoZmDJKlWBfz99F0d2uf33fnWHOaF2tO8LSgiKBFPyMBl4RXMmPXRRBMtirnJK8bsQodQWS2qtbshtzifol/cCa4xGPJ30LTOSH+Je669Uomx6TFZUY5cF7ylq5lhudIa7ZB3LZUwIvVe9Ql1s13dx5D1HQ/uQFQ/92OSeoCgT/7urc5ExQtFyarB8fDUnFVarcnKRi9zZp1Whapo96uddrJsywPkk7Vzrecj2I4OSvuMu23g+cfXmv+4e5FB8EgARG8Mmhrda+02fzgtpv60HSvY3GG5z6KFyNJmC1ARFmehyZg2uL7Sie7QUTO8U9TN53NjJ85oqJ4f/efLWLp6B96E2ffVucxoZqUlhn8eXNwz75r3ISuMMBiV9x6zkB7jf+jNViH6XdFFcrO9lB3OtzxjAYEJ5OdknXSzYEtl1JUtCQlAkpLKqCLauXzXs8/Vo4VlIuFvz2kDoPQEf69EsopN0L9NNuNU5iL/lvcgS4yweS/qB2ckP8LjtO+oQ+4uTiLzrR4QXZtE0Zc2+kNaBjPbnA2kOFQmlrBc0LUmHloFXNOPOrmewM3/mjFBrgtHK9aW6CXc4B9LCtZV7bOO41zqWu63jmGR04nPXFSzSTaN4dhHvQpkGzlc8LSwcjNQERULp3LgGAKdX9z89WXSEHhJWi6JmpeSC75MKzez9+e0d/YZitXQ791zcmOrp0bl/uFpn8qDzfi5xvMF/3L3oalnOj8mDGWt/mmssM0im/NznEZEzrgSde8LsABrQlgPF50SNJAlBkVDuvqgxs564xO+KDvGkTf0M7up6Bu/kT7QNcEmz2jT0E+AZqUm0rJfB4mcvj2q5tum6vOK6mc557/OU8w6ScfKG/WNmJ/+bR23fS1NpFMRzxemFsSVZQLjkL8i3Fhnt+UQlBEVCUUrRIMAk1ZHSuXHwZXmCsVgUT/duQf2qqUW2PxJgftGydJIUvnV3p4fjNW5ysx6h0QAAH51JREFUPMUioyn3WccwK/lB3kt6l/ZqHfHRyV3Em9KE+hezt0asHKGQe4JClMDXd5yHy9CMjsJsFle3rccD/1sS8v5VUmxkR2lcmYdittGK2UYrTlf7uMU6hRusf9IneS6rjUZ84+7OWHfnMl/TMJE8/P3SqI0NjIVwxiL6GlyimmfJSU1QiBKwWS2kFJrqLJbDEvueU5+f/3V+mZxrh67Dy/lNpU87/w8LBkOTPmNB8n28bPuEzpbVSO0wfIkUgABfzd0WsWNFe8xvwoSgUqqPUmrk0aNHg+8sRJyb+fglYe1f1rGTQwrfuC+jp2MYV+UN4Ud3V/pZZ/GdfQhT7AP5l3UMNZC/RVF60f58mTAhqLUeq7W+OyMjI9ZFEaLUStq7NdCgfbPp2kpPsVI35inXnXTK+4CnnHdwnFQeTxrF3OT7+SRpOFdb/iJN5ioVcUruCQpRCvHQ8KcUnFnTcz/ulWta06VxDS5/a0axqasya6SzYlf0amfZVOJbd3e+dXenidrJtdaZ/M06i8utizmmU9mla/KX0YqXXTfhJnKrZghRGhKCQpSCdzhDsxgOydAaMtKS2Dqsd8G2SQ92ZfuhnCLTXUVjpQp/NuoGDHPdyGuuf9Berecftmlca51Bc8sO/m6dyXh3Z8a5uzBfN0MnToOUiIIjJ/0v9hsJEoJClMLFTWvxy30X0LZBfDXD166SQu0qsZ8Q28DCAt2cBc7mvOK8kb9ZZ9HesoHrrdO4xTaFvboas42WjHN35g/jXGRmGuFr2Y4jUT2+hKAQpXTO6VVjev5QOs+NvrcLz/+6KvqFCeAgGfzH3Zv/uCGdk3S3LKandQH9rLPoZ53FTl2TCe7z+NXdhZX6DCQQRVmQEBSiAuiQWT2uZiU5QSq/Ghfwq3EBtZxHuNr6F90sy7jdOom7bePZZtRmnNGZqe52LNFNpMlURI2EoBAVRLX00i/DFA37qZpfQ+xNBsfpYV3I1ZbZ3GMdx322X9mrqzHPOJvv3JcwzzgbQwJRRJCEoBDlXKiNhu/ecC7jV+zhuTGxbRYN5CiV+MHdjR/c3ajCcbpZltHbOo++1tn0tc4GYInRhE9cVzLLaE026TEusSjvJASFqCBqVEpmQJdMbj6vEUdPOhn4wzKmrs2KdbH8yqZSQZNpmjOXSyxLucM2gXaWjXxofxeXtrBUN2GGuw0zjDYs142llijCJiEoRDkX7rRSVouierqdD25uR/NnJ1Ej3c7B/DGF9aumsuvIyWgUs1RySGG80Znxjs4k46C12szF1uVcZFnOQ7YfeUSN5rCuxF9GK6YbbZjhbsM+Sj/JuUh8EoJCJLDxD1zI5v3m67GlJFn54vaONKtbmS6v/AHAoz2a8sj3y8qyiGHLw85C3ZyFrua8wfVUI5uulpVclB+KV1nnQhKsMxoww/DUEucbzckjOuswivJNQlCIBNayXgYt6/kfw9itWe0i31tiORN4CR2mCr8a5/OrcT6gaa52cJFlGRdZljPA+ht32SaQrVOZbzRnnnE2E9znsYtasS62iBMSgkLEqRf7tozrTiwADaqlsvNwPDWfKtbqhqx1N2Skuw+p5NLZsobLLYu43LqQy6xLeDrpWw7qyqw2GrFSn8Fkd0eW6jORcYnxyW6N7n1eCUEh4tSALpl8O287a/ceK/bYmhd7MmHFHh79YRm1qyRH7Jyp9pLP6Xl123r8uqzk68hFw0lS+NM4lz+Nc3nKdSdnqZ1cYFlJd8tiulpX0pWV/NM2lmydyhLjLOYaLZhjtGC1boSD+BxSUtFYotzXSUJQiHIo1W6lX7v6JNksXNmqbsSOe9nZdUpepqT4nxR7g27ABncDvnD3BKemndpAC8s2zrVs5DzLGi62LgcgT9tYrTNZapzJRl2f6UZbdmppQo0FFeUauoSgEHHsrq6NefSHZVhMrgNKKa5uWy+i5zM7TyCFZ6G5t9uZjFq4I6LliS7FYt2Uxe6mfO2+HID67OccyyZaWzZzrmUjN1j/JFV5es5uN2qxVjckQ51ghXEGH7j6cpgqsXwBIgIkBIWIY9e0b0DvNqeV2flKs4r3GTXTadewKou3R3fC42jaRS12GbUYb3QGwIqbzpbVtFRbOdeykRZqG40sWZxnWcudtokc1pVYbTTCjYUcUnjf1Ze1uiEuubSWG/KTEiLOpcRJM+MHN7Vjypp9/LxkV7HHaqR7hh/89K8LmLv5IDeMnFvWxYsKN1b+MlrzF63B7dlWjwM0t2ynsdpDS8tWmqmdtLBsA6CndQEubWGbrkOWrsYyfSaLjSbs11XJ0lXZRU2kA054ot1hWUJQCFHMXV3P4JOZW4psa1a3Mpk104qEoM5vDx1z/wVlWr5gHuvRlOG/rY/KsXdTk91GTf6AgmBMxkEDtZ+WahstLNtoobbSUGXRxbq6yHNzdDJbdF226NPYoWuxM/9flq7KTl2LY6RFpczlWbQ/MkgICiGK8C7Oe0GTmtz2+YKA+3pvCZamGTUabFHuVu8rDzubdH026fr54xU90siludpOLXWEJmo3tdQRmqmdtFJbuNyykGTlKnKcw7oSAId0ZVbrRhzSlTlCZY7qdI7odI6SzhFdiaOkk0YeB3QGu6lBItcuLeHeqA6ThKAQwpTvQHrw31Ov8NZzTq9aZCo2X1teuZIznpwQ8NwzH7+EHm/N4KTTHXJ541EOKSzWTUHDZJ/HFAa1OcLpKou66jAN1H4aqn1kqBPUVwc5R22iiuUEGSon4DncWuHExjFSydXJ5GInGQepKo/Nuh5p5JJOLnt0DY6Tysn8mXNaqy3MM86mqjqODTd7dXUsGLiwYmDBgkFDlcUBnYFFaTI4zj5dDSc2kvH8bF3YsGBgQVNZ5XBAZ5ChTpCr7VxlnctkdwdOkowbCyr/I1MyTjQKNxYMFOkqj1ydRE2VTR5JnNR23FixYGDFYBmtgSsi/aMpICEohCgxszUKU5Ks/HBvFy59Y7rpc0KpNZ5ePY26GSlsOWA+5VtJyhVvNBb2UZ19uvqpKrUJCwaVySFDnaAqxwv+b2nZSjJOjpNKEi4qc5IUlUcKDjI4wYWWVWzW9cghhdaWrbgMK3U4jA03NVQ2aeRSzXqM6uo4AEd1Gi6sWPPDx0CRoXLI00nkkIwG0snDhQU3VkDjwoobCxoLVTiBApKVs6DsV1rnoVH5MemRix3L/7d372Fy1fUdx9/fvWQ32Vt2k91NNpvbZnO/bRLIhSSQBEhCLkYuAoJogRQLSaEoUag+gD4gkVpFKy3aVkWKAt4ewMvTomBtHxUrCogiEJBWfYBYxKhYMJJf/zhnNjOzZ+4z55zZ+byeZ5/MnHPmnO+czM53f3cchqOOI7TwCg28Rr05/uCaeIXG4XN6SbmyVcRKgiKSt8kdzYHbK1Eb6qohk4XgCHUcopVDrpX/oXc4Yd6bVO0a6HD23fHjCKrWndg6hnMqeFWtOyIiGa2ckboSQ2fLGJ5+37acryukjXD74uAhIKWkQFfSqyUawZ+ZUmYxyoeSoIhkdO7qacOPE3mtPqmjQqZkU0jB8OZzl5d90L+MHrddsKqi51cSFJG8NGaZxDG9w0yuguAFa2emPA9KpaoNFYAZE1sqen61CYoI171+EZPag9v7EurrR2a2TIkq13yP48elTk59JOBEpVRpKoFKvpQERYQ3rZ6e85jGoCTo/5te8ovZsEGRjFQdKiJ5aRkz8m/m9bMnAvl1Xpjb25axd+k1OxeMaBcspTSXq2fpnN5Wrt25IOsxl24aZGjq+OKDkKqgJCgiOS2fNp6WppFJ8IbTFvPv+zbQ3pxavZkoCfa2Nw1Xs771hAG+c9WJgefvaWtm/+mLU7aVlgSz7+9tb07p4BNkQV87d1y0uvggMlg0RStPxImSoIjk1N8ZPGC5qaGe6RNGdlxIDJGoM+P+K07gis1z2DU0paIx5tKSVFqNcpq3/vGaHzROlARFJKdCC2W9bU2smN7JB96wlHFjGti7aXZKyeuMFf0jXpPemaaUwfJBr/znPzs25Xl9ziXLrTKTAOR5N1sDSt5SfkqCIlJ2DfV1fOHi41g7ODFwf9/4sRW9flBv09UDE1Ken74id8m00quaZ3NNjjZLKQ8lQRGJhfRSVz7lpdOWFVbF+v6kdsemhuydeaLu4doY8koYtUp3WUQKdsdFq7nylHkVvUY+taEfPGuooNf25BgLmS7KRFjKtQe6KzvAPCxnHjOy2rzcVOksIhmtmN4JwBvS2vBWD0wYUb1YqNt3r8o4ZAKyt53dduFKZgR0yAG4d+867nv8hZJiS0jPQ82Ndbxy+EhZzi25nTi/t+LXUElQRDLq7xzHs/u3c/yc7rKfe+3gRAa6W4t6bcfYRqZ2eb0sv3PVppR9i/s7yrICRVBB7Fv7NnLhupkBezztzTEpV2jGnLwpCYpILOWbxyZ3ZO5kM6c3OMnmW9OYPpSip72Z+ZMzj/N74IoNnJfH7DuVVun5NvP1ybQeuXGkJCgisVBMx5hMEgl0x5I+ZkwYx9U7vJ6WK2d0sXTq+LzbM4OSZbYEOqG1qWztcaWMZbzp7OC20kxmTKjM2MVS21TDaJJVEhSRWNo0t6fo1ybaE+sMvrlvIxf4VZgtTQ3cvWdt1tJcQjkH1H/pkuO45U3LvdhCqKpMn8Enl2t2LqxIHFFOSpAvJUERiYX0MXnXnboo5fmz+7fnfa5EoinlS7jOUksyu4b6/HNmf13Q7kVTOoqOo5qVmgLDSKJKgiISS9nGyeUqTZWjsHXCnO6UL+FEEkxc+9RlU7h377oRr2tsGBl3MV/llfj6vz7tD4tyWzWziw8nVcVWQUFQSVBE4qEcX5iPv3crkH+VY39n5k41DRmScKvfA7SrZQydLSOrHesC3oi3LfqMMLYxwwQBZQqtu60pZehMqTPuqE1QRKQAiSWdEnkoKCEl+893buKut64p6BqbF/Ry/amL2LdlbuD+wM40RXybV6IU1Vhfxzu3juwUVM5L9RY4IUHUlARFJBby+SJe0u+1reUq6F28YRZnHTOVN6/JPVxh5cwunnnfNq7YPCfrcc0NiQRrnLtqOs0ZSlVByavQtq3P/Pmqgo7PV6YwytX2Vu42vDCqU5UERaRq5Pud2N7cyPvPWBK4BmKQujpj76bZWY9ZMyu/GXLKMen2cbOCJx4vh9NXTGH+5Ha2L5lcsWskNDceTTGFdGwKk5KgiMRCPqWIsCZCCVpvtxq6++ejp62Zr122nr4sU9YVK3GHvn3lJi47cfbwtHtxpiQoIqNCWxnX33vmhvxKLUEdcMY1ZV+dIlciTwxcP3lBafNmfv1tx3Pj6UtStmUqpeaT3pdPG5/zmMTfCX3jx3L5yXOK+sMhUeWdfL5KUhIUkVjI5/su0zH3v/0EvrlvQxmjKd62RaVVM152klct29RQz8UbZhV9nsGeNs48dmrKtsxtgrnPt3ZwIl/+y5FDQpoa6vjQWUuLCTHQ6oEJDE31Em4Y6zkqCYpI7OX6kh7obmVCa1M4weRQV2ecnZR80if4zvZWrt25gFOX5b98ULYhHglLk0tWGY7JN9kkD/pfP/tou+Xw5AR5nSW7N62aTsfYwma8KYWSoIjEQrZEd87KaSnPy7FKRFjSJ/h2wNtOzt4TdfjYMrzNu/euY8vCkVWryecuptpxh9+xJvm1mao/J+U5bGLrwklMq9A8ppkoCYpI7A1/t1Zx55Tk0JdPK77DyJvXTOfGM7y2vqAkOdgzcuWMo9PIBZ8zuR0ukx1L+lKe71zqTyOHZU3Wt+9exT1712Y99wfP9KpT6/0eScOnU5ugiNSSN66cyp0XrR5+/tVL1wPwhhVe9WKr3+mkPqj7ZgSSv/xvPmd53q9LT0aJlSfy6Ujy3l2LhjupBB1+956RCSeR5JJLpcmvzTWpwLP7tzN3UlvKtuT3nngYdJa1gxPpyVES/NMR7wxNjakpKYz/5ZisACkitc7MuOG01N6MC/raU8aX3XTWMu76/s9ZHOKE1Ev6O3ju0CtZj+nvHFvQuLv0ktO6wYk886uXRx6Xoy9pU0Md794+n+u+8vjwtqCxkZdsGGTjvB4W9h29b6VWh5bjtQndfnvu3N62HEeWn5KgiFSN7rYm9mwcDPWa9wRMkl1uxbb9OWD3+gH+7v4DHPq/wxmPq6uzlARYDuVsld04r4fbd69ijT/vaJhtvqOmOtTMdprZxw8dOhR1KCJSIxIltUJKQ86Vo/RkiQD8c5aWNEoZimAZnxRm7eBE6tKqubWUUgGcc/c65y7q6KjNdbtEJN6Sv85720sbzpGeGypRbjppfvZFjZMTb6VKblpFQkSkCqSXpIJKMMlpYrCnjfsuPz5pX4YSZb7rJpaYg4IKXFPGZx+DONwZxiypY0w8OiwVQklQRKTM3pFhmaVks0voBJJINYkS2JEiSmK5XnFejhU4mvzFg1831MeCye1A6gD6bBLHZ4wtxGGg6hgjIlKkTF/WnS1jRmyrZBlp9cAEvvHTg4ETfxdrsCd7km5qqOeRqzfT2txAfZ3xyNWb6RiX30wvK6Z38pPnfptxfzFtrcVSSVBEpESlfllnmnYs3wLRNTsXAt4KEeU0p3fkwPtkHeMah8ds5psAAU5dPiWv4zR3qIiIDPv8X6wBjrY5JpJkfb3528t7va9eup4nrtta3pPizZiT7byqDhURqQJhzmC6cmYXx8zoApLbBFOPKTYHZkqeDfV1FUsSTQ3Zl5yCcKpDlQRFREpU2Hd1aubqahmTNFdmfmcaMUTCJdrQ8o+k2NJWX0cz56+dWdyLY0hJUESkSJM7mhlTX8e+LfNG7FvS30Fz49HSTlCC+th5K1g0pYObHzgQeP5c4+8SHUhKqT48aX5vQW1v377qxOIvlidVh4qIVIHmxnqevP6UwH3p060FJbQtCycVdd30pJWYaWXcmNxVjOlWD3SlPL/twpU8+ovKzLy1ZWEvS6fmXqF+uHdoRaJIpSQoIhIThX7pJ/JqX0cz+7bM5XVL+7K/INN1ky68fnY362d3F3WeXD523jGFvUBDJERERodi5sHM9Jr0zWbGno2DTO3Kf0HaVX4JcEl/7pLZaKYkKCISsUxtYHs2DnLCHK9UtjOglFdK29mWhZN4+OqTWTmzK3aTnalNUESkBqWX8DrGNnLrBSs5/NoRGiqwkPD4cSNntomDMOciVRIUEYm5xvrUSrsGf3B8a8ACusUIY8miuFISFBEJUXBVX2H1f5M7xvLu7fM5ZXH+q9lLMCVBEZEQ5FPWKqT6b/f6geKDGXHdaGxbPIkdSwJ6tCbmUtWMMSIio0OYU6xVi78/d0Xg9jDHCap3qIhIxMLsDRkkrk2CYbRVKgmKiIQgr+rQmCaj0UxJUESkxsWtd6jGCYqIROD+t5/Ay6++VpFzz+xuAWDD3MpMSTYaqWOMiEiIBrqzr6ReilndrTx89cl0jB25AnvUbYJxE+btUHWoiEhIxo8bE1j1GGZvyGymT8h/7tFK2u6Pf5zaWfl4VBIUERE+df6xLOhrjzoMAM5fO4M3rpzG2CKWhiqUkqCIiLBhbk/UIQwzs1ASIKg6VEQkci7EGVIklZKgiIjULCVBERGpWUqCIiIxEcb6eZJKSVBERGqWkqCISMQ0Vj46SoIiInGh2tDQKQmKiEjNUhIUEYmY5g6NjpKgiEhMqDY0fEqCIiJSs5QERUQi5tQ/NDJKgiIiMRG3Fd5rgZKgiEjEVkzvBGDAX31ewqOllEREInbOymkcP7ubqV3xWNS2lqgkKCISMTNTAoyIkqCIiNQsJUEREalZSoIiIlKzlARFRKRmKQmKiEjNUhIUEZGapSQoIiI1S0lQRERqlpKgiIjULCVBERGpWUqCIiJSs5QERUSkZikJiohIzVISFBGRmqUkKCIiNcucc1HHUFZm9ivgv8twqonA/5bhPGGptnih+mJWvJVXbTFXW7xQfTGXK97pzrnu9I2jLgmWi5l93zl3TNRx5Kva4oXqi1nxVl61xVxt8UL1xVzpeFUdKiIiNUtJUEREapaSYGYfjzqAAlVbvFB9MSveyqu2mKstXqi+mCsar9oERUSkZqkkKCIiNUtJUEREapaSYBoz22pmT5jZATO7Mup4kpnZs2b2IzN72My+72/rMrP7zOwp/99Of7uZ2Uf89/GomS0PIb5PmNlBM3ssaVvB8ZnZW/zjnzKzt4Qc77Vm9kv/Hj9sZtuS9l3lx/uEmW1J2h7aZ8bMpprZA2b2EzP7sZld5m+P5X3OEm8s77OZNZvZ98zsET/e9/jbZ5rZg/617zSzMf72Jv/5AX//jFzvI8SYP2VmP0u6x0P+9sh/9/xr1ZvZD83sy/7zaO6xc04//g9QDzwNDABjgEeABVHHlRTfs8DEtG03Alf6j68E3u8/3gZ8DTBgNfBgCPEdDywHHis2PqALeMb/t9N/3BlivNcCVwQcu8D/PDQBM/3PSX3YnxlgMrDcf9wGPOnHFsv7nCXeWN5n/z61+o8bgQf9+3YXcLa//RbgYv/xJcAt/uOzgTuzvY8KfSYyxfwp4IyA4yP/3fOv9zbgM8CX/eeR3GOVBFOtBA44555xzv0RuAPYFXFMuewCbvUf3wq8Pmn7p53nu8B4M5tcyUCcc98Cfl1ifFuA+5xzv3bOvQTcB2wNMd5MdgF3OOdedc79DDiA93kJ9TPjnHvOOfcD//HvgMeBKcT0PmeJN5NI77N/n37vP230fxywCfi8vz39/ibu++eBE83MsryPsssScyaR/+6ZWT+wHfgn/7kR0T1WEkw1Bfh50vNfkP0XNmwO+Dcze8jMLvK39TrnnvMfPw/0+o/j8l4KjS8Oce/1q4k+kahWzBJXZPH61ULL8P7yj/19TosXYnqf/Wq6h4GDeIngaeA3zrk/BVx7OC5//yFgQpjxBsXsnEvc4+v9e/whM2tKjzkttjBjvgl4B3DEfz6BiO6xkmB1WeecWw6cAuwxs+OTdzqvjiC2Y17iHp/vH4BZwBDwHPC30YYTzMxagS8Af+Wc+23yvjje54B4Y3ufnXOvOeeGgH68ksW8iEPKKT1mM1sEXIUX+7F4VZzvjDDEYWa2AzjonHso6lhASTDdL4GpSc/7/W2x4Jz7pf/vQeBLeL+gLySqOf1/D/qHx+W9FBpfpHE7517wv1COAP/I0eqV2MRrZo14CeV259wX/c2xvc9B8VbDfXbO/QZ4AFiDV2XYEHDt4bj8/R3Ai1HEmxbzVr8q2jnnXgU+SXzu8VrgdWb2LF619ibgw0R1j4tp0BytP0ADXmPwTI42vi+MOi4/thagLenxt/Hq6/+G1A4RN/qPt5Pa+P29kOKcQWpHk4Liw/uL9Wd4DfOd/uOuEOOdnPT4crw2B4CFpDbCP4PXWSPUz4x/vz4N3JS2PZb3OUu8sbzPQDcw3n88FvgPYAfwOVI7bVziP95DaqeNu7K9jwp9JjLFPDnp/+AmYH8cPhNpsW/gaMeYSO5xxd5ctf7g9Zx6Eq8d4F1Rx5MU14D/H/4I8ONEbHh1498AngK+nvjQ+h/wm/338SPgmBBi/Cxe1dZhvPr5C4uJD7gAr5H7AHB+yPHe5sfzKHAPqV/W7/LjfQI4JYrPDLAOr6rzUeBh/2dbXO9zlnhjeZ+BJcAP/bgeA65O+v37nn+vPgc0+dub/ecH/P0Dud5HiDHf79/jx4B/4WgP0sh/95Kut4GjSTCSe6xp00REpGapTVBERGqWkqCIiNQsJUEREalZSoIiIlKzlARFRKRmKQmKiEjNUhIUEZGapSQoIinMbL+ZfT3qOETCoCQoIumG8GZ2ERn1lARFJN0Q3vR8IqOekqBIjJjZFDP7tJm9aGa/MbMvmFmvv2+imTkzu9zM/svMXjGzJ81sc9o55pvZPWZ2yMwOmtlHzWxswHU+aWbP++d5zMw2m9kkvLUI/2hmXzWzl83saTPbGN5dEAmPkqBITJjZTOAHeMvBrMObXHgi3oz64JXQAHbjrQ23BG/S5M8kkpyZLQG+A/wUbx250/BWFHhv0nX68Ra27fT3L8JbheK3SdfYA3wIWIo3AfMHy/x2RWJBE2iLxISZ/SvwkHPur5O2nQR80TnXbmZXAPuBBc65J/39s/Bm11/unPuhmT2ItzTUhUnneAdwoXNurv/8K/6uHS7tC8DMrsRbimmec+55f9t5wA3Ouf7KvHOR6DTkPkREKs3MpgObgfVmdmnSrnrgD/7jIeDeRAL0Da8qb2Zz8RZO3Z12+lfx1lxLXGcbcGx6Aky7xvNJ2wbxEq3IqKMkKBIPS/ES2oqAfX/0/x0C7krbdxzwCv56asBrwONpxyzAWzcucY4/AQ9liGMI+EjatmWot6iMUkqCIvFwGGgBnnfO/T59p5k1A3MZ2Y7/drxV2f9gZr/z94/BS3T4nWrO5Wjp8DDe730bSaVI/9hxwGy8BVqTLQO+WPQ7E4kxdYwRiYfvAi8Bt5nZMjObZWYnm9nNZlaH13nFgDea2Xozm2tmt+FVVV7ln+NB4EVgv//644Gv4a00f2fSMS8Bt5jZQjObZ2a7zWwpXkcb8DrbAGBmE4B+VBKUUUpJUCQGnHMv4VVndgAP4CWdDwC/cM4dwaumfAq4BvgsXmmtE1ifaL9zzh0CdgFr8Ko/bwXuBs5MtP85514EdgLT8RLvd4GzgBcS13DOvZwU2jK80uNPKvXeRaKk3qEiVcDMPgr0OOfOjDoWkdFEJUGR6jBEUjWliJSHkqBIzJmZcXRgvIiUkapDRUSkZqkkKCIiNUtJUEREapaSoIiI1CwlQRERqVlKgiIiUrOUBEVEpGYpCYqISM36f976wwAckIFnAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2b0HRF4JZLT","executionInfo":{"status":"ok","timestamp":1629654826071,"user_tz":-60,"elapsed":7470,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"1e4a23d3-c51a-4135-c5f6-f1b2ab46f845"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":74,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 0.010548749127599207\n","MSE_err of valid data 0.00996089446263766\n","MSE_err of test data 0.011697787222351045\n","MSE_err of total data 0.010604867470578256\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_klpkVSbvzPA"},"source":["#### 2 variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IuLO6BafZO5","executionInfo":{"status":"ok","timestamp":1629654826072,"user_tz":-60,"elapsed":18,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"e1181d84-b889-4dfa-c83a-81ef4ddf0abd"},"source":["print(\"compress to 2\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 4000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":75,"outputs":[{"output_type":"stream","text":["compress to 2\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_M8w50osfZre","executionInfo":{"status":"ok","timestamp":1629655306746,"user_tz":-60,"elapsed":480689,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"83f4be92-367f-42f7-d5ba-2a574fd6338f"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(2).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 1.857198 | valid loss: 1.837136\n","Epoch:  1 | train loss: 1.791979 | valid loss: 1.774647\n","Epoch:  2 | train loss: 1.744195 | valid loss: 1.693542\n","Epoch:  3 | train loss: 1.590363 | valid loss: 1.637057\n","Epoch:  4 | train loss: 1.632799 | valid loss: 1.574667\n","Epoch:  5 | train loss: 1.499311 | valid loss: 1.481753\n","Epoch:  6 | train loss: 1.189584 | valid loss: 1.344249\n","Epoch:  7 | train loss: 1.091188 | valid loss: 1.176951\n","Epoch:  8 | train loss: 0.691499 | valid loss: 0.995758\n","Epoch:  9 | train loss: 0.824559 | valid loss: 0.824026\n","Epoch:  10 | train loss: 0.627258 | valid loss: 0.678767\n","Epoch:  11 | train loss: 0.574179 | valid loss: 0.568907\n","Epoch:  12 | train loss: 0.511327 | valid loss: 0.492526\n","Epoch:  13 | train loss: 0.460364 | valid loss: 0.443119\n","Epoch:  14 | train loss: 0.329234 | valid loss: 0.408862\n","Epoch:  15 | train loss: 0.346505 | valid loss: 0.386432\n","Epoch:  16 | train loss: 0.372502 | valid loss: 0.373704\n","Epoch:  17 | train loss: 0.425394 | valid loss: 0.366688\n","Epoch:  18 | train loss: 0.374944 | valid loss: 0.361317\n","Epoch:  19 | train loss: 0.398651 | valid loss: 0.358084\n","Epoch:  20 | train loss: 0.356330 | valid loss: 0.355999\n","Epoch:  21 | train loss: 0.339964 | valid loss: 0.353945\n","Epoch:  22 | train loss: 0.292532 | valid loss: 0.352117\n","Epoch:  23 | train loss: 0.357529 | valid loss: 0.350943\n","Epoch:  24 | train loss: 0.345821 | valid loss: 0.350226\n","Epoch:  25 | train loss: 0.338213 | valid loss: 0.349131\n","Epoch:  26 | train loss: 0.331858 | valid loss: 0.348438\n","Epoch:  27 | train loss: 0.347146 | valid loss: 0.348200\n","Epoch:  28 | train loss: 0.401891 | valid loss: 0.347650\n","Epoch:  29 | train loss: 0.313429 | valid loss: 0.347947\n","Epoch:  30 | train loss: 0.320585 | valid loss: 0.347376\n","Epoch:  31 | train loss: 0.358032 | valid loss: 0.346676\n","Epoch:  32 | train loss: 0.284661 | valid loss: 0.346238\n","Epoch:  33 | train loss: 0.319968 | valid loss: 0.346295\n","Epoch:  34 | train loss: 0.362776 | valid loss: 0.345990\n","Epoch:  35 | train loss: 0.309532 | valid loss: 0.345896\n","Epoch:  36 | train loss: 0.330739 | valid loss: 0.346063\n","Epoch:  37 | train loss: 0.352021 | valid loss: 0.345433\n","Epoch:  38 | train loss: 0.347487 | valid loss: 0.345407\n","Epoch:  39 | train loss: 0.310369 | valid loss: 0.345228\n","Epoch:  40 | train loss: 0.399541 | valid loss: 0.345874\n","Epoch:  41 | train loss: 0.300409 | valid loss: 0.345279\n","Epoch:  42 | train loss: 0.305853 | valid loss: 0.345151\n","Epoch:  43 | train loss: 0.278337 | valid loss: 0.345291\n","Epoch:  44 | train loss: 0.378293 | valid loss: 0.345399\n","Epoch:  45 | train loss: 0.228131 | valid loss: 0.345146\n","Epoch:  46 | train loss: 0.391572 | valid loss: 0.344478\n","Epoch:  47 | train loss: 0.376398 | valid loss: 0.343749\n","Epoch:  48 | train loss: 0.304859 | valid loss: 0.343796\n","Epoch:  49 | train loss: 0.256556 | valid loss: 0.343783\n","Epoch:  50 | train loss: 0.317451 | valid loss: 0.343521\n","Epoch:  51 | train loss: 0.275367 | valid loss: 0.344441\n","Epoch:  52 | train loss: 0.371163 | valid loss: 0.343598\n","Epoch:  53 | train loss: 0.278349 | valid loss: 0.343648\n","Epoch:  54 | train loss: 0.327792 | valid loss: 0.344051\n","Epoch:  55 | train loss: 0.300903 | valid loss: 0.342988\n","Epoch:  56 | train loss: 0.332635 | valid loss: 0.343794\n","Epoch:  57 | train loss: 0.372531 | valid loss: 0.343260\n","Epoch:  58 | train loss: 0.378820 | valid loss: 0.343717\n","Epoch:  59 | train loss: 0.357070 | valid loss: 0.343206\n","Epoch:  60 | train loss: 0.360623 | valid loss: 0.343080\n","Epoch:  61 | train loss: 0.404113 | valid loss: 0.343328\n","Epoch:  62 | train loss: 0.280723 | valid loss: 0.343218\n","Epoch:  63 | train loss: 0.300927 | valid loss: 0.342846\n","Epoch:  64 | train loss: 0.333825 | valid loss: 0.343550\n","Epoch:  65 | train loss: 0.264184 | valid loss: 0.343359\n","Epoch:  66 | train loss: 0.312472 | valid loss: 0.343631\n","Epoch:  67 | train loss: 0.333558 | valid loss: 0.343360\n","Epoch:  68 | train loss: 0.240906 | valid loss: 0.342994\n","Epoch:  69 | train loss: 0.379274 | valid loss: 0.343429\n","Epoch:  70 | train loss: 0.384222 | valid loss: 0.343167\n","Epoch:  71 | train loss: 0.287564 | valid loss: 0.343308\n","Epoch:  72 | train loss: 0.361328 | valid loss: 0.343580\n","Epoch:  73 | train loss: 0.412149 | valid loss: 0.342965\n","Epoch:  74 | train loss: 0.260696 | valid loss: 0.343364\n","Epoch:  75 | train loss: 0.317766 | valid loss: 0.343020\n","Epoch:  76 | train loss: 0.328656 | valid loss: 0.342670\n","Epoch:  77 | train loss: 0.317913 | valid loss: 0.343315\n","Epoch:  78 | train loss: 0.322423 | valid loss: 0.342887\n","Epoch:  79 | train loss: 0.300614 | valid loss: 0.343476\n","Epoch:  80 | train loss: 0.283368 | valid loss: 0.342747\n","Epoch:  81 | train loss: 0.324400 | valid loss: 0.342824\n","Epoch:  82 | train loss: 0.364269 | valid loss: 0.343299\n","Epoch:  83 | train loss: 0.368184 | valid loss: 0.343391\n","Epoch:  84 | train loss: 0.293938 | valid loss: 0.342785\n","Epoch:  85 | train loss: 0.266155 | valid loss: 0.343430\n","Epoch:  86 | train loss: 0.368695 | valid loss: 0.344035\n","Epoch:  87 | train loss: 0.353564 | valid loss: 0.342744\n","Epoch:  88 | train loss: 0.256624 | valid loss: 0.343083\n","Epoch:  89 | train loss: 0.320235 | valid loss: 0.343199\n","Epoch:  90 | train loss: 0.385566 | valid loss: 0.342687\n","Epoch:  91 | train loss: 0.293214 | valid loss: 0.342722\n","Epoch:  92 | train loss: 0.305290 | valid loss: 0.342384\n","Epoch:  93 | train loss: 0.269160 | valid loss: 0.343017\n","Epoch:  94 | train loss: 0.272235 | valid loss: 0.342325\n","Epoch:  95 | train loss: 0.336964 | valid loss: 0.342546\n","Epoch:  96 | train loss: 0.378211 | valid loss: 0.342344\n","Epoch:  97 | train loss: 0.267449 | valid loss: 0.342458\n","Epoch:  98 | train loss: 0.294225 | valid loss: 0.342580\n","Epoch:  99 | train loss: 0.291756 | valid loss: 0.342511\n","Epoch:  100 | train loss: 0.314247 | valid loss: 0.342511\n","Epoch:  101 | train loss: 0.370280 | valid loss: 0.342506\n","Epoch:  102 | train loss: 0.349522 | valid loss: 0.342779\n","Epoch:  103 | train loss: 0.366878 | valid loss: 0.342364\n","Epoch:  104 | train loss: 0.317486 | valid loss: 0.342919\n","Epoch:  105 | train loss: 0.366367 | valid loss: 0.342254\n","Epoch:  106 | train loss: 0.356806 | valid loss: 0.342551\n","Epoch:  107 | train loss: 0.266750 | valid loss: 0.342273\n","Epoch:  108 | train loss: 0.337476 | valid loss: 0.342205\n","Epoch:  109 | train loss: 0.326420 | valid loss: 0.342096\n","Epoch:  110 | train loss: 0.333887 | valid loss: 0.342556\n","Epoch:  111 | train loss: 0.348364 | valid loss: 0.342196\n","Epoch:  112 | train loss: 0.255387 | valid loss: 0.342360\n","Epoch:  113 | train loss: 0.360090 | valid loss: 0.342188\n","Epoch:  114 | train loss: 0.359698 | valid loss: 0.342276\n","Epoch:  115 | train loss: 0.316846 | valid loss: 0.341805\n","Epoch:  116 | train loss: 0.249561 | valid loss: 0.341954\n","Epoch:  117 | train loss: 0.311247 | valid loss: 0.341842\n","Epoch:  118 | train loss: 0.312741 | valid loss: 0.342108\n","Epoch:  119 | train loss: 0.349830 | valid loss: 0.341886\n","Epoch:  120 | train loss: 0.318887 | valid loss: 0.342149\n","Epoch:  121 | train loss: 0.339901 | valid loss: 0.341737\n","Epoch:  122 | train loss: 0.279900 | valid loss: 0.341745\n","Epoch:  123 | train loss: 0.397284 | valid loss: 0.341581\n","Epoch:  124 | train loss: 0.273980 | valid loss: 0.341558\n","Epoch:  125 | train loss: 0.254143 | valid loss: 0.341879\n","Epoch:  126 | train loss: 0.368165 | valid loss: 0.341568\n","Epoch:  127 | train loss: 0.403891 | valid loss: 0.341632\n","Epoch:  128 | train loss: 0.343312 | valid loss: 0.341919\n","Epoch:  129 | train loss: 0.344005 | valid loss: 0.341849\n","Epoch:  130 | train loss: 0.347248 | valid loss: 0.341785\n","Epoch:  131 | train loss: 0.304875 | valid loss: 0.341267\n","Epoch:  132 | train loss: 0.321669 | valid loss: 0.341558\n","Epoch:  133 | train loss: 0.328303 | valid loss: 0.341238\n","Epoch:  134 | train loss: 0.331145 | valid loss: 0.341193\n","Epoch:  135 | train loss: 0.336203 | valid loss: 0.341229\n","Epoch:  136 | train loss: 0.323919 | valid loss: 0.341150\n","Epoch:  137 | train loss: 0.288031 | valid loss: 0.341338\n","Epoch:  138 | train loss: 0.351966 | valid loss: 0.341390\n","Epoch:  139 | train loss: 0.306261 | valid loss: 0.341325\n","Epoch:  140 | train loss: 0.316994 | valid loss: 0.341111\n","Epoch:  141 | train loss: 0.263530 | valid loss: 0.341182\n","Epoch:  142 | train loss: 0.379473 | valid loss: 0.341043\n","Epoch:  143 | train loss: 0.296506 | valid loss: 0.341535\n","Epoch:  144 | train loss: 0.361009 | valid loss: 0.341609\n","Epoch:  145 | train loss: 0.332936 | valid loss: 0.340936\n","Epoch:  146 | train loss: 0.237752 | valid loss: 0.341188\n","Epoch:  147 | train loss: 0.324603 | valid loss: 0.341044\n","Epoch:  148 | train loss: 0.293577 | valid loss: 0.340653\n","Epoch:  149 | train loss: 0.283148 | valid loss: 0.341052\n","Epoch:  150 | train loss: 0.315988 | valid loss: 0.341067\n","Epoch:  151 | train loss: 0.308404 | valid loss: 0.340362\n","Epoch:  152 | train loss: 0.325308 | valid loss: 0.340398\n","Epoch:  153 | train loss: 0.315668 | valid loss: 0.340947\n","Epoch:  154 | train loss: 0.286918 | valid loss: 0.340362\n","Epoch:  155 | train loss: 0.271145 | valid loss: 0.340317\n","Epoch:  156 | train loss: 0.252990 | valid loss: 0.340377\n","Epoch:  157 | train loss: 0.265591 | valid loss: 0.340434\n","Epoch:  158 | train loss: 0.380192 | valid loss: 0.340114\n","Epoch:  159 | train loss: 0.406868 | valid loss: 0.340299\n","Epoch:  160 | train loss: 0.323041 | valid loss: 0.340357\n","Epoch:  161 | train loss: 0.350275 | valid loss: 0.340143\n","Epoch:  162 | train loss: 0.321859 | valid loss: 0.339992\n","Epoch:  163 | train loss: 0.346460 | valid loss: 0.340370\n","Epoch:  164 | train loss: 0.331635 | valid loss: 0.340534\n","Epoch:  165 | train loss: 0.307134 | valid loss: 0.340210\n","Epoch:  166 | train loss: 0.382559 | valid loss: 0.340220\n","Epoch:  167 | train loss: 0.288548 | valid loss: 0.339911\n","Epoch:  168 | train loss: 0.332978 | valid loss: 0.339628\n","Epoch:  169 | train loss: 0.375022 | valid loss: 0.339924\n","Epoch:  170 | train loss: 0.276039 | valid loss: 0.339643\n","Epoch:  171 | train loss: 0.340792 | valid loss: 0.339917\n","Epoch:  172 | train loss: 0.282299 | valid loss: 0.340031\n","Epoch:  173 | train loss: 0.323866 | valid loss: 0.339606\n","Epoch:  174 | train loss: 0.332147 | valid loss: 0.339581\n","Epoch:  175 | train loss: 0.339834 | valid loss: 0.339673\n","Epoch:  176 | train loss: 0.304171 | valid loss: 0.339550\n","Epoch:  177 | train loss: 0.257946 | valid loss: 0.339541\n","Epoch:  178 | train loss: 0.292726 | valid loss: 0.339441\n","Epoch:  179 | train loss: 0.324138 | valid loss: 0.339555\n","Epoch:  180 | train loss: 0.351020 | valid loss: 0.339324\n","Epoch:  181 | train loss: 0.298294 | valid loss: 0.339391\n","Epoch:  182 | train loss: 0.290201 | valid loss: 0.338957\n","Epoch:  183 | train loss: 0.274222 | valid loss: 0.339111\n","Epoch:  184 | train loss: 0.277737 | valid loss: 0.339502\n","Epoch:  185 | train loss: 0.340777 | valid loss: 0.339349\n","Epoch:  186 | train loss: 0.397581 | valid loss: 0.339526\n","Epoch:  187 | train loss: 0.321443 | valid loss: 0.338812\n","Epoch:  188 | train loss: 0.408291 | valid loss: 0.339091\n","Epoch:  189 | train loss: 0.395366 | valid loss: 0.338989\n","Epoch:  190 | train loss: 0.375699 | valid loss: 0.338862\n","Epoch:  191 | train loss: 0.285931 | valid loss: 0.338753\n","Epoch:  192 | train loss: 0.350194 | valid loss: 0.338697\n","Epoch:  193 | train loss: 0.335090 | valid loss: 0.338594\n","Epoch:  194 | train loss: 0.330508 | valid loss: 0.338866\n","Epoch:  195 | train loss: 0.291320 | valid loss: 0.338436\n","Epoch:  196 | train loss: 0.336990 | valid loss: 0.338529\n","Epoch:  197 | train loss: 0.313386 | valid loss: 0.339071\n","Epoch:  198 | train loss: 0.271937 | valid loss: 0.338427\n","Epoch:  199 | train loss: 0.345910 | valid loss: 0.338414\n","Epoch:  200 | train loss: 0.260177 | valid loss: 0.338115\n","Epoch:  201 | train loss: 0.253716 | valid loss: 0.338366\n","Epoch:  202 | train loss: 0.381638 | valid loss: 0.338687\n","Epoch:  203 | train loss: 0.315160 | valid loss: 0.338015\n","Epoch:  204 | train loss: 0.341756 | valid loss: 0.338492\n","Epoch:  205 | train loss: 0.239342 | valid loss: 0.338865\n","Epoch:  206 | train loss: 0.328286 | valid loss: 0.338110\n","Epoch:  207 | train loss: 0.296150 | valid loss: 0.338034\n","Epoch:  208 | train loss: 0.264078 | valid loss: 0.338179\n","Epoch:  209 | train loss: 0.334235 | valid loss: 0.337798\n","Epoch:  210 | train loss: 0.437895 | valid loss: 0.337702\n","Epoch:  211 | train loss: 0.267133 | valid loss: 0.337612\n","Epoch:  212 | train loss: 0.320880 | valid loss: 0.338069\n","Epoch:  213 | train loss: 0.389735 | valid loss: 0.337565\n","Epoch:  214 | train loss: 0.322928 | valid loss: 0.337513\n","Epoch:  215 | train loss: 0.255173 | valid loss: 0.337396\n","Epoch:  216 | train loss: 0.289117 | valid loss: 0.337228\n","Epoch:  217 | train loss: 0.287551 | valid loss: 0.337178\n","Epoch:  218 | train loss: 0.337989 | valid loss: 0.337394\n","Epoch:  219 | train loss: 0.261979 | valid loss: 0.337216\n","Epoch:  220 | train loss: 0.340067 | valid loss: 0.337324\n","Epoch:  221 | train loss: 0.304855 | valid loss: 0.337195\n","Epoch:  222 | train loss: 0.391553 | valid loss: 0.337340\n","Epoch:  223 | train loss: 0.293160 | valid loss: 0.336934\n","Epoch:  224 | train loss: 0.268965 | valid loss: 0.337063\n","Epoch:  225 | train loss: 0.340878 | valid loss: 0.336864\n","Epoch:  226 | train loss: 0.333457 | valid loss: 0.336979\n","Epoch:  227 | train loss: 0.343020 | valid loss: 0.337136\n","Epoch:  228 | train loss: 0.364277 | valid loss: 0.337012\n","Epoch:  229 | train loss: 0.327830 | valid loss: 0.337082\n","Epoch:  230 | train loss: 0.337487 | valid loss: 0.336797\n","Epoch:  231 | train loss: 0.200152 | valid loss: 0.336940\n","Epoch:  232 | train loss: 0.368555 | valid loss: 0.336883\n","Epoch:  233 | train loss: 0.342065 | valid loss: 0.336494\n","Epoch:  234 | train loss: 0.272503 | valid loss: 0.336265\n","Epoch:  235 | train loss: 0.328122 | valid loss: 0.336703\n","Epoch:  236 | train loss: 0.367598 | valid loss: 0.336764\n","Epoch:  237 | train loss: 0.290677 | valid loss: 0.336688\n","Epoch:  238 | train loss: 0.313060 | valid loss: 0.336128\n","Epoch:  239 | train loss: 0.236745 | valid loss: 0.336192\n","Epoch:  240 | train loss: 0.262735 | valid loss: 0.336138\n","Epoch:  241 | train loss: 0.375534 | valid loss: 0.335932\n","Epoch:  242 | train loss: 0.304670 | valid loss: 0.335956\n","Epoch:  243 | train loss: 0.329101 | valid loss: 0.336363\n","Epoch:  244 | train loss: 0.292917 | valid loss: 0.335682\n","Epoch:  245 | train loss: 0.341393 | valid loss: 0.335593\n","Epoch:  246 | train loss: 0.379517 | valid loss: 0.335788\n","Epoch:  247 | train loss: 0.364839 | valid loss: 0.335856\n","Epoch:  248 | train loss: 0.403007 | valid loss: 0.335332\n","Epoch:  249 | train loss: 0.249541 | valid loss: 0.335446\n","Epoch:  250 | train loss: 0.326966 | valid loss: 0.335194\n","Epoch:  251 | train loss: 0.347848 | valid loss: 0.335392\n","Epoch:  252 | train loss: 0.291063 | valid loss: 0.335114\n","Epoch:  253 | train loss: 0.303665 | valid loss: 0.335161\n","Epoch:  254 | train loss: 0.321901 | valid loss: 0.334812\n","Epoch:  255 | train loss: 0.382015 | valid loss: 0.334983\n","Epoch:  256 | train loss: 0.251347 | valid loss: 0.335281\n","Epoch:  257 | train loss: 0.390193 | valid loss: 0.334488\n","Epoch:  258 | train loss: 0.318726 | valid loss: 0.334705\n","Epoch:  259 | train loss: 0.291456 | valid loss: 0.334394\n","Epoch:  260 | train loss: 0.338213 | valid loss: 0.334535\n","Epoch:  261 | train loss: 0.289665 | valid loss: 0.334729\n","Epoch:  262 | train loss: 0.301458 | valid loss: 0.334342\n","Epoch:  263 | train loss: 0.328238 | valid loss: 0.334212\n","Epoch:  264 | train loss: 0.355498 | valid loss: 0.334188\n","Epoch:  265 | train loss: 0.340513 | valid loss: 0.334292\n","Epoch:  266 | train loss: 0.288967 | valid loss: 0.334005\n","Epoch:  267 | train loss: 0.276494 | valid loss: 0.333935\n","Epoch:  268 | train loss: 0.384663 | valid loss: 0.333848\n","Epoch:  269 | train loss: 0.307507 | valid loss: 0.333668\n","Epoch:  270 | train loss: 0.319356 | valid loss: 0.333639\n","Epoch:  271 | train loss: 0.300030 | valid loss: 0.333355\n","Epoch:  272 | train loss: 0.357420 | valid loss: 0.333474\n","Epoch:  273 | train loss: 0.368156 | valid loss: 0.333153\n","Epoch:  274 | train loss: 0.321118 | valid loss: 0.333370\n","Epoch:  275 | train loss: 0.318793 | valid loss: 0.333224\n","Epoch:  276 | train loss: 0.312257 | valid loss: 0.332938\n","Epoch:  277 | train loss: 0.312707 | valid loss: 0.333215\n","Epoch:  278 | train loss: 0.296135 | valid loss: 0.332663\n","Epoch:  279 | train loss: 0.343757 | valid loss: 0.332934\n","Epoch:  280 | train loss: 0.271353 | valid loss: 0.332656\n","Epoch:  281 | train loss: 0.272511 | valid loss: 0.332630\n","Epoch:  282 | train loss: 0.322420 | valid loss: 0.332655\n","Epoch:  283 | train loss: 0.282344 | valid loss: 0.332317\n","Epoch:  284 | train loss: 0.285117 | valid loss: 0.332389\n","Epoch:  285 | train loss: 0.225012 | valid loss: 0.332156\n","Epoch:  286 | train loss: 0.340940 | valid loss: 0.332383\n","Epoch:  287 | train loss: 0.345604 | valid loss: 0.331917\n","Epoch:  288 | train loss: 0.317942 | valid loss: 0.332201\n","Epoch:  289 | train loss: 0.313274 | valid loss: 0.332083\n","Epoch:  290 | train loss: 0.262745 | valid loss: 0.331808\n","Epoch:  291 | train loss: 0.320723 | valid loss: 0.331779\n","Epoch:  292 | train loss: 0.265913 | valid loss: 0.331642\n","Epoch:  293 | train loss: 0.383575 | valid loss: 0.331439\n","Epoch:  294 | train loss: 0.377424 | valid loss: 0.331381\n","Epoch:  295 | train loss: 0.336528 | valid loss: 0.331350\n","Epoch:  296 | train loss: 0.385037 | valid loss: 0.331542\n","Epoch:  297 | train loss: 0.395832 | valid loss: 0.331054\n","Epoch:  298 | train loss: 0.286919 | valid loss: 0.330709\n","Epoch:  299 | train loss: 0.363648 | valid loss: 0.330819\n","Epoch:  300 | train loss: 0.282520 | valid loss: 0.330799\n","Epoch:  301 | train loss: 0.279928 | valid loss: 0.330591\n","Epoch:  302 | train loss: 0.371021 | valid loss: 0.330404\n","Epoch:  303 | train loss: 0.359918 | valid loss: 0.330274\n","Epoch:  304 | train loss: 0.293489 | valid loss: 0.330430\n","Epoch:  305 | train loss: 0.243040 | valid loss: 0.329905\n","Epoch:  306 | train loss: 0.341126 | valid loss: 0.330098\n","Epoch:  307 | train loss: 0.295785 | valid loss: 0.330180\n","Epoch:  308 | train loss: 0.384037 | valid loss: 0.329934\n","Epoch:  309 | train loss: 0.302563 | valid loss: 0.329702\n","Epoch:  310 | train loss: 0.305425 | valid loss: 0.329560\n","Epoch:  311 | train loss: 0.321071 | valid loss: 0.329495\n","Epoch:  312 | train loss: 0.306372 | valid loss: 0.329847\n","Epoch:  313 | train loss: 0.324875 | valid loss: 0.329282\n","Epoch:  314 | train loss: 0.278626 | valid loss: 0.329242\n","Epoch:  315 | train loss: 0.275379 | valid loss: 0.329295\n","Epoch:  316 | train loss: 0.341350 | valid loss: 0.328806\n","Epoch:  317 | train loss: 0.308104 | valid loss: 0.328738\n","Epoch:  318 | train loss: 0.271935 | valid loss: 0.328833\n","Epoch:  319 | train loss: 0.291973 | valid loss: 0.328816\n","Epoch:  320 | train loss: 0.271901 | valid loss: 0.328595\n","Epoch:  321 | train loss: 0.316899 | valid loss: 0.328457\n","Epoch:  322 | train loss: 0.304974 | valid loss: 0.328413\n","Epoch:  323 | train loss: 0.409131 | valid loss: 0.328260\n","Epoch:  324 | train loss: 0.387051 | valid loss: 0.328242\n","Epoch:  325 | train loss: 0.263875 | valid loss: 0.328037\n","Epoch:  326 | train loss: 0.304072 | valid loss: 0.327758\n","Epoch:  327 | train loss: 0.269253 | valid loss: 0.327699\n","Epoch:  328 | train loss: 0.255401 | valid loss: 0.327664\n","Epoch:  329 | train loss: 0.291212 | valid loss: 0.327414\n","Epoch:  330 | train loss: 0.293443 | valid loss: 0.327574\n","Epoch:  331 | train loss: 0.331741 | valid loss: 0.327311\n","Epoch:  332 | train loss: 0.292484 | valid loss: 0.327315\n","Epoch:  333 | train loss: 0.281690 | valid loss: 0.327125\n","Epoch:  334 | train loss: 0.296374 | valid loss: 0.326965\n","Epoch:  335 | train loss: 0.327884 | valid loss: 0.326852\n","Epoch:  336 | train loss: 0.272592 | valid loss: 0.326692\n","Epoch:  337 | train loss: 0.286587 | valid loss: 0.326586\n","Epoch:  338 | train loss: 0.354515 | valid loss: 0.326669\n","Epoch:  339 | train loss: 0.343603 | valid loss: 0.326318\n","Epoch:  340 | train loss: 0.372669 | valid loss: 0.326267\n","Epoch:  341 | train loss: 0.332408 | valid loss: 0.326008\n","Epoch:  342 | train loss: 0.375150 | valid loss: 0.326058\n","Epoch:  343 | train loss: 0.356166 | valid loss: 0.325787\n","Epoch:  344 | train loss: 0.318989 | valid loss: 0.325532\n","Epoch:  345 | train loss: 0.289590 | valid loss: 0.325457\n","Epoch:  346 | train loss: 0.392503 | valid loss: 0.325490\n","Epoch:  347 | train loss: 0.253544 | valid loss: 0.325313\n","Epoch:  348 | train loss: 0.363456 | valid loss: 0.325147\n","Epoch:  349 | train loss: 0.391235 | valid loss: 0.325177\n","Epoch:  350 | train loss: 0.279303 | valid loss: 0.325105\n","Epoch:  351 | train loss: 0.331652 | valid loss: 0.324702\n","Epoch:  352 | train loss: 0.381096 | valid loss: 0.324754\n","Epoch:  353 | train loss: 0.331208 | valid loss: 0.324639\n","Epoch:  354 | train loss: 0.283747 | valid loss: 0.324277\n","Epoch:  355 | train loss: 0.319525 | valid loss: 0.324476\n","Epoch:  356 | train loss: 0.324675 | valid loss: 0.324059\n","Epoch:  357 | train loss: 0.267252 | valid loss: 0.323923\n","Epoch:  358 | train loss: 0.283589 | valid loss: 0.323827\n","Epoch:  359 | train loss: 0.345351 | valid loss: 0.323805\n","Epoch:  360 | train loss: 0.226585 | valid loss: 0.323564\n","Epoch:  361 | train loss: 0.342664 | valid loss: 0.323388\n","Epoch:  362 | train loss: 0.297783 | valid loss: 0.323172\n","Epoch:  363 | train loss: 0.252452 | valid loss: 0.323174\n","Epoch:  364 | train loss: 0.307757 | valid loss: 0.323371\n","Epoch:  365 | train loss: 0.369665 | valid loss: 0.323096\n","Epoch:  366 | train loss: 0.237941 | valid loss: 0.322543\n","Epoch:  367 | train loss: 0.338213 | valid loss: 0.322663\n","Epoch:  368 | train loss: 0.326837 | valid loss: 0.322475\n","Epoch:  369 | train loss: 0.318775 | valid loss: 0.322368\n","Epoch:  370 | train loss: 0.347703 | valid loss: 0.322169\n","Epoch:  371 | train loss: 0.314180 | valid loss: 0.322254\n","Epoch:  372 | train loss: 0.396706 | valid loss: 0.321810\n","Epoch:  373 | train loss: 0.296746 | valid loss: 0.321597\n","Epoch:  374 | train loss: 0.348683 | valid loss: 0.321669\n","Epoch:  375 | train loss: 0.268855 | valid loss: 0.321731\n","Epoch:  376 | train loss: 0.228749 | valid loss: 0.321526\n","Epoch:  377 | train loss: 0.308370 | valid loss: 0.321066\n","Epoch:  378 | train loss: 0.332128 | valid loss: 0.321141\n","Epoch:  379 | train loss: 0.259032 | valid loss: 0.321025\n","Epoch:  380 | train loss: 0.294592 | valid loss: 0.320840\n","Epoch:  381 | train loss: 0.387998 | valid loss: 0.320458\n","Epoch:  382 | train loss: 0.309142 | valid loss: 0.320440\n","Epoch:  383 | train loss: 0.336829 | valid loss: 0.320214\n","Epoch:  384 | train loss: 0.317910 | valid loss: 0.320414\n","Epoch:  385 | train loss: 0.407648 | valid loss: 0.319913\n","Epoch:  386 | train loss: 0.325128 | valid loss: 0.319761\n","Epoch:  387 | train loss: 0.332403 | valid loss: 0.319699\n","Epoch:  388 | train loss: 0.223139 | valid loss: 0.319431\n","Epoch:  389 | train loss: 0.297370 | valid loss: 0.319587\n","Epoch:  390 | train loss: 0.267590 | valid loss: 0.319326\n","Epoch:  391 | train loss: 0.255605 | valid loss: 0.319038\n","Epoch:  392 | train loss: 0.378155 | valid loss: 0.318843\n","Epoch:  393 | train loss: 0.281840 | valid loss: 0.318785\n","Epoch:  394 | train loss: 0.320075 | valid loss: 0.318596\n","Epoch:  395 | train loss: 0.332418 | valid loss: 0.318538\n","Epoch:  396 | train loss: 0.231065 | valid loss: 0.318245\n","Epoch:  397 | train loss: 0.263751 | valid loss: 0.318140\n","Epoch:  398 | train loss: 0.288253 | valid loss: 0.317948\n","Epoch:  399 | train loss: 0.307233 | valid loss: 0.317826\n","Epoch:  400 | train loss: 0.349497 | valid loss: 0.317815\n","Epoch:  401 | train loss: 0.319750 | valid loss: 0.317776\n","Epoch:  402 | train loss: 0.337624 | valid loss: 0.317289\n","Epoch:  403 | train loss: 0.334865 | valid loss: 0.317252\n","Epoch:  404 | train loss: 0.336819 | valid loss: 0.317156\n","Epoch:  405 | train loss: 0.296050 | valid loss: 0.316861\n","Epoch:  406 | train loss: 0.271883 | valid loss: 0.316626\n","Epoch:  407 | train loss: 0.273845 | valid loss: 0.316543\n","Epoch:  408 | train loss: 0.375029 | valid loss: 0.316443\n","Epoch:  409 | train loss: 0.230025 | valid loss: 0.316271\n","Epoch:  410 | train loss: 0.333569 | valid loss: 0.316191\n","Epoch:  411 | train loss: 0.228308 | valid loss: 0.315818\n","Epoch:  412 | train loss: 0.313058 | valid loss: 0.315757\n","Epoch:  413 | train loss: 0.273397 | valid loss: 0.315586\n","Epoch:  414 | train loss: 0.288621 | valid loss: 0.315399\n","Epoch:  415 | train loss: 0.248340 | valid loss: 0.315404\n","Epoch:  416 | train loss: 0.350913 | valid loss: 0.315040\n","Epoch:  417 | train loss: 0.310872 | valid loss: 0.314881\n","Epoch:  418 | train loss: 0.320510 | valid loss: 0.314593\n","Epoch:  419 | train loss: 0.253937 | valid loss: 0.314439\n","Epoch:  420 | train loss: 0.260300 | valid loss: 0.314068\n","Epoch:  421 | train loss: 0.279492 | valid loss: 0.314284\n","Epoch:  422 | train loss: 0.313044 | valid loss: 0.313886\n","Epoch:  423 | train loss: 0.353564 | valid loss: 0.314012\n","Epoch:  424 | train loss: 0.325544 | valid loss: 0.313672\n","Epoch:  425 | train loss: 0.334290 | valid loss: 0.313584\n","Epoch:  426 | train loss: 0.302519 | valid loss: 0.313154\n","Epoch:  427 | train loss: 0.298304 | valid loss: 0.313247\n","Epoch:  428 | train loss: 0.158379 | valid loss: 0.312898\n","Epoch:  429 | train loss: 0.254615 | valid loss: 0.312836\n","Epoch:  430 | train loss: 0.262831 | valid loss: 0.312804\n","Epoch:  431 | train loss: 0.261973 | valid loss: 0.312716\n","Epoch:  432 | train loss: 0.237479 | valid loss: 0.312446\n","Epoch:  433 | train loss: 0.287160 | valid loss: 0.312059\n","Epoch:  434 | train loss: 0.224924 | valid loss: 0.311953\n","Epoch:  435 | train loss: 0.223843 | valid loss: 0.311889\n","Epoch:  436 | train loss: 0.265715 | valid loss: 0.311447\n","Epoch:  437 | train loss: 0.270959 | valid loss: 0.311644\n","Epoch:  438 | train loss: 0.283182 | valid loss: 0.311133\n","Epoch:  439 | train loss: 0.250249 | valid loss: 0.310895\n","Epoch:  440 | train loss: 0.329457 | valid loss: 0.310873\n","Epoch:  441 | train loss: 0.325693 | valid loss: 0.310433\n","Epoch:  442 | train loss: 0.263245 | valid loss: 0.310406\n","Epoch:  443 | train loss: 0.221730 | valid loss: 0.310139\n","Epoch:  444 | train loss: 0.200783 | valid loss: 0.310177\n","Epoch:  445 | train loss: 0.317183 | valid loss: 0.309858\n","Epoch:  446 | train loss: 0.145582 | valid loss: 0.309835\n","Epoch:  447 | train loss: 0.491357 | valid loss: 0.309275\n","Epoch:  448 | train loss: 0.423350 | valid loss: 0.309128\n","Epoch:  449 | train loss: 0.395452 | valid loss: 0.308742\n","Epoch:  450 | train loss: 0.386550 | valid loss: 0.308805\n","Epoch:  451 | train loss: 0.296502 | valid loss: 0.308322\n","Epoch:  452 | train loss: 0.226809 | valid loss: 0.308182\n","Epoch:  453 | train loss: 0.295014 | valid loss: 0.307996\n","Epoch:  454 | train loss: 0.274711 | valid loss: 0.307913\n","Epoch:  455 | train loss: 0.270048 | valid loss: 0.307681\n","Epoch:  456 | train loss: 0.317581 | valid loss: 0.307343\n","Epoch:  457 | train loss: 0.284578 | valid loss: 0.307218\n","Epoch:  458 | train loss: 0.263082 | valid loss: 0.307410\n","Epoch:  459 | train loss: 0.377422 | valid loss: 0.306784\n","Epoch:  460 | train loss: 0.343686 | valid loss: 0.306503\n","Epoch:  461 | train loss: 0.367800 | valid loss: 0.306378\n","Epoch:  462 | train loss: 0.313950 | valid loss: 0.305821\n","Epoch:  463 | train loss: 0.304418 | valid loss: 0.306238\n","Epoch:  464 | train loss: 0.236486 | valid loss: 0.305620\n","Epoch:  465 | train loss: 0.245716 | valid loss: 0.305435\n","Epoch:  466 | train loss: 0.318930 | valid loss: 0.305072\n","Epoch:  467 | train loss: 0.300094 | valid loss: 0.304900\n","Epoch:  468 | train loss: 0.284318 | valid loss: 0.304602\n","Epoch:  469 | train loss: 0.303011 | valid loss: 0.304496\n","Epoch:  470 | train loss: 0.318708 | valid loss: 0.304091\n","Epoch:  471 | train loss: 0.347961 | valid loss: 0.303861\n","Epoch:  472 | train loss: 0.214345 | valid loss: 0.303530\n","Epoch:  473 | train loss: 0.313130 | valid loss: 0.303638\n","Epoch:  474 | train loss: 0.400867 | valid loss: 0.303277\n","Epoch:  475 | train loss: 0.263594 | valid loss: 0.302810\n","Epoch:  476 | train loss: 0.186474 | valid loss: 0.302574\n","Epoch:  477 | train loss: 0.271343 | valid loss: 0.302377\n","Epoch:  478 | train loss: 0.383908 | valid loss: 0.302142\n","Epoch:  479 | train loss: 0.340971 | valid loss: 0.301749\n","Epoch:  480 | train loss: 0.267375 | valid loss: 0.301449\n","Epoch:  481 | train loss: 0.301606 | valid loss: 0.301440\n","Epoch:  482 | train loss: 0.294503 | valid loss: 0.301178\n","Epoch:  483 | train loss: 0.319573 | valid loss: 0.300932\n","Epoch:  484 | train loss: 0.384048 | valid loss: 0.300637\n","Epoch:  485 | train loss: 0.191794 | valid loss: 0.300204\n","Epoch:  486 | train loss: 0.302434 | valid loss: 0.299978\n","Epoch:  487 | train loss: 0.299739 | valid loss: 0.299702\n","Epoch:  488 | train loss: 0.290905 | valid loss: 0.299372\n","Epoch:  489 | train loss: 0.299206 | valid loss: 0.299184\n","Epoch:  490 | train loss: 0.198238 | valid loss: 0.298965\n","Epoch:  491 | train loss: 0.322740 | valid loss: 0.298864\n","Epoch:  492 | train loss: 0.289159 | valid loss: 0.298564\n","Epoch:  493 | train loss: 0.207997 | valid loss: 0.298370\n","Epoch:  494 | train loss: 0.240969 | valid loss: 0.298088\n","Epoch:  495 | train loss: 0.323869 | valid loss: 0.297792\n","Epoch:  496 | train loss: 0.254370 | valid loss: 0.297491\n","Epoch:  497 | train loss: 0.225668 | valid loss: 0.297309\n","Epoch:  498 | train loss: 0.319991 | valid loss: 0.297117\n","Epoch:  499 | train loss: 0.276861 | valid loss: 0.296730\n","Epoch:  500 | train loss: 0.234183 | valid loss: 0.296583\n","Epoch:  501 | train loss: 0.347396 | valid loss: 0.296264\n","Epoch:  502 | train loss: 0.277411 | valid loss: 0.296124\n","Epoch:  503 | train loss: 0.296721 | valid loss: 0.296137\n","Epoch:  504 | train loss: 0.254097 | valid loss: 0.295721\n","Epoch:  505 | train loss: 0.205941 | valid loss: 0.295335\n","Epoch:  506 | train loss: 0.271364 | valid loss: 0.294955\n","Epoch:  507 | train loss: 0.330890 | valid loss: 0.294813\n","Epoch:  508 | train loss: 0.284799 | valid loss: 0.294555\n","Epoch:  509 | train loss: 0.264840 | valid loss: 0.294228\n","Epoch:  510 | train loss: 0.325402 | valid loss: 0.294236\n","Epoch:  511 | train loss: 0.323451 | valid loss: 0.293832\n","Epoch:  512 | train loss: 0.263211 | valid loss: 0.293666\n","Epoch:  513 | train loss: 0.309742 | valid loss: 0.293371\n","Epoch:  514 | train loss: 0.299930 | valid loss: 0.292987\n","Epoch:  515 | train loss: 0.358716 | valid loss: 0.293031\n","Epoch:  516 | train loss: 0.333704 | valid loss: 0.292631\n","Epoch:  517 | train loss: 0.302886 | valid loss: 0.292225\n","Epoch:  518 | train loss: 0.274793 | valid loss: 0.292127\n","Epoch:  519 | train loss: 0.318977 | valid loss: 0.292071\n","Epoch:  520 | train loss: 0.294680 | valid loss: 0.291695\n","Epoch:  521 | train loss: 0.270763 | valid loss: 0.291471\n","Epoch:  522 | train loss: 0.334280 | valid loss: 0.291066\n","Epoch:  523 | train loss: 0.279995 | valid loss: 0.291170\n","Epoch:  524 | train loss: 0.274021 | valid loss: 0.290538\n","Epoch:  525 | train loss: 0.264945 | valid loss: 0.290458\n","Epoch:  526 | train loss: 0.282997 | valid loss: 0.289992\n","Epoch:  527 | train loss: 0.242120 | valid loss: 0.289613\n","Epoch:  528 | train loss: 0.240450 | valid loss: 0.289516\n","Epoch:  529 | train loss: 0.280700 | valid loss: 0.289179\n","Epoch:  530 | train loss: 0.231337 | valid loss: 0.288849\n","Epoch:  531 | train loss: 0.320334 | valid loss: 0.288627\n","Epoch:  532 | train loss: 0.358473 | valid loss: 0.288393\n","Epoch:  533 | train loss: 0.263771 | valid loss: 0.288145\n","Epoch:  534 | train loss: 0.272505 | valid loss: 0.288057\n","Epoch:  535 | train loss: 0.218003 | valid loss: 0.287724\n","Epoch:  536 | train loss: 0.244721 | valid loss: 0.287402\n","Epoch:  537 | train loss: 0.279239 | valid loss: 0.287308\n","Epoch:  538 | train loss: 0.233141 | valid loss: 0.286881\n","Epoch:  539 | train loss: 0.255104 | valid loss: 0.286773\n","Epoch:  540 | train loss: 0.311025 | valid loss: 0.286438\n","Epoch:  541 | train loss: 0.244980 | valid loss: 0.286228\n","Epoch:  542 | train loss: 0.218844 | valid loss: 0.286105\n","Epoch:  543 | train loss: 0.248656 | valid loss: 0.285810\n","Epoch:  544 | train loss: 0.294792 | valid loss: 0.285485\n","Epoch:  545 | train loss: 0.241452 | valid loss: 0.285384\n","Epoch:  546 | train loss: 0.257737 | valid loss: 0.285247\n","Epoch:  547 | train loss: 0.281516 | valid loss: 0.284851\n","Epoch:  548 | train loss: 0.295267 | valid loss: 0.284628\n","Epoch:  549 | train loss: 0.262629 | valid loss: 0.284674\n","Epoch:  550 | train loss: 0.268329 | valid loss: 0.284233\n","Epoch:  551 | train loss: 0.249691 | valid loss: 0.284024\n","Epoch:  552 | train loss: 0.261683 | valid loss: 0.283745\n","Epoch:  553 | train loss: 0.229264 | valid loss: 0.283436\n","Epoch:  554 | train loss: 0.260188 | valid loss: 0.283303\n","Epoch:  555 | train loss: 0.216640 | valid loss: 0.282955\n","Epoch:  556 | train loss: 0.196982 | valid loss: 0.282711\n","Epoch:  557 | train loss: 0.244451 | valid loss: 0.282581\n","Epoch:  558 | train loss: 0.297237 | valid loss: 0.282287\n","Epoch:  559 | train loss: 0.283025 | valid loss: 0.281956\n","Epoch:  560 | train loss: 0.257714 | valid loss: 0.281633\n","Epoch:  561 | train loss: 0.314689 | valid loss: 0.281486\n","Epoch:  562 | train loss: 0.237235 | valid loss: 0.281227\n","Epoch:  563 | train loss: 0.282925 | valid loss: 0.281103\n","Epoch:  564 | train loss: 0.266741 | valid loss: 0.280932\n","Epoch:  565 | train loss: 0.301983 | valid loss: 0.280531\n","Epoch:  566 | train loss: 0.247959 | valid loss: 0.280420\n","Epoch:  567 | train loss: 0.267613 | valid loss: 0.280081\n","Epoch:  568 | train loss: 0.273784 | valid loss: 0.279970\n","Epoch:  569 | train loss: 0.289107 | valid loss: 0.279613\n","Epoch:  570 | train loss: 0.204965 | valid loss: 0.279371\n","Epoch:  571 | train loss: 0.325925 | valid loss: 0.279321\n","Epoch:  572 | train loss: 0.292287 | valid loss: 0.279089\n","Epoch:  573 | train loss: 0.290976 | valid loss: 0.278807\n","Epoch:  574 | train loss: 0.265765 | valid loss: 0.278578\n","Epoch:  575 | train loss: 0.242646 | valid loss: 0.278462\n","Epoch:  576 | train loss: 0.305290 | valid loss: 0.278268\n","Epoch:  577 | train loss: 0.304225 | valid loss: 0.278118\n","Epoch:  578 | train loss: 0.246770 | valid loss: 0.277743\n","Epoch:  579 | train loss: 0.270952 | valid loss: 0.277662\n","Epoch:  580 | train loss: 0.203087 | valid loss: 0.277343\n","Epoch:  581 | train loss: 0.267748 | valid loss: 0.277265\n","Epoch:  582 | train loss: 0.237122 | valid loss: 0.277112\n","Epoch:  583 | train loss: 0.236676 | valid loss: 0.276754\n","Epoch:  584 | train loss: 0.284472 | valid loss: 0.276425\n","Epoch:  585 | train loss: 0.328357 | valid loss: 0.276584\n","Epoch:  586 | train loss: 0.299821 | valid loss: 0.276138\n","Epoch:  587 | train loss: 0.201608 | valid loss: 0.276126\n","Epoch:  588 | train loss: 0.361916 | valid loss: 0.275764\n","Epoch:  589 | train loss: 0.273720 | valid loss: 0.275399\n","Epoch:  590 | train loss: 0.262122 | valid loss: 0.275195\n","Epoch:  591 | train loss: 0.292308 | valid loss: 0.275154\n","Epoch:  592 | train loss: 0.272932 | valid loss: 0.274952\n","Epoch:  593 | train loss: 0.280910 | valid loss: 0.274536\n","Epoch:  594 | train loss: 0.289384 | valid loss: 0.274511\n","Epoch:  595 | train loss: 0.230335 | valid loss: 0.274118\n","Epoch:  596 | train loss: 0.279254 | valid loss: 0.273970\n","Epoch:  597 | train loss: 0.266263 | valid loss: 0.273866\n","Epoch:  598 | train loss: 0.257136 | valid loss: 0.273541\n","Epoch:  599 | train loss: 0.286569 | valid loss: 0.273404\n","Epoch:  600 | train loss: 0.281369 | valid loss: 0.273189\n","Epoch:  601 | train loss: 0.263649 | valid loss: 0.272987\n","Epoch:  602 | train loss: 0.328377 | valid loss: 0.272721\n","Epoch:  603 | train loss: 0.269406 | valid loss: 0.272679\n","Epoch:  604 | train loss: 0.268030 | valid loss: 0.272377\n","Epoch:  605 | train loss: 0.367430 | valid loss: 0.272329\n","Epoch:  606 | train loss: 0.230754 | valid loss: 0.271945\n","Epoch:  607 | train loss: 0.195910 | valid loss: 0.271742\n","Epoch:  608 | train loss: 0.281427 | valid loss: 0.271433\n","Epoch:  609 | train loss: 0.281523 | valid loss: 0.271303\n","Epoch:  610 | train loss: 0.323874 | valid loss: 0.271105\n","Epoch:  611 | train loss: 0.319760 | valid loss: 0.270862\n","Epoch:  612 | train loss: 0.266990 | valid loss: 0.270635\n","Epoch:  613 | train loss: 0.334528 | valid loss: 0.270517\n","Epoch:  614 | train loss: 0.266691 | valid loss: 0.270250\n","Epoch:  615 | train loss: 0.277052 | valid loss: 0.270147\n","Epoch:  616 | train loss: 0.272827 | valid loss: 0.269889\n","Epoch:  617 | train loss: 0.259185 | valid loss: 0.269635\n","Epoch:  618 | train loss: 0.277791 | valid loss: 0.269325\n","Epoch:  619 | train loss: 0.306237 | valid loss: 0.269221\n","Epoch:  620 | train loss: 0.268656 | valid loss: 0.268965\n","Epoch:  621 | train loss: 0.323119 | valid loss: 0.269008\n","Epoch:  622 | train loss: 0.268342 | valid loss: 0.268568\n","Epoch:  623 | train loss: 0.279139 | valid loss: 0.268412\n","Epoch:  624 | train loss: 0.299117 | valid loss: 0.268156\n","Epoch:  625 | train loss: 0.267464 | valid loss: 0.268043\n","Epoch:  626 | train loss: 0.247365 | valid loss: 0.267886\n","Epoch:  627 | train loss: 0.250646 | valid loss: 0.267765\n","Epoch:  628 | train loss: 0.257559 | valid loss: 0.267429\n","Epoch:  629 | train loss: 0.303813 | valid loss: 0.267275\n","Epoch:  630 | train loss: 0.274647 | valid loss: 0.267260\n","Epoch:  631 | train loss: 0.249812 | valid loss: 0.266952\n","Epoch:  632 | train loss: 0.235741 | valid loss: 0.266745\n","Epoch:  633 | train loss: 0.251200 | valid loss: 0.266686\n","Epoch:  634 | train loss: 0.320104 | valid loss: 0.266469\n","Epoch:  635 | train loss: 0.233280 | valid loss: 0.266103\n","Epoch:  636 | train loss: 0.247493 | valid loss: 0.265956\n","Epoch:  637 | train loss: 0.225784 | valid loss: 0.265763\n","Epoch:  638 | train loss: 0.318003 | valid loss: 0.265773\n","Epoch:  639 | train loss: 0.227060 | valid loss: 0.265464\n","Epoch:  640 | train loss: 0.219637 | valid loss: 0.265326\n","Epoch:  641 | train loss: 0.341515 | valid loss: 0.265047\n","Epoch:  642 | train loss: 0.283630 | valid loss: 0.264928\n","Epoch:  643 | train loss: 0.208789 | valid loss: 0.264872\n","Epoch:  644 | train loss: 0.284732 | valid loss: 0.264478\n","Epoch:  645 | train loss: 0.311065 | valid loss: 0.264486\n","Epoch:  646 | train loss: 0.256395 | valid loss: 0.264060\n","Epoch:  647 | train loss: 0.231850 | valid loss: 0.263909\n","Epoch:  648 | train loss: 0.199153 | valid loss: 0.263693\n","Epoch:  649 | train loss: 0.269604 | valid loss: 0.263766\n","Epoch:  650 | train loss: 0.289748 | valid loss: 0.263336\n","Epoch:  651 | train loss: 0.257461 | valid loss: 0.263314\n","Epoch:  652 | train loss: 0.203374 | valid loss: 0.263307\n","Epoch:  653 | train loss: 0.261124 | valid loss: 0.262908\n","Epoch:  654 | train loss: 0.270622 | valid loss: 0.262796\n","Epoch:  655 | train loss: 0.199960 | valid loss: 0.262508\n","Epoch:  656 | train loss: 0.263793 | valid loss: 0.262455\n","Epoch:  657 | train loss: 0.271089 | valid loss: 0.262253\n","Epoch:  658 | train loss: 0.259022 | valid loss: 0.261925\n","Epoch:  659 | train loss: 0.221072 | valid loss: 0.261946\n","Epoch:  660 | train loss: 0.279826 | valid loss: 0.261670\n","Epoch:  661 | train loss: 0.302345 | valid loss: 0.261711\n","Epoch:  662 | train loss: 0.230320 | valid loss: 0.261402\n","Epoch:  663 | train loss: 0.287582 | valid loss: 0.261346\n","Epoch:  664 | train loss: 0.248717 | valid loss: 0.261055\n","Epoch:  665 | train loss: 0.195156 | valid loss: 0.260802\n","Epoch:  666 | train loss: 0.258310 | valid loss: 0.260780\n","Epoch:  667 | train loss: 0.300844 | valid loss: 0.260633\n","Epoch:  668 | train loss: 0.261883 | valid loss: 0.260323\n","Epoch:  669 | train loss: 0.220805 | valid loss: 0.260114\n","Epoch:  670 | train loss: 0.224355 | valid loss: 0.260282\n","Epoch:  671 | train loss: 0.265437 | valid loss: 0.259864\n","Epoch:  672 | train loss: 0.292172 | valid loss: 0.259669\n","Epoch:  673 | train loss: 0.205969 | valid loss: 0.259559\n","Epoch:  674 | train loss: 0.239595 | valid loss: 0.259365\n","Epoch:  675 | train loss: 0.198538 | valid loss: 0.259310\n","Epoch:  676 | train loss: 0.343845 | valid loss: 0.259189\n","Epoch:  677 | train loss: 0.309588 | valid loss: 0.258917\n","Epoch:  678 | train loss: 0.293577 | valid loss: 0.258812\n","Epoch:  679 | train loss: 0.213314 | valid loss: 0.258450\n","Epoch:  680 | train loss: 0.247423 | valid loss: 0.258499\n","Epoch:  681 | train loss: 0.254806 | valid loss: 0.258294\n","Epoch:  682 | train loss: 0.262812 | valid loss: 0.258222\n","Epoch:  683 | train loss: 0.175524 | valid loss: 0.257982\n","Epoch:  684 | train loss: 0.212183 | valid loss: 0.258005\n","Epoch:  685 | train loss: 0.274502 | valid loss: 0.257679\n","Epoch:  686 | train loss: 0.243401 | valid loss: 0.257503\n","Epoch:  687 | train loss: 0.300080 | valid loss: 0.257419\n","Epoch:  688 | train loss: 0.218750 | valid loss: 0.257118\n","Epoch:  689 | train loss: 0.229389 | valid loss: 0.256955\n","Epoch:  690 | train loss: 0.214815 | valid loss: 0.256936\n","Epoch:  691 | train loss: 0.308244 | valid loss: 0.256811\n","Epoch:  692 | train loss: 0.225852 | valid loss: 0.256682\n","Epoch:  693 | train loss: 0.280048 | valid loss: 0.256358\n","Epoch:  694 | train loss: 0.256752 | valid loss: 0.256132\n","Epoch:  695 | train loss: 0.266184 | valid loss: 0.256030\n","Epoch:  696 | train loss: 0.212048 | valid loss: 0.255937\n","Epoch:  697 | train loss: 0.193687 | valid loss: 0.255954\n","Epoch:  698 | train loss: 0.279107 | valid loss: 0.255635\n","Epoch:  699 | train loss: 0.267142 | valid loss: 0.255382\n","Epoch:  700 | train loss: 0.249718 | valid loss: 0.255190\n","Epoch:  701 | train loss: 0.271812 | valid loss: 0.255191\n","Epoch:  702 | train loss: 0.189301 | valid loss: 0.254984\n","Epoch:  703 | train loss: 0.272796 | valid loss: 0.254904\n","Epoch:  704 | train loss: 0.319336 | valid loss: 0.254613\n","Epoch:  705 | train loss: 0.187184 | valid loss: 0.254583\n","Epoch:  706 | train loss: 0.259389 | valid loss: 0.254579\n","Epoch:  707 | train loss: 0.233850 | valid loss: 0.254331\n","Epoch:  708 | train loss: 0.236513 | valid loss: 0.253999\n","Epoch:  709 | train loss: 0.229791 | valid loss: 0.253900\n","Epoch:  710 | train loss: 0.233115 | valid loss: 0.253708\n","Epoch:  711 | train loss: 0.221047 | valid loss: 0.253639\n","Epoch:  712 | train loss: 0.294124 | valid loss: 0.253291\n","Epoch:  713 | train loss: 0.253978 | valid loss: 0.253423\n","Epoch:  714 | train loss: 0.215695 | valid loss: 0.253382\n","Epoch:  715 | train loss: 0.239591 | valid loss: 0.253065\n","Epoch:  716 | train loss: 0.271887 | valid loss: 0.252871\n","Epoch:  717 | train loss: 0.223014 | valid loss: 0.252791\n","Epoch:  718 | train loss: 0.256531 | valid loss: 0.252852\n","Epoch:  719 | train loss: 0.167130 | valid loss: 0.252439\n","Epoch:  720 | train loss: 0.272611 | valid loss: 0.252340\n","Epoch:  721 | train loss: 0.253708 | valid loss: 0.252221\n","Epoch:  722 | train loss: 0.237252 | valid loss: 0.252079\n","Epoch:  723 | train loss: 0.208130 | valid loss: 0.251686\n","Epoch:  724 | train loss: 0.246223 | valid loss: 0.251835\n","Epoch:  725 | train loss: 0.281383 | valid loss: 0.251515\n","Epoch:  726 | train loss: 0.250007 | valid loss: 0.251436\n","Epoch:  727 | train loss: 0.246701 | valid loss: 0.251261\n","Epoch:  728 | train loss: 0.258151 | valid loss: 0.251199\n","Epoch:  729 | train loss: 0.231196 | valid loss: 0.250861\n","Epoch:  730 | train loss: 0.229937 | valid loss: 0.250782\n","Epoch:  731 | train loss: 0.186040 | valid loss: 0.250630\n","Epoch:  732 | train loss: 0.224458 | valid loss: 0.250714\n","Epoch:  733 | train loss: 0.209595 | valid loss: 0.250312\n","Epoch:  734 | train loss: 0.236428 | valid loss: 0.250338\n","Epoch:  735 | train loss: 0.235099 | valid loss: 0.250310\n","Epoch:  736 | train loss: 0.245728 | valid loss: 0.250002\n","Epoch:  737 | train loss: 0.222913 | valid loss: 0.249739\n","Epoch:  738 | train loss: 0.220794 | valid loss: 0.249764\n","Epoch:  739 | train loss: 0.207224 | valid loss: 0.249713\n","Epoch:  740 | train loss: 0.237912 | valid loss: 0.249471\n","Epoch:  741 | train loss: 0.141771 | valid loss: 0.249432\n","Epoch:  742 | train loss: 0.277696 | valid loss: 0.249153\n","Epoch:  743 | train loss: 0.233583 | valid loss: 0.249039\n","Epoch:  744 | train loss: 0.221282 | valid loss: 0.248887\n","Epoch:  745 | train loss: 0.221937 | valid loss: 0.248776\n","Epoch:  746 | train loss: 0.232451 | valid loss: 0.248657\n","Epoch:  747 | train loss: 0.202549 | valid loss: 0.248572\n","Epoch:  748 | train loss: 0.217998 | valid loss: 0.248477\n","Epoch:  749 | train loss: 0.263797 | valid loss: 0.248238\n","Epoch:  750 | train loss: 0.253251 | valid loss: 0.248097\n","Epoch:  751 | train loss: 0.282840 | valid loss: 0.248118\n","Epoch:  752 | train loss: 0.243102 | valid loss: 0.247969\n","Epoch:  753 | train loss: 0.217795 | valid loss: 0.247907\n","Epoch:  754 | train loss: 0.239842 | valid loss: 0.247457\n","Epoch:  755 | train loss: 0.288517 | valid loss: 0.247400\n","Epoch:  756 | train loss: 0.237911 | valid loss: 0.247476\n","Epoch:  757 | train loss: 0.300859 | valid loss: 0.247130\n","Epoch:  758 | train loss: 0.235360 | valid loss: 0.247131\n","Epoch:  759 | train loss: 0.245390 | valid loss: 0.246967\n","Epoch:  760 | train loss: 0.232416 | valid loss: 0.246808\n","Epoch:  761 | train loss: 0.325952 | valid loss: 0.246666\n","Epoch:  762 | train loss: 0.291741 | valid loss: 0.246535\n","Epoch:  763 | train loss: 0.322132 | valid loss: 0.246400\n","Epoch:  764 | train loss: 0.249438 | valid loss: 0.246061\n","Epoch:  765 | train loss: 0.238838 | valid loss: 0.245937\n","Epoch:  766 | train loss: 0.204320 | valid loss: 0.245888\n","Epoch:  767 | train loss: 0.292682 | valid loss: 0.245808\n","Epoch:  768 | train loss: 0.223587 | valid loss: 0.245715\n","Epoch:  769 | train loss: 0.301731 | valid loss: 0.245382\n","Epoch:  770 | train loss: 0.234108 | valid loss: 0.245366\n","Epoch:  771 | train loss: 0.290363 | valid loss: 0.245118\n","Epoch:  772 | train loss: 0.220287 | valid loss: 0.245191\n","Epoch:  773 | train loss: 0.212792 | valid loss: 0.244852\n","Epoch:  774 | train loss: 0.256562 | valid loss: 0.244824\n","Epoch:  775 | train loss: 0.318999 | valid loss: 0.244660\n","Epoch:  776 | train loss: 0.205591 | valid loss: 0.244511\n","Epoch:  777 | train loss: 0.240139 | valid loss: 0.244330\n","Epoch:  778 | train loss: 0.215570 | valid loss: 0.244194\n","Epoch:  779 | train loss: 0.196864 | valid loss: 0.244057\n","Epoch:  780 | train loss: 0.216975 | valid loss: 0.244055\n","Epoch:  781 | train loss: 0.244784 | valid loss: 0.243852\n","Epoch:  782 | train loss: 0.220041 | valid loss: 0.243622\n","Epoch:  783 | train loss: 0.230107 | valid loss: 0.243357\n","Epoch:  784 | train loss: 0.250730 | valid loss: 0.243439\n","Epoch:  785 | train loss: 0.206967 | valid loss: 0.243242\n","Epoch:  786 | train loss: 0.221903 | valid loss: 0.243268\n","Epoch:  787 | train loss: 0.257496 | valid loss: 0.243017\n","Epoch:  788 | train loss: 0.180364 | valid loss: 0.242906\n","Epoch:  789 | train loss: 0.218230 | valid loss: 0.242671\n","Epoch:  790 | train loss: 0.196589 | valid loss: 0.242541\n","Epoch:  791 | train loss: 0.210401 | valid loss: 0.242454\n","Epoch:  792 | train loss: 0.223229 | valid loss: 0.242278\n","Epoch:  793 | train loss: 0.270965 | valid loss: 0.242168\n","Epoch:  794 | train loss: 0.192299 | valid loss: 0.242123\n","Epoch:  795 | train loss: 0.340045 | valid loss: 0.242096\n","Epoch:  796 | train loss: 0.243769 | valid loss: 0.241866\n","Epoch:  797 | train loss: 0.228137 | valid loss: 0.241532\n","Epoch:  798 | train loss: 0.240701 | valid loss: 0.241433\n","Epoch:  799 | train loss: 0.216431 | valid loss: 0.241471\n","Epoch:  800 | train loss: 0.289966 | valid loss: 0.241175\n","Epoch:  801 | train loss: 0.217308 | valid loss: 0.241194\n","Epoch:  802 | train loss: 0.230989 | valid loss: 0.240980\n","Epoch:  803 | train loss: 0.245823 | valid loss: 0.240793\n","Epoch:  804 | train loss: 0.199828 | valid loss: 0.240725\n","Epoch:  805 | train loss: 0.254219 | valid loss: 0.240677\n","Epoch:  806 | train loss: 0.220634 | valid loss: 0.240649\n","Epoch:  807 | train loss: 0.223536 | valid loss: 0.240439\n","Epoch:  808 | train loss: 0.248344 | valid loss: 0.240252\n","Epoch:  809 | train loss: 0.266381 | valid loss: 0.240158\n","Epoch:  810 | train loss: 0.217555 | valid loss: 0.240071\n","Epoch:  811 | train loss: 0.236077 | valid loss: 0.239843\n","Epoch:  812 | train loss: 0.242486 | valid loss: 0.239753\n","Epoch:  813 | train loss: 0.240386 | valid loss: 0.239689\n","Epoch:  814 | train loss: 0.187196 | valid loss: 0.239539\n","Epoch:  815 | train loss: 0.204320 | valid loss: 0.239359\n","Epoch:  816 | train loss: 0.261649 | valid loss: 0.239290\n","Epoch:  817 | train loss: 0.263357 | valid loss: 0.239270\n","Epoch:  818 | train loss: 0.217212 | valid loss: 0.239088\n","Epoch:  819 | train loss: 0.325789 | valid loss: 0.239008\n","Epoch:  820 | train loss: 0.242846 | valid loss: 0.238725\n","Epoch:  821 | train loss: 0.295780 | valid loss: 0.238731\n","Epoch:  822 | train loss: 0.151536 | valid loss: 0.238589\n","Epoch:  823 | train loss: 0.192436 | valid loss: 0.238395\n","Epoch:  824 | train loss: 0.190302 | valid loss: 0.238247\n","Epoch:  825 | train loss: 0.233498 | valid loss: 0.238087\n","Epoch:  826 | train loss: 0.272338 | valid loss: 0.238055\n","Epoch:  827 | train loss: 0.240790 | valid loss: 0.237963\n","Epoch:  828 | train loss: 0.201634 | valid loss: 0.237801\n","Epoch:  829 | train loss: 0.231556 | valid loss: 0.237572\n","Epoch:  830 | train loss: 0.231532 | valid loss: 0.237489\n","Epoch:  831 | train loss: 0.207817 | valid loss: 0.237512\n","Epoch:  832 | train loss: 0.228790 | valid loss: 0.237173\n","Epoch:  833 | train loss: 0.201729 | valid loss: 0.237305\n","Epoch:  834 | train loss: 0.280514 | valid loss: 0.237121\n","Epoch:  835 | train loss: 0.197928 | valid loss: 0.236989\n","Epoch:  836 | train loss: 0.225928 | valid loss: 0.236763\n","Epoch:  837 | train loss: 0.274938 | valid loss: 0.236618\n","Epoch:  838 | train loss: 0.184540 | valid loss: 0.236561\n","Epoch:  839 | train loss: 0.242990 | valid loss: 0.236473\n","Epoch:  840 | train loss: 0.325370 | valid loss: 0.236362\n","Epoch:  841 | train loss: 0.220575 | valid loss: 0.236214\n","Epoch:  842 | train loss: 0.216139 | valid loss: 0.236029\n","Epoch:  843 | train loss: 0.267639 | valid loss: 0.235936\n","Epoch:  844 | train loss: 0.226487 | valid loss: 0.235764\n","Epoch:  845 | train loss: 0.201376 | valid loss: 0.235818\n","Epoch:  846 | train loss: 0.186143 | valid loss: 0.235695\n","Epoch:  847 | train loss: 0.210354 | valid loss: 0.235633\n","Epoch:  848 | train loss: 0.223698 | valid loss: 0.235416\n","Epoch:  849 | train loss: 0.222234 | valid loss: 0.235329\n","Epoch:  850 | train loss: 0.160495 | valid loss: 0.235244\n","Epoch:  851 | train loss: 0.254738 | valid loss: 0.235097\n","Epoch:  852 | train loss: 0.271307 | valid loss: 0.235094\n","Epoch:  853 | train loss: 0.208059 | valid loss: 0.234858\n","Epoch:  854 | train loss: 0.246564 | valid loss: 0.234779\n","Epoch:  855 | train loss: 0.210810 | valid loss: 0.234534\n","Epoch:  856 | train loss: 0.248309 | valid loss: 0.234410\n","Epoch:  857 | train loss: 0.245489 | valid loss: 0.234384\n","Epoch:  858 | train loss: 0.203208 | valid loss: 0.234227\n","Epoch:  859 | train loss: 0.184409 | valid loss: 0.234075\n","Epoch:  860 | train loss: 0.233797 | valid loss: 0.234042\n","Epoch:  861 | train loss: 0.220254 | valid loss: 0.233992\n","Epoch:  862 | train loss: 0.292663 | valid loss: 0.233704\n","Epoch:  863 | train loss: 0.197811 | valid loss: 0.233602\n","Epoch:  864 | train loss: 0.228688 | valid loss: 0.233420\n","Epoch:  865 | train loss: 0.306580 | valid loss: 0.233317\n","Epoch:  866 | train loss: 0.261454 | valid loss: 0.233153\n","Epoch:  867 | train loss: 0.211534 | valid loss: 0.233049\n","Epoch:  868 | train loss: 0.181398 | valid loss: 0.232934\n","Epoch:  869 | train loss: 0.220405 | valid loss: 0.232978\n","Epoch:  870 | train loss: 0.268475 | valid loss: 0.232835\n","Epoch:  871 | train loss: 0.213399 | valid loss: 0.232794\n","Epoch:  872 | train loss: 0.260409 | valid loss: 0.232390\n","Epoch:  873 | train loss: 0.245056 | valid loss: 0.232304\n","Epoch:  874 | train loss: 0.250999 | valid loss: 0.232171\n","Epoch:  875 | train loss: 0.234773 | valid loss: 0.232126\n","Epoch:  876 | train loss: 0.228406 | valid loss: 0.232044\n","Epoch:  877 | train loss: 0.233417 | valid loss: 0.231953\n","Epoch:  878 | train loss: 0.224267 | valid loss: 0.231864\n","Epoch:  879 | train loss: 0.228915 | valid loss: 0.231633\n","Epoch:  880 | train loss: 0.253913 | valid loss: 0.231635\n","Epoch:  881 | train loss: 0.246990 | valid loss: 0.231441\n","Epoch:  882 | train loss: 0.215293 | valid loss: 0.231263\n","Epoch:  883 | train loss: 0.264956 | valid loss: 0.231283\n","Epoch:  884 | train loss: 0.221769 | valid loss: 0.231137\n","Epoch:  885 | train loss: 0.202292 | valid loss: 0.230882\n","Epoch:  886 | train loss: 0.259207 | valid loss: 0.230918\n","Epoch:  887 | train loss: 0.167247 | valid loss: 0.230714\n","Epoch:  888 | train loss: 0.241302 | valid loss: 0.230693\n","Epoch:  889 | train loss: 0.210537 | valid loss: 0.230476\n","Epoch:  890 | train loss: 0.162297 | valid loss: 0.230385\n","Epoch:  891 | train loss: 0.247730 | valid loss: 0.230519\n","Epoch:  892 | train loss: 0.281925 | valid loss: 0.230265\n","Epoch:  893 | train loss: 0.247243 | valid loss: 0.230121\n","Epoch:  894 | train loss: 0.269836 | valid loss: 0.230021\n","Epoch:  895 | train loss: 0.279830 | valid loss: 0.229825\n","Epoch:  896 | train loss: 0.252070 | valid loss: 0.229800\n","Epoch:  897 | train loss: 0.177147 | valid loss: 0.229584\n","Epoch:  898 | train loss: 0.211923 | valid loss: 0.229629\n","Epoch:  899 | train loss: 0.173473 | valid loss: 0.229406\n","Epoch:  900 | train loss: 0.208325 | valid loss: 0.229349\n","Epoch:  901 | train loss: 0.207558 | valid loss: 0.229285\n","Epoch:  902 | train loss: 0.298043 | valid loss: 0.229067\n","Epoch:  903 | train loss: 0.214179 | valid loss: 0.228927\n","Epoch:  904 | train loss: 0.188387 | valid loss: 0.228802\n","Epoch:  905 | train loss: 0.275733 | valid loss: 0.228683\n","Epoch:  906 | train loss: 0.249126 | valid loss: 0.228675\n","Epoch:  907 | train loss: 0.243597 | valid loss: 0.228521\n","Epoch:  908 | train loss: 0.221361 | valid loss: 0.228777\n","Epoch:  909 | train loss: 0.220383 | valid loss: 0.228401\n","Epoch:  910 | train loss: 0.241115 | valid loss: 0.228226\n","Epoch:  911 | train loss: 0.181418 | valid loss: 0.228066\n","Epoch:  912 | train loss: 0.208196 | valid loss: 0.228000\n","Epoch:  913 | train loss: 0.222847 | valid loss: 0.227756\n","Epoch:  914 | train loss: 0.253108 | valid loss: 0.227813\n","Epoch:  915 | train loss: 0.208734 | valid loss: 0.227576\n","Epoch:  916 | train loss: 0.240075 | valid loss: 0.227604\n","Epoch:  917 | train loss: 0.194699 | valid loss: 0.227495\n","Epoch:  918 | train loss: 0.182907 | valid loss: 0.227361\n","Epoch:  919 | train loss: 0.247158 | valid loss: 0.227324\n","Epoch:  920 | train loss: 0.211739 | valid loss: 0.227276\n","Epoch:  921 | train loss: 0.214360 | valid loss: 0.227267\n","Epoch:  922 | train loss: 0.239251 | valid loss: 0.226850\n","Epoch:  923 | train loss: 0.238581 | valid loss: 0.226891\n","Epoch:  924 | train loss: 0.201887 | valid loss: 0.226825\n","Epoch:  925 | train loss: 0.172211 | valid loss: 0.226599\n","Epoch:  926 | train loss: 0.164496 | valid loss: 0.226546\n","Epoch:  927 | train loss: 0.171112 | valid loss: 0.226254\n","Epoch:  928 | train loss: 0.162282 | valid loss: 0.226347\n","Epoch:  929 | train loss: 0.221462 | valid loss: 0.226129\n","Epoch:  930 | train loss: 0.141155 | valid loss: 0.226095\n","Epoch:  931 | train loss: 0.264530 | valid loss: 0.225960\n","Epoch:  932 | train loss: 0.216111 | valid loss: 0.225811\n","Epoch:  933 | train loss: 0.215685 | valid loss: 0.225764\n","Epoch:  934 | train loss: 0.256564 | valid loss: 0.225524\n","Epoch:  935 | train loss: 0.237481 | valid loss: 0.225383\n","Epoch:  936 | train loss: 0.261090 | valid loss: 0.225530\n","Epoch:  937 | train loss: 0.214462 | valid loss: 0.225265\n","Epoch:  938 | train loss: 0.223869 | valid loss: 0.225106\n","Epoch:  939 | train loss: 0.215029 | valid loss: 0.225063\n","Epoch:  940 | train loss: 0.273025 | valid loss: 0.224934\n","Epoch:  941 | train loss: 0.170120 | valid loss: 0.225018\n","Epoch:  942 | train loss: 0.266338 | valid loss: 0.224849\n","Epoch:  943 | train loss: 0.189758 | valid loss: 0.224851\n","Epoch:  944 | train loss: 0.182149 | valid loss: 0.224675\n","Epoch:  945 | train loss: 0.237660 | valid loss: 0.224572\n","Epoch:  946 | train loss: 0.202581 | valid loss: 0.224378\n","Epoch:  947 | train loss: 0.231215 | valid loss: 0.224224\n","Epoch:  948 | train loss: 0.227649 | valid loss: 0.224177\n","Epoch:  949 | train loss: 0.207484 | valid loss: 0.224097\n","Epoch:  950 | train loss: 0.148359 | valid loss: 0.224093\n","Epoch:  951 | train loss: 0.213464 | valid loss: 0.223805\n","Epoch:  952 | train loss: 0.233528 | valid loss: 0.223957\n","Epoch:  953 | train loss: 0.202342 | valid loss: 0.223782\n","Epoch:  954 | train loss: 0.192188 | valid loss: 0.223594\n","Epoch:  955 | train loss: 0.197410 | valid loss: 0.223582\n","Epoch:  956 | train loss: 0.197523 | valid loss: 0.223363\n","Epoch:  957 | train loss: 0.203423 | valid loss: 0.223263\n","Epoch:  958 | train loss: 0.189920 | valid loss: 0.223093\n","Epoch:  959 | train loss: 0.223884 | valid loss: 0.223177\n","Epoch:  960 | train loss: 0.268156 | valid loss: 0.222946\n","Epoch:  961 | train loss: 0.237229 | valid loss: 0.222796\n","Epoch:  962 | train loss: 0.215406 | valid loss: 0.222817\n","Epoch:  963 | train loss: 0.213751 | valid loss: 0.222679\n","Epoch:  964 | train loss: 0.192736 | valid loss: 0.222746\n","Epoch:  965 | train loss: 0.228430 | valid loss: 0.222508\n","Epoch:  966 | train loss: 0.170876 | valid loss: 0.222461\n","Epoch:  967 | train loss: 0.179738 | valid loss: 0.222442\n","Epoch:  968 | train loss: 0.214984 | valid loss: 0.222081\n","Epoch:  969 | train loss: 0.266990 | valid loss: 0.221896\n","Epoch:  970 | train loss: 0.169276 | valid loss: 0.221900\n","Epoch:  971 | train loss: 0.189204 | valid loss: 0.221916\n","Epoch:  972 | train loss: 0.243020 | valid loss: 0.221837\n","Epoch:  973 | train loss: 0.212708 | valid loss: 0.221616\n","Epoch:  974 | train loss: 0.206069 | valid loss: 0.221690\n","Epoch:  975 | train loss: 0.220418 | valid loss: 0.221408\n","Epoch:  976 | train loss: 0.170634 | valid loss: 0.221643\n","Epoch:  977 | train loss: 0.232768 | valid loss: 0.221514\n","Epoch:  978 | train loss: 0.209905 | valid loss: 0.221221\n","Epoch:  979 | train loss: 0.193095 | valid loss: 0.221142\n","Epoch:  980 | train loss: 0.241305 | valid loss: 0.221026\n","Epoch:  981 | train loss: 0.243775 | valid loss: 0.220876\n","Epoch:  982 | train loss: 0.162513 | valid loss: 0.220727\n","Epoch:  983 | train loss: 0.230892 | valid loss: 0.220709\n","Epoch:  984 | train loss: 0.253447 | valid loss: 0.220480\n","Epoch:  985 | train loss: 0.211498 | valid loss: 0.220439\n","Epoch:  986 | train loss: 0.191493 | valid loss: 0.220413\n","Epoch:  987 | train loss: 0.179633 | valid loss: 0.220218\n","Epoch:  988 | train loss: 0.222981 | valid loss: 0.219970\n","Epoch:  989 | train loss: 0.205176 | valid loss: 0.220007\n","Epoch:  990 | train loss: 0.201425 | valid loss: 0.220038\n","Epoch:  991 | train loss: 0.295783 | valid loss: 0.219793\n","Epoch:  992 | train loss: 0.165744 | valid loss: 0.219750\n","Epoch:  993 | train loss: 0.241228 | valid loss: 0.219658\n","Epoch:  994 | train loss: 0.193375 | valid loss: 0.219596\n","Epoch:  995 | train loss: 0.172502 | valid loss: 0.219475\n","Epoch:  996 | train loss: 0.243287 | valid loss: 0.219326\n","Epoch:  997 | train loss: 0.239623 | valid loss: 0.219266\n","Epoch:  998 | train loss: 0.209465 | valid loss: 0.219231\n","Epoch:  999 | train loss: 0.219749 | valid loss: 0.219104\n","Epoch:  1000 | train loss: 0.180537 | valid loss: 0.219085\n","Epoch:  1001 | train loss: 0.196666 | valid loss: 0.218929\n","Epoch:  1002 | train loss: 0.214815 | valid loss: 0.218673\n","Epoch:  1003 | train loss: 0.223673 | valid loss: 0.218631\n","Epoch:  1004 | train loss: 0.191823 | valid loss: 0.218626\n","Epoch:  1005 | train loss: 0.193383 | valid loss: 0.218368\n","Epoch:  1006 | train loss: 0.253811 | valid loss: 0.218399\n","Epoch:  1007 | train loss: 0.241276 | valid loss: 0.218342\n","Epoch:  1008 | train loss: 0.170896 | valid loss: 0.218217\n","Epoch:  1009 | train loss: 0.176482 | valid loss: 0.218167\n","Epoch:  1010 | train loss: 0.237054 | valid loss: 0.218025\n","Epoch:  1011 | train loss: 0.266364 | valid loss: 0.217973\n","Epoch:  1012 | train loss: 0.191549 | valid loss: 0.217808\n","Epoch:  1013 | train loss: 0.192247 | valid loss: 0.217709\n","Epoch:  1014 | train loss: 0.254074 | valid loss: 0.217546\n","Epoch:  1015 | train loss: 0.194577 | valid loss: 0.217395\n","Epoch:  1016 | train loss: 0.197221 | valid loss: 0.217521\n","Epoch:  1017 | train loss: 0.260867 | valid loss: 0.217342\n","Epoch:  1018 | train loss: 0.194089 | valid loss: 0.217186\n","Epoch:  1019 | train loss: 0.205977 | valid loss: 0.217261\n","Epoch:  1020 | train loss: 0.198660 | valid loss: 0.217048\n","Epoch:  1021 | train loss: 0.157637 | valid loss: 0.216999\n","Epoch:  1022 | train loss: 0.186835 | valid loss: 0.217026\n","Epoch:  1023 | train loss: 0.211745 | valid loss: 0.216758\n","Epoch:  1024 | train loss: 0.229067 | valid loss: 0.216656\n","Epoch:  1025 | train loss: 0.245229 | valid loss: 0.216544\n","Epoch:  1026 | train loss: 0.194960 | valid loss: 0.216434\n","Epoch:  1027 | train loss: 0.246067 | valid loss: 0.216266\n","Epoch:  1028 | train loss: 0.203783 | valid loss: 0.216294\n","Epoch:  1029 | train loss: 0.252967 | valid loss: 0.216122\n","Epoch:  1030 | train loss: 0.241377 | valid loss: 0.215967\n","Epoch:  1031 | train loss: 0.200676 | valid loss: 0.216128\n","Epoch:  1032 | train loss: 0.214577 | valid loss: 0.216058\n","Epoch:  1033 | train loss: 0.240714 | valid loss: 0.215621\n","Epoch:  1034 | train loss: 0.180176 | valid loss: 0.215677\n","Epoch:  1035 | train loss: 0.243106 | valid loss: 0.215622\n","Epoch:  1036 | train loss: 0.202803 | valid loss: 0.215419\n","Epoch:  1037 | train loss: 0.190799 | valid loss: 0.215273\n","Epoch:  1038 | train loss: 0.185800 | valid loss: 0.215400\n","Epoch:  1039 | train loss: 0.202606 | valid loss: 0.215114\n","Epoch:  1040 | train loss: 0.211386 | valid loss: 0.215012\n","Epoch:  1041 | train loss: 0.279470 | valid loss: 0.214919\n","Epoch:  1042 | train loss: 0.204904 | valid loss: 0.214788\n","Epoch:  1043 | train loss: 0.300398 | valid loss: 0.214867\n","Epoch:  1044 | train loss: 0.154281 | valid loss: 0.214568\n","Epoch:  1045 | train loss: 0.212824 | valid loss: 0.214512\n","Epoch:  1046 | train loss: 0.195886 | valid loss: 0.214420\n","Epoch:  1047 | train loss: 0.202283 | valid loss: 0.214408\n","Epoch:  1048 | train loss: 0.198013 | valid loss: 0.214234\n","Epoch:  1049 | train loss: 0.228205 | valid loss: 0.214144\n","Epoch:  1050 | train loss: 0.277254 | valid loss: 0.214258\n","Epoch:  1051 | train loss: 0.200200 | valid loss: 0.214055\n","Epoch:  1052 | train loss: 0.190872 | valid loss: 0.213884\n","Epoch:  1053 | train loss: 0.166703 | valid loss: 0.213843\n","Epoch:  1054 | train loss: 0.235293 | valid loss: 0.213663\n","Epoch:  1055 | train loss: 0.244275 | valid loss: 0.213524\n","Epoch:  1056 | train loss: 0.281436 | valid loss: 0.213371\n","Epoch:  1057 | train loss: 0.228576 | valid loss: 0.213461\n","Epoch:  1058 | train loss: 0.180413 | valid loss: 0.213200\n","Epoch:  1059 | train loss: 0.155448 | valid loss: 0.213088\n","Epoch:  1060 | train loss: 0.200505 | valid loss: 0.213187\n","Epoch:  1061 | train loss: 0.188979 | valid loss: 0.212915\n","Epoch:  1062 | train loss: 0.167681 | valid loss: 0.212849\n","Epoch:  1063 | train loss: 0.194932 | valid loss: 0.212841\n","Epoch:  1064 | train loss: 0.235270 | valid loss: 0.212860\n","Epoch:  1065 | train loss: 0.189799 | valid loss: 0.212674\n","Epoch:  1066 | train loss: 0.208774 | valid loss: 0.212460\n","Epoch:  1067 | train loss: 0.220029 | valid loss: 0.212364\n","Epoch:  1068 | train loss: 0.214883 | valid loss: 0.212291\n","Epoch:  1069 | train loss: 0.178053 | valid loss: 0.212161\n","Epoch:  1070 | train loss: 0.204226 | valid loss: 0.212053\n","Epoch:  1071 | train loss: 0.209650 | valid loss: 0.212107\n","Epoch:  1072 | train loss: 0.204352 | valid loss: 0.211950\n","Epoch:  1073 | train loss: 0.123313 | valid loss: 0.211841\n","Epoch:  1074 | train loss: 0.173428 | valid loss: 0.211622\n","Epoch:  1075 | train loss: 0.252401 | valid loss: 0.211621\n","Epoch:  1076 | train loss: 0.176443 | valid loss: 0.211423\n","Epoch:  1077 | train loss: 0.205885 | valid loss: 0.211382\n","Epoch:  1078 | train loss: 0.178519 | valid loss: 0.211328\n","Epoch:  1079 | train loss: 0.163019 | valid loss: 0.211379\n","Epoch:  1080 | train loss: 0.225010 | valid loss: 0.211293\n","Epoch:  1081 | train loss: 0.170083 | valid loss: 0.211098\n","Epoch:  1082 | train loss: 0.190898 | valid loss: 0.210817\n","Epoch:  1083 | train loss: 0.236693 | valid loss: 0.210754\n","Epoch:  1084 | train loss: 0.201372 | valid loss: 0.210730\n","Epoch:  1085 | train loss: 0.174976 | valid loss: 0.210677\n","Epoch:  1086 | train loss: 0.214631 | valid loss: 0.210558\n","Epoch:  1087 | train loss: 0.249540 | valid loss: 0.210370\n","Epoch:  1088 | train loss: 0.221298 | valid loss: 0.210306\n","Epoch:  1089 | train loss: 0.225241 | valid loss: 0.210132\n","Epoch:  1090 | train loss: 0.214859 | valid loss: 0.209966\n","Epoch:  1091 | train loss: 0.234712 | valid loss: 0.209903\n","Epoch:  1092 | train loss: 0.243016 | valid loss: 0.209869\n","Epoch:  1093 | train loss: 0.218761 | valid loss: 0.209758\n","Epoch:  1094 | train loss: 0.225520 | valid loss: 0.209713\n","Epoch:  1095 | train loss: 0.186361 | valid loss: 0.209639\n","Epoch:  1096 | train loss: 0.179035 | valid loss: 0.209478\n","Epoch:  1097 | train loss: 0.224340 | valid loss: 0.209346\n","Epoch:  1098 | train loss: 0.181647 | valid loss: 0.209083\n","Epoch:  1099 | train loss: 0.170330 | valid loss: 0.209197\n","Epoch:  1100 | train loss: 0.207202 | valid loss: 0.209064\n","Epoch:  1101 | train loss: 0.222556 | valid loss: 0.208853\n","Epoch:  1102 | train loss: 0.181082 | valid loss: 0.208849\n","Epoch:  1103 | train loss: 0.181245 | valid loss: 0.208810\n","Epoch:  1104 | train loss: 0.200259 | valid loss: 0.208634\n","Epoch:  1105 | train loss: 0.203600 | valid loss: 0.208543\n","Epoch:  1106 | train loss: 0.187114 | valid loss: 0.208507\n","Epoch:  1107 | train loss: 0.251035 | valid loss: 0.208342\n","Epoch:  1108 | train loss: 0.169558 | valid loss: 0.208266\n","Epoch:  1109 | train loss: 0.203010 | valid loss: 0.208213\n","Epoch:  1110 | train loss: 0.243700 | valid loss: 0.208169\n","Epoch:  1111 | train loss: 0.241550 | valid loss: 0.208045\n","Epoch:  1112 | train loss: 0.177453 | valid loss: 0.207902\n","Epoch:  1113 | train loss: 0.210537 | valid loss: 0.207826\n","Epoch:  1114 | train loss: 0.204516 | valid loss: 0.207735\n","Epoch:  1115 | train loss: 0.225826 | valid loss: 0.207768\n","Epoch:  1116 | train loss: 0.196809 | valid loss: 0.207510\n","Epoch:  1117 | train loss: 0.259528 | valid loss: 0.207198\n","Epoch:  1118 | train loss: 0.253467 | valid loss: 0.207284\n","Epoch:  1119 | train loss: 0.180549 | valid loss: 0.207052\n","Epoch:  1120 | train loss: 0.159058 | valid loss: 0.206921\n","Epoch:  1121 | train loss: 0.166976 | valid loss: 0.206794\n","Epoch:  1122 | train loss: 0.229054 | valid loss: 0.206694\n","Epoch:  1123 | train loss: 0.183016 | valid loss: 0.206634\n","Epoch:  1124 | train loss: 0.173490 | valid loss: 0.206805\n","Epoch:  1125 | train loss: 0.236668 | valid loss: 0.206485\n","Epoch:  1126 | train loss: 0.231676 | valid loss: 0.206391\n","Epoch:  1127 | train loss: 0.199758 | valid loss: 0.206420\n","Epoch:  1128 | train loss: 0.169144 | valid loss: 0.206143\n","Epoch:  1129 | train loss: 0.208049 | valid loss: 0.206155\n","Epoch:  1130 | train loss: 0.197348 | valid loss: 0.206038\n","Epoch:  1131 | train loss: 0.164410 | valid loss: 0.205771\n","Epoch:  1132 | train loss: 0.215215 | valid loss: 0.205802\n","Epoch:  1133 | train loss: 0.186538 | valid loss: 0.205627\n","Epoch:  1134 | train loss: 0.205248 | valid loss: 0.205546\n","Epoch:  1135 | train loss: 0.214751 | valid loss: 0.205458\n","Epoch:  1136 | train loss: 0.168527 | valid loss: 0.205307\n","Epoch:  1137 | train loss: 0.208507 | valid loss: 0.205270\n","Epoch:  1138 | train loss: 0.208101 | valid loss: 0.204970\n","Epoch:  1139 | train loss: 0.175705 | valid loss: 0.205006\n","Epoch:  1140 | train loss: 0.171664 | valid loss: 0.204900\n","Epoch:  1141 | train loss: 0.206361 | valid loss: 0.204784\n","Epoch:  1142 | train loss: 0.185809 | valid loss: 0.204763\n","Epoch:  1143 | train loss: 0.209959 | valid loss: 0.204602\n","Epoch:  1144 | train loss: 0.247994 | valid loss: 0.204541\n","Epoch:  1145 | train loss: 0.232529 | valid loss: 0.204289\n","Epoch:  1146 | train loss: 0.186545 | valid loss: 0.204547\n","Epoch:  1147 | train loss: 0.181329 | valid loss: 0.204161\n","Epoch:  1148 | train loss: 0.178567 | valid loss: 0.204066\n","Epoch:  1149 | train loss: 0.205995 | valid loss: 0.204143\n","Epoch:  1150 | train loss: 0.166769 | valid loss: 0.203865\n","Epoch:  1151 | train loss: 0.169277 | valid loss: 0.203770\n","Epoch:  1152 | train loss: 0.226320 | valid loss: 0.203820\n","Epoch:  1153 | train loss: 0.208271 | valid loss: 0.203627\n","Epoch:  1154 | train loss: 0.206522 | valid loss: 0.203543\n","Epoch:  1155 | train loss: 0.161997 | valid loss: 0.203337\n","Epoch:  1156 | train loss: 0.195828 | valid loss: 0.203297\n","Epoch:  1157 | train loss: 0.180281 | valid loss: 0.203114\n","Epoch:  1158 | train loss: 0.257412 | valid loss: 0.203180\n","Epoch:  1159 | train loss: 0.152293 | valid loss: 0.202892\n","Epoch:  1160 | train loss: 0.208266 | valid loss: 0.202820\n","Epoch:  1161 | train loss: 0.167545 | valid loss: 0.202909\n","Epoch:  1162 | train loss: 0.229099 | valid loss: 0.202744\n","Epoch:  1163 | train loss: 0.201237 | valid loss: 0.202579\n","Epoch:  1164 | train loss: 0.215355 | valid loss: 0.202594\n","Epoch:  1165 | train loss: 0.239991 | valid loss: 0.202346\n","Epoch:  1166 | train loss: 0.172090 | valid loss: 0.202256\n","Epoch:  1167 | train loss: 0.255785 | valid loss: 0.202129\n","Epoch:  1168 | train loss: 0.201928 | valid loss: 0.201970\n","Epoch:  1169 | train loss: 0.233493 | valid loss: 0.201857\n","Epoch:  1170 | train loss: 0.223762 | valid loss: 0.201852\n","Epoch:  1171 | train loss: 0.225106 | valid loss: 0.201742\n","Epoch:  1172 | train loss: 0.155876 | valid loss: 0.201576\n","Epoch:  1173 | train loss: 0.171556 | valid loss: 0.201518\n","Epoch:  1174 | train loss: 0.226436 | valid loss: 0.201309\n","Epoch:  1175 | train loss: 0.139376 | valid loss: 0.201346\n","Epoch:  1176 | train loss: 0.193718 | valid loss: 0.201365\n","Epoch:  1177 | train loss: 0.212498 | valid loss: 0.201114\n","Epoch:  1178 | train loss: 0.176722 | valid loss: 0.200963\n","Epoch:  1179 | train loss: 0.202645 | valid loss: 0.201023\n","Epoch:  1180 | train loss: 0.168052 | valid loss: 0.200952\n","Epoch:  1181 | train loss: 0.208875 | valid loss: 0.200769\n","Epoch:  1182 | train loss: 0.227706 | valid loss: 0.200621\n","Epoch:  1183 | train loss: 0.216209 | valid loss: 0.200343\n","Epoch:  1184 | train loss: 0.191038 | valid loss: 0.200397\n","Epoch:  1185 | train loss: 0.146323 | valid loss: 0.200146\n","Epoch:  1186 | train loss: 0.189050 | valid loss: 0.200117\n","Epoch:  1187 | train loss: 0.186404 | valid loss: 0.200005\n","Epoch:  1188 | train loss: 0.223210 | valid loss: 0.199935\n","Epoch:  1189 | train loss: 0.230626 | valid loss: 0.199779\n","Epoch:  1190 | train loss: 0.193966 | valid loss: 0.199658\n","Epoch:  1191 | train loss: 0.149307 | valid loss: 0.199700\n","Epoch:  1192 | train loss: 0.157112 | valid loss: 0.199522\n","Epoch:  1193 | train loss: 0.185154 | valid loss: 0.199150\n","Epoch:  1194 | train loss: 0.209639 | valid loss: 0.199240\n","Epoch:  1195 | train loss: 0.238820 | valid loss: 0.199304\n","Epoch:  1196 | train loss: 0.188049 | valid loss: 0.199081\n","Epoch:  1197 | train loss: 0.187908 | valid loss: 0.198953\n","Epoch:  1198 | train loss: 0.156456 | valid loss: 0.198705\n","Epoch:  1199 | train loss: 0.189011 | valid loss: 0.198632\n","Epoch:  1200 | train loss: 0.207969 | valid loss: 0.198663\n","Epoch:  1201 | train loss: 0.227933 | valid loss: 0.198570\n","Epoch:  1202 | train loss: 0.212938 | valid loss: 0.198488\n","Epoch:  1203 | train loss: 0.158663 | valid loss: 0.198319\n","Epoch:  1204 | train loss: 0.211385 | valid loss: 0.197993\n","Epoch:  1205 | train loss: 0.186098 | valid loss: 0.197917\n","Epoch:  1206 | train loss: 0.250736 | valid loss: 0.197918\n","Epoch:  1207 | train loss: 0.195435 | valid loss: 0.197828\n","Epoch:  1208 | train loss: 0.234783 | valid loss: 0.197721\n","Epoch:  1209 | train loss: 0.181307 | valid loss: 0.197579\n","Epoch:  1210 | train loss: 0.147277 | valid loss: 0.197354\n","Epoch:  1211 | train loss: 0.180537 | valid loss: 0.197325\n","Epoch:  1212 | train loss: 0.167357 | valid loss: 0.197262\n","Epoch:  1213 | train loss: 0.160961 | valid loss: 0.197110\n","Epoch:  1214 | train loss: 0.143019 | valid loss: 0.197035\n","Epoch:  1215 | train loss: 0.156128 | valid loss: 0.196892\n","Epoch:  1216 | train loss: 0.152714 | valid loss: 0.196762\n","Epoch:  1217 | train loss: 0.207300 | valid loss: 0.196633\n","Epoch:  1218 | train loss: 0.177300 | valid loss: 0.196602\n","Epoch:  1219 | train loss: 0.168480 | valid loss: 0.196594\n","Epoch:  1220 | train loss: 0.274659 | valid loss: 0.196408\n","Epoch:  1221 | train loss: 0.181881 | valid loss: 0.196238\n","Epoch:  1222 | train loss: 0.169263 | valid loss: 0.196062\n","Epoch:  1223 | train loss: 0.124394 | valid loss: 0.195967\n","Epoch:  1224 | train loss: 0.130553 | valid loss: 0.195876\n","Epoch:  1225 | train loss: 0.202410 | valid loss: 0.195729\n","Epoch:  1226 | train loss: 0.173431 | valid loss: 0.195665\n","Epoch:  1227 | train loss: 0.190521 | valid loss: 0.195527\n","Epoch:  1228 | train loss: 0.204974 | valid loss: 0.195461\n","Epoch:  1229 | train loss: 0.211397 | valid loss: 0.195335\n","Epoch:  1230 | train loss: 0.167807 | valid loss: 0.195284\n","Epoch:  1231 | train loss: 0.162923 | valid loss: 0.195163\n","Epoch:  1232 | train loss: 0.166098 | valid loss: 0.195133\n","Epoch:  1233 | train loss: 0.194660 | valid loss: 0.195090\n","Epoch:  1234 | train loss: 0.185697 | valid loss: 0.194963\n","Epoch:  1235 | train loss: 0.184078 | valid loss: 0.194797\n","Epoch:  1236 | train loss: 0.189236 | valid loss: 0.194627\n","Epoch:  1237 | train loss: 0.169242 | valid loss: 0.194575\n","Epoch:  1238 | train loss: 0.164211 | valid loss: 0.194153\n","Epoch:  1239 | train loss: 0.197054 | valid loss: 0.194412\n","Epoch:  1240 | train loss: 0.211683 | valid loss: 0.194241\n","Epoch:  1241 | train loss: 0.168269 | valid loss: 0.194138\n","Epoch:  1242 | train loss: 0.210903 | valid loss: 0.193875\n","Epoch:  1243 | train loss: 0.204445 | valid loss: 0.193798\n","Epoch:  1244 | train loss: 0.181347 | valid loss: 0.193752\n","Epoch:  1245 | train loss: 0.210169 | valid loss: 0.193672\n","Epoch:  1246 | train loss: 0.168086 | valid loss: 0.193543\n","Epoch:  1247 | train loss: 0.234448 | valid loss: 0.193521\n","Epoch:  1248 | train loss: 0.201600 | valid loss: 0.193202\n","Epoch:  1249 | train loss: 0.125504 | valid loss: 0.193083\n","Epoch:  1250 | train loss: 0.180504 | valid loss: 0.193057\n","Epoch:  1251 | train loss: 0.208637 | valid loss: 0.193054\n","Epoch:  1252 | train loss: 0.261935 | valid loss: 0.193042\n","Epoch:  1253 | train loss: 0.199523 | valid loss: 0.192682\n","Epoch:  1254 | train loss: 0.208263 | valid loss: 0.192681\n","Epoch:  1255 | train loss: 0.151618 | valid loss: 0.192730\n","Epoch:  1256 | train loss: 0.240199 | valid loss: 0.192526\n","Epoch:  1257 | train loss: 0.176515 | valid loss: 0.192438\n","Epoch:  1258 | train loss: 0.200051 | valid loss: 0.192155\n","Epoch:  1259 | train loss: 0.175334 | valid loss: 0.192088\n","Epoch:  1260 | train loss: 0.189550 | valid loss: 0.192016\n","Epoch:  1261 | train loss: 0.174417 | valid loss: 0.191818\n","Epoch:  1262 | train loss: 0.224857 | valid loss: 0.191920\n","Epoch:  1263 | train loss: 0.188411 | valid loss: 0.191775\n","Epoch:  1264 | train loss: 0.172063 | valid loss: 0.191671\n","Epoch:  1265 | train loss: 0.184971 | valid loss: 0.191509\n","Epoch:  1266 | train loss: 0.216814 | valid loss: 0.191243\n","Epoch:  1267 | train loss: 0.210339 | valid loss: 0.191236\n","Epoch:  1268 | train loss: 0.200633 | valid loss: 0.191168\n","Epoch:  1269 | train loss: 0.235427 | valid loss: 0.190919\n","Epoch:  1270 | train loss: 0.160279 | valid loss: 0.190776\n","Epoch:  1271 | train loss: 0.172587 | valid loss: 0.190763\n","Epoch:  1272 | train loss: 0.196660 | valid loss: 0.190725\n","Epoch:  1273 | train loss: 0.243720 | valid loss: 0.190506\n","Epoch:  1274 | train loss: 0.240153 | valid loss: 0.190575\n","Epoch:  1275 | train loss: 0.206515 | valid loss: 0.190459\n","Epoch:  1276 | train loss: 0.268967 | valid loss: 0.190125\n","Epoch:  1277 | train loss: 0.177681 | valid loss: 0.190338\n","Epoch:  1278 | train loss: 0.183703 | valid loss: 0.190074\n","Epoch:  1279 | train loss: 0.187104 | valid loss: 0.189963\n","Epoch:  1280 | train loss: 0.218180 | valid loss: 0.189690\n","Epoch:  1281 | train loss: 0.197882 | valid loss: 0.189583\n","Epoch:  1282 | train loss: 0.209721 | valid loss: 0.189471\n","Epoch:  1283 | train loss: 0.243854 | valid loss: 0.189559\n","Epoch:  1284 | train loss: 0.219600 | valid loss: 0.189342\n","Epoch:  1285 | train loss: 0.188835 | valid loss: 0.189158\n","Epoch:  1286 | train loss: 0.177810 | valid loss: 0.189170\n","Epoch:  1287 | train loss: 0.209648 | valid loss: 0.189102\n","Epoch:  1288 | train loss: 0.157202 | valid loss: 0.188825\n","Epoch:  1289 | train loss: 0.191271 | valid loss: 0.188646\n","Epoch:  1290 | train loss: 0.205065 | valid loss: 0.188640\n","Epoch:  1291 | train loss: 0.176688 | valid loss: 0.188656\n","Epoch:  1292 | train loss: 0.219370 | valid loss: 0.188426\n","Epoch:  1293 | train loss: 0.116776 | valid loss: 0.188343\n","Epoch:  1294 | train loss: 0.163478 | valid loss: 0.188031\n","Epoch:  1295 | train loss: 0.178851 | valid loss: 0.188177\n","Epoch:  1296 | train loss: 0.178949 | valid loss: 0.187932\n","Epoch:  1297 | train loss: 0.189226 | valid loss: 0.187747\n","Epoch:  1298 | train loss: 0.159102 | valid loss: 0.187783\n","Epoch:  1299 | train loss: 0.158404 | valid loss: 0.187535\n","Epoch:  1300 | train loss: 0.176183 | valid loss: 0.187603\n","Epoch:  1301 | train loss: 0.172949 | valid loss: 0.187396\n","Epoch:  1302 | train loss: 0.166715 | valid loss: 0.187351\n","Epoch:  1303 | train loss: 0.216918 | valid loss: 0.187130\n","Epoch:  1304 | train loss: 0.219196 | valid loss: 0.187072\n","Epoch:  1305 | train loss: 0.175050 | valid loss: 0.186808\n","Epoch:  1306 | train loss: 0.190629 | valid loss: 0.186835\n","Epoch:  1307 | train loss: 0.177322 | valid loss: 0.186864\n","Epoch:  1308 | train loss: 0.148987 | valid loss: 0.186547\n","Epoch:  1309 | train loss: 0.142655 | valid loss: 0.186472\n","Epoch:  1310 | train loss: 0.158118 | valid loss: 0.186473\n","Epoch:  1311 | train loss: 0.181369 | valid loss: 0.186275\n","Epoch:  1312 | train loss: 0.167439 | valid loss: 0.186060\n","Epoch:  1313 | train loss: 0.164670 | valid loss: 0.186009\n","Epoch:  1314 | train loss: 0.202028 | valid loss: 0.185807\n","Epoch:  1315 | train loss: 0.154395 | valid loss: 0.185791\n","Epoch:  1316 | train loss: 0.159579 | valid loss: 0.185753\n","Epoch:  1317 | train loss: 0.169944 | valid loss: 0.185516\n","Epoch:  1318 | train loss: 0.174645 | valid loss: 0.185367\n","Epoch:  1319 | train loss: 0.138571 | valid loss: 0.185243\n","Epoch:  1320 | train loss: 0.198298 | valid loss: 0.185371\n","Epoch:  1321 | train loss: 0.206042 | valid loss: 0.185249\n","Epoch:  1322 | train loss: 0.149969 | valid loss: 0.185129\n","Epoch:  1323 | train loss: 0.198021 | valid loss: 0.184795\n","Epoch:  1324 | train loss: 0.174560 | valid loss: 0.184714\n","Epoch:  1325 | train loss: 0.175992 | valid loss: 0.184699\n","Epoch:  1326 | train loss: 0.207095 | valid loss: 0.184508\n","Epoch:  1327 | train loss: 0.198285 | valid loss: 0.184504\n","Epoch:  1328 | train loss: 0.179860 | valid loss: 0.184283\n","Epoch:  1329 | train loss: 0.164672 | valid loss: 0.184277\n","Epoch:  1330 | train loss: 0.153078 | valid loss: 0.184052\n","Epoch:  1331 | train loss: 0.203361 | valid loss: 0.183820\n","Epoch:  1332 | train loss: 0.208277 | valid loss: 0.183861\n","Epoch:  1333 | train loss: 0.208421 | valid loss: 0.183728\n","Epoch:  1334 | train loss: 0.209710 | valid loss: 0.183592\n","Epoch:  1335 | train loss: 0.162243 | valid loss: 0.183499\n","Epoch:  1336 | train loss: 0.185346 | valid loss: 0.183170\n","Epoch:  1337 | train loss: 0.190182 | valid loss: 0.183257\n","Epoch:  1338 | train loss: 0.184999 | valid loss: 0.183062\n","Epoch:  1339 | train loss: 0.174420 | valid loss: 0.182958\n","Epoch:  1340 | train loss: 0.173521 | valid loss: 0.182824\n","Epoch:  1341 | train loss: 0.226414 | valid loss: 0.182729\n","Epoch:  1342 | train loss: 0.177267 | valid loss: 0.182535\n","Epoch:  1343 | train loss: 0.202859 | valid loss: 0.182527\n","Epoch:  1344 | train loss: 0.166182 | valid loss: 0.182484\n","Epoch:  1345 | train loss: 0.149151 | valid loss: 0.182291\n","Epoch:  1346 | train loss: 0.183297 | valid loss: 0.182116\n","Epoch:  1347 | train loss: 0.178481 | valid loss: 0.181938\n","Epoch:  1348 | train loss: 0.187926 | valid loss: 0.181985\n","Epoch:  1349 | train loss: 0.159282 | valid loss: 0.181936\n","Epoch:  1350 | train loss: 0.202498 | valid loss: 0.181697\n","Epoch:  1351 | train loss: 0.160176 | valid loss: 0.181554\n","Epoch:  1352 | train loss: 0.203511 | valid loss: 0.181483\n","Epoch:  1353 | train loss: 0.267545 | valid loss: 0.181383\n","Epoch:  1354 | train loss: 0.239274 | valid loss: 0.181309\n","Epoch:  1355 | train loss: 0.169864 | valid loss: 0.180977\n","Epoch:  1356 | train loss: 0.102355 | valid loss: 0.180991\n","Epoch:  1357 | train loss: 0.216013 | valid loss: 0.180757\n","Epoch:  1358 | train loss: 0.201111 | valid loss: 0.180812\n","Epoch:  1359 | train loss: 0.182129 | valid loss: 0.180614\n","Epoch:  1360 | train loss: 0.209975 | valid loss: 0.180501\n","Epoch:  1361 | train loss: 0.194102 | valid loss: 0.180302\n","Epoch:  1362 | train loss: 0.156420 | valid loss: 0.180219\n","Epoch:  1363 | train loss: 0.183021 | valid loss: 0.180165\n","Epoch:  1364 | train loss: 0.198858 | valid loss: 0.179880\n","Epoch:  1365 | train loss: 0.211275 | valid loss: 0.179883\n","Epoch:  1366 | train loss: 0.173400 | valid loss: 0.179777\n","Epoch:  1367 | train loss: 0.222554 | valid loss: 0.179509\n","Epoch:  1368 | train loss: 0.169087 | valid loss: 0.179456\n","Epoch:  1369 | train loss: 0.203085 | valid loss: 0.179419\n","Epoch:  1370 | train loss: 0.162507 | valid loss: 0.179322\n","Epoch:  1371 | train loss: 0.160081 | valid loss: 0.179291\n","Epoch:  1372 | train loss: 0.204753 | valid loss: 0.179080\n","Epoch:  1373 | train loss: 0.184255 | valid loss: 0.178917\n","Epoch:  1374 | train loss: 0.205029 | valid loss: 0.178871\n","Epoch:  1375 | train loss: 0.146789 | valid loss: 0.178616\n","Epoch:  1376 | train loss: 0.203103 | valid loss: 0.178510\n","Epoch:  1377 | train loss: 0.185392 | valid loss: 0.178359\n","Epoch:  1378 | train loss: 0.163343 | valid loss: 0.178341\n","Epoch:  1379 | train loss: 0.171953 | valid loss: 0.178007\n","Epoch:  1380 | train loss: 0.226885 | valid loss: 0.178021\n","Epoch:  1381 | train loss: 0.138375 | valid loss: 0.177911\n","Epoch:  1382 | train loss: 0.191961 | valid loss: 0.177802\n","Epoch:  1383 | train loss: 0.199902 | valid loss: 0.177633\n","Epoch:  1384 | train loss: 0.141027 | valid loss: 0.177562\n","Epoch:  1385 | train loss: 0.185444 | valid loss: 0.177374\n","Epoch:  1386 | train loss: 0.168325 | valid loss: 0.177271\n","Epoch:  1387 | train loss: 0.172916 | valid loss: 0.177061\n","Epoch:  1388 | train loss: 0.215470 | valid loss: 0.177073\n","Epoch:  1389 | train loss: 0.183697 | valid loss: 0.176936\n","Epoch:  1390 | train loss: 0.191525 | valid loss: 0.176708\n","Epoch:  1391 | train loss: 0.183050 | valid loss: 0.176667\n","Epoch:  1392 | train loss: 0.144834 | valid loss: 0.176558\n","Epoch:  1393 | train loss: 0.213392 | valid loss: 0.176399\n","Epoch:  1394 | train loss: 0.180929 | valid loss: 0.176327\n","Epoch:  1395 | train loss: 0.196773 | valid loss: 0.176326\n","Epoch:  1396 | train loss: 0.213356 | valid loss: 0.176163\n","Epoch:  1397 | train loss: 0.156683 | valid loss: 0.175792\n","Epoch:  1398 | train loss: 0.188494 | valid loss: 0.175951\n","Epoch:  1399 | train loss: 0.152493 | valid loss: 0.175729\n","Epoch:  1400 | train loss: 0.153190 | valid loss: 0.175649\n","Epoch:  1401 | train loss: 0.161278 | valid loss: 0.175416\n","Epoch:  1402 | train loss: 0.188905 | valid loss: 0.175448\n","Epoch:  1403 | train loss: 0.185162 | valid loss: 0.175151\n","Epoch:  1404 | train loss: 0.166741 | valid loss: 0.175261\n","Epoch:  1405 | train loss: 0.139584 | valid loss: 0.174995\n","Epoch:  1406 | train loss: 0.170980 | valid loss: 0.174852\n","Epoch:  1407 | train loss: 0.147846 | valid loss: 0.174588\n","Epoch:  1408 | train loss: 0.152752 | valid loss: 0.174595\n","Epoch:  1409 | train loss: 0.137914 | valid loss: 0.174543\n","Epoch:  1410 | train loss: 0.214436 | valid loss: 0.174465\n","Epoch:  1411 | train loss: 0.199281 | valid loss: 0.174350\n","Epoch:  1412 | train loss: 0.219507 | valid loss: 0.174207\n","Epoch:  1413 | train loss: 0.186672 | valid loss: 0.174066\n","Epoch:  1414 | train loss: 0.193853 | valid loss: 0.173868\n","Epoch:  1415 | train loss: 0.182892 | valid loss: 0.173921\n","Epoch:  1416 | train loss: 0.206079 | valid loss: 0.173755\n","Epoch:  1417 | train loss: 0.180922 | valid loss: 0.173472\n","Epoch:  1418 | train loss: 0.218706 | valid loss: 0.173474\n","Epoch:  1419 | train loss: 0.140523 | valid loss: 0.173405\n","Epoch:  1420 | train loss: 0.157373 | valid loss: 0.173349\n","Epoch:  1421 | train loss: 0.147574 | valid loss: 0.173031\n","Epoch:  1422 | train loss: 0.161995 | valid loss: 0.173027\n","Epoch:  1423 | train loss: 0.162665 | valid loss: 0.172776\n","Epoch:  1424 | train loss: 0.129054 | valid loss: 0.172734\n","Epoch:  1425 | train loss: 0.194684 | valid loss: 0.172607\n","Epoch:  1426 | train loss: 0.158340 | valid loss: 0.172581\n","Epoch:  1427 | train loss: 0.149438 | valid loss: 0.172402\n","Epoch:  1428 | train loss: 0.170890 | valid loss: 0.172406\n","Epoch:  1429 | train loss: 0.170116 | valid loss: 0.172316\n","Epoch:  1430 | train loss: 0.141752 | valid loss: 0.172061\n","Epoch:  1431 | train loss: 0.186223 | valid loss: 0.172031\n","Epoch:  1432 | train loss: 0.186686 | valid loss: 0.171763\n","Epoch:  1433 | train loss: 0.179628 | valid loss: 0.171686\n","Epoch:  1434 | train loss: 0.209638 | valid loss: 0.171455\n","Epoch:  1435 | train loss: 0.196254 | valid loss: 0.171552\n","Epoch:  1436 | train loss: 0.180451 | valid loss: 0.171294\n","Epoch:  1437 | train loss: 0.162650 | valid loss: 0.171032\n","Epoch:  1438 | train loss: 0.193719 | valid loss: 0.171121\n","Epoch:  1439 | train loss: 0.163682 | valid loss: 0.170923\n","Epoch:  1440 | train loss: 0.168316 | valid loss: 0.170966\n","Epoch:  1441 | train loss: 0.160975 | valid loss: 0.170869\n","Epoch:  1442 | train loss: 0.130649 | valid loss: 0.170746\n","Epoch:  1443 | train loss: 0.180283 | valid loss: 0.170493\n","Epoch:  1444 | train loss: 0.170552 | valid loss: 0.170401\n","Epoch:  1445 | train loss: 0.188132 | valid loss: 0.170235\n","Epoch:  1446 | train loss: 0.204444 | valid loss: 0.170303\n","Epoch:  1447 | train loss: 0.151389 | valid loss: 0.170057\n","Epoch:  1448 | train loss: 0.188868 | valid loss: 0.169980\n","Epoch:  1449 | train loss: 0.183843 | valid loss: 0.169813\n","Epoch:  1450 | train loss: 0.170250 | valid loss: 0.169491\n","Epoch:  1451 | train loss: 0.152074 | valid loss: 0.169425\n","Epoch:  1452 | train loss: 0.173813 | valid loss: 0.169591\n","Epoch:  1453 | train loss: 0.144830 | valid loss: 0.169236\n","Epoch:  1454 | train loss: 0.178002 | valid loss: 0.169203\n","Epoch:  1455 | train loss: 0.191787 | valid loss: 0.168993\n","Epoch:  1456 | train loss: 0.156021 | valid loss: 0.169062\n","Epoch:  1457 | train loss: 0.150509 | valid loss: 0.168819\n","Epoch:  1458 | train loss: 0.180982 | valid loss: 0.168748\n","Epoch:  1459 | train loss: 0.168407 | valid loss: 0.168629\n","Epoch:  1460 | train loss: 0.159582 | valid loss: 0.168525\n","Epoch:  1461 | train loss: 0.144034 | valid loss: 0.168308\n","Epoch:  1462 | train loss: 0.142989 | valid loss: 0.168429\n","Epoch:  1463 | train loss: 0.156238 | valid loss: 0.168145\n","Epoch:  1464 | train loss: 0.172643 | valid loss: 0.168140\n","Epoch:  1465 | train loss: 0.191840 | valid loss: 0.167856\n","Epoch:  1466 | train loss: 0.152004 | valid loss: 0.167848\n","Epoch:  1467 | train loss: 0.185475 | valid loss: 0.167842\n","Epoch:  1468 | train loss: 0.184882 | valid loss: 0.167478\n","Epoch:  1469 | train loss: 0.160246 | valid loss: 0.167500\n","Epoch:  1470 | train loss: 0.171989 | valid loss: 0.167255\n","Epoch:  1471 | train loss: 0.156495 | valid loss: 0.167201\n","Epoch:  1472 | train loss: 0.177876 | valid loss: 0.167092\n","Epoch:  1473 | train loss: 0.125841 | valid loss: 0.166913\n","Epoch:  1474 | train loss: 0.129459 | valid loss: 0.166809\n","Epoch:  1475 | train loss: 0.145680 | valid loss: 0.166540\n","Epoch:  1476 | train loss: 0.230959 | valid loss: 0.166757\n","Epoch:  1477 | train loss: 0.140909 | valid loss: 0.166536\n","Epoch:  1478 | train loss: 0.152742 | valid loss: 0.166206\n","Epoch:  1479 | train loss: 0.187333 | valid loss: 0.166221\n","Epoch:  1480 | train loss: 0.157143 | valid loss: 0.166083\n","Epoch:  1481 | train loss: 0.267766 | valid loss: 0.166039\n","Epoch:  1482 | train loss: 0.204421 | valid loss: 0.165876\n","Epoch:  1483 | train loss: 0.144798 | valid loss: 0.165689\n","Epoch:  1484 | train loss: 0.153154 | valid loss: 0.165691\n","Epoch:  1485 | train loss: 0.138060 | valid loss: 0.165615\n","Epoch:  1486 | train loss: 0.141977 | valid loss: 0.165331\n","Epoch:  1487 | train loss: 0.139717 | valid loss: 0.165236\n","Epoch:  1488 | train loss: 0.155645 | valid loss: 0.165046\n","Epoch:  1489 | train loss: 0.141422 | valid loss: 0.165023\n","Epoch:  1490 | train loss: 0.134813 | valid loss: 0.164913\n","Epoch:  1491 | train loss: 0.175448 | valid loss: 0.164941\n","Epoch:  1492 | train loss: 0.155246 | valid loss: 0.164845\n","Epoch:  1493 | train loss: 0.163402 | valid loss: 0.164869\n","Epoch:  1494 | train loss: 0.158671 | valid loss: 0.164598\n","Epoch:  1495 | train loss: 0.123253 | valid loss: 0.164299\n","Epoch:  1496 | train loss: 0.155282 | valid loss: 0.164416\n","Epoch:  1497 | train loss: 0.194818 | valid loss: 0.164095\n","Epoch:  1498 | train loss: 0.137457 | valid loss: 0.163913\n","Epoch:  1499 | train loss: 0.145964 | valid loss: 0.164006\n","Epoch:  1500 | train loss: 0.183009 | valid loss: 0.163758\n","Epoch:  1501 | train loss: 0.172968 | valid loss: 0.163604\n","Epoch:  1502 | train loss: 0.136441 | valid loss: 0.163709\n","Epoch:  1503 | train loss: 0.156559 | valid loss: 0.163400\n","Epoch:  1504 | train loss: 0.137820 | valid loss: 0.163299\n","Epoch:  1505 | train loss: 0.136125 | valid loss: 0.163040\n","Epoch:  1506 | train loss: 0.171858 | valid loss: 0.162885\n","Epoch:  1507 | train loss: 0.145655 | valid loss: 0.163083\n","Epoch:  1508 | train loss: 0.171230 | valid loss: 0.162749\n","Epoch:  1509 | train loss: 0.159999 | valid loss: 0.162740\n","Epoch:  1510 | train loss: 0.153869 | valid loss: 0.162759\n","Epoch:  1511 | train loss: 0.150425 | valid loss: 0.162486\n","Epoch:  1512 | train loss: 0.190298 | valid loss: 0.162377\n","Epoch:  1513 | train loss: 0.196189 | valid loss: 0.162255\n","Epoch:  1514 | train loss: 0.144169 | valid loss: 0.162114\n","Epoch:  1515 | train loss: 0.124941 | valid loss: 0.161958\n","Epoch:  1516 | train loss: 0.173274 | valid loss: 0.161852\n","Epoch:  1517 | train loss: 0.137071 | valid loss: 0.161700\n","Epoch:  1518 | train loss: 0.152508 | valid loss: 0.161434\n","Epoch:  1519 | train loss: 0.182358 | valid loss: 0.161436\n","Epoch:  1520 | train loss: 0.162174 | valid loss: 0.161490\n","Epoch:  1521 | train loss: 0.144339 | valid loss: 0.161127\n","Epoch:  1522 | train loss: 0.127657 | valid loss: 0.161100\n","Epoch:  1523 | train loss: 0.151189 | valid loss: 0.161002\n","Epoch:  1524 | train loss: 0.177206 | valid loss: 0.160883\n","Epoch:  1525 | train loss: 0.156082 | valid loss: 0.160789\n","Epoch:  1526 | train loss: 0.119564 | valid loss: 0.160641\n","Epoch:  1527 | train loss: 0.119124 | valid loss: 0.160447\n","Epoch:  1528 | train loss: 0.175586 | valid loss: 0.160466\n","Epoch:  1529 | train loss: 0.155286 | valid loss: 0.160319\n","Epoch:  1530 | train loss: 0.147283 | valid loss: 0.160339\n","Epoch:  1531 | train loss: 0.303077 | valid loss: 0.160139\n","Epoch:  1532 | train loss: 0.138295 | valid loss: 0.159965\n","Epoch:  1533 | train loss: 0.124825 | valid loss: 0.159795\n","Epoch:  1534 | train loss: 0.147912 | valid loss: 0.159733\n","Epoch:  1535 | train loss: 0.174923 | valid loss: 0.159701\n","Epoch:  1536 | train loss: 0.132431 | valid loss: 0.159577\n","Epoch:  1537 | train loss: 0.157730 | valid loss: 0.159351\n","Epoch:  1538 | train loss: 0.171755 | valid loss: 0.159154\n","Epoch:  1539 | train loss: 0.182933 | valid loss: 0.159136\n","Epoch:  1540 | train loss: 0.151772 | valid loss: 0.158878\n","Epoch:  1541 | train loss: 0.154477 | valid loss: 0.158798\n","Epoch:  1542 | train loss: 0.142193 | valid loss: 0.158809\n","Epoch:  1543 | train loss: 0.150969 | valid loss: 0.158606\n","Epoch:  1544 | train loss: 0.127873 | valid loss: 0.158454\n","Epoch:  1545 | train loss: 0.186471 | valid loss: 0.158243\n","Epoch:  1546 | train loss: 0.147362 | valid loss: 0.158354\n","Epoch:  1547 | train loss: 0.174648 | valid loss: 0.158102\n","Epoch:  1548 | train loss: 0.166286 | valid loss: 0.158088\n","Epoch:  1549 | train loss: 0.194119 | valid loss: 0.157955\n","Epoch:  1550 | train loss: 0.158808 | valid loss: 0.157836\n","Epoch:  1551 | train loss: 0.173877 | valid loss: 0.157586\n","Epoch:  1552 | train loss: 0.137117 | valid loss: 0.157639\n","Epoch:  1553 | train loss: 0.180279 | valid loss: 0.157469\n","Epoch:  1554 | train loss: 0.124662 | valid loss: 0.157394\n","Epoch:  1555 | train loss: 0.177617 | valid loss: 0.157302\n","Epoch:  1556 | train loss: 0.173944 | valid loss: 0.157244\n","Epoch:  1557 | train loss: 0.152768 | valid loss: 0.157184\n","Epoch:  1558 | train loss: 0.162195 | valid loss: 0.156863\n","Epoch:  1559 | train loss: 0.151420 | valid loss: 0.156811\n","Epoch:  1560 | train loss: 0.166712 | valid loss: 0.156661\n","Epoch:  1561 | train loss: 0.138589 | valid loss: 0.156602\n","Epoch:  1562 | train loss: 0.127357 | valid loss: 0.156434\n","Epoch:  1563 | train loss: 0.143586 | valid loss: 0.156267\n","Epoch:  1564 | train loss: 0.136836 | valid loss: 0.156339\n","Epoch:  1565 | train loss: 0.195260 | valid loss: 0.156020\n","Epoch:  1566 | train loss: 0.148403 | valid loss: 0.155862\n","Epoch:  1567 | train loss: 0.158485 | valid loss: 0.155751\n","Epoch:  1568 | train loss: 0.171954 | valid loss: 0.155732\n","Epoch:  1569 | train loss: 0.115844 | valid loss: 0.155455\n","Epoch:  1570 | train loss: 0.158392 | valid loss: 0.155573\n","Epoch:  1571 | train loss: 0.163894 | valid loss: 0.155278\n","Epoch:  1572 | train loss: 0.133796 | valid loss: 0.155317\n","Epoch:  1573 | train loss: 0.131519 | valid loss: 0.155334\n","Epoch:  1574 | train loss: 0.164207 | valid loss: 0.155165\n","Epoch:  1575 | train loss: 0.156958 | valid loss: 0.154947\n","Epoch:  1576 | train loss: 0.129047 | valid loss: 0.154914\n","Epoch:  1577 | train loss: 0.176830 | valid loss: 0.154702\n","Epoch:  1578 | train loss: 0.186377 | valid loss: 0.154519\n","Epoch:  1579 | train loss: 0.147663 | valid loss: 0.154374\n","Epoch:  1580 | train loss: 0.165541 | valid loss: 0.154341\n","Epoch:  1581 | train loss: 0.161966 | valid loss: 0.154220\n","Epoch:  1582 | train loss: 0.170452 | valid loss: 0.154244\n","Epoch:  1583 | train loss: 0.151952 | valid loss: 0.153989\n","Epoch:  1584 | train loss: 0.169724 | valid loss: 0.153914\n","Epoch:  1585 | train loss: 0.159407 | valid loss: 0.153777\n","Epoch:  1586 | train loss: 0.156413 | valid loss: 0.153693\n","Epoch:  1587 | train loss: 0.132275 | valid loss: 0.153658\n","Epoch:  1588 | train loss: 0.147329 | valid loss: 0.153448\n","Epoch:  1589 | train loss: 0.167182 | valid loss: 0.153346\n","Epoch:  1590 | train loss: 0.160929 | valid loss: 0.153335\n","Epoch:  1591 | train loss: 0.158344 | valid loss: 0.153197\n","Epoch:  1592 | train loss: 0.119405 | valid loss: 0.153058\n","Epoch:  1593 | train loss: 0.163423 | valid loss: 0.152955\n","Epoch:  1594 | train loss: 0.148426 | valid loss: 0.152959\n","Epoch:  1595 | train loss: 0.124542 | valid loss: 0.152723\n","Epoch:  1596 | train loss: 0.132518 | valid loss: 0.152453\n","Epoch:  1597 | train loss: 0.121091 | valid loss: 0.152510\n","Epoch:  1598 | train loss: 0.142300 | valid loss: 0.152350\n","Epoch:  1599 | train loss: 0.149985 | valid loss: 0.152214\n","Epoch:  1600 | train loss: 0.126744 | valid loss: 0.152157\n","Epoch:  1601 | train loss: 0.126812 | valid loss: 0.151870\n","Epoch:  1602 | train loss: 0.141750 | valid loss: 0.151846\n","Epoch:  1603 | train loss: 0.155743 | valid loss: 0.151722\n","Epoch:  1604 | train loss: 0.156408 | valid loss: 0.151689\n","Epoch:  1605 | train loss: 0.154333 | valid loss: 0.151518\n","Epoch:  1606 | train loss: 0.131575 | valid loss: 0.151511\n","Epoch:  1607 | train loss: 0.147475 | valid loss: 0.151090\n","Epoch:  1608 | train loss: 0.154269 | valid loss: 0.151143\n","Epoch:  1609 | train loss: 0.169028 | valid loss: 0.150872\n","Epoch:  1610 | train loss: 0.166269 | valid loss: 0.150897\n","Epoch:  1611 | train loss: 0.167616 | valid loss: 0.150758\n","Epoch:  1612 | train loss: 0.140010 | valid loss: 0.150550\n","Epoch:  1613 | train loss: 0.136964 | valid loss: 0.150639\n","Epoch:  1614 | train loss: 0.144517 | valid loss: 0.150280\n","Epoch:  1615 | train loss: 0.160177 | valid loss: 0.150294\n","Epoch:  1616 | train loss: 0.162506 | valid loss: 0.150054\n","Epoch:  1617 | train loss: 0.148172 | valid loss: 0.150015\n","Epoch:  1618 | train loss: 0.142566 | valid loss: 0.149719\n","Epoch:  1619 | train loss: 0.150300 | valid loss: 0.149834\n","Epoch:  1620 | train loss: 0.145960 | valid loss: 0.149457\n","Epoch:  1621 | train loss: 0.289779 | valid loss: 0.149441\n","Epoch:  1622 | train loss: 0.132947 | valid loss: 0.149293\n","Epoch:  1623 | train loss: 0.153018 | valid loss: 0.149245\n","Epoch:  1624 | train loss: 0.147588 | valid loss: 0.149182\n","Epoch:  1625 | train loss: 0.175444 | valid loss: 0.149028\n","Epoch:  1626 | train loss: 0.170731 | valid loss: 0.148947\n","Epoch:  1627 | train loss: 0.134663 | valid loss: 0.148843\n","Epoch:  1628 | train loss: 0.195140 | valid loss: 0.148719\n","Epoch:  1629 | train loss: 0.150368 | valid loss: 0.148496\n","Epoch:  1630 | train loss: 0.148541 | valid loss: 0.148240\n","Epoch:  1631 | train loss: 0.143434 | valid loss: 0.148232\n","Epoch:  1632 | train loss: 0.157926 | valid loss: 0.148235\n","Epoch:  1633 | train loss: 0.147760 | valid loss: 0.148030\n","Epoch:  1634 | train loss: 0.141108 | valid loss: 0.148007\n","Epoch:  1635 | train loss: 0.140020 | valid loss: 0.147843\n","Epoch:  1636 | train loss: 0.106093 | valid loss: 0.147738\n","Epoch:  1637 | train loss: 0.138813 | valid loss: 0.147644\n","Epoch:  1638 | train loss: 0.100409 | valid loss: 0.147672\n","Epoch:  1639 | train loss: 0.147134 | valid loss: 0.147486\n","Epoch:  1640 | train loss: 0.127067 | valid loss: 0.147412\n","Epoch:  1641 | train loss: 0.119060 | valid loss: 0.147190\n","Epoch:  1642 | train loss: 0.134840 | valid loss: 0.147125\n","Epoch:  1643 | train loss: 0.160216 | valid loss: 0.147043\n","Epoch:  1644 | train loss: 0.138331 | valid loss: 0.146799\n","Epoch:  1645 | train loss: 0.129285 | valid loss: 0.146808\n","Epoch:  1646 | train loss: 0.154688 | valid loss: 0.146671\n","Epoch:  1647 | train loss: 0.137269 | valid loss: 0.146551\n","Epoch:  1648 | train loss: 0.155828 | valid loss: 0.146206\n","Epoch:  1649 | train loss: 0.164858 | valid loss: 0.146113\n","Epoch:  1650 | train loss: 0.145630 | valid loss: 0.146221\n","Epoch:  1651 | train loss: 0.136655 | valid loss: 0.145899\n","Epoch:  1652 | train loss: 0.130760 | valid loss: 0.145939\n","Epoch:  1653 | train loss: 0.145732 | valid loss: 0.145843\n","Epoch:  1654 | train loss: 0.149210 | valid loss: 0.145606\n","Epoch:  1655 | train loss: 0.134936 | valid loss: 0.145616\n","Epoch:  1656 | train loss: 0.140698 | valid loss: 0.145480\n","Epoch:  1657 | train loss: 0.148008 | valid loss: 0.145607\n","Epoch:  1658 | train loss: 0.154993 | valid loss: 0.145143\n","Epoch:  1659 | train loss: 0.133035 | valid loss: 0.145253\n","Epoch:  1660 | train loss: 0.302759 | valid loss: 0.145003\n","Epoch:  1661 | train loss: 0.145538 | valid loss: 0.144868\n","Epoch:  1662 | train loss: 0.167669 | valid loss: 0.144791\n","Epoch:  1663 | train loss: 0.138028 | valid loss: 0.144522\n","Epoch:  1664 | train loss: 0.138970 | valid loss: 0.144584\n","Epoch:  1665 | train loss: 0.163587 | valid loss: 0.144448\n","Epoch:  1666 | train loss: 0.134642 | valid loss: 0.144315\n","Epoch:  1667 | train loss: 0.142305 | valid loss: 0.144122\n","Epoch:  1668 | train loss: 0.149518 | valid loss: 0.144212\n","Epoch:  1669 | train loss: 0.122165 | valid loss: 0.144107\n","Epoch:  1670 | train loss: 0.139343 | valid loss: 0.143873\n","Epoch:  1671 | train loss: 0.169078 | valid loss: 0.143790\n","Epoch:  1672 | train loss: 0.144335 | valid loss: 0.143633\n","Epoch:  1673 | train loss: 0.154266 | valid loss: 0.143499\n","Epoch:  1674 | train loss: 0.141090 | valid loss: 0.143492\n","Epoch:  1675 | train loss: 0.123270 | valid loss: 0.143333\n","Epoch:  1676 | train loss: 0.112205 | valid loss: 0.143307\n","Epoch:  1677 | train loss: 0.151016 | valid loss: 0.143239\n","Epoch:  1678 | train loss: 0.120361 | valid loss: 0.143112\n","Epoch:  1679 | train loss: 0.134760 | valid loss: 0.143016\n","Epoch:  1680 | train loss: 0.153572 | valid loss: 0.142799\n","Epoch:  1681 | train loss: 0.145374 | valid loss: 0.142667\n","Epoch:  1682 | train loss: 0.145720 | valid loss: 0.142614\n","Epoch:  1683 | train loss: 0.161704 | valid loss: 0.142532\n","Epoch:  1684 | train loss: 0.184579 | valid loss: 0.142554\n","Epoch:  1685 | train loss: 0.133216 | valid loss: 0.142300\n","Epoch:  1686 | train loss: 0.157666 | valid loss: 0.142256\n","Epoch:  1687 | train loss: 0.120386 | valid loss: 0.142206\n","Epoch:  1688 | train loss: 0.150169 | valid loss: 0.142001\n","Epoch:  1689 | train loss: 0.175260 | valid loss: 0.141862\n","Epoch:  1690 | train loss: 0.139235 | valid loss: 0.142042\n","Epoch:  1691 | train loss: 0.148194 | valid loss: 0.142005\n","Epoch:  1692 | train loss: 0.142334 | valid loss: 0.141635\n","Epoch:  1693 | train loss: 0.159189 | valid loss: 0.141534\n","Epoch:  1694 | train loss: 0.161318 | valid loss: 0.141588\n","Epoch:  1695 | train loss: 0.140844 | valid loss: 0.141366\n","Epoch:  1696 | train loss: 0.133154 | valid loss: 0.141189\n","Epoch:  1697 | train loss: 0.138436 | valid loss: 0.141234\n","Epoch:  1698 | train loss: 0.134940 | valid loss: 0.141083\n","Epoch:  1699 | train loss: 0.126782 | valid loss: 0.140950\n","Epoch:  1700 | train loss: 0.135555 | valid loss: 0.140945\n","Epoch:  1701 | train loss: 0.145184 | valid loss: 0.140841\n","Epoch:  1702 | train loss: 0.121186 | valid loss: 0.140583\n","Epoch:  1703 | train loss: 0.158693 | valid loss: 0.140634\n","Epoch:  1704 | train loss: 0.155966 | valid loss: 0.140485\n","Epoch:  1705 | train loss: 0.126429 | valid loss: 0.140367\n","Epoch:  1706 | train loss: 0.155023 | valid loss: 0.140304\n","Epoch:  1707 | train loss: 0.158903 | valid loss: 0.140218\n","Epoch:  1708 | train loss: 0.145005 | valid loss: 0.140008\n","Epoch:  1709 | train loss: 0.105066 | valid loss: 0.139892\n","Epoch:  1710 | train loss: 0.144137 | valid loss: 0.139831\n","Epoch:  1711 | train loss: 0.126375 | valid loss: 0.139791\n","Epoch:  1712 | train loss: 0.131068 | valid loss: 0.139613\n","Epoch:  1713 | train loss: 0.129708 | valid loss: 0.139464\n","Epoch:  1714 | train loss: 0.189257 | valid loss: 0.139641\n","Epoch:  1715 | train loss: 0.124544 | valid loss: 0.139416\n","Epoch:  1716 | train loss: 0.132879 | valid loss: 0.139260\n","Epoch:  1717 | train loss: 0.143156 | valid loss: 0.139206\n","Epoch:  1718 | train loss: 0.118653 | valid loss: 0.138859\n","Epoch:  1719 | train loss: 0.123120 | valid loss: 0.139046\n","Epoch:  1720 | train loss: 0.148837 | valid loss: 0.138863\n","Epoch:  1721 | train loss: 0.146542 | valid loss: 0.138553\n","Epoch:  1722 | train loss: 0.145208 | valid loss: 0.138488\n","Epoch:  1723 | train loss: 0.147871 | valid loss: 0.138450\n","Epoch:  1724 | train loss: 0.153579 | valid loss: 0.138533\n","Epoch:  1725 | train loss: 0.138797 | valid loss: 0.138325\n","Epoch:  1726 | train loss: 0.122724 | valid loss: 0.138260\n","Epoch:  1727 | train loss: 0.138068 | valid loss: 0.137990\n","Epoch:  1728 | train loss: 0.123412 | valid loss: 0.137935\n","Epoch:  1729 | train loss: 0.163819 | valid loss: 0.137775\n","Epoch:  1730 | train loss: 0.137541 | valid loss: 0.137682\n","Epoch:  1731 | train loss: 0.128663 | valid loss: 0.137604\n","Epoch:  1732 | train loss: 0.133191 | valid loss: 0.137452\n","Epoch:  1733 | train loss: 0.169289 | valid loss: 0.137240\n","Epoch:  1734 | train loss: 0.112603 | valid loss: 0.137217\n","Epoch:  1735 | train loss: 0.117657 | valid loss: 0.137092\n","Epoch:  1736 | train loss: 0.129827 | valid loss: 0.136951\n","Epoch:  1737 | train loss: 0.137313 | valid loss: 0.136934\n","Epoch:  1738 | train loss: 0.138120 | valid loss: 0.136789\n","Epoch:  1739 | train loss: 0.143887 | valid loss: 0.136690\n","Epoch:  1740 | train loss: 0.152237 | valid loss: 0.136559\n","Epoch:  1741 | train loss: 0.131029 | valid loss: 0.136483\n","Epoch:  1742 | train loss: 0.139029 | valid loss: 0.136433\n","Epoch:  1743 | train loss: 0.116004 | valid loss: 0.136346\n","Epoch:  1744 | train loss: 0.151795 | valid loss: 0.136213\n","Epoch:  1745 | train loss: 0.136797 | valid loss: 0.136046\n","Epoch:  1746 | train loss: 0.131789 | valid loss: 0.136073\n","Epoch:  1747 | train loss: 0.142140 | valid loss: 0.135754\n","Epoch:  1748 | train loss: 0.111829 | valid loss: 0.135788\n","Epoch:  1749 | train loss: 0.136095 | valid loss: 0.135653\n","Epoch:  1750 | train loss: 0.131327 | valid loss: 0.135482\n","Epoch:  1751 | train loss: 0.131830 | valid loss: 0.135382\n","Epoch:  1752 | train loss: 0.130623 | valid loss: 0.135333\n","Epoch:  1753 | train loss: 0.141561 | valid loss: 0.135201\n","Epoch:  1754 | train loss: 0.122151 | valid loss: 0.135185\n","Epoch:  1755 | train loss: 0.139359 | valid loss: 0.135074\n","Epoch:  1756 | train loss: 0.129148 | valid loss: 0.135052\n","Epoch:  1757 | train loss: 0.111779 | valid loss: 0.134770\n","Epoch:  1758 | train loss: 0.138488 | valid loss: 0.134875\n","Epoch:  1759 | train loss: 0.124451 | valid loss: 0.134799\n","Epoch:  1760 | train loss: 0.144962 | valid loss: 0.134640\n","Epoch:  1761 | train loss: 0.125509 | valid loss: 0.134550\n","Epoch:  1762 | train loss: 0.132275 | valid loss: 0.134481\n","Epoch:  1763 | train loss: 0.083337 | valid loss: 0.134183\n","Epoch:  1764 | train loss: 0.128714 | valid loss: 0.134219\n","Epoch:  1765 | train loss: 0.271961 | valid loss: 0.133895\n","Epoch:  1766 | train loss: 0.128298 | valid loss: 0.134085\n","Epoch:  1767 | train loss: 0.130465 | valid loss: 0.133910\n","Epoch:  1768 | train loss: 0.117218 | valid loss: 0.133783\n","Epoch:  1769 | train loss: 0.142076 | valid loss: 0.133621\n","Epoch:  1770 | train loss: 0.157175 | valid loss: 0.133570\n","Epoch:  1771 | train loss: 0.111316 | valid loss: 0.133456\n","Epoch:  1772 | train loss: 0.126556 | valid loss: 0.133540\n","Epoch:  1773 | train loss: 0.130340 | valid loss: 0.133296\n","Epoch:  1774 | train loss: 0.135197 | valid loss: 0.133224\n","Epoch:  1775 | train loss: 0.141489 | valid loss: 0.133226\n","Epoch:  1776 | train loss: 0.130673 | valid loss: 0.133097\n","Epoch:  1777 | train loss: 0.115664 | valid loss: 0.132933\n","Epoch:  1778 | train loss: 0.145637 | valid loss: 0.132795\n","Epoch:  1779 | train loss: 0.138059 | valid loss: 0.132766\n","Epoch:  1780 | train loss: 0.130778 | valid loss: 0.132608\n","Epoch:  1781 | train loss: 0.116356 | valid loss: 0.132616\n","Epoch:  1782 | train loss: 0.111846 | valid loss: 0.132535\n","Epoch:  1783 | train loss: 0.115762 | valid loss: 0.132318\n","Epoch:  1784 | train loss: 0.144313 | valid loss: 0.132375\n","Epoch:  1785 | train loss: 0.111204 | valid loss: 0.132161\n","Epoch:  1786 | train loss: 0.132369 | valid loss: 0.132051\n","Epoch:  1787 | train loss: 0.141200 | valid loss: 0.131918\n","Epoch:  1788 | train loss: 0.143590 | valid loss: 0.131943\n","Epoch:  1789 | train loss: 0.123646 | valid loss: 0.131929\n","Epoch:  1790 | train loss: 0.119608 | valid loss: 0.131764\n","Epoch:  1791 | train loss: 0.113774 | valid loss: 0.131704\n","Epoch:  1792 | train loss: 0.151566 | valid loss: 0.131660\n","Epoch:  1793 | train loss: 0.138367 | valid loss: 0.131487\n","Epoch:  1794 | train loss: 0.105875 | valid loss: 0.131413\n","Epoch:  1795 | train loss: 0.129292 | valid loss: 0.131313\n","Epoch:  1796 | train loss: 0.135663 | valid loss: 0.131313\n","Epoch:  1797 | train loss: 0.127188 | valid loss: 0.131146\n","Epoch:  1798 | train loss: 0.146310 | valid loss: 0.130940\n","Epoch:  1799 | train loss: 0.120763 | valid loss: 0.130882\n","Epoch:  1800 | train loss: 0.121498 | valid loss: 0.130728\n","Epoch:  1801 | train loss: 0.118932 | valid loss: 0.130768\n","Epoch:  1802 | train loss: 0.105700 | valid loss: 0.130630\n","Epoch:  1803 | train loss: 0.109238 | valid loss: 0.130552\n","Epoch:  1804 | train loss: 0.136897 | valid loss: 0.130399\n","Epoch:  1805 | train loss: 0.128760 | valid loss: 0.130404\n","Epoch:  1806 | train loss: 0.108853 | valid loss: 0.130313\n","Epoch:  1807 | train loss: 0.122774 | valid loss: 0.130009\n","Epoch:  1808 | train loss: 0.136941 | valid loss: 0.130119\n","Epoch:  1809 | train loss: 0.117476 | valid loss: 0.130188\n","Epoch:  1810 | train loss: 0.132306 | valid loss: 0.129835\n","Epoch:  1811 | train loss: 0.124272 | valid loss: 0.129665\n","Epoch:  1812 | train loss: 0.151442 | valid loss: 0.129723\n","Epoch:  1813 | train loss: 0.101963 | valid loss: 0.129741\n","Epoch:  1814 | train loss: 0.138969 | valid loss: 0.129421\n","Epoch:  1815 | train loss: 0.111371 | valid loss: 0.129376\n","Epoch:  1816 | train loss: 0.110414 | valid loss: 0.129446\n","Epoch:  1817 | train loss: 0.126481 | valid loss: 0.129135\n","Epoch:  1818 | train loss: 0.109525 | valid loss: 0.129114\n","Epoch:  1819 | train loss: 0.110198 | valid loss: 0.129042\n","Epoch:  1820 | train loss: 0.152090 | valid loss: 0.128953\n","Epoch:  1821 | train loss: 0.136957 | valid loss: 0.128791\n","Epoch:  1822 | train loss: 0.131315 | valid loss: 0.128693\n","Epoch:  1823 | train loss: 0.129728 | valid loss: 0.128566\n","Epoch:  1824 | train loss: 0.115118 | valid loss: 0.128615\n","Epoch:  1825 | train loss: 0.125078 | valid loss: 0.128436\n","Epoch:  1826 | train loss: 0.120890 | valid loss: 0.128357\n","Epoch:  1827 | train loss: 0.148692 | valid loss: 0.128280\n","Epoch:  1828 | train loss: 0.135197 | valid loss: 0.128239\n","Epoch:  1829 | train loss: 0.120675 | valid loss: 0.128179\n","Epoch:  1830 | train loss: 0.115919 | valid loss: 0.128029\n","Epoch:  1831 | train loss: 0.135561 | valid loss: 0.127865\n","Epoch:  1832 | train loss: 0.132523 | valid loss: 0.127787\n","Epoch:  1833 | train loss: 0.132887 | valid loss: 0.127689\n","Epoch:  1834 | train loss: 0.135339 | valid loss: 0.127671\n","Epoch:  1835 | train loss: 0.146458 | valid loss: 0.127547\n","Epoch:  1836 | train loss: 0.118107 | valid loss: 0.127435\n","Epoch:  1837 | train loss: 0.108948 | valid loss: 0.127454\n","Epoch:  1838 | train loss: 0.154493 | valid loss: 0.127334\n","Epoch:  1839 | train loss: 0.115155 | valid loss: 0.127288\n","Epoch:  1840 | train loss: 0.117909 | valid loss: 0.127078\n","Epoch:  1841 | train loss: 0.143159 | valid loss: 0.126985\n","Epoch:  1842 | train loss: 0.119132 | valid loss: 0.126876\n","Epoch:  1843 | train loss: 0.099233 | valid loss: 0.126855\n","Epoch:  1844 | train loss: 0.141597 | valid loss: 0.126708\n","Epoch:  1845 | train loss: 0.141480 | valid loss: 0.126545\n","Epoch:  1846 | train loss: 0.158920 | valid loss: 0.126708\n","Epoch:  1847 | train loss: 0.155267 | valid loss: 0.126456\n","Epoch:  1848 | train loss: 0.137406 | valid loss: 0.126435\n","Epoch:  1849 | train loss: 0.129192 | valid loss: 0.126324\n","Epoch:  1850 | train loss: 0.098357 | valid loss: 0.126363\n","Epoch:  1851 | train loss: 0.121718 | valid loss: 0.126239\n","Epoch:  1852 | train loss: 0.110899 | valid loss: 0.126098\n","Epoch:  1853 | train loss: 0.122158 | valid loss: 0.126101\n","Epoch:  1854 | train loss: 0.103667 | valid loss: 0.126035\n","Epoch:  1855 | train loss: 0.123003 | valid loss: 0.125897\n","Epoch:  1856 | train loss: 0.140394 | valid loss: 0.125669\n","Epoch:  1857 | train loss: 0.128344 | valid loss: 0.125787\n","Epoch:  1858 | train loss: 0.140031 | valid loss: 0.125718\n","Epoch:  1859 | train loss: 0.122240 | valid loss: 0.125543\n","Epoch:  1860 | train loss: 0.154437 | valid loss: 0.125509\n","Epoch:  1861 | train loss: 0.092180 | valid loss: 0.125612\n","Epoch:  1862 | train loss: 0.099994 | valid loss: 0.125379\n","Epoch:  1863 | train loss: 0.114771 | valid loss: 0.125166\n","Epoch:  1864 | train loss: 0.104247 | valid loss: 0.125058\n","Epoch:  1865 | train loss: 0.136020 | valid loss: 0.125051\n","Epoch:  1866 | train loss: 0.118829 | valid loss: 0.125060\n","Epoch:  1867 | train loss: 0.311369 | valid loss: 0.124804\n","Epoch:  1868 | train loss: 0.120940 | valid loss: 0.124744\n","Epoch:  1869 | train loss: 0.111385 | valid loss: 0.124554\n","Epoch:  1870 | train loss: 0.109441 | valid loss: 0.124466\n","Epoch:  1871 | train loss: 0.135449 | valid loss: 0.124496\n","Epoch:  1872 | train loss: 0.126774 | valid loss: 0.124465\n","Epoch:  1873 | train loss: 0.126011 | valid loss: 0.124485\n","Epoch:  1874 | train loss: 0.134037 | valid loss: 0.124341\n","Epoch:  1875 | train loss: 0.140790 | valid loss: 0.124165\n","Epoch:  1876 | train loss: 0.126344 | valid loss: 0.124153\n","Epoch:  1877 | train loss: 0.116867 | valid loss: 0.124017\n","Epoch:  1878 | train loss: 0.121999 | valid loss: 0.123743\n","Epoch:  1879 | train loss: 0.155453 | valid loss: 0.123978\n","Epoch:  1880 | train loss: 0.149017 | valid loss: 0.123997\n","Epoch:  1881 | train loss: 0.116652 | valid loss: 0.123531\n","Epoch:  1882 | train loss: 0.110649 | valid loss: 0.123535\n","Epoch:  1883 | train loss: 0.088534 | valid loss: 0.123612\n","Epoch:  1884 | train loss: 0.104484 | valid loss: 0.123406\n","Epoch:  1885 | train loss: 0.125351 | valid loss: 0.123325\n","Epoch:  1886 | train loss: 0.131064 | valid loss: 0.123178\n","Epoch:  1887 | train loss: 0.123736 | valid loss: 0.123214\n","Epoch:  1888 | train loss: 0.120298 | valid loss: 0.123184\n","Epoch:  1889 | train loss: 0.116901 | valid loss: 0.123065\n","Epoch:  1890 | train loss: 0.107596 | valid loss: 0.122891\n","Epoch:  1891 | train loss: 0.089797 | valid loss: 0.122872\n","Epoch:  1892 | train loss: 0.122403 | valid loss: 0.122743\n","Epoch:  1893 | train loss: 0.129700 | valid loss: 0.122743\n","Epoch:  1894 | train loss: 0.109885 | valid loss: 0.122746\n","Epoch:  1895 | train loss: 0.111423 | valid loss: 0.122543\n","Epoch:  1896 | train loss: 0.116591 | valid loss: 0.122459\n","Epoch:  1897 | train loss: 0.130742 | valid loss: 0.122235\n","Epoch:  1898 | train loss: 0.106766 | valid loss: 0.122284\n","Epoch:  1899 | train loss: 0.104856 | valid loss: 0.122278\n","Epoch:  1900 | train loss: 0.136342 | valid loss: 0.122136\n","Epoch:  1901 | train loss: 0.101267 | valid loss: 0.122025\n","Epoch:  1902 | train loss: 0.134530 | valid loss: 0.122084\n","Epoch:  1903 | train loss: 0.138645 | valid loss: 0.121879\n","Epoch:  1904 | train loss: 0.108894 | valid loss: 0.121834\n","Epoch:  1905 | train loss: 0.109429 | valid loss: 0.121707\n","Epoch:  1906 | train loss: 0.123846 | valid loss: 0.121587\n","Epoch:  1907 | train loss: 0.108358 | valid loss: 0.121602\n","Epoch:  1908 | train loss: 0.102779 | valid loss: 0.121577\n","Epoch:  1909 | train loss: 0.103592 | valid loss: 0.121363\n","Epoch:  1910 | train loss: 0.103970 | valid loss: 0.121433\n","Epoch:  1911 | train loss: 0.134623 | valid loss: 0.121245\n","Epoch:  1912 | train loss: 0.121024 | valid loss: 0.121202\n","Epoch:  1913 | train loss: 0.121924 | valid loss: 0.121192\n","Epoch:  1914 | train loss: 0.113098 | valid loss: 0.121027\n","Epoch:  1915 | train loss: 0.118661 | valid loss: 0.120958\n","Epoch:  1916 | train loss: 0.096643 | valid loss: 0.121119\n","Epoch:  1917 | train loss: 0.133624 | valid loss: 0.121054\n","Epoch:  1918 | train loss: 0.114581 | valid loss: 0.120760\n","Epoch:  1919 | train loss: 0.115871 | valid loss: 0.120730\n","Epoch:  1920 | train loss: 0.100792 | valid loss: 0.120848\n","Epoch:  1921 | train loss: 0.121470 | valid loss: 0.120495\n","Epoch:  1922 | train loss: 0.114381 | valid loss: 0.120413\n","Epoch:  1923 | train loss: 0.144923 | valid loss: 0.120367\n","Epoch:  1924 | train loss: 0.138326 | valid loss: 0.120232\n","Epoch:  1925 | train loss: 0.119197 | valid loss: 0.120246\n","Epoch:  1926 | train loss: 0.146465 | valid loss: 0.120164\n","Epoch:  1927 | train loss: 0.111375 | valid loss: 0.120187\n","Epoch:  1928 | train loss: 0.129701 | valid loss: 0.120103\n","Epoch:  1929 | train loss: 0.105388 | valid loss: 0.119940\n","Epoch:  1930 | train loss: 0.125094 | valid loss: 0.119801\n","Epoch:  1931 | train loss: 0.126723 | valid loss: 0.119773\n","Epoch:  1932 | train loss: 0.099701 | valid loss: 0.119710\n","Epoch:  1933 | train loss: 0.134630 | valid loss: 0.119755\n","Epoch:  1934 | train loss: 0.117312 | valid loss: 0.119678\n","Epoch:  1935 | train loss: 0.106724 | valid loss: 0.119680\n","Epoch:  1936 | train loss: 0.110147 | valid loss: 0.119601\n","Epoch:  1937 | train loss: 0.123825 | valid loss: 0.119331\n","Epoch:  1938 | train loss: 0.140736 | valid loss: 0.119496\n","Epoch:  1939 | train loss: 0.105309 | valid loss: 0.119390\n","Epoch:  1940 | train loss: 0.133561 | valid loss: 0.119215\n","Epoch:  1941 | train loss: 0.107918 | valid loss: 0.119216\n","Epoch:  1942 | train loss: 0.117579 | valid loss: 0.119134\n","Epoch:  1943 | train loss: 0.148713 | valid loss: 0.118937\n","Epoch:  1944 | train loss: 0.119935 | valid loss: 0.118930\n","Epoch:  1945 | train loss: 0.122966 | valid loss: 0.118841\n","Epoch:  1946 | train loss: 0.122620 | valid loss: 0.118875\n","Epoch:  1947 | train loss: 0.114582 | valid loss: 0.118708\n","Epoch:  1948 | train loss: 0.095641 | valid loss: 0.118653\n","Epoch:  1949 | train loss: 0.106912 | valid loss: 0.118535\n","Epoch:  1950 | train loss: 0.106638 | valid loss: 0.118386\n","Epoch:  1951 | train loss: 0.110478 | valid loss: 0.118519\n","Epoch:  1952 | train loss: 0.122469 | valid loss: 0.118361\n","Epoch:  1953 | train loss: 0.114016 | valid loss: 0.118261\n","Epoch:  1954 | train loss: 0.110713 | valid loss: 0.118023\n","Epoch:  1955 | train loss: 0.100662 | valid loss: 0.118070\n","Epoch:  1956 | train loss: 0.119928 | valid loss: 0.117988\n","Epoch:  1957 | train loss: 0.138763 | valid loss: 0.117871\n","Epoch:  1958 | train loss: 0.110070 | valid loss: 0.117784\n","Epoch:  1959 | train loss: 0.121544 | valid loss: 0.117873\n","Epoch:  1960 | train loss: 0.114123 | valid loss: 0.117717\n","Epoch:  1961 | train loss: 0.102750 | valid loss: 0.117630\n","Epoch:  1962 | train loss: 0.125509 | valid loss: 0.117635\n","Epoch:  1963 | train loss: 0.103238 | valid loss: 0.117611\n","Epoch:  1964 | train loss: 0.137436 | valid loss: 0.117317\n","Epoch:  1965 | train loss: 0.124582 | valid loss: 0.117416\n","Epoch:  1966 | train loss: 0.099678 | valid loss: 0.117362\n","Epoch:  1967 | train loss: 0.112471 | valid loss: 0.117239\n","Epoch:  1968 | train loss: 0.107882 | valid loss: 0.117280\n","Epoch:  1969 | train loss: 0.121600 | valid loss: 0.117080\n","Epoch:  1970 | train loss: 0.125327 | valid loss: 0.116956\n","Epoch:  1971 | train loss: 0.109017 | valid loss: 0.117056\n","Epoch:  1972 | train loss: 0.112578 | valid loss: 0.116739\n","Epoch:  1973 | train loss: 0.113049 | valid loss: 0.116869\n","Epoch:  1974 | train loss: 0.117552 | valid loss: 0.116848\n","Epoch:  1975 | train loss: 0.114674 | valid loss: 0.116855\n","Epoch:  1976 | train loss: 0.119051 | valid loss: 0.116607\n","Epoch:  1977 | train loss: 0.108261 | valid loss: 0.116480\n","Epoch:  1978 | train loss: 0.121036 | valid loss: 0.116523\n","Epoch:  1979 | train loss: 0.123090 | valid loss: 0.116534\n","Epoch:  1980 | train loss: 0.093526 | valid loss: 0.116306\n","Epoch:  1981 | train loss: 0.125857 | valid loss: 0.116239\n","Epoch:  1982 | train loss: 0.101473 | valid loss: 0.116240\n","Epoch:  1983 | train loss: 0.119045 | valid loss: 0.116255\n","Epoch:  1984 | train loss: 0.118300 | valid loss: 0.116045\n","Epoch:  1985 | train loss: 0.102451 | valid loss: 0.116019\n","Epoch:  1986 | train loss: 0.123248 | valid loss: 0.116041\n","Epoch:  1987 | train loss: 0.114219 | valid loss: 0.115980\n","Epoch:  1988 | train loss: 0.126150 | valid loss: 0.115924\n","Epoch:  1989 | train loss: 0.117346 | valid loss: 0.115851\n","Epoch:  1990 | train loss: 0.099031 | valid loss: 0.115824\n","Epoch:  1991 | train loss: 0.135472 | valid loss: 0.115670\n","Epoch:  1992 | train loss: 0.120225 | valid loss: 0.115748\n","Epoch:  1993 | train loss: 0.101448 | valid loss: 0.115618\n","Epoch:  1994 | train loss: 0.119580 | valid loss: 0.115497\n","Epoch:  1995 | train loss: 0.100468 | valid loss: 0.115443\n","Epoch:  1996 | train loss: 0.092829 | valid loss: 0.115332\n","Epoch:  1997 | train loss: 0.127346 | valid loss: 0.115242\n","Epoch:  1998 | train loss: 0.103882 | valid loss: 0.115193\n","Epoch:  1999 | train loss: 0.109646 | valid loss: 0.115304\n","Epoch:  2000 | train loss: 0.114415 | valid loss: 0.115197\n","Epoch:  2001 | train loss: 0.098970 | valid loss: 0.115123\n","Epoch:  2002 | train loss: 0.102507 | valid loss: 0.114953\n","Epoch:  2003 | train loss: 0.129233 | valid loss: 0.114880\n","Epoch:  2004 | train loss: 0.135096 | valid loss: 0.114848\n","Epoch:  2005 | train loss: 0.106869 | valid loss: 0.114955\n","Epoch:  2006 | train loss: 0.108086 | valid loss: 0.114741\n","Epoch:  2007 | train loss: 0.118881 | valid loss: 0.114765\n","Epoch:  2008 | train loss: 0.131407 | valid loss: 0.114612\n","Epoch:  2009 | train loss: 0.109948 | valid loss: 0.114568\n","Epoch:  2010 | train loss: 0.113819 | valid loss: 0.114346\n","Epoch:  2011 | train loss: 0.110289 | valid loss: 0.114301\n","Epoch:  2012 | train loss: 0.114093 | valid loss: 0.114169\n","Epoch:  2013 | train loss: 0.112624 | valid loss: 0.114301\n","Epoch:  2014 | train loss: 0.113728 | valid loss: 0.114149\n","Epoch:  2015 | train loss: 0.118716 | valid loss: 0.114085\n","Epoch:  2016 | train loss: 0.099043 | valid loss: 0.114103\n","Epoch:  2017 | train loss: 0.113243 | valid loss: 0.114041\n","Epoch:  2018 | train loss: 0.103521 | valid loss: 0.114023\n","Epoch:  2019 | train loss: 0.107355 | valid loss: 0.114039\n","Epoch:  2020 | train loss: 0.118785 | valid loss: 0.114012\n","Epoch:  2021 | train loss: 0.282914 | valid loss: 0.113714\n","Epoch:  2022 | train loss: 0.114303 | valid loss: 0.113734\n","Epoch:  2023 | train loss: 0.128268 | valid loss: 0.113644\n","Epoch:  2024 | train loss: 0.091286 | valid loss: 0.113626\n","Epoch:  2025 | train loss: 0.116380 | valid loss: 0.113565\n","Epoch:  2026 | train loss: 0.114773 | valid loss: 0.113472\n","Epoch:  2027 | train loss: 0.107489 | valid loss: 0.113642\n","Epoch:  2028 | train loss: 0.115237 | valid loss: 0.113401\n","Epoch:  2029 | train loss: 0.122577 | valid loss: 0.113261\n","Epoch:  2030 | train loss: 0.122425 | valid loss: 0.113262\n","Epoch:  2031 | train loss: 0.083219 | valid loss: 0.113190\n","Epoch:  2032 | train loss: 0.130389 | valid loss: 0.113082\n","Epoch:  2033 | train loss: 0.098387 | valid loss: 0.113000\n","Epoch:  2034 | train loss: 0.143560 | valid loss: 0.113027\n","Epoch:  2035 | train loss: 0.103056 | valid loss: 0.112944\n","Epoch:  2036 | train loss: 0.099944 | valid loss: 0.112923\n","Epoch:  2037 | train loss: 0.107060 | valid loss: 0.112850\n","Epoch:  2038 | train loss: 0.101499 | valid loss: 0.112700\n","Epoch:  2039 | train loss: 0.122512 | valid loss: 0.113086\n","Epoch:  2040 | train loss: 0.110288 | valid loss: 0.112626\n","Epoch:  2041 | train loss: 0.121400 | valid loss: 0.112522\n","Epoch:  2042 | train loss: 0.102534 | valid loss: 0.112519\n","Epoch:  2043 | train loss: 0.096670 | valid loss: 0.112472\n","Epoch:  2044 | train loss: 0.102268 | valid loss: 0.112393\n","Epoch:  2045 | train loss: 0.107917 | valid loss: 0.112409\n","Epoch:  2046 | train loss: 0.112202 | valid loss: 0.112502\n","Epoch:  2047 | train loss: 0.127867 | valid loss: 0.112231\n","Epoch:  2048 | train loss: 0.105825 | valid loss: 0.112226\n","Epoch:  2049 | train loss: 0.104698 | valid loss: 0.112018\n","Epoch:  2050 | train loss: 0.100782 | valid loss: 0.112061\n","Epoch:  2051 | train loss: 0.106762 | valid loss: 0.112125\n","Epoch:  2052 | train loss: 0.137160 | valid loss: 0.112124\n","Epoch:  2053 | train loss: 0.098844 | valid loss: 0.112037\n","Epoch:  2054 | train loss: 0.108007 | valid loss: 0.111832\n","Epoch:  2055 | train loss: 0.122216 | valid loss: 0.111673\n","Epoch:  2056 | train loss: 0.110393 | valid loss: 0.111798\n","Epoch:  2057 | train loss: 0.111894 | valid loss: 0.111649\n","Epoch:  2058 | train loss: 0.111523 | valid loss: 0.111717\n","Epoch:  2059 | train loss: 0.117751 | valid loss: 0.111577\n","Epoch:  2060 | train loss: 0.089065 | valid loss: 0.111456\n","Epoch:  2061 | train loss: 0.112996 | valid loss: 0.111330\n","Epoch:  2062 | train loss: 0.112271 | valid loss: 0.111395\n","Epoch:  2063 | train loss: 0.108662 | valid loss: 0.111343\n","Epoch:  2064 | train loss: 0.119761 | valid loss: 0.111148\n","Epoch:  2065 | train loss: 0.120718 | valid loss: 0.111316\n","Epoch:  2066 | train loss: 0.114325 | valid loss: 0.111162\n","Epoch:  2067 | train loss: 0.094972 | valid loss: 0.111134\n","Epoch:  2068 | train loss: 0.135964 | valid loss: 0.111040\n","Epoch:  2069 | train loss: 0.118356 | valid loss: 0.110958\n","Epoch:  2070 | train loss: 0.109880 | valid loss: 0.111005\n","Epoch:  2071 | train loss: 0.098382 | valid loss: 0.111031\n","Epoch:  2072 | train loss: 0.104423 | valid loss: 0.110851\n","Epoch:  2073 | train loss: 0.102663 | valid loss: 0.110886\n","Epoch:  2074 | train loss: 0.265915 | valid loss: 0.110550\n","Epoch:  2075 | train loss: 0.117149 | valid loss: 0.110644\n","Epoch:  2076 | train loss: 0.113889 | valid loss: 0.110776\n","Epoch:  2077 | train loss: 0.119277 | valid loss: 0.110645\n","Epoch:  2078 | train loss: 0.113044 | valid loss: 0.110445\n","Epoch:  2079 | train loss: 0.121728 | valid loss: 0.110453\n","Epoch:  2080 | train loss: 0.122908 | valid loss: 0.110393\n","Epoch:  2081 | train loss: 0.127898 | valid loss: 0.110437\n","Epoch:  2082 | train loss: 0.123467 | valid loss: 0.110295\n","Epoch:  2083 | train loss: 0.115386 | valid loss: 0.110191\n","Epoch:  2084 | train loss: 0.096487 | valid loss: 0.110403\n","Epoch:  2085 | train loss: 0.107400 | valid loss: 0.110100\n","Epoch:  2086 | train loss: 0.099817 | valid loss: 0.110182\n","Epoch:  2087 | train loss: 0.104694 | valid loss: 0.110154\n","Epoch:  2088 | train loss: 0.136653 | valid loss: 0.110015\n","Epoch:  2089 | train loss: 0.110805 | valid loss: 0.109954\n","Epoch:  2090 | train loss: 0.096792 | valid loss: 0.109892\n","Epoch:  2091 | train loss: 0.089777 | valid loss: 0.109832\n","Epoch:  2092 | train loss: 0.116629 | valid loss: 0.109840\n","Epoch:  2093 | train loss: 0.121268 | valid loss: 0.109545\n","Epoch:  2094 | train loss: 0.118519 | valid loss: 0.109610\n","Epoch:  2095 | train loss: 0.133608 | valid loss: 0.109564\n","Epoch:  2096 | train loss: 0.112282 | valid loss: 0.109574\n","Epoch:  2097 | train loss: 0.097245 | valid loss: 0.109516\n","Epoch:  2098 | train loss: 0.090413 | valid loss: 0.109449\n","Epoch:  2099 | train loss: 0.124255 | valid loss: 0.109489\n","Epoch:  2100 | train loss: 0.106913 | valid loss: 0.109371\n","Epoch:  2101 | train loss: 0.128979 | valid loss: 0.109194\n","Epoch:  2102 | train loss: 0.115727 | valid loss: 0.108993\n","Epoch:  2103 | train loss: 0.117897 | valid loss: 0.109262\n","Epoch:  2104 | train loss: 0.111750 | valid loss: 0.109116\n","Epoch:  2105 | train loss: 0.112650 | valid loss: 0.109007\n","Epoch:  2106 | train loss: 0.120018 | valid loss: 0.108959\n","Epoch:  2107 | train loss: 0.140485 | valid loss: 0.109048\n","Epoch:  2108 | train loss: 0.101356 | valid loss: 0.108776\n","Epoch:  2109 | train loss: 0.120724 | valid loss: 0.108842\n","Epoch:  2110 | train loss: 0.084378 | valid loss: 0.108786\n","Epoch:  2111 | train loss: 0.110397 | valid loss: 0.108754\n","Epoch:  2112 | train loss: 0.099243 | valid loss: 0.108607\n","Epoch:  2113 | train loss: 0.090649 | valid loss: 0.108626\n","Epoch:  2114 | train loss: 0.149918 | valid loss: 0.108547\n","Epoch:  2115 | train loss: 0.111394 | valid loss: 0.108505\n","Epoch:  2116 | train loss: 0.125966 | valid loss: 0.108511\n","Epoch:  2117 | train loss: 0.092652 | valid loss: 0.108316\n","Epoch:  2118 | train loss: 0.105840 | valid loss: 0.108264\n","Epoch:  2119 | train loss: 0.111907 | valid loss: 0.108305\n","Epoch:  2120 | train loss: 0.125855 | valid loss: 0.108245\n","Epoch:  2121 | train loss: 0.101439 | valid loss: 0.108174\n","Epoch:  2122 | train loss: 0.100361 | valid loss: 0.108198\n","Epoch:  2123 | train loss: 0.127988 | valid loss: 0.108205\n","Epoch:  2124 | train loss: 0.105300 | valid loss: 0.108029\n","Epoch:  2125 | train loss: 0.103904 | valid loss: 0.108039\n","Epoch:  2126 | train loss: 0.101357 | valid loss: 0.107904\n","Epoch:  2127 | train loss: 0.108826 | valid loss: 0.107953\n","Epoch:  2128 | train loss: 0.108269 | valid loss: 0.107977\n","Epoch:  2129 | train loss: 0.088940 | valid loss: 0.107710\n","Epoch:  2130 | train loss: 0.089596 | valid loss: 0.107662\n","Epoch:  2131 | train loss: 0.112053 | valid loss: 0.107768\n","Epoch:  2132 | train loss: 0.111013 | valid loss: 0.107689\n","Epoch:  2133 | train loss: 0.125378 | valid loss: 0.107517\n","Epoch:  2134 | train loss: 0.098735 | valid loss: 0.107521\n","Epoch:  2135 | train loss: 0.093099 | valid loss: 0.107460\n","Epoch:  2136 | train loss: 0.096594 | valid loss: 0.107539\n","Epoch:  2137 | train loss: 0.097304 | valid loss: 0.107450\n","Epoch:  2138 | train loss: 0.097572 | valid loss: 0.107234\n","Epoch:  2139 | train loss: 0.107178 | valid loss: 0.107325\n","Epoch:  2140 | train loss: 0.097923 | valid loss: 0.107377\n","Epoch:  2141 | train loss: 0.100186 | valid loss: 0.107154\n","Epoch:  2142 | train loss: 0.099297 | valid loss: 0.107059\n","Epoch:  2143 | train loss: 0.106487 | valid loss: 0.107003\n","Epoch:  2144 | train loss: 0.118026 | valid loss: 0.107055\n","Epoch:  2145 | train loss: 0.119164 | valid loss: 0.106943\n","Epoch:  2146 | train loss: 0.096209 | valid loss: 0.106961\n","Epoch:  2147 | train loss: 0.093481 | valid loss: 0.106774\n","Epoch:  2148 | train loss: 0.111265 | valid loss: 0.106796\n","Epoch:  2149 | train loss: 0.081344 | valid loss: 0.106709\n","Epoch:  2150 | train loss: 0.111897 | valid loss: 0.106562\n","Epoch:  2151 | train loss: 0.113053 | valid loss: 0.106713\n","Epoch:  2152 | train loss: 0.108947 | valid loss: 0.106754\n","Epoch:  2153 | train loss: 0.103617 | valid loss: 0.106714\n","Epoch:  2154 | train loss: 0.096068 | valid loss: 0.106444\n","Epoch:  2155 | train loss: 0.129449 | valid loss: 0.106568\n","Epoch:  2156 | train loss: 0.088998 | valid loss: 0.106324\n","Epoch:  2157 | train loss: 0.088668 | valid loss: 0.106476\n","Epoch:  2158 | train loss: 0.094886 | valid loss: 0.106315\n","Epoch:  2159 | train loss: 0.117438 | valid loss: 0.106306\n","Epoch:  2160 | train loss: 0.099165 | valid loss: 0.106381\n","Epoch:  2161 | train loss: 0.101368 | valid loss: 0.106262\n","Epoch:  2162 | train loss: 0.127551 | valid loss: 0.106171\n","Epoch:  2163 | train loss: 0.116383 | valid loss: 0.106118\n","Epoch:  2164 | train loss: 0.095853 | valid loss: 0.106154\n","Epoch:  2165 | train loss: 0.094055 | valid loss: 0.106125\n","Epoch:  2166 | train loss: 0.092858 | valid loss: 0.105876\n","Epoch:  2167 | train loss: 0.111345 | valid loss: 0.105896\n","Epoch:  2168 | train loss: 0.118977 | valid loss: 0.105848\n","Epoch:  2169 | train loss: 0.118919 | valid loss: 0.105852\n","Epoch:  2170 | train loss: 0.114940 | valid loss: 0.105747\n","Epoch:  2171 | train loss: 0.089041 | valid loss: 0.105579\n","Epoch:  2172 | train loss: 0.090518 | valid loss: 0.105600\n","Epoch:  2173 | train loss: 0.105530 | valid loss: 0.105541\n","Epoch:  2174 | train loss: 0.118773 | valid loss: 0.105763\n","Epoch:  2175 | train loss: 0.102592 | valid loss: 0.105498\n","Epoch:  2176 | train loss: 0.095009 | valid loss: 0.105564\n","Epoch:  2177 | train loss: 0.113892 | valid loss: 0.105488\n","Epoch:  2178 | train loss: 0.121728 | valid loss: 0.105244\n","Epoch:  2179 | train loss: 0.114956 | valid loss: 0.105284\n","Epoch:  2180 | train loss: 0.117407 | valid loss: 0.105438\n","Epoch:  2181 | train loss: 0.121586 | valid loss: 0.105257\n","Epoch:  2182 | train loss: 0.093800 | valid loss: 0.105244\n","Epoch:  2183 | train loss: 0.109217 | valid loss: 0.105109\n","Epoch:  2184 | train loss: 0.095362 | valid loss: 0.105230\n","Epoch:  2185 | train loss: 0.107781 | valid loss: 0.105060\n","Epoch:  2186 | train loss: 0.113930 | valid loss: 0.104987\n","Epoch:  2187 | train loss: 0.103898 | valid loss: 0.104973\n","Epoch:  2188 | train loss: 0.130401 | valid loss: 0.104890\n","Epoch:  2189 | train loss: 0.116281 | valid loss: 0.104784\n","Epoch:  2190 | train loss: 0.101683 | valid loss: 0.104812\n","Epoch:  2191 | train loss: 0.098622 | valid loss: 0.104807\n","Epoch:  2192 | train loss: 0.104570 | valid loss: 0.104757\n","Epoch:  2193 | train loss: 0.095706 | valid loss: 0.104676\n","Epoch:  2194 | train loss: 0.126201 | valid loss: 0.104727\n","Epoch:  2195 | train loss: 0.101725 | valid loss: 0.104535\n","Epoch:  2196 | train loss: 0.121639 | valid loss: 0.104503\n","Epoch:  2197 | train loss: 0.092693 | valid loss: 0.104555\n","Epoch:  2198 | train loss: 0.113305 | valid loss: 0.104392\n","Epoch:  2199 | train loss: 0.088771 | valid loss: 0.104385\n","Epoch:  2200 | train loss: 0.080731 | valid loss: 0.104415\n","Epoch:  2201 | train loss: 0.121700 | valid loss: 0.104478\n","Epoch:  2202 | train loss: 0.111693 | valid loss: 0.104257\n","Epoch:  2203 | train loss: 0.095728 | valid loss: 0.104197\n","Epoch:  2204 | train loss: 0.077789 | valid loss: 0.104224\n","Epoch:  2205 | train loss: 0.116645 | valid loss: 0.104284\n","Epoch:  2206 | train loss: 0.099358 | valid loss: 0.104333\n","Epoch:  2207 | train loss: 0.092942 | valid loss: 0.103985\n","Epoch:  2208 | train loss: 0.090534 | valid loss: 0.104027\n","Epoch:  2209 | train loss: 0.097419 | valid loss: 0.103904\n","Epoch:  2210 | train loss: 0.115579 | valid loss: 0.104047\n","Epoch:  2211 | train loss: 0.098483 | valid loss: 0.103914\n","Epoch:  2212 | train loss: 0.121473 | valid loss: 0.103904\n","Epoch:  2213 | train loss: 0.120109 | valid loss: 0.103824\n","Epoch:  2214 | train loss: 0.303612 | valid loss: 0.103834\n","Epoch:  2215 | train loss: 0.116246 | valid loss: 0.103809\n","Epoch:  2216 | train loss: 0.090302 | valid loss: 0.103659\n","Epoch:  2217 | train loss: 0.108710 | valid loss: 0.103756\n","Epoch:  2218 | train loss: 0.106820 | valid loss: 0.103665\n","Epoch:  2219 | train loss: 0.082867 | valid loss: 0.103596\n","Epoch:  2220 | train loss: 0.128349 | valid loss: 0.103500\n","Epoch:  2221 | train loss: 0.111652 | valid loss: 0.103495\n","Epoch:  2222 | train loss: 0.086741 | valid loss: 0.103384\n","Epoch:  2223 | train loss: 0.114094 | valid loss: 0.103619\n","Epoch:  2224 | train loss: 0.085300 | valid loss: 0.103348\n","Epoch:  2225 | train loss: 0.091358 | valid loss: 0.103285\n","Epoch:  2226 | train loss: 0.083351 | valid loss: 0.103295\n","Epoch:  2227 | train loss: 0.124524 | valid loss: 0.103448\n","Epoch:  2228 | train loss: 0.112523 | valid loss: 0.103210\n","Epoch:  2229 | train loss: 0.104311 | valid loss: 0.103008\n","Epoch:  2230 | train loss: 0.104664 | valid loss: 0.102996\n","Epoch:  2231 | train loss: 0.112169 | valid loss: 0.102997\n","Epoch:  2232 | train loss: 0.130555 | valid loss: 0.103120\n","Epoch:  2233 | train loss: 0.113192 | valid loss: 0.102894\n","Epoch:  2234 | train loss: 0.121218 | valid loss: 0.102798\n","Epoch:  2235 | train loss: 0.110386 | valid loss: 0.102794\n","Epoch:  2236 | train loss: 0.104885 | valid loss: 0.102858\n","Epoch:  2237 | train loss: 0.115222 | valid loss: 0.102765\n","Epoch:  2238 | train loss: 0.091079 | valid loss: 0.102819\n","Epoch:  2239 | train loss: 0.097844 | valid loss: 0.102682\n","Epoch:  2240 | train loss: 0.128091 | valid loss: 0.102606\n","Epoch:  2241 | train loss: 0.109584 | valid loss: 0.102668\n","Epoch:  2242 | train loss: 0.091404 | valid loss: 0.102688\n","Epoch:  2243 | train loss: 0.130894 | valid loss: 0.102506\n","Epoch:  2244 | train loss: 0.139567 | valid loss: 0.102532\n","Epoch:  2245 | train loss: 0.094535 | valid loss: 0.102411\n","Epoch:  2246 | train loss: 0.108831 | valid loss: 0.102415\n","Epoch:  2247 | train loss: 0.113672 | valid loss: 0.102444\n","Epoch:  2248 | train loss: 0.130822 | valid loss: 0.102365\n","Epoch:  2249 | train loss: 0.096358 | valid loss: 0.102393\n","Epoch:  2250 | train loss: 0.124282 | valid loss: 0.102299\n","Epoch:  2251 | train loss: 0.083347 | valid loss: 0.102194\n","Epoch:  2252 | train loss: 0.096981 | valid loss: 0.102135\n","Epoch:  2253 | train loss: 0.090591 | valid loss: 0.102144\n","Epoch:  2254 | train loss: 0.095640 | valid loss: 0.101993\n","Epoch:  2255 | train loss: 0.095441 | valid loss: 0.102285\n","Epoch:  2256 | train loss: 0.099283 | valid loss: 0.101993\n","Epoch:  2257 | train loss: 0.097288 | valid loss: 0.102026\n","Epoch:  2258 | train loss: 0.112105 | valid loss: 0.101984\n","Epoch:  2259 | train loss: 0.125151 | valid loss: 0.102033\n","Epoch:  2260 | train loss: 0.110428 | valid loss: 0.101923\n","Epoch:  2261 | train loss: 0.097639 | valid loss: 0.101800\n","Epoch:  2262 | train loss: 0.084050 | valid loss: 0.101983\n","Epoch:  2263 | train loss: 0.089764 | valid loss: 0.101901\n","Epoch:  2264 | train loss: 0.112285 | valid loss: 0.101769\n","Epoch:  2265 | train loss: 0.091451 | valid loss: 0.101748\n","Epoch:  2266 | train loss: 0.093359 | valid loss: 0.101654\n","Epoch:  2267 | train loss: 0.098466 | valid loss: 0.101674\n","Epoch:  2268 | train loss: 0.113617 | valid loss: 0.101591\n","Epoch:  2269 | train loss: 0.115666 | valid loss: 0.101454\n","Epoch:  2270 | train loss: 0.135439 | valid loss: 0.101608\n","Epoch:  2271 | train loss: 0.072158 | valid loss: 0.101515\n","Epoch:  2272 | train loss: 0.086975 | valid loss: 0.101461\n","Epoch:  2273 | train loss: 0.095628 | valid loss: 0.101358\n","Epoch:  2274 | train loss: 0.099980 | valid loss: 0.101234\n","Epoch:  2275 | train loss: 0.087606 | valid loss: 0.101321\n","Epoch:  2276 | train loss: 0.104005 | valid loss: 0.101232\n","Epoch:  2277 | train loss: 0.091117 | valid loss: 0.101222\n","Epoch:  2278 | train loss: 0.095025 | valid loss: 0.101252\n","Epoch:  2279 | train loss: 0.107439 | valid loss: 0.101192\n","Epoch:  2280 | train loss: 0.102000 | valid loss: 0.101149\n","Epoch:  2281 | train loss: 0.098422 | valid loss: 0.100996\n","Epoch:  2282 | train loss: 0.126228 | valid loss: 0.101164\n","Epoch:  2283 | train loss: 0.128163 | valid loss: 0.101024\n","Epoch:  2284 | train loss: 0.105917 | valid loss: 0.100971\n","Epoch:  2285 | train loss: 0.102203 | valid loss: 0.100932\n","Epoch:  2286 | train loss: 0.087392 | valid loss: 0.100956\n","Epoch:  2287 | train loss: 0.285218 | valid loss: 0.100781\n","Epoch:  2288 | train loss: 0.097639 | valid loss: 0.100707\n","Epoch:  2289 | train loss: 0.090990 | valid loss: 0.100637\n","Epoch:  2290 | train loss: 0.113099 | valid loss: 0.100716\n","Epoch:  2291 | train loss: 0.103550 | valid loss: 0.100670\n","Epoch:  2292 | train loss: 0.087032 | valid loss: 0.100693\n","Epoch:  2293 | train loss: 0.095864 | valid loss: 0.100570\n","Epoch:  2294 | train loss: 0.114071 | valid loss: 0.100634\n","Epoch:  2295 | train loss: 0.075520 | valid loss: 0.100638\n","Epoch:  2296 | train loss: 0.100475 | valid loss: 0.100536\n","Epoch:  2297 | train loss: 0.109589 | valid loss: 0.100495\n","Epoch:  2298 | train loss: 0.081413 | valid loss: 0.100529\n","Epoch:  2299 | train loss: 0.102215 | valid loss: 0.100352\n","Epoch:  2300 | train loss: 0.092719 | valid loss: 0.100309\n","Epoch:  2301 | train loss: 0.094327 | valid loss: 0.100280\n","Epoch:  2302 | train loss: 0.089926 | valid loss: 0.100185\n","Epoch:  2303 | train loss: 0.097720 | valid loss: 0.100111\n","Epoch:  2304 | train loss: 0.113537 | valid loss: 0.100238\n","Epoch:  2305 | train loss: 0.085901 | valid loss: 0.100074\n","Epoch:  2306 | train loss: 0.096487 | valid loss: 0.100178\n","Epoch:  2307 | train loss: 0.106392 | valid loss: 0.100090\n","Epoch:  2308 | train loss: 0.093676 | valid loss: 0.100167\n","Epoch:  2309 | train loss: 0.097774 | valid loss: 0.100014\n","Epoch:  2310 | train loss: 0.090650 | valid loss: 0.100028\n","Epoch:  2311 | train loss: 0.078546 | valid loss: 0.099997\n","Epoch:  2312 | train loss: 0.096413 | valid loss: 0.100199\n","Epoch:  2313 | train loss: 0.103678 | valid loss: 0.099895\n","Epoch:  2314 | train loss: 0.116040 | valid loss: 0.099827\n","Epoch:  2315 | train loss: 0.101153 | valid loss: 0.099780\n","Epoch:  2316 | train loss: 0.119231 | valid loss: 0.099895\n","Epoch:  2317 | train loss: 0.075415 | valid loss: 0.099640\n","Epoch:  2318 | train loss: 0.113347 | valid loss: 0.099734\n","Epoch:  2319 | train loss: 0.090049 | valid loss: 0.099748\n","Epoch:  2320 | train loss: 0.111234 | valid loss: 0.099639\n","Epoch:  2321 | train loss: 0.084027 | valid loss: 0.099551\n","Epoch:  2322 | train loss: 0.098425 | valid loss: 0.099453\n","Epoch:  2323 | train loss: 0.089896 | valid loss: 0.099585\n","Epoch:  2324 | train loss: 0.115638 | valid loss: 0.099480\n","Epoch:  2325 | train loss: 0.093630 | valid loss: 0.099349\n","Epoch:  2326 | train loss: 0.104784 | valid loss: 0.099431\n","Epoch:  2327 | train loss: 0.083805 | valid loss: 0.099450\n","Epoch:  2328 | train loss: 0.083531 | valid loss: 0.099394\n","Epoch:  2329 | train loss: 0.123247 | valid loss: 0.099327\n","Epoch:  2330 | train loss: 0.110809 | valid loss: 0.099368\n","Epoch:  2331 | train loss: 0.091163 | valid loss: 0.099304\n","Epoch:  2332 | train loss: 0.104638 | valid loss: 0.099207\n","Epoch:  2333 | train loss: 0.096496 | valid loss: 0.099223\n","Epoch:  2334 | train loss: 0.086382 | valid loss: 0.099075\n","Epoch:  2335 | train loss: 0.110707 | valid loss: 0.099130\n","Epoch:  2336 | train loss: 0.108792 | valid loss: 0.099017\n","Epoch:  2337 | train loss: 0.080528 | valid loss: 0.099154\n","Epoch:  2338 | train loss: 0.102209 | valid loss: 0.098919\n","Epoch:  2339 | train loss: 0.092264 | valid loss: 0.099032\n","Epoch:  2340 | train loss: 0.093337 | valid loss: 0.098925\n","Epoch:  2341 | train loss: 0.097303 | valid loss: 0.098796\n","Epoch:  2342 | train loss: 0.110105 | valid loss: 0.098782\n","Epoch:  2343 | train loss: 0.093691 | valid loss: 0.098835\n","Epoch:  2344 | train loss: 0.086430 | valid loss: 0.098838\n","Epoch:  2345 | train loss: 0.131058 | valid loss: 0.098670\n","Epoch:  2346 | train loss: 0.104583 | valid loss: 0.098765\n","Epoch:  2347 | train loss: 0.104004 | valid loss: 0.098757\n","Epoch:  2348 | train loss: 0.100749 | valid loss: 0.098681\n","Epoch:  2349 | train loss: 0.081619 | valid loss: 0.098900\n","Epoch:  2350 | train loss: 0.086200 | valid loss: 0.098620\n","Epoch:  2351 | train loss: 0.094199 | valid loss: 0.098700\n","Epoch:  2352 | train loss: 0.099316 | valid loss: 0.098475\n","Epoch:  2353 | train loss: 0.088564 | valid loss: 0.098499\n","Epoch:  2354 | train loss: 0.092493 | valid loss: 0.098388\n","Epoch:  2355 | train loss: 0.091954 | valid loss: 0.098352\n","Epoch:  2356 | train loss: 0.132128 | valid loss: 0.098455\n","Epoch:  2357 | train loss: 0.083095 | valid loss: 0.098361\n","Epoch:  2358 | train loss: 0.116882 | valid loss: 0.098333\n","Epoch:  2359 | train loss: 0.106610 | valid loss: 0.098382\n","Epoch:  2360 | train loss: 0.098569 | valid loss: 0.098375\n","Epoch:  2361 | train loss: 0.084253 | valid loss: 0.098371\n","Epoch:  2362 | train loss: 0.108690 | valid loss: 0.098273\n","Epoch:  2363 | train loss: 0.251907 | valid loss: 0.098147\n","Epoch:  2364 | train loss: 0.108055 | valid loss: 0.098168\n","Epoch:  2365 | train loss: 0.089522 | valid loss: 0.098139\n","Epoch:  2366 | train loss: 0.090967 | valid loss: 0.098025\n","Epoch:  2367 | train loss: 0.272045 | valid loss: 0.098002\n","Epoch:  2368 | train loss: 0.080016 | valid loss: 0.098111\n","Epoch:  2369 | train loss: 0.099971 | valid loss: 0.098037\n","Epoch:  2370 | train loss: 0.096474 | valid loss: 0.097833\n","Epoch:  2371 | train loss: 0.109387 | valid loss: 0.097870\n","Epoch:  2372 | train loss: 0.104321 | valid loss: 0.097838\n","Epoch:  2373 | train loss: 0.103178 | valid loss: 0.097879\n","Epoch:  2374 | train loss: 0.089584 | valid loss: 0.097891\n","Epoch:  2375 | train loss: 0.080102 | valid loss: 0.097876\n","Epoch:  2376 | train loss: 0.144236 | valid loss: 0.097763\n","Epoch:  2377 | train loss: 0.084529 | valid loss: 0.097812\n","Epoch:  2378 | train loss: 0.101008 | valid loss: 0.097643\n","Epoch:  2379 | train loss: 0.094093 | valid loss: 0.097704\n","Epoch:  2380 | train loss: 0.114195 | valid loss: 0.097658\n","Epoch:  2381 | train loss: 0.083439 | valid loss: 0.097667\n","Epoch:  2382 | train loss: 0.081233 | valid loss: 0.097591\n","Epoch:  2383 | train loss: 0.110640 | valid loss: 0.097595\n","Epoch:  2384 | train loss: 0.098771 | valid loss: 0.097509\n","Epoch:  2385 | train loss: 0.103117 | valid loss: 0.097584\n","Epoch:  2386 | train loss: 0.079017 | valid loss: 0.097520\n","Epoch:  2387 | train loss: 0.077625 | valid loss: 0.097475\n","Epoch:  2388 | train loss: 0.076688 | valid loss: 0.097456\n","Epoch:  2389 | train loss: 0.097484 | valid loss: 0.097403\n","Epoch:  2390 | train loss: 0.078931 | valid loss: 0.097279\n","Epoch:  2391 | train loss: 0.113422 | valid loss: 0.097346\n","Epoch:  2392 | train loss: 0.100751 | valid loss: 0.097316\n","Epoch:  2393 | train loss: 0.079317 | valid loss: 0.097345\n","Epoch:  2394 | train loss: 0.102728 | valid loss: 0.097265\n","Epoch:  2395 | train loss: 0.119013 | valid loss: 0.097185\n","Epoch:  2396 | train loss: 0.100381 | valid loss: 0.097081\n","Epoch:  2397 | train loss: 0.111332 | valid loss: 0.097057\n","Epoch:  2398 | train loss: 0.091846 | valid loss: 0.097202\n","Epoch:  2399 | train loss: 0.122962 | valid loss: 0.097121\n","Epoch:  2400 | train loss: 0.089790 | valid loss: 0.097089\n","Epoch:  2401 | train loss: 0.114535 | valid loss: 0.096973\n","Epoch:  2402 | train loss: 0.074563 | valid loss: 0.097092\n","Epoch:  2403 | train loss: 0.100283 | valid loss: 0.097096\n","Epoch:  2404 | train loss: 0.092066 | valid loss: 0.097084\n","Epoch:  2405 | train loss: 0.090956 | valid loss: 0.096918\n","Epoch:  2406 | train loss: 0.099042 | valid loss: 0.096846\n","Epoch:  2407 | train loss: 0.101596 | valid loss: 0.096879\n","Epoch:  2408 | train loss: 0.120167 | valid loss: 0.097045\n","Epoch:  2409 | train loss: 0.077150 | valid loss: 0.096877\n","Epoch:  2410 | train loss: 0.097799 | valid loss: 0.096649\n","Epoch:  2411 | train loss: 0.081520 | valid loss: 0.096721\n","Epoch:  2412 | train loss: 0.274008 | valid loss: 0.096632\n","Epoch:  2413 | train loss: 0.115045 | valid loss: 0.096779\n","Epoch:  2414 | train loss: 0.119041 | valid loss: 0.096699\n","Epoch:  2415 | train loss: 0.086591 | valid loss: 0.096653\n","Epoch:  2416 | train loss: 0.094575 | valid loss: 0.096582\n","Epoch:  2417 | train loss: 0.095767 | valid loss: 0.096801\n","Epoch:  2418 | train loss: 0.099425 | valid loss: 0.096479\n","Epoch:  2419 | train loss: 0.118948 | valid loss: 0.096626\n","Epoch:  2420 | train loss: 0.095021 | valid loss: 0.096557\n","Epoch:  2421 | train loss: 0.082746 | valid loss: 0.096488\n","Epoch:  2422 | train loss: 0.087885 | valid loss: 0.096414\n","Epoch:  2423 | train loss: 0.085399 | valid loss: 0.096314\n","Epoch:  2424 | train loss: 0.093800 | valid loss: 0.096557\n","Epoch:  2425 | train loss: 0.092815 | valid loss: 0.096426\n","Epoch:  2426 | train loss: 0.097792 | valid loss: 0.096500\n","Epoch:  2427 | train loss: 0.104755 | valid loss: 0.096326\n","Epoch:  2428 | train loss: 0.120431 | valid loss: 0.096331\n","Epoch:  2429 | train loss: 0.098989 | valid loss: 0.096251\n","Epoch:  2430 | train loss: 0.102837 | valid loss: 0.096279\n","Epoch:  2431 | train loss: 0.086625 | valid loss: 0.096225\n","Epoch:  2432 | train loss: 0.087763 | valid loss: 0.096218\n","Epoch:  2433 | train loss: 0.096619 | valid loss: 0.096090\n","Epoch:  2434 | train loss: 0.114754 | valid loss: 0.096054\n","Epoch:  2435 | train loss: 0.080014 | valid loss: 0.096064\n","Epoch:  2436 | train loss: 0.082906 | valid loss: 0.096086\n","Epoch:  2437 | train loss: 0.097319 | valid loss: 0.096032\n","Epoch:  2438 | train loss: 0.105114 | valid loss: 0.096090\n","Epoch:  2439 | train loss: 0.113558 | valid loss: 0.095883\n","Epoch:  2440 | train loss: 0.105360 | valid loss: 0.095955\n","Epoch:  2441 | train loss: 0.097659 | valid loss: 0.095916\n","Epoch:  2442 | train loss: 0.099040 | valid loss: 0.096034\n","Epoch:  2443 | train loss: 0.124082 | valid loss: 0.096000\n","Epoch:  2444 | train loss: 0.115821 | valid loss: 0.095735\n","Epoch:  2445 | train loss: 0.085840 | valid loss: 0.095871\n","Epoch:  2446 | train loss: 0.091239 | valid loss: 0.095679\n","Epoch:  2447 | train loss: 0.080411 | valid loss: 0.095763\n","Epoch:  2448 | train loss: 0.082215 | valid loss: 0.095804\n","Epoch:  2449 | train loss: 0.089499 | valid loss: 0.095735\n","Epoch:  2450 | train loss: 0.088793 | valid loss: 0.095712\n","Epoch:  2451 | train loss: 0.093526 | valid loss: 0.095613\n","Epoch:  2452 | train loss: 0.082417 | valid loss: 0.095668\n","Epoch:  2453 | train loss: 0.079099 | valid loss: 0.095604\n","Epoch:  2454 | train loss: 0.107515 | valid loss: 0.095601\n","Epoch:  2455 | train loss: 0.087655 | valid loss: 0.095545\n","Epoch:  2456 | train loss: 0.087252 | valid loss: 0.095424\n","Epoch:  2457 | train loss: 0.096119 | valid loss: 0.095434\n","Epoch:  2458 | train loss: 0.094751 | valid loss: 0.095564\n","Epoch:  2459 | train loss: 0.100032 | valid loss: 0.095578\n","Epoch:  2460 | train loss: 0.076589 | valid loss: 0.095456\n","Epoch:  2461 | train loss: 0.098947 | valid loss: 0.095351\n","Epoch:  2462 | train loss: 0.105285 | valid loss: 0.095375\n","Epoch:  2463 | train loss: 0.089540 | valid loss: 0.095383\n","Epoch:  2464 | train loss: 0.081899 | valid loss: 0.095274\n","Epoch:  2465 | train loss: 0.093823 | valid loss: 0.095261\n","Epoch:  2466 | train loss: 0.099652 | valid loss: 0.095269\n","Epoch:  2467 | train loss: 0.089725 | valid loss: 0.095259\n","Epoch:  2468 | train loss: 0.082108 | valid loss: 0.095060\n","Epoch:  2469 | train loss: 0.091643 | valid loss: 0.095199\n","Epoch:  2470 | train loss: 0.074650 | valid loss: 0.095204\n","Epoch:  2471 | train loss: 0.104482 | valid loss: 0.095116\n","Epoch:  2472 | train loss: 0.100391 | valid loss: 0.095100\n","Epoch:  2473 | train loss: 0.083420 | valid loss: 0.094969\n","Epoch:  2474 | train loss: 0.079701 | valid loss: 0.095036\n","Epoch:  2475 | train loss: 0.087070 | valid loss: 0.095008\n","Epoch:  2476 | train loss: 0.088436 | valid loss: 0.095004\n","Epoch:  2477 | train loss: 0.092644 | valid loss: 0.094934\n","Epoch:  2478 | train loss: 0.107730 | valid loss: 0.094951\n","Epoch:  2479 | train loss: 0.103104 | valid loss: 0.094844\n","Epoch:  2480 | train loss: 0.122101 | valid loss: 0.094949\n","Epoch:  2481 | train loss: 0.109410 | valid loss: 0.094801\n","Epoch:  2482 | train loss: 0.095655 | valid loss: 0.094775\n","Epoch:  2483 | train loss: 0.115926 | valid loss: 0.094729\n","Epoch:  2484 | train loss: 0.082324 | valid loss: 0.094689\n","Epoch:  2485 | train loss: 0.087606 | valid loss: 0.094734\n","Epoch:  2486 | train loss: 0.114539 | valid loss: 0.094709\n","Epoch:  2487 | train loss: 0.081889 | valid loss: 0.094776\n","Epoch:  2488 | train loss: 0.072816 | valid loss: 0.094578\n","Epoch:  2489 | train loss: 0.097050 | valid loss: 0.094629\n","Epoch:  2490 | train loss: 0.119385 | valid loss: 0.094641\n","Epoch:  2491 | train loss: 0.086335 | valid loss: 0.094508\n","Epoch:  2492 | train loss: 0.097641 | valid loss: 0.094487\n","Epoch:  2493 | train loss: 0.077088 | valid loss: 0.094495\n","Epoch:  2494 | train loss: 0.079287 | valid loss: 0.094519\n","Epoch:  2495 | train loss: 0.109882 | valid loss: 0.094514\n","Epoch:  2496 | train loss: 0.087889 | valid loss: 0.094603\n","Epoch:  2497 | train loss: 0.087260 | valid loss: 0.094437\n","Epoch:  2498 | train loss: 0.103743 | valid loss: 0.094559\n","Epoch:  2499 | train loss: 0.096830 | valid loss: 0.094445\n","Epoch:  2500 | train loss: 0.112042 | valid loss: 0.094430\n","Epoch:  2501 | train loss: 0.096450 | valid loss: 0.094371\n","Epoch:  2502 | train loss: 0.098029 | valid loss: 0.094451\n","Epoch:  2503 | train loss: 0.087344 | valid loss: 0.094374\n","Epoch:  2504 | train loss: 0.101163 | valid loss: 0.094302\n","Epoch:  2505 | train loss: 0.097775 | valid loss: 0.094308\n","Epoch:  2506 | train loss: 0.091853 | valid loss: 0.094216\n","Epoch:  2507 | train loss: 0.099381 | valid loss: 0.094126\n","Epoch:  2508 | train loss: 0.101458 | valid loss: 0.094177\n","Epoch:  2509 | train loss: 0.128876 | valid loss: 0.094173\n","Epoch:  2510 | train loss: 0.095004 | valid loss: 0.094267\n","Epoch:  2511 | train loss: 0.092944 | valid loss: 0.094129\n","Epoch:  2512 | train loss: 0.098566 | valid loss: 0.094111\n","Epoch:  2513 | train loss: 0.085876 | valid loss: 0.093995\n","Epoch:  2514 | train loss: 0.091760 | valid loss: 0.094013\n","Epoch:  2515 | train loss: 0.069973 | valid loss: 0.094053\n","Epoch:  2516 | train loss: 0.086457 | valid loss: 0.094127\n","Epoch:  2517 | train loss: 0.121808 | valid loss: 0.093902\n","Epoch:  2518 | train loss: 0.097176 | valid loss: 0.093905\n","Epoch:  2519 | train loss: 0.106225 | valid loss: 0.093845\n","Epoch:  2520 | train loss: 0.098863 | valid loss: 0.093986\n","Epoch:  2521 | train loss: 0.093965 | valid loss: 0.094008\n","Epoch:  2522 | train loss: 0.111918 | valid loss: 0.093943\n","Epoch:  2523 | train loss: 0.108218 | valid loss: 0.093934\n","Epoch:  2524 | train loss: 0.123165 | valid loss: 0.093707\n","Epoch:  2525 | train loss: 0.086149 | valid loss: 0.093870\n","Epoch:  2526 | train loss: 0.095931 | valid loss: 0.093717\n","Epoch:  2527 | train loss: 0.093429 | valid loss: 0.093690\n","Epoch:  2528 | train loss: 0.093228 | valid loss: 0.093733\n","Epoch:  2529 | train loss: 0.096250 | valid loss: 0.093664\n","Epoch:  2530 | train loss: 0.075232 | valid loss: 0.093737\n","Epoch:  2531 | train loss: 0.105079 | valid loss: 0.093715\n","Epoch:  2532 | train loss: 0.083636 | valid loss: 0.093511\n","Epoch:  2533 | train loss: 0.085659 | valid loss: 0.093548\n","Epoch:  2534 | train loss: 0.095815 | valid loss: 0.093498\n","Epoch:  2535 | train loss: 0.086483 | valid loss: 0.093531\n","Epoch:  2536 | train loss: 0.092306 | valid loss: 0.093427\n","Epoch:  2537 | train loss: 0.097333 | valid loss: 0.093346\n","Epoch:  2538 | train loss: 0.112380 | valid loss: 0.093461\n","Epoch:  2539 | train loss: 0.128536 | valid loss: 0.093348\n","Epoch:  2540 | train loss: 0.094320 | valid loss: 0.093371\n","Epoch:  2541 | train loss: 0.085221 | valid loss: 0.093490\n","Epoch:  2542 | train loss: 0.112082 | valid loss: 0.093491\n","Epoch:  2543 | train loss: 0.083929 | valid loss: 0.093303\n","Epoch:  2544 | train loss: 0.094327 | valid loss: 0.093402\n","Epoch:  2545 | train loss: 0.100909 | valid loss: 0.093317\n","Epoch:  2546 | train loss: 0.103893 | valid loss: 0.093188\n","Epoch:  2547 | train loss: 0.084892 | valid loss: 0.093091\n","Epoch:  2548 | train loss: 0.097320 | valid loss: 0.093197\n","Epoch:  2549 | train loss: 0.108846 | valid loss: 0.093217\n","Epoch:  2550 | train loss: 0.086503 | valid loss: 0.093197\n","Epoch:  2551 | train loss: 0.122146 | valid loss: 0.093149\n","Epoch:  2552 | train loss: 0.097363 | valid loss: 0.093162\n","Epoch:  2553 | train loss: 0.080199 | valid loss: 0.093173\n","Epoch:  2554 | train loss: 0.105759 | valid loss: 0.092968\n","Epoch:  2555 | train loss: 0.093658 | valid loss: 0.092998\n","Epoch:  2556 | train loss: 0.084472 | valid loss: 0.093032\n","Epoch:  2557 | train loss: 0.094238 | valid loss: 0.092946\n","Epoch:  2558 | train loss: 0.085421 | valid loss: 0.093018\n","Epoch:  2559 | train loss: 0.092493 | valid loss: 0.093004\n","Epoch:  2560 | train loss: 0.088693 | valid loss: 0.092940\n","Epoch:  2561 | train loss: 0.105716 | valid loss: 0.093089\n","Epoch:  2562 | train loss: 0.099045 | valid loss: 0.092943\n","Epoch:  2563 | train loss: 0.103129 | valid loss: 0.092923\n","Epoch:  2564 | train loss: 0.088806 | valid loss: 0.092981\n","Epoch:  2565 | train loss: 0.102302 | valid loss: 0.092912\n","Epoch:  2566 | train loss: 0.080304 | valid loss: 0.092912\n","Epoch:  2567 | train loss: 0.079515 | valid loss: 0.092728\n","Epoch:  2568 | train loss: 0.094610 | valid loss: 0.092884\n","Epoch:  2569 | train loss: 0.097322 | valid loss: 0.092827\n","Epoch:  2570 | train loss: 0.115164 | valid loss: 0.092769\n","Epoch:  2571 | train loss: 0.091528 | valid loss: 0.092713\n","Epoch:  2572 | train loss: 0.092814 | valid loss: 0.092736\n","Epoch:  2573 | train loss: 0.083248 | valid loss: 0.092707\n","Epoch:  2574 | train loss: 0.085040 | valid loss: 0.092592\n","Epoch:  2575 | train loss: 0.084466 | valid loss: 0.092683\n","Epoch:  2576 | train loss: 0.088093 | valid loss: 0.092616\n","Epoch:  2577 | train loss: 0.108232 | valid loss: 0.092599\n","Epoch:  2578 | train loss: 0.072718 | valid loss: 0.092549\n","Epoch:  2579 | train loss: 0.111798 | valid loss: 0.092440\n","Epoch:  2580 | train loss: 0.090472 | valid loss: 0.092546\n","Epoch:  2581 | train loss: 0.097278 | valid loss: 0.092539\n","Epoch:  2582 | train loss: 0.104649 | valid loss: 0.092574\n","Epoch:  2583 | train loss: 0.087259 | valid loss: 0.092422\n","Epoch:  2584 | train loss: 0.079664 | valid loss: 0.092433\n","Epoch:  2585 | train loss: 0.107143 | valid loss: 0.092430\n","Epoch:  2586 | train loss: 0.094018 | valid loss: 0.092481\n","Epoch:  2587 | train loss: 0.072422 | valid loss: 0.092365\n","Epoch:  2588 | train loss: 0.133680 | valid loss: 0.092481\n","Epoch:  2589 | train loss: 0.089634 | valid loss: 0.092259\n","Epoch:  2590 | train loss: 0.085524 | valid loss: 0.092287\n","Epoch:  2591 | train loss: 0.097715 | valid loss: 0.092405\n","Epoch:  2592 | train loss: 0.105868 | valid loss: 0.092291\n","Epoch:  2593 | train loss: 0.101678 | valid loss: 0.092405\n","Epoch:  2594 | train loss: 0.114172 | valid loss: 0.092288\n","Epoch:  2595 | train loss: 0.101896 | valid loss: 0.092183\n","Epoch:  2596 | train loss: 0.110937 | valid loss: 0.092245\n","Epoch:  2597 | train loss: 0.072034 | valid loss: 0.092154\n","Epoch:  2598 | train loss: 0.075106 | valid loss: 0.092192\n","Epoch:  2599 | train loss: 0.112187 | valid loss: 0.092157\n","Epoch:  2600 | train loss: 0.267507 | valid loss: 0.092098\n","Epoch:  2601 | train loss: 0.092066 | valid loss: 0.092129\n","Epoch:  2602 | train loss: 0.080140 | valid loss: 0.092189\n","Epoch:  2603 | train loss: 0.101518 | valid loss: 0.092128\n","Epoch:  2604 | train loss: 0.093922 | valid loss: 0.092052\n","Epoch:  2605 | train loss: 0.094794 | valid loss: 0.092031\n","Epoch:  2606 | train loss: 0.075241 | valid loss: 0.092032\n","Epoch:  2607 | train loss: 0.083402 | valid loss: 0.091992\n","Epoch:  2608 | train loss: 0.101023 | valid loss: 0.091901\n","Epoch:  2609 | train loss: 0.081801 | valid loss: 0.092226\n","Epoch:  2610 | train loss: 0.091024 | valid loss: 0.091973\n","Epoch:  2611 | train loss: 0.082916 | valid loss: 0.091949\n","Epoch:  2612 | train loss: 0.097544 | valid loss: 0.092081\n","Epoch:  2613 | train loss: 0.126088 | valid loss: 0.091875\n","Epoch:  2614 | train loss: 0.079777 | valid loss: 0.091859\n","Epoch:  2615 | train loss: 0.107719 | valid loss: 0.091852\n","Epoch:  2616 | train loss: 0.110002 | valid loss: 0.091854\n","Epoch:  2617 | train loss: 0.097717 | valid loss: 0.091785\n","Epoch:  2618 | train loss: 0.109540 | valid loss: 0.091839\n","Epoch:  2619 | train loss: 0.069396 | valid loss: 0.091705\n","Epoch:  2620 | train loss: 0.081142 | valid loss: 0.091742\n","Epoch:  2621 | train loss: 0.093947 | valid loss: 0.091784\n","Epoch:  2622 | train loss: 0.072186 | valid loss: 0.091637\n","Epoch:  2623 | train loss: 0.128646 | valid loss: 0.091731\n","Epoch:  2624 | train loss: 0.081112 | valid loss: 0.091639\n","Epoch:  2625 | train loss: 0.103992 | valid loss: 0.091715\n","Epoch:  2626 | train loss: 0.098475 | valid loss: 0.091706\n","Epoch:  2627 | train loss: 0.081641 | valid loss: 0.091662\n","Epoch:  2628 | train loss: 0.116313 | valid loss: 0.091596\n","Epoch:  2629 | train loss: 0.088873 | valid loss: 0.091583\n","Epoch:  2630 | train loss: 0.097955 | valid loss: 0.091704\n","Epoch:  2631 | train loss: 0.084689 | valid loss: 0.091445\n","Epoch:  2632 | train loss: 0.087982 | valid loss: 0.091644\n","Epoch:  2633 | train loss: 0.109397 | valid loss: 0.091521\n","Epoch:  2634 | train loss: 0.072273 | valid loss: 0.091541\n","Epoch:  2635 | train loss: 0.096848 | valid loss: 0.091437\n","Epoch:  2636 | train loss: 0.122956 | valid loss: 0.091408\n","Epoch:  2637 | train loss: 0.101053 | valid loss: 0.091428\n","Epoch:  2638 | train loss: 0.085345 | valid loss: 0.091500\n","Epoch:  2639 | train loss: 0.082035 | valid loss: 0.091577\n","Epoch:  2640 | train loss: 0.117491 | valid loss: 0.091431\n","Epoch:  2641 | train loss: 0.073472 | valid loss: 0.091373\n","Epoch:  2642 | train loss: 0.105242 | valid loss: 0.091365\n","Epoch:  2643 | train loss: 0.084201 | valid loss: 0.091364\n","Epoch:  2644 | train loss: 0.099520 | valid loss: 0.091386\n","Epoch:  2645 | train loss: 0.108169 | valid loss: 0.091429\n","Epoch:  2646 | train loss: 0.098815 | valid loss: 0.091353\n","Epoch:  2647 | train loss: 0.087024 | valid loss: 0.091248\n","Epoch:  2648 | train loss: 0.085363 | valid loss: 0.091288\n","Epoch:  2649 | train loss: 0.094768 | valid loss: 0.091125\n","Epoch:  2650 | train loss: 0.091741 | valid loss: 0.091282\n","Epoch:  2651 | train loss: 0.115700 | valid loss: 0.091120\n","Epoch:  2652 | train loss: 0.075977 | valid loss: 0.091178\n","Epoch:  2653 | train loss: 0.097361 | valid loss: 0.091202\n","Epoch:  2654 | train loss: 0.084199 | valid loss: 0.091265\n","Epoch:  2655 | train loss: 0.102962 | valid loss: 0.091167\n","Epoch:  2656 | train loss: 0.096588 | valid loss: 0.091053\n","Epoch:  2657 | train loss: 0.092468 | valid loss: 0.091046\n","Epoch:  2658 | train loss: 0.075766 | valid loss: 0.091047\n","Epoch:  2659 | train loss: 0.076872 | valid loss: 0.091010\n","Epoch:  2660 | train loss: 0.095951 | valid loss: 0.091047\n","Epoch:  2661 | train loss: 0.085616 | valid loss: 0.090944\n","Epoch:  2662 | train loss: 0.096427 | valid loss: 0.091080\n","Epoch:  2663 | train loss: 0.104487 | valid loss: 0.090903\n","Epoch:  2664 | train loss: 0.077174 | valid loss: 0.090931\n","Epoch:  2665 | train loss: 0.099778 | valid loss: 0.090909\n","Epoch:  2666 | train loss: 0.088657 | valid loss: 0.090940\n","Epoch:  2667 | train loss: 0.100670 | valid loss: 0.090838\n","Epoch:  2668 | train loss: 0.108550 | valid loss: 0.090833\n","Epoch:  2669 | train loss: 0.097572 | valid loss: 0.090848\n","Epoch:  2670 | train loss: 0.090395 | valid loss: 0.090749\n","Epoch:  2671 | train loss: 0.078592 | valid loss: 0.090800\n","Epoch:  2672 | train loss: 0.090553 | valid loss: 0.090737\n","Epoch:  2673 | train loss: 0.082853 | valid loss: 0.090760\n","Epoch:  2674 | train loss: 0.093257 | valid loss: 0.090817\n","Epoch:  2675 | train loss: 0.071240 | valid loss: 0.090755\n","Epoch:  2676 | train loss: 0.069323 | valid loss: 0.090776\n","Epoch:  2677 | train loss: 0.071994 | valid loss: 0.090718\n","Epoch:  2678 | train loss: 0.103621 | valid loss: 0.090778\n","Epoch:  2679 | train loss: 0.104295 | valid loss: 0.090753\n","Epoch:  2680 | train loss: 0.073429 | valid loss: 0.090621\n","Epoch:  2681 | train loss: 0.074723 | valid loss: 0.090664\n","Epoch:  2682 | train loss: 0.086708 | valid loss: 0.090674\n","Epoch:  2683 | train loss: 0.090496 | valid loss: 0.090659\n","Epoch:  2684 | train loss: 0.110879 | valid loss: 0.090707\n","Epoch:  2685 | train loss: 0.072872 | valid loss: 0.090644\n","Epoch:  2686 | train loss: 0.104153 | valid loss: 0.090556\n","Epoch:  2687 | train loss: 0.087169 | valid loss: 0.090546\n","Epoch:  2688 | train loss: 0.101865 | valid loss: 0.090563\n","Epoch:  2689 | train loss: 0.080253 | valid loss: 0.090561\n","Epoch:  2690 | train loss: 0.076619 | valid loss: 0.090636\n","Epoch:  2691 | train loss: 0.103281 | valid loss: 0.090566\n","Epoch:  2692 | train loss: 0.089407 | valid loss: 0.090577\n","Epoch:  2693 | train loss: 0.088144 | valid loss: 0.090557\n","Epoch:  2694 | train loss: 0.095906 | valid loss: 0.090374\n","Epoch:  2695 | train loss: 0.101872 | valid loss: 0.090697\n","Epoch:  2696 | train loss: 0.105142 | valid loss: 0.090327\n","Epoch:  2697 | train loss: 0.077199 | valid loss: 0.090530\n","Epoch:  2698 | train loss: 0.097520 | valid loss: 0.090265\n","Epoch:  2699 | train loss: 0.087923 | valid loss: 0.090422\n","Epoch:  2700 | train loss: 0.106179 | valid loss: 0.090497\n","Epoch:  2701 | train loss: 0.110994 | valid loss: 0.090264\n","Epoch:  2702 | train loss: 0.091714 | valid loss: 0.090343\n","Epoch:  2703 | train loss: 0.072889 | valid loss: 0.090478\n","Epoch:  2704 | train loss: 0.102061 | valid loss: 0.090448\n","Epoch:  2705 | train loss: 0.102731 | valid loss: 0.090342\n","Epoch:  2706 | train loss: 0.093705 | valid loss: 0.090388\n","Epoch:  2707 | train loss: 0.098973 | valid loss: 0.090392\n","Epoch:  2708 | train loss: 0.097121 | valid loss: 0.090291\n","Epoch:  2709 | train loss: 0.102159 | valid loss: 0.090268\n","Epoch:  2710 | train loss: 0.088409 | valid loss: 0.090152\n","Epoch:  2711 | train loss: 0.105996 | valid loss: 0.090370\n","Epoch:  2712 | train loss: 0.073529 | valid loss: 0.090132\n","Epoch:  2713 | train loss: 0.114660 | valid loss: 0.090111\n","Epoch:  2714 | train loss: 0.081655 | valid loss: 0.090062\n","Epoch:  2715 | train loss: 0.099064 | valid loss: 0.090208\n","Epoch:  2716 | train loss: 0.094195 | valid loss: 0.090133\n","Epoch:  2717 | train loss: 0.095620 | valid loss: 0.090017\n","Epoch:  2718 | train loss: 0.101622 | valid loss: 0.090096\n","Epoch:  2719 | train loss: 0.071426 | valid loss: 0.089980\n","Epoch:  2720 | train loss: 0.106455 | valid loss: 0.089979\n","Epoch:  2721 | train loss: 0.078493 | valid loss: 0.090037\n","Epoch:  2722 | train loss: 0.090661 | valid loss: 0.090008\n","Epoch:  2723 | train loss: 0.095369 | valid loss: 0.089957\n","Epoch:  2724 | train loss: 0.082066 | valid loss: 0.090018\n","Epoch:  2725 | train loss: 0.068777 | valid loss: 0.089918\n","Epoch:  2726 | train loss: 0.090154 | valid loss: 0.089908\n","Epoch:  2727 | train loss: 0.077623 | valid loss: 0.089919\n","Epoch:  2728 | train loss: 0.075218 | valid loss: 0.089822\n","Epoch:  2729 | train loss: 0.107877 | valid loss: 0.089968\n","Epoch:  2730 | train loss: 0.071747 | valid loss: 0.089811\n","Epoch:  2731 | train loss: 0.076706 | valid loss: 0.089882\n","Epoch:  2732 | train loss: 0.087629 | valid loss: 0.089849\n","Epoch:  2733 | train loss: 0.094082 | valid loss: 0.089874\n","Epoch:  2734 | train loss: 0.087550 | valid loss: 0.089950\n","Epoch:  2735 | train loss: 0.085815 | valid loss: 0.089875\n","Epoch:  2736 | train loss: 0.086371 | valid loss: 0.089804\n","Epoch:  2737 | train loss: 0.089337 | valid loss: 0.089791\n","Epoch:  2738 | train loss: 0.080002 | valid loss: 0.089743\n","Epoch:  2739 | train loss: 0.084956 | valid loss: 0.089800\n","Epoch:  2740 | train loss: 0.089691 | valid loss: 0.089787\n","Epoch:  2741 | train loss: 0.104040 | valid loss: 0.089769\n","Epoch:  2742 | train loss: 0.093425 | valid loss: 0.089707\n","Epoch:  2743 | train loss: 0.114601 | valid loss: 0.089734\n","Epoch:  2744 | train loss: 0.101677 | valid loss: 0.089726\n","Epoch:  2745 | train loss: 0.100713 | valid loss: 0.089809\n","Epoch:  2746 | train loss: 0.083112 | valid loss: 0.089684\n","Epoch:  2747 | train loss: 0.095762 | valid loss: 0.089531\n","Epoch:  2748 | train loss: 0.089240 | valid loss: 0.089532\n","Epoch:  2749 | train loss: 0.106714 | valid loss: 0.089782\n","Epoch:  2750 | train loss: 0.089787 | valid loss: 0.089721\n","Epoch:  2751 | train loss: 0.096403 | valid loss: 0.089600\n","Epoch:  2752 | train loss: 0.077576 | valid loss: 0.089651\n","Epoch:  2753 | train loss: 0.091261 | valid loss: 0.089602\n","Epoch:  2754 | train loss: 0.109773 | valid loss: 0.089574\n","Epoch:  2755 | train loss: 0.096813 | valid loss: 0.089466\n","Epoch:  2756 | train loss: 0.090878 | valid loss: 0.089437\n","Epoch:  2757 | train loss: 0.092567 | valid loss: 0.089621\n","Epoch:  2758 | train loss: 0.075861 | valid loss: 0.089569\n","Epoch:  2759 | train loss: 0.080604 | valid loss: 0.089483\n","Epoch:  2760 | train loss: 0.087161 | valid loss: 0.089414\n","Epoch:  2761 | train loss: 0.105700 | valid loss: 0.089417\n","Epoch:  2762 | train loss: 0.074763 | valid loss: 0.089576\n","Epoch:  2763 | train loss: 0.073514 | valid loss: 0.089456\n","Epoch:  2764 | train loss: 0.096159 | valid loss: 0.089403\n","Epoch:  2765 | train loss: 0.089995 | valid loss: 0.089437\n","Epoch:  2766 | train loss: 0.084713 | valid loss: 0.089516\n","Epoch:  2767 | train loss: 0.092061 | valid loss: 0.089357\n","Epoch:  2768 | train loss: 0.100390 | valid loss: 0.089383\n","Epoch:  2769 | train loss: 0.070776 | valid loss: 0.089350\n","Epoch:  2770 | train loss: 0.130816 | valid loss: 0.089272\n","Epoch:  2771 | train loss: 0.094758 | valid loss: 0.089397\n","Epoch:  2772 | train loss: 0.082712 | valid loss: 0.089261\n","Epoch:  2773 | train loss: 0.074799 | valid loss: 0.089334\n","Epoch:  2774 | train loss: 0.106397 | valid loss: 0.089330\n","Epoch:  2775 | train loss: 0.097252 | valid loss: 0.089171\n","Epoch:  2776 | train loss: 0.094998 | valid loss: 0.089406\n","Epoch:  2777 | train loss: 0.106774 | valid loss: 0.089211\n","Epoch:  2778 | train loss: 0.088230 | valid loss: 0.089361\n","Epoch:  2779 | train loss: 0.099725 | valid loss: 0.089222\n","Epoch:  2780 | train loss: 0.089862 | valid loss: 0.089186\n","Epoch:  2781 | train loss: 0.111519 | valid loss: 0.089192\n","Epoch:  2782 | train loss: 0.087535 | valid loss: 0.089104\n","Epoch:  2783 | train loss: 0.090976 | valid loss: 0.089102\n","Epoch:  2784 | train loss: 0.097566 | valid loss: 0.089065\n","Epoch:  2785 | train loss: 0.066780 | valid loss: 0.089122\n","Epoch:  2786 | train loss: 0.093646 | valid loss: 0.089140\n","Epoch:  2787 | train loss: 0.090503 | valid loss: 0.089106\n","Epoch:  2788 | train loss: 0.250644 | valid loss: 0.089294\n","Epoch:  2789 | train loss: 0.071834 | valid loss: 0.089061\n","Epoch:  2790 | train loss: 0.087123 | valid loss: 0.089122\n","Epoch:  2791 | train loss: 0.122008 | valid loss: 0.089115\n","Epoch:  2792 | train loss: 0.086875 | valid loss: 0.088971\n","Epoch:  2793 | train loss: 0.071799 | valid loss: 0.089158\n","Epoch:  2794 | train loss: 0.085610 | valid loss: 0.088980\n","Epoch:  2795 | train loss: 0.106225 | valid loss: 0.089015\n","Epoch:  2796 | train loss: 0.075124 | valid loss: 0.089133\n","Epoch:  2797 | train loss: 0.076356 | valid loss: 0.088957\n","Epoch:  2798 | train loss: 0.079816 | valid loss: 0.088970\n","Epoch:  2799 | train loss: 0.076561 | valid loss: 0.089106\n","Epoch:  2800 | train loss: 0.099633 | valid loss: 0.088859\n","Epoch:  2801 | train loss: 0.107618 | valid loss: 0.089155\n","Epoch:  2802 | train loss: 0.084352 | valid loss: 0.088914\n","Epoch:  2803 | train loss: 0.114358 | valid loss: 0.089069\n","Epoch:  2804 | train loss: 0.097363 | valid loss: 0.089039\n","Epoch:  2805 | train loss: 0.114874 | valid loss: 0.088996\n","Epoch:  2806 | train loss: 0.082056 | valid loss: 0.088841\n","Epoch:  2807 | train loss: 0.080817 | valid loss: 0.088864\n","Epoch:  2808 | train loss: 0.087022 | valid loss: 0.088980\n","Epoch:  2809 | train loss: 0.083439 | valid loss: 0.088752\n","Epoch:  2810 | train loss: 0.070388 | valid loss: 0.088845\n","Epoch:  2811 | train loss: 0.073513 | valid loss: 0.088754\n","Epoch:  2812 | train loss: 0.083013 | valid loss: 0.088735\n","Epoch:  2813 | train loss: 0.081530 | valid loss: 0.088911\n","Epoch:  2814 | train loss: 0.078988 | valid loss: 0.088720\n","Epoch:  2815 | train loss: 0.094758 | valid loss: 0.088679\n","Epoch:  2816 | train loss: 0.097906 | valid loss: 0.088817\n","Epoch:  2817 | train loss: 0.255041 | valid loss: 0.088837\n","Epoch:  2818 | train loss: 0.101724 | valid loss: 0.088743\n","Epoch:  2819 | train loss: 0.104233 | valid loss: 0.088639\n","Epoch:  2820 | train loss: 0.102203 | valid loss: 0.088640\n","Epoch:  2821 | train loss: 0.095234 | valid loss: 0.088665\n","Epoch:  2822 | train loss: 0.104814 | valid loss: 0.088765\n","Epoch:  2823 | train loss: 0.086378 | valid loss: 0.088671\n","Epoch:  2824 | train loss: 0.095928 | valid loss: 0.088656\n","Epoch:  2825 | train loss: 0.097865 | valid loss: 0.088642\n","Epoch:  2826 | train loss: 0.109800 | valid loss: 0.088673\n","Epoch:  2827 | train loss: 0.092649 | valid loss: 0.088680\n","Epoch:  2828 | train loss: 0.103289 | valid loss: 0.088635\n","Epoch:  2829 | train loss: 0.094101 | valid loss: 0.088637\n","Epoch:  2830 | train loss: 0.091749 | valid loss: 0.088597\n","Epoch:  2831 | train loss: 0.104009 | valid loss: 0.088522\n","Epoch:  2832 | train loss: 0.099416 | valid loss: 0.088551\n","Epoch:  2833 | train loss: 0.119507 | valid loss: 0.088405\n","Epoch:  2834 | train loss: 0.103136 | valid loss: 0.088488\n","Epoch:  2835 | train loss: 0.096464 | valid loss: 0.088477\n","Epoch:  2836 | train loss: 0.086814 | valid loss: 0.088394\n","Epoch:  2837 | train loss: 0.073287 | valid loss: 0.088469\n","Epoch:  2838 | train loss: 0.095014 | valid loss: 0.088619\n","Epoch:  2839 | train loss: 0.078356 | valid loss: 0.088475\n","Epoch:  2840 | train loss: 0.066538 | valid loss: 0.088573\n","Epoch:  2841 | train loss: 0.102705 | valid loss: 0.088337\n","Epoch:  2842 | train loss: 0.073725 | valid loss: 0.088572\n","Epoch:  2843 | train loss: 0.113755 | valid loss: 0.088508\n","Epoch:  2844 | train loss: 0.082590 | valid loss: 0.088337\n","Epoch:  2845 | train loss: 0.074277 | valid loss: 0.088289\n","Epoch:  2846 | train loss: 0.105727 | valid loss: 0.088501\n","Epoch:  2847 | train loss: 0.071724 | valid loss: 0.088509\n","Epoch:  2848 | train loss: 0.091028 | valid loss: 0.088358\n","Epoch:  2849 | train loss: 0.066634 | valid loss: 0.088350\n","Epoch:  2850 | train loss: 0.083613 | valid loss: 0.088414\n","Epoch:  2851 | train loss: 0.098163 | valid loss: 0.088348\n","Epoch:  2852 | train loss: 0.070872 | valid loss: 0.088302\n","Epoch:  2853 | train loss: 0.101122 | valid loss: 0.088277\n","Epoch:  2854 | train loss: 0.072145 | valid loss: 0.088219\n","Epoch:  2855 | train loss: 0.078481 | valid loss: 0.088315\n","Epoch:  2856 | train loss: 0.078150 | valid loss: 0.088169\n","Epoch:  2857 | train loss: 0.063632 | valid loss: 0.088372\n","Epoch:  2858 | train loss: 0.088236 | valid loss: 0.088329\n","Epoch:  2859 | train loss: 0.082614 | valid loss: 0.088347\n","Epoch:  2860 | train loss: 0.091998 | valid loss: 0.088161\n","Epoch:  2861 | train loss: 0.108630 | valid loss: 0.088329\n","Epoch:  2862 | train loss: 0.083658 | valid loss: 0.088175\n","Epoch:  2863 | train loss: 0.099945 | valid loss: 0.088186\n","Epoch:  2864 | train loss: 0.086576 | valid loss: 0.088138\n","Epoch:  2865 | train loss: 0.075196 | valid loss: 0.088245\n","Epoch:  2866 | train loss: 0.089765 | valid loss: 0.088178\n","Epoch:  2867 | train loss: 0.084982 | valid loss: 0.088257\n","Epoch:  2868 | train loss: 0.079871 | valid loss: 0.088159\n","Epoch:  2869 | train loss: 0.111455 | valid loss: 0.088080\n","Epoch:  2870 | train loss: 0.067743 | valid loss: 0.088119\n","Epoch:  2871 | train loss: 0.096667 | valid loss: 0.088059\n","Epoch:  2872 | train loss: 0.071825 | valid loss: 0.088207\n","Epoch:  2873 | train loss: 0.091671 | valid loss: 0.088106\n","Epoch:  2874 | train loss: 0.081637 | valid loss: 0.088183\n","Epoch:  2875 | train loss: 0.095809 | valid loss: 0.088207\n","Epoch:  2876 | train loss: 0.092139 | valid loss: 0.088066\n","Epoch:  2877 | train loss: 0.075628 | valid loss: 0.088045\n","Epoch:  2878 | train loss: 0.087840 | valid loss: 0.088032\n","Epoch:  2879 | train loss: 0.096968 | valid loss: 0.087962\n","Epoch:  2880 | train loss: 0.082558 | valid loss: 0.088116\n","Epoch:  2881 | train loss: 0.079356 | valid loss: 0.087853\n","Epoch:  2882 | train loss: 0.070503 | valid loss: 0.088010\n","Epoch:  2883 | train loss: 0.081026 | valid loss: 0.087989\n","Epoch:  2884 | train loss: 0.097969 | valid loss: 0.087821\n","Epoch:  2885 | train loss: 0.075964 | valid loss: 0.088046\n","Epoch:  2886 | train loss: 0.077397 | valid loss: 0.088018\n","Epoch:  2887 | train loss: 0.111319 | valid loss: 0.087941\n","Epoch:  2888 | train loss: 0.074280 | valid loss: 0.088015\n","Epoch:  2889 | train loss: 0.103390 | valid loss: 0.087963\n","Epoch:  2890 | train loss: 0.091101 | valid loss: 0.087936\n","Epoch:  2891 | train loss: 0.071952 | valid loss: 0.088028\n","Epoch:  2892 | train loss: 0.082081 | valid loss: 0.087685\n","Epoch:  2893 | train loss: 0.100059 | valid loss: 0.087803\n","Epoch:  2894 | train loss: 0.063158 | valid loss: 0.087805\n","Epoch:  2895 | train loss: 0.074015 | valid loss: 0.087836\n","Epoch:  2896 | train loss: 0.070293 | valid loss: 0.087804\n","Epoch:  2897 | train loss: 0.087414 | valid loss: 0.087815\n","Epoch:  2898 | train loss: 0.101806 | valid loss: 0.087772\n","Epoch:  2899 | train loss: 0.090449 | valid loss: 0.087787\n","Epoch:  2900 | train loss: 0.077757 | valid loss: 0.087757\n","Epoch:  2901 | train loss: 0.081284 | valid loss: 0.087767\n","Epoch:  2902 | train loss: 0.077197 | valid loss: 0.087953\n","Epoch:  2903 | train loss: 0.079366 | valid loss: 0.087857\n","Epoch:  2904 | train loss: 0.117557 | valid loss: 0.087642\n","Epoch:  2905 | train loss: 0.094331 | valid loss: 0.087634\n","Epoch:  2906 | train loss: 0.079767 | valid loss: 0.087789\n","Epoch:  2907 | train loss: 0.096775 | valid loss: 0.087743\n","Epoch:  2908 | train loss: 0.090447 | valid loss: 0.087654\n","Epoch:  2909 | train loss: 0.081788 | valid loss: 0.087711\n","Epoch:  2910 | train loss: 0.107542 | valid loss: 0.087794\n","Epoch:  2911 | train loss: 0.100091 | valid loss: 0.087593\n","Epoch:  2912 | train loss: 0.096737 | valid loss: 0.087747\n","Epoch:  2913 | train loss: 0.094564 | valid loss: 0.087688\n","Epoch:  2914 | train loss: 0.081335 | valid loss: 0.087674\n","Epoch:  2915 | train loss: 0.084997 | valid loss: 0.087631\n","Epoch:  2916 | train loss: 0.078913 | valid loss: 0.087694\n","Epoch:  2917 | train loss: 0.075734 | valid loss: 0.087536\n","Epoch:  2918 | train loss: 0.082718 | valid loss: 0.087629\n","Epoch:  2919 | train loss: 0.083767 | valid loss: 0.087735\n","Epoch:  2920 | train loss: 0.105151 | valid loss: 0.087611\n","Epoch:  2921 | train loss: 0.066571 | valid loss: 0.087632\n","Epoch:  2922 | train loss: 0.095295 | valid loss: 0.087560\n","Epoch:  2923 | train loss: 0.104097 | valid loss: 0.087511\n","Epoch:  2924 | train loss: 0.096382 | valid loss: 0.087536\n","Epoch:  2925 | train loss: 0.075435 | valid loss: 0.087576\n","Epoch:  2926 | train loss: 0.088050 | valid loss: 0.087530\n","Epoch:  2927 | train loss: 0.074282 | valid loss: 0.087671\n","Epoch:  2928 | train loss: 0.074427 | valid loss: 0.087635\n","Epoch:  2929 | train loss: 0.082419 | valid loss: 0.087583\n","Epoch:  2930 | train loss: 0.077766 | valid loss: 0.087521\n","Epoch:  2931 | train loss: 0.068396 | valid loss: 0.087589\n","Epoch:  2932 | train loss: 0.073471 | valid loss: 0.087548\n","Epoch:  2933 | train loss: 0.088791 | valid loss: 0.087581\n","Epoch:  2934 | train loss: 0.084116 | valid loss: 0.087388\n","Epoch:  2935 | train loss: 0.071391 | valid loss: 0.087512\n","Epoch:  2936 | train loss: 0.093174 | valid loss: 0.087430\n","Epoch:  2937 | train loss: 0.105703 | valid loss: 0.087354\n","Epoch:  2938 | train loss: 0.083611 | valid loss: 0.087412\n","Epoch:  2939 | train loss: 0.085755 | valid loss: 0.087560\n","Epoch:  2940 | train loss: 0.084162 | valid loss: 0.087575\n","Epoch:  2941 | train loss: 0.073504 | valid loss: 0.087392\n","Epoch:  2942 | train loss: 0.093820 | valid loss: 0.087434\n","Epoch:  2943 | train loss: 0.123704 | valid loss: 0.087343\n","Epoch:  2944 | train loss: 0.083990 | valid loss: 0.087392\n","Epoch:  2945 | train loss: 0.090063 | valid loss: 0.087475\n","Epoch:  2946 | train loss: 0.090166 | valid loss: 0.087357\n","Epoch:  2947 | train loss: 0.108732 | valid loss: 0.087312\n","Epoch:  2948 | train loss: 0.096558 | valid loss: 0.087381\n","Epoch:  2949 | train loss: 0.081374 | valid loss: 0.087430\n","Epoch:  2950 | train loss: 0.069835 | valid loss: 0.087531\n","Epoch:  2951 | train loss: 0.090129 | valid loss: 0.087295\n","Epoch:  2952 | train loss: 0.095764 | valid loss: 0.087264\n","Epoch:  2953 | train loss: 0.090137 | valid loss: 0.087282\n","Epoch:  2954 | train loss: 0.079941 | valid loss: 0.087369\n","Epoch:  2955 | train loss: 0.080798 | valid loss: 0.087287\n","Epoch:  2956 | train loss: 0.099767 | valid loss: 0.087220\n","Epoch:  2957 | train loss: 0.083260 | valid loss: 0.087298\n","Epoch:  2958 | train loss: 0.098294 | valid loss: 0.087189\n","Epoch:  2959 | train loss: 0.079830 | valid loss: 0.087281\n","Epoch:  2960 | train loss: 0.084824 | valid loss: 0.087159\n","Epoch:  2961 | train loss: 0.078983 | valid loss: 0.087236\n","Epoch:  2962 | train loss: 0.106736 | valid loss: 0.087246\n","Epoch:  2963 | train loss: 0.075617 | valid loss: 0.087223\n","Epoch:  2964 | train loss: 0.079537 | valid loss: 0.087221\n","Epoch:  2965 | train loss: 0.102607 | valid loss: 0.087213\n","Epoch:  2966 | train loss: 0.082921 | valid loss: 0.087162\n","Epoch:  2967 | train loss: 0.094090 | valid loss: 0.087163\n","Epoch:  2968 | train loss: 0.067466 | valid loss: 0.087168\n","Epoch:  2969 | train loss: 0.091910 | valid loss: 0.087176\n","Epoch:  2970 | train loss: 0.080294 | valid loss: 0.087221\n","Epoch:  2971 | train loss: 0.081405 | valid loss: 0.087165\n","Epoch:  2972 | train loss: 0.075669 | valid loss: 0.087246\n","Epoch:  2973 | train loss: 0.073558 | valid loss: 0.087137\n","Epoch:  2974 | train loss: 0.088788 | valid loss: 0.087165\n","Epoch:  2975 | train loss: 0.074043 | valid loss: 0.087249\n","Epoch:  2976 | train loss: 0.088855 | valid loss: 0.087123\n","Epoch:  2977 | train loss: 0.070212 | valid loss: 0.087108\n","Epoch:  2978 | train loss: 0.094589 | valid loss: 0.087084\n","Epoch:  2979 | train loss: 0.107675 | valid loss: 0.087038\n","Epoch:  2980 | train loss: 0.101865 | valid loss: 0.087127\n","Epoch:  2981 | train loss: 0.079120 | valid loss: 0.087085\n","Epoch:  2982 | train loss: 0.080152 | valid loss: 0.087080\n","Epoch:  2983 | train loss: 0.093450 | valid loss: 0.087138\n","Epoch:  2984 | train loss: 0.094698 | valid loss: 0.087090\n","Epoch:  2985 | train loss: 0.098659 | valid loss: 0.087179\n","Epoch:  2986 | train loss: 0.086904 | valid loss: 0.087028\n","Epoch:  2987 | train loss: 0.079572 | valid loss: 0.087014\n","Epoch:  2988 | train loss: 0.078208 | valid loss: 0.086988\n","Epoch:  2989 | train loss: 0.100022 | valid loss: 0.087003\n","Epoch:  2990 | train loss: 0.088086 | valid loss: 0.087081\n","Epoch:  2991 | train loss: 0.082241 | valid loss: 0.087015\n","Epoch:  2992 | train loss: 0.070552 | valid loss: 0.086999\n","Epoch:  2993 | train loss: 0.106237 | valid loss: 0.087160\n","Epoch:  2994 | train loss: 0.090347 | valid loss: 0.087003\n","Epoch:  2995 | train loss: 0.087906 | valid loss: 0.086881\n","Epoch:  2996 | train loss: 0.081530 | valid loss: 0.086979\n","Epoch:  2997 | train loss: 0.072427 | valid loss: 0.086922\n","Epoch:  2998 | train loss: 0.082900 | valid loss: 0.087122\n","Epoch:  2999 | train loss: 0.102497 | valid loss: 0.086898\n","Epoch:  3000 | train loss: 0.103099 | valid loss: 0.086949\n","Epoch:  3001 | train loss: 0.065504 | valid loss: 0.086919\n","Epoch:  3002 | train loss: 0.092510 | valid loss: 0.086877\n","Epoch:  3003 | train loss: 0.076140 | valid loss: 0.086946\n","Epoch:  3004 | train loss: 0.098750 | valid loss: 0.087048\n","Epoch:  3005 | train loss: 0.070951 | valid loss: 0.086978\n","Epoch:  3006 | train loss: 0.078040 | valid loss: 0.086759\n","Epoch:  3007 | train loss: 0.103039 | valid loss: 0.086905\n","Epoch:  3008 | train loss: 0.095743 | valid loss: 0.086945\n","Epoch:  3009 | train loss: 0.103606 | valid loss: 0.086985\n","Epoch:  3010 | train loss: 0.082110 | valid loss: 0.087047\n","Epoch:  3011 | train loss: 0.125679 | valid loss: 0.086850\n","Epoch:  3012 | train loss: 0.078068 | valid loss: 0.086829\n","Epoch:  3013 | train loss: 0.082160 | valid loss: 0.086767\n","Epoch:  3014 | train loss: 0.084132 | valid loss: 0.086822\n","Epoch:  3015 | train loss: 0.075523 | valid loss: 0.086881\n","Epoch:  3016 | train loss: 0.104868 | valid loss: 0.086832\n","Epoch:  3017 | train loss: 0.070842 | valid loss: 0.086852\n","Epoch:  3018 | train loss: 0.084293 | valid loss: 0.086772\n","Epoch:  3019 | train loss: 0.077487 | valid loss: 0.086842\n","Epoch:  3020 | train loss: 0.088430 | valid loss: 0.086705\n","Epoch:  3021 | train loss: 0.087854 | valid loss: 0.086759\n","Epoch:  3022 | train loss: 0.084987 | valid loss: 0.086680\n","Epoch:  3023 | train loss: 0.123433 | valid loss: 0.086864\n","Epoch:  3024 | train loss: 0.069445 | valid loss: 0.086678\n","Epoch:  3025 | train loss: 0.082775 | valid loss: 0.086672\n","Epoch:  3026 | train loss: 0.076853 | valid loss: 0.086672\n","Epoch:  3027 | train loss: 0.091936 | valid loss: 0.086722\n","Epoch:  3028 | train loss: 0.079433 | valid loss: 0.086642\n","Epoch:  3029 | train loss: 0.113006 | valid loss: 0.086653\n","Epoch:  3030 | train loss: 0.076552 | valid loss: 0.086730\n","Epoch:  3031 | train loss: 0.082015 | valid loss: 0.086654\n","Epoch:  3032 | train loss: 0.080706 | valid loss: 0.086682\n","Epoch:  3033 | train loss: 0.101808 | valid loss: 0.086751\n","Epoch:  3034 | train loss: 0.085624 | valid loss: 0.086610\n","Epoch:  3035 | train loss: 0.076467 | valid loss: 0.086671\n","Epoch:  3036 | train loss: 0.097479 | valid loss: 0.086657\n","Epoch:  3037 | train loss: 0.088640 | valid loss: 0.086583\n","Epoch:  3038 | train loss: 0.079484 | valid loss: 0.086712\n","Epoch:  3039 | train loss: 0.070683 | valid loss: 0.086580\n","Epoch:  3040 | train loss: 0.122129 | valid loss: 0.086731\n","Epoch:  3041 | train loss: 0.088443 | valid loss: 0.086519\n","Epoch:  3042 | train loss: 0.083419 | valid loss: 0.086650\n","Epoch:  3043 | train loss: 0.072943 | valid loss: 0.086549\n","Epoch:  3044 | train loss: 0.090851 | valid loss: 0.086700\n","Epoch:  3045 | train loss: 0.098095 | valid loss: 0.086641\n","Epoch:  3046 | train loss: 0.126663 | valid loss: 0.086577\n","Epoch:  3047 | train loss: 0.065462 | valid loss: 0.086581\n","Epoch:  3048 | train loss: 0.086538 | valid loss: 0.086559\n","Epoch:  3049 | train loss: 0.071112 | valid loss: 0.086506\n","Epoch:  3050 | train loss: 0.091586 | valid loss: 0.086505\n","Epoch:  3051 | train loss: 0.079651 | valid loss: 0.086500\n","Epoch:  3052 | train loss: 0.088552 | valid loss: 0.086550\n","Epoch:  3053 | train loss: 0.108923 | valid loss: 0.086529\n","Epoch:  3054 | train loss: 0.071964 | valid loss: 0.086450\n","Epoch:  3055 | train loss: 0.085479 | valid loss: 0.086485\n","Epoch:  3056 | train loss: 0.098826 | valid loss: 0.086521\n","Epoch:  3057 | train loss: 0.083734 | valid loss: 0.086416\n","Epoch:  3058 | train loss: 0.070214 | valid loss: 0.086422\n","Epoch:  3059 | train loss: 0.076562 | valid loss: 0.086546\n","Epoch:  3060 | train loss: 0.100544 | valid loss: 0.086605\n","Epoch:  3061 | train loss: 0.085391 | valid loss: 0.086497\n","Epoch:  3062 | train loss: 0.087787 | valid loss: 0.086673\n","Epoch:  3063 | train loss: 0.072310 | valid loss: 0.086563\n","Epoch:  3064 | train loss: 0.085722 | valid loss: 0.086406\n","Epoch:  3065 | train loss: 0.093852 | valid loss: 0.086477\n","Epoch:  3066 | train loss: 0.084024 | valid loss: 0.086382\n","Epoch:  3067 | train loss: 0.082172 | valid loss: 0.086443\n","Epoch:  3068 | train loss: 0.090688 | valid loss: 0.086414\n","Epoch:  3069 | train loss: 0.082273 | valid loss: 0.086429\n","Epoch:  3070 | train loss: 0.078196 | valid loss: 0.086400\n","Epoch:  3071 | train loss: 0.081894 | valid loss: 0.086493\n","Epoch:  3072 | train loss: 0.098596 | valid loss: 0.086328\n","Epoch:  3073 | train loss: 0.074819 | valid loss: 0.086378\n","Epoch:  3074 | train loss: 0.117406 | valid loss: 0.086408\n","Epoch:  3075 | train loss: 0.081356 | valid loss: 0.086356\n","Epoch:  3076 | train loss: 0.082858 | valid loss: 0.086411\n","Epoch:  3077 | train loss: 0.102794 | valid loss: 0.086436\n","Epoch:  3078 | train loss: 0.067155 | valid loss: 0.086340\n","Epoch:  3079 | train loss: 0.102929 | valid loss: 0.086330\n","Epoch:  3080 | train loss: 0.088217 | valid loss: 0.086274\n","Epoch:  3081 | train loss: 0.083338 | valid loss: 0.086505\n","Epoch:  3082 | train loss: 0.117692 | valid loss: 0.086365\n","Epoch:  3083 | train loss: 0.077963 | valid loss: 0.086309\n","Epoch:  3084 | train loss: 0.094934 | valid loss: 0.086294\n","Epoch:  3085 | train loss: 0.060675 | valid loss: 0.086449\n","Epoch:  3086 | train loss: 0.089431 | valid loss: 0.086390\n","Epoch:  3087 | train loss: 0.094063 | valid loss: 0.086247\n","Epoch:  3088 | train loss: 0.087860 | valid loss: 0.086355\n","Epoch:  3089 | train loss: 0.087028 | valid loss: 0.086342\n","Epoch:  3090 | train loss: 0.085769 | valid loss: 0.086235\n","Epoch:  3091 | train loss: 0.094522 | valid loss: 0.086344\n","Epoch:  3092 | train loss: 0.099966 | valid loss: 0.086341\n","Epoch:  3093 | train loss: 0.084462 | valid loss: 0.086212\n","Epoch:  3094 | train loss: 0.078362 | valid loss: 0.086238\n","Epoch:  3095 | train loss: 0.078542 | valid loss: 0.086209\n","Epoch:  3096 | train loss: 0.077793 | valid loss: 0.086252\n","Epoch:  3097 | train loss: 0.087900 | valid loss: 0.086293\n","Epoch:  3098 | train loss: 0.080478 | valid loss: 0.086217\n","Epoch:  3099 | train loss: 0.069782 | valid loss: 0.086261\n","Epoch:  3100 | train loss: 0.071686 | valid loss: 0.086161\n","Epoch:  3101 | train loss: 0.101491 | valid loss: 0.086185\n","Epoch:  3102 | train loss: 0.079181 | valid loss: 0.086251\n","Epoch:  3103 | train loss: 0.093024 | valid loss: 0.086114\n","Epoch:  3104 | train loss: 0.096643 | valid loss: 0.086145\n","Epoch:  3105 | train loss: 0.073915 | valid loss: 0.086208\n","Epoch:  3106 | train loss: 0.102654 | valid loss: 0.086150\n","Epoch:  3107 | train loss: 0.082511 | valid loss: 0.086242\n","Epoch:  3108 | train loss: 0.091305 | valid loss: 0.086159\n","Epoch:  3109 | train loss: 0.092083 | valid loss: 0.086141\n","Epoch:  3110 | train loss: 0.092400 | valid loss: 0.086211\n","Epoch:  3111 | train loss: 0.108201 | valid loss: 0.086225\n","Epoch:  3112 | train loss: 0.073494 | valid loss: 0.086190\n","Epoch:  3113 | train loss: 0.095674 | valid loss: 0.086076\n","Epoch:  3114 | train loss: 0.074537 | valid loss: 0.086045\n","Epoch:  3115 | train loss: 0.078765 | valid loss: 0.086115\n","Epoch:  3116 | train loss: 0.083067 | valid loss: 0.086098\n","Epoch:  3117 | train loss: 0.072755 | valid loss: 0.086214\n","Epoch:  3118 | train loss: 0.103929 | valid loss: 0.086146\n","Epoch:  3119 | train loss: 0.075074 | valid loss: 0.086122\n","Epoch:  3120 | train loss: 0.089059 | valid loss: 0.086109\n","Epoch:  3121 | train loss: 0.092255 | valid loss: 0.086059\n","Epoch:  3122 | train loss: 0.085662 | valid loss: 0.086055\n","Epoch:  3123 | train loss: 0.086430 | valid loss: 0.086034\n","Epoch:  3124 | train loss: 0.064163 | valid loss: 0.086129\n","Epoch:  3125 | train loss: 0.085568 | valid loss: 0.086180\n","Epoch:  3126 | train loss: 0.265860 | valid loss: 0.086031\n","Epoch:  3127 | train loss: 0.101221 | valid loss: 0.086049\n","Epoch:  3128 | train loss: 0.080027 | valid loss: 0.086054\n","Epoch:  3129 | train loss: 0.082654 | valid loss: 0.085965\n","Epoch:  3130 | train loss: 0.095523 | valid loss: 0.086155\n","Epoch:  3131 | train loss: 0.081910 | valid loss: 0.086048\n","Epoch:  3132 | train loss: 0.065880 | valid loss: 0.086052\n","Epoch:  3133 | train loss: 0.116248 | valid loss: 0.085970\n","Epoch:  3134 | train loss: 0.095021 | valid loss: 0.086005\n","Epoch:  3135 | train loss: 0.076481 | valid loss: 0.085981\n","Epoch:  3136 | train loss: 0.097040 | valid loss: 0.086060\n","Epoch:  3137 | train loss: 0.084907 | valid loss: 0.085967\n","Epoch:  3138 | train loss: 0.095132 | valid loss: 0.086031\n","Epoch:  3139 | train loss: 0.084958 | valid loss: 0.086020\n","Epoch:  3140 | train loss: 0.110879 | valid loss: 0.086129\n","Epoch:  3141 | train loss: 0.074281 | valid loss: 0.085973\n","Epoch:  3142 | train loss: 0.076909 | valid loss: 0.085950\n","Epoch:  3143 | train loss: 0.117779 | valid loss: 0.085927\n","Epoch:  3144 | train loss: 0.110776 | valid loss: 0.086096\n","Epoch:  3145 | train loss: 0.066140 | valid loss: 0.085926\n","Epoch:  3146 | train loss: 0.077259 | valid loss: 0.085971\n","Epoch:  3147 | train loss: 0.079891 | valid loss: 0.085914\n","Epoch:  3148 | train loss: 0.111451 | valid loss: 0.085917\n","Epoch:  3149 | train loss: 0.066733 | valid loss: 0.086004\n","Epoch:  3150 | train loss: 0.089346 | valid loss: 0.085883\n","Epoch:  3151 | train loss: 0.090855 | valid loss: 0.085952\n","Epoch:  3152 | train loss: 0.086470 | valid loss: 0.086099\n","Epoch:  3153 | train loss: 0.081905 | valid loss: 0.085825\n","Epoch:  3154 | train loss: 0.080225 | valid loss: 0.085956\n","Epoch:  3155 | train loss: 0.081910 | valid loss: 0.085845\n","Epoch:  3156 | train loss: 0.104490 | valid loss: 0.085895\n","Epoch:  3157 | train loss: 0.102448 | valid loss: 0.085897\n","Epoch:  3158 | train loss: 0.082769 | valid loss: 0.085920\n","Epoch:  3159 | train loss: 0.070606 | valid loss: 0.085889\n","Epoch:  3160 | train loss: 0.075575 | valid loss: 0.085784\n","Epoch:  3161 | train loss: 0.094051 | valid loss: 0.085951\n","Epoch:  3162 | train loss: 0.073408 | valid loss: 0.085930\n","Epoch:  3163 | train loss: 0.071984 | valid loss: 0.085853\n","Epoch:  3164 | train loss: 0.063678 | valid loss: 0.085905\n","Epoch:  3165 | train loss: 0.082601 | valid loss: 0.085874\n","Epoch:  3166 | train loss: 0.085753 | valid loss: 0.085862\n","Epoch:  3167 | train loss: 0.068440 | valid loss: 0.085837\n","Epoch:  3168 | train loss: 0.077066 | valid loss: 0.085823\n","Epoch:  3169 | train loss: 0.095333 | valid loss: 0.085966\n","Epoch:  3170 | train loss: 0.087791 | valid loss: 0.085855\n","Epoch:  3171 | train loss: 0.079443 | valid loss: 0.085786\n","Epoch:  3172 | train loss: 0.094171 | valid loss: 0.085837\n","Epoch:  3173 | train loss: 0.090076 | valid loss: 0.085743\n","Epoch:  3174 | train loss: 0.063148 | valid loss: 0.085802\n","Epoch:  3175 | train loss: 0.105831 | valid loss: 0.085816\n","Epoch:  3176 | train loss: 0.084834 | valid loss: 0.085786\n","Epoch:  3177 | train loss: 0.071250 | valid loss: 0.085780\n","Epoch:  3178 | train loss: 0.077268 | valid loss: 0.085853\n","Epoch:  3179 | train loss: 0.087237 | valid loss: 0.085747\n","Epoch:  3180 | train loss: 0.097676 | valid loss: 0.085843\n","Epoch:  3181 | train loss: 0.089389 | valid loss: 0.085706\n","Epoch:  3182 | train loss: 0.070468 | valid loss: 0.085738\n","Epoch:  3183 | train loss: 0.071934 | valid loss: 0.085676\n","Epoch:  3184 | train loss: 0.081987 | valid loss: 0.085730\n","Epoch:  3185 | train loss: 0.090746 | valid loss: 0.085826\n","Epoch:  3186 | train loss: 0.079200 | valid loss: 0.085723\n","Epoch:  3187 | train loss: 0.083609 | valid loss: 0.085647\n","Epoch:  3188 | train loss: 0.090271 | valid loss: 0.085769\n","Epoch:  3189 | train loss: 0.078533 | valid loss: 0.085877\n","Epoch:  3190 | train loss: 0.077730 | valid loss: 0.085874\n","Epoch:  3191 | train loss: 0.101456 | valid loss: 0.085861\n","Epoch:  3192 | train loss: 0.090228 | valid loss: 0.085703\n","Epoch:  3193 | train loss: 0.073699 | valid loss: 0.085735\n","Epoch:  3194 | train loss: 0.069911 | valid loss: 0.085739\n","Epoch:  3195 | train loss: 0.081983 | valid loss: 0.085784\n","Epoch:  3196 | train loss: 0.103270 | valid loss: 0.085722\n","Epoch:  3197 | train loss: 0.067564 | valid loss: 0.085645\n","Epoch:  3198 | train loss: 0.092778 | valid loss: 0.085801\n","Epoch:  3199 | train loss: 0.111478 | valid loss: 0.085718\n","Epoch:  3200 | train loss: 0.085394 | valid loss: 0.085656\n","Epoch:  3201 | train loss: 0.087469 | valid loss: 0.085663\n","Epoch:  3202 | train loss: 0.074725 | valid loss: 0.085680\n","Epoch:  3203 | train loss: 0.078863 | valid loss: 0.085671\n","Epoch:  3204 | train loss: 0.082758 | valid loss: 0.085742\n","Epoch:  3205 | train loss: 0.081963 | valid loss: 0.085679\n","Epoch:  3206 | train loss: 0.066887 | valid loss: 0.085742\n","Epoch:  3207 | train loss: 0.091131 | valid loss: 0.085688\n","Epoch:  3208 | train loss: 0.098251 | valid loss: 0.085652\n","Epoch:  3209 | train loss: 0.078090 | valid loss: 0.085715\n","Epoch:  3210 | train loss: 0.087009 | valid loss: 0.085777\n","Epoch:  3211 | train loss: 0.085201 | valid loss: 0.085528\n","Epoch:  3212 | train loss: 0.080410 | valid loss: 0.085567\n","Epoch:  3213 | train loss: 0.065211 | valid loss: 0.085629\n","Epoch:  3214 | train loss: 0.100384 | valid loss: 0.085557\n","Epoch:  3215 | train loss: 0.073172 | valid loss: 0.085561\n","Epoch:  3216 | train loss: 0.069789 | valid loss: 0.085596\n","Epoch:  3217 | train loss: 0.107740 | valid loss: 0.085608\n","Epoch:  3218 | train loss: 0.094314 | valid loss: 0.085726\n","Epoch:  3219 | train loss: 0.080162 | valid loss: 0.085621\n","Epoch:  3220 | train loss: 0.077690 | valid loss: 0.085653\n","Epoch:  3221 | train loss: 0.092658 | valid loss: 0.085592\n","Epoch:  3222 | train loss: 0.073962 | valid loss: 0.085544\n","Epoch:  3223 | train loss: 0.094845 | valid loss: 0.085576\n","Epoch:  3224 | train loss: 0.072805 | valid loss: 0.085583\n","Epoch:  3225 | train loss: 0.100036 | valid loss: 0.085509\n","Epoch:  3226 | train loss: 0.101924 | valid loss: 0.085608\n","Epoch:  3227 | train loss: 0.090897 | valid loss: 0.085582\n","Epoch:  3228 | train loss: 0.078536 | valid loss: 0.085526\n","Epoch:  3229 | train loss: 0.078650 | valid loss: 0.085509\n","Epoch:  3230 | train loss: 0.071571 | valid loss: 0.085574\n","Epoch:  3231 | train loss: 0.094319 | valid loss: 0.085606\n","Epoch:  3232 | train loss: 0.086562 | valid loss: 0.085525\n","Epoch:  3233 | train loss: 0.084492 | valid loss: 0.085473\n","Epoch:  3234 | train loss: 0.095888 | valid loss: 0.085555\n","Epoch:  3235 | train loss: 0.264004 | valid loss: 0.085495\n","Epoch:  3236 | train loss: 0.092268 | valid loss: 0.085419\n","Epoch:  3237 | train loss: 0.101616 | valid loss: 0.085425\n","Epoch:  3238 | train loss: 0.081127 | valid loss: 0.085487\n","Epoch:  3239 | train loss: 0.084545 | valid loss: 0.085558\n","Epoch:  3240 | train loss: 0.097138 | valid loss: 0.085578\n","Epoch:  3241 | train loss: 0.077957 | valid loss: 0.085581\n","Epoch:  3242 | train loss: 0.083174 | valid loss: 0.085452\n","Epoch:  3243 | train loss: 0.115578 | valid loss: 0.085496\n","Epoch:  3244 | train loss: 0.088965 | valid loss: 0.085482\n","Epoch:  3245 | train loss: 0.269832 | valid loss: 0.085498\n","Epoch:  3246 | train loss: 0.101669 | valid loss: 0.085483\n","Epoch:  3247 | train loss: 0.095191 | valid loss: 0.085497\n","Epoch:  3248 | train loss: 0.094269 | valid loss: 0.085522\n","Epoch:  3249 | train loss: 0.098856 | valid loss: 0.085414\n","Epoch:  3250 | train loss: 0.105817 | valid loss: 0.085444\n","Epoch:  3251 | train loss: 0.091141 | valid loss: 0.085440\n","Epoch:  3252 | train loss: 0.082564 | valid loss: 0.085583\n","Epoch:  3253 | train loss: 0.091411 | valid loss: 0.085516\n","Epoch:  3254 | train loss: 0.080125 | valid loss: 0.085487\n","Epoch:  3255 | train loss: 0.082919 | valid loss: 0.085501\n","Epoch:  3256 | train loss: 0.251221 | valid loss: 0.085464\n","Epoch:  3257 | train loss: 0.081593 | valid loss: 0.085534\n","Epoch:  3258 | train loss: 0.078878 | valid loss: 0.085386\n","Epoch:  3259 | train loss: 0.084674 | valid loss: 0.085528\n","Epoch:  3260 | train loss: 0.128508 | valid loss: 0.085552\n","Epoch:  3261 | train loss: 0.083932 | valid loss: 0.085481\n","Epoch:  3262 | train loss: 0.066094 | valid loss: 0.085412\n","Epoch:  3263 | train loss: 0.077195 | valid loss: 0.085444\n","Epoch:  3264 | train loss: 0.081028 | valid loss: 0.085459\n","Epoch:  3265 | train loss: 0.067172 | valid loss: 0.085424\n","Epoch:  3266 | train loss: 0.087979 | valid loss: 0.085437\n","Epoch:  3267 | train loss: 0.068524 | valid loss: 0.085428\n","Epoch:  3268 | train loss: 0.091243 | valid loss: 0.085451\n","Epoch:  3269 | train loss: 0.080810 | valid loss: 0.085506\n","Epoch:  3270 | train loss: 0.080902 | valid loss: 0.085382\n","Epoch:  3271 | train loss: 0.090031 | valid loss: 0.085354\n","Epoch:  3272 | train loss: 0.076659 | valid loss: 0.085397\n","Epoch:  3273 | train loss: 0.064074 | valid loss: 0.085513\n","Epoch:  3274 | train loss: 0.065181 | valid loss: 0.085347\n","Epoch:  3275 | train loss: 0.086114 | valid loss: 0.085366\n","Epoch:  3276 | train loss: 0.077629 | valid loss: 0.085329\n","Epoch:  3277 | train loss: 0.075993 | valid loss: 0.085607\n","Epoch:  3278 | train loss: 0.078952 | valid loss: 0.085478\n","Epoch:  3279 | train loss: 0.088687 | valid loss: 0.085325\n","Epoch:  3280 | train loss: 0.079559 | valid loss: 0.085394\n","Epoch:  3281 | train loss: 0.091103 | valid loss: 0.085474\n","Epoch:  3282 | train loss: 0.073026 | valid loss: 0.085366\n","Epoch:  3283 | train loss: 0.080700 | valid loss: 0.085418\n","Epoch:  3284 | train loss: 0.064795 | valid loss: 0.085384\n","Epoch:  3285 | train loss: 0.068980 | valid loss: 0.085421\n","Epoch:  3286 | train loss: 0.087732 | valid loss: 0.085452\n","Epoch:  3287 | train loss: 0.090135 | valid loss: 0.085310\n","Epoch:  3288 | train loss: 0.072116 | valid loss: 0.085272\n","Epoch:  3289 | train loss: 0.090392 | valid loss: 0.085339\n","Epoch:  3290 | train loss: 0.110570 | valid loss: 0.085311\n","Epoch:  3291 | train loss: 0.100393 | valid loss: 0.085369\n","Epoch:  3292 | train loss: 0.088756 | valid loss: 0.085349\n","Epoch:  3293 | train loss: 0.078501 | valid loss: 0.085460\n","Epoch:  3294 | train loss: 0.088952 | valid loss: 0.085270\n","Epoch:  3295 | train loss: 0.081418 | valid loss: 0.085393\n","Epoch:  3296 | train loss: 0.082549 | valid loss: 0.085324\n","Epoch:  3297 | train loss: 0.094962 | valid loss: 0.085263\n","Epoch:  3298 | train loss: 0.087924 | valid loss: 0.085297\n","Epoch:  3299 | train loss: 0.079785 | valid loss: 0.085319\n","Epoch:  3300 | train loss: 0.085084 | valid loss: 0.085335\n","Epoch:  3301 | train loss: 0.077676 | valid loss: 0.085244\n","Epoch:  3302 | train loss: 0.087519 | valid loss: 0.085418\n","Epoch:  3303 | train loss: 0.071447 | valid loss: 0.085239\n","Epoch:  3304 | train loss: 0.083449 | valid loss: 0.085270\n","Epoch:  3305 | train loss: 0.081192 | valid loss: 0.085299\n","Epoch:  3306 | train loss: 0.106510 | valid loss: 0.085198\n","Epoch:  3307 | train loss: 0.090986 | valid loss: 0.085242\n","Epoch:  3308 | train loss: 0.087123 | valid loss: 0.085268\n","Epoch:  3309 | train loss: 0.068115 | valid loss: 0.085293\n","Epoch:  3310 | train loss: 0.085814 | valid loss: 0.085323\n","Epoch:  3311 | train loss: 0.092656 | valid loss: 0.085290\n","Epoch:  3312 | train loss: 0.059321 | valid loss: 0.085239\n","Epoch:  3313 | train loss: 0.093362 | valid loss: 0.085274\n","Epoch:  3314 | train loss: 0.062823 | valid loss: 0.085330\n","Epoch:  3315 | train loss: 0.088809 | valid loss: 0.085253\n","Epoch:  3316 | train loss: 0.071465 | valid loss: 0.085372\n","Epoch:  3317 | train loss: 0.063384 | valid loss: 0.085223\n","Epoch:  3318 | train loss: 0.062323 | valid loss: 0.085254\n","Epoch:  3319 | train loss: 0.083413 | valid loss: 0.085240\n","Epoch:  3320 | train loss: 0.117532 | valid loss: 0.085292\n","Epoch:  3321 | train loss: 0.068852 | valid loss: 0.085308\n","Epoch:  3322 | train loss: 0.075100 | valid loss: 0.085238\n","Epoch:  3323 | train loss: 0.073667 | valid loss: 0.085190\n","Epoch:  3324 | train loss: 0.067516 | valid loss: 0.085157\n","Epoch:  3325 | train loss: 0.073712 | valid loss: 0.085272\n","Epoch:  3326 | train loss: 0.072081 | valid loss: 0.085147\n","Epoch:  3327 | train loss: 0.092112 | valid loss: 0.085184\n","Epoch:  3328 | train loss: 0.095173 | valid loss: 0.085186\n","Epoch:  3329 | train loss: 0.088483 | valid loss: 0.085177\n","Epoch:  3330 | train loss: 0.108710 | valid loss: 0.085148\n","Epoch:  3331 | train loss: 0.114531 | valid loss: 0.085169\n","Epoch:  3332 | train loss: 0.075632 | valid loss: 0.085244\n","Epoch:  3333 | train loss: 0.073313 | valid loss: 0.085247\n","Epoch:  3334 | train loss: 0.097655 | valid loss: 0.085235\n","Epoch:  3335 | train loss: 0.083438 | valid loss: 0.085339\n","Epoch:  3336 | train loss: 0.079616 | valid loss: 0.085246\n","Epoch:  3337 | train loss: 0.074190 | valid loss: 0.085125\n","Epoch:  3338 | train loss: 0.084534 | valid loss: 0.085136\n","Epoch:  3339 | train loss: 0.085494 | valid loss: 0.085163\n","Epoch:  3340 | train loss: 0.100318 | valid loss: 0.085168\n","Epoch:  3341 | train loss: 0.078684 | valid loss: 0.085209\n","Epoch:  3342 | train loss: 0.080874 | valid loss: 0.085232\n","Epoch:  3343 | train loss: 0.091529 | valid loss: 0.085047\n","Epoch:  3344 | train loss: 0.064590 | valid loss: 0.085146\n","Epoch:  3345 | train loss: 0.092023 | valid loss: 0.085240\n","Epoch:  3346 | train loss: 0.093220 | valid loss: 0.085147\n","Epoch:  3347 | train loss: 0.079497 | valid loss: 0.085163\n","Epoch:  3348 | train loss: 0.081324 | valid loss: 0.085200\n","Epoch:  3349 | train loss: 0.096093 | valid loss: 0.085118\n","Epoch:  3350 | train loss: 0.104715 | valid loss: 0.085235\n","Epoch:  3351 | train loss: 0.077914 | valid loss: 0.085086\n","Epoch:  3352 | train loss: 0.108178 | valid loss: 0.085113\n","Epoch:  3353 | train loss: 0.102385 | valid loss: 0.085069\n","Epoch:  3354 | train loss: 0.090432 | valid loss: 0.085177\n","Epoch:  3355 | train loss: 0.106232 | valid loss: 0.085187\n","Epoch:  3356 | train loss: 0.100827 | valid loss: 0.085186\n","Epoch:  3357 | train loss: 0.093679 | valid loss: 0.085146\n","Epoch:  3358 | train loss: 0.063920 | valid loss: 0.085217\n","Epoch:  3359 | train loss: 0.080267 | valid loss: 0.085101\n","Epoch:  3360 | train loss: 0.127513 | valid loss: 0.085034\n","Epoch:  3361 | train loss: 0.073206 | valid loss: 0.085152\n","Epoch:  3362 | train loss: 0.090453 | valid loss: 0.085088\n","Epoch:  3363 | train loss: 0.069901 | valid loss: 0.085115\n","Epoch:  3364 | train loss: 0.068749 | valid loss: 0.085110\n","Epoch:  3365 | train loss: 0.076066 | valid loss: 0.085057\n","Epoch:  3366 | train loss: 0.095978 | valid loss: 0.085100\n","Epoch:  3367 | train loss: 0.140444 | valid loss: 0.085106\n","Epoch:  3368 | train loss: 0.073373 | valid loss: 0.085060\n","Epoch:  3369 | train loss: 0.105819 | valid loss: 0.085074\n","Epoch:  3370 | train loss: 0.078216 | valid loss: 0.085090\n","Epoch:  3371 | train loss: 0.085559 | valid loss: 0.085072\n","Epoch:  3372 | train loss: 0.082124 | valid loss: 0.085047\n","Epoch:  3373 | train loss: 0.075589 | valid loss: 0.085167\n","Epoch:  3374 | train loss: 0.109477 | valid loss: 0.085006\n","Epoch:  3375 | train loss: 0.245022 | valid loss: 0.085064\n","Epoch:  3376 | train loss: 0.078576 | valid loss: 0.085108\n","Epoch:  3377 | train loss: 0.071434 | valid loss: 0.085072\n","Epoch:  3378 | train loss: 0.072724 | valid loss: 0.085042\n","Epoch:  3379 | train loss: 0.073028 | valid loss: 0.085091\n","Epoch:  3380 | train loss: 0.098413 | valid loss: 0.085014\n","Epoch:  3381 | train loss: 0.080030 | valid loss: 0.084968\n","Epoch:  3382 | train loss: 0.104215 | valid loss: 0.084990\n","Epoch:  3383 | train loss: 0.091631 | valid loss: 0.085095\n","Epoch:  3384 | train loss: 0.085115 | valid loss: 0.084958\n","Epoch:  3385 | train loss: 0.070211 | valid loss: 0.085011\n","Epoch:  3386 | train loss: 0.093990 | valid loss: 0.085189\n","Epoch:  3387 | train loss: 0.087344 | valid loss: 0.084921\n","Epoch:  3388 | train loss: 0.076623 | valid loss: 0.085097\n","Epoch:  3389 | train loss: 0.092086 | valid loss: 0.085002\n","Epoch:  3390 | train loss: 0.108362 | valid loss: 0.084972\n","Epoch:  3391 | train loss: 0.070764 | valid loss: 0.085043\n","Epoch:  3392 | train loss: 0.095355 | valid loss: 0.085021\n","Epoch:  3393 | train loss: 0.083353 | valid loss: 0.084985\n","Epoch:  3394 | train loss: 0.078562 | valid loss: 0.085060\n","Epoch:  3395 | train loss: 0.083517 | valid loss: 0.085009\n","Epoch:  3396 | train loss: 0.080719 | valid loss: 0.085058\n","Epoch:  3397 | train loss: 0.103866 | valid loss: 0.084936\n","Epoch:  3398 | train loss: 0.105601 | valid loss: 0.084960\n","Epoch:  3399 | train loss: 0.087529 | valid loss: 0.084983\n","Epoch:  3400 | train loss: 0.078899 | valid loss: 0.084970\n","Epoch:  3401 | train loss: 0.089056 | valid loss: 0.085064\n","Epoch:  3402 | train loss: 0.251349 | valid loss: 0.084967\n","Epoch:  3403 | train loss: 0.088497 | valid loss: 0.084969\n","Epoch:  3404 | train loss: 0.093318 | valid loss: 0.084933\n","Epoch:  3405 | train loss: 0.273007 | valid loss: 0.085037\n","Epoch:  3406 | train loss: 0.097197 | valid loss: 0.084956\n","Epoch:  3407 | train loss: 0.083316 | valid loss: 0.084991\n","Epoch:  3408 | train loss: 0.072531 | valid loss: 0.084937\n","Epoch:  3409 | train loss: 0.063095 | valid loss: 0.084960\n","Epoch:  3410 | train loss: 0.076145 | valid loss: 0.084969\n","Epoch:  3411 | train loss: 0.080121 | valid loss: 0.084902\n","Epoch:  3412 | train loss: 0.080767 | valid loss: 0.084951\n","Epoch:  3413 | train loss: 0.076786 | valid loss: 0.084937\n","Epoch:  3414 | train loss: 0.103493 | valid loss: 0.084871\n","Epoch:  3415 | train loss: 0.072473 | valid loss: 0.085018\n","Epoch:  3416 | train loss: 0.095613 | valid loss: 0.084912\n","Epoch:  3417 | train loss: 0.058279 | valid loss: 0.084920\n","Epoch:  3418 | train loss: 0.086095 | valid loss: 0.085125\n","Epoch:  3419 | train loss: 0.102472 | valid loss: 0.085019\n","Epoch:  3420 | train loss: 0.087248 | valid loss: 0.084934\n","Epoch:  3421 | train loss: 0.075110 | valid loss: 0.084904\n","Epoch:  3422 | train loss: 0.081655 | valid loss: 0.084836\n","Epoch:  3423 | train loss: 0.084157 | valid loss: 0.084956\n","Epoch:  3424 | train loss: 0.075752 | valid loss: 0.084883\n","Epoch:  3425 | train loss: 0.064468 | valid loss: 0.084923\n","Epoch:  3426 | train loss: 0.092277 | valid loss: 0.084977\n","Epoch:  3427 | train loss: 0.074962 | valid loss: 0.084941\n","Epoch:  3428 | train loss: 0.116244 | valid loss: 0.084947\n","Epoch:  3429 | train loss: 0.076845 | valid loss: 0.084926\n","Epoch:  3430 | train loss: 0.078951 | valid loss: 0.084928\n","Epoch:  3431 | train loss: 0.258470 | valid loss: 0.084962\n","Epoch:  3432 | train loss: 0.082382 | valid loss: 0.084924\n","Epoch:  3433 | train loss: 0.102411 | valid loss: 0.084946\n","Epoch:  3434 | train loss: 0.100867 | valid loss: 0.084930\n","Epoch:  3435 | train loss: 0.064743 | valid loss: 0.084951\n","Epoch:  3436 | train loss: 0.092627 | valid loss: 0.084910\n","Epoch:  3437 | train loss: 0.081529 | valid loss: 0.084909\n","Epoch:  3438 | train loss: 0.102704 | valid loss: 0.084893\n","Epoch:  3439 | train loss: 0.092346 | valid loss: 0.084893\n","Epoch:  3440 | train loss: 0.104476 | valid loss: 0.084909\n","Epoch:  3441 | train loss: 0.089199 | valid loss: 0.084908\n","Epoch:  3442 | train loss: 0.106304 | valid loss: 0.084964\n","Epoch:  3443 | train loss: 0.093619 | valid loss: 0.084916\n","Epoch:  3444 | train loss: 0.072560 | valid loss: 0.084857\n","Epoch:  3445 | train loss: 0.092273 | valid loss: 0.084829\n","Epoch:  3446 | train loss: 0.085555 | valid loss: 0.084870\n","Epoch:  3447 | train loss: 0.071611 | valid loss: 0.084877\n","Epoch:  3448 | train loss: 0.066049 | valid loss: 0.084854\n","Epoch:  3449 | train loss: 0.086121 | valid loss: 0.084874\n","Epoch:  3450 | train loss: 0.066290 | valid loss: 0.084855\n","Epoch:  3451 | train loss: 0.092771 | valid loss: 0.084878\n","Epoch:  3452 | train loss: 0.083063 | valid loss: 0.084875\n","Epoch:  3453 | train loss: 0.083040 | valid loss: 0.084860\n","Epoch:  3454 | train loss: 0.066290 | valid loss: 0.084834\n","Epoch:  3455 | train loss: 0.078828 | valid loss: 0.084916\n","Epoch:  3456 | train loss: 0.077552 | valid loss: 0.085023\n","Epoch:  3457 | train loss: 0.073348 | valid loss: 0.084952\n","Epoch:  3458 | train loss: 0.075236 | valid loss: 0.084869\n","Epoch:  3459 | train loss: 0.068117 | valid loss: 0.085004\n","Epoch:  3460 | train loss: 0.083173 | valid loss: 0.084831\n","Epoch:  3461 | train loss: 0.114041 | valid loss: 0.084746\n","Epoch:  3462 | train loss: 0.102618 | valid loss: 0.084884\n","Epoch:  3463 | train loss: 0.089298 | valid loss: 0.084952\n","Epoch:  3464 | train loss: 0.085859 | valid loss: 0.084849\n","Epoch:  3465 | train loss: 0.067893 | valid loss: 0.084930\n","Epoch:  3466 | train loss: 0.064693 | valid loss: 0.084940\n","Epoch:  3467 | train loss: 0.098294 | valid loss: 0.084833\n","Epoch:  3468 | train loss: 0.084620 | valid loss: 0.084763\n","Epoch:  3469 | train loss: 0.094103 | valid loss: 0.084881\n","Epoch:  3470 | train loss: 0.094732 | valid loss: 0.084957\n","Epoch:  3471 | train loss: 0.081751 | valid loss: 0.084821\n","Epoch:  3472 | train loss: 0.078839 | valid loss: 0.084936\n","Epoch:  3473 | train loss: 0.077415 | valid loss: 0.084754\n","Epoch:  3474 | train loss: 0.097513 | valid loss: 0.084798\n","Epoch:  3475 | train loss: 0.060732 | valid loss: 0.084844\n","Epoch:  3476 | train loss: 0.077095 | valid loss: 0.084742\n","Epoch:  3477 | train loss: 0.066722 | valid loss: 0.084854\n","Epoch:  3478 | train loss: 0.078245 | valid loss: 0.084811\n","Epoch:  3479 | train loss: 0.100718 | valid loss: 0.084917\n","Epoch:  3480 | train loss: 0.071838 | valid loss: 0.084813\n","Epoch:  3481 | train loss: 0.084835 | valid loss: 0.084913\n","Epoch:  3482 | train loss: 0.086267 | valid loss: 0.084825\n","Epoch:  3483 | train loss: 0.104347 | valid loss: 0.084818\n","Epoch:  3484 | train loss: 0.083763 | valid loss: 0.084824\n","Epoch:  3485 | train loss: 0.073197 | valid loss: 0.084822\n","Epoch:  3486 | train loss: 0.082466 | valid loss: 0.084803\n","Epoch:  3487 | train loss: 0.094715 | valid loss: 0.084831\n","Epoch:  3488 | train loss: 0.092775 | valid loss: 0.084904\n","Epoch:  3489 | train loss: 0.068433 | valid loss: 0.084832\n","Epoch:  3490 | train loss: 0.068804 | valid loss: 0.084885\n","Epoch:  3491 | train loss: 0.098130 | valid loss: 0.084775\n","Epoch:  3492 | train loss: 0.080219 | valid loss: 0.084776\n","Epoch:  3493 | train loss: 0.097341 | valid loss: 0.084810\n","Epoch:  3494 | train loss: 0.072269 | valid loss: 0.084794\n","Epoch:  3495 | train loss: 0.112660 | valid loss: 0.084743\n","Epoch:  3496 | train loss: 0.096485 | valid loss: 0.084831\n","Epoch:  3497 | train loss: 0.095165 | valid loss: 0.084926\n","Epoch:  3498 | train loss: 0.082637 | valid loss: 0.084909\n","Epoch:  3499 | train loss: 0.075959 | valid loss: 0.084945\n","Epoch:  3500 | train loss: 0.102803 | valid loss: 0.084930\n","Epoch:  3501 | train loss: 0.081095 | valid loss: 0.084808\n","Epoch:  3502 | train loss: 0.119921 | valid loss: 0.084894\n","Epoch:  3503 | train loss: 0.115017 | valid loss: 0.084765\n","Epoch:  3504 | train loss: 0.082464 | valid loss: 0.084728\n","Epoch:  3505 | train loss: 0.084125 | valid loss: 0.084845\n","Epoch:  3506 | train loss: 0.108846 | valid loss: 0.084773\n","Epoch:  3507 | train loss: 0.079927 | valid loss: 0.084812\n","Epoch:  3508 | train loss: 0.068948 | valid loss: 0.084760\n","Epoch:  3509 | train loss: 0.090316 | valid loss: 0.084759\n","Epoch:  3510 | train loss: 0.088627 | valid loss: 0.084824\n","Epoch:  3511 | train loss: 0.101690 | valid loss: 0.084722\n","Epoch:  3512 | train loss: 0.085936 | valid loss: 0.084756\n","Epoch:  3513 | train loss: 0.075211 | valid loss: 0.084888\n","Epoch:  3514 | train loss: 0.124507 | valid loss: 0.084763\n","Epoch:  3515 | train loss: 0.084961 | valid loss: 0.084789\n","Epoch:  3516 | train loss: 0.062484 | valid loss: 0.084754\n","Epoch:  3517 | train loss: 0.074235 | valid loss: 0.084779\n","Epoch:  3518 | train loss: 0.078006 | valid loss: 0.084720\n","Epoch:  3519 | train loss: 0.067621 | valid loss: 0.084861\n","Epoch:  3520 | train loss: 0.079880 | valid loss: 0.084770\n","Epoch:  3521 | train loss: 0.102689 | valid loss: 0.084759\n","Epoch:  3522 | train loss: 0.062726 | valid loss: 0.084801\n","Epoch:  3523 | train loss: 0.082501 | valid loss: 0.084762\n","Epoch:  3524 | train loss: 0.074541 | valid loss: 0.084714\n","Epoch:  3525 | train loss: 0.089309 | valid loss: 0.084807\n","Epoch:  3526 | train loss: 0.076483 | valid loss: 0.084795\n","Epoch:  3527 | train loss: 0.074451 | valid loss: 0.084748\n","Epoch:  3528 | train loss: 0.083311 | valid loss: 0.084737\n","Epoch:  3529 | train loss: 0.076459 | valid loss: 0.084835\n","Epoch:  3530 | train loss: 0.076765 | valid loss: 0.084770\n","Epoch:  3531 | train loss: 0.078149 | valid loss: 0.084795\n","Epoch:  3532 | train loss: 0.109209 | valid loss: 0.084742\n","Epoch:  3533 | train loss: 0.079964 | valid loss: 0.084858\n","Epoch:  3534 | train loss: 0.083367 | valid loss: 0.084830\n","Epoch:  3535 | train loss: 0.061990 | valid loss: 0.084731\n","Epoch:  3536 | train loss: 0.083158 | valid loss: 0.084771\n","Epoch:  3537 | train loss: 0.092746 | valid loss: 0.084753\n","Epoch:  3538 | train loss: 0.068608 | valid loss: 0.084784\n","Epoch:  3539 | train loss: 0.073571 | valid loss: 0.084758\n","Epoch:  3540 | train loss: 0.062529 | valid loss: 0.084819\n","Epoch:  3541 | train loss: 0.073927 | valid loss: 0.084887\n","Epoch:  3542 | train loss: 0.099064 | valid loss: 0.084655\n","Epoch:  3543 | train loss: 0.074776 | valid loss: 0.084673\n","Epoch:  3544 | train loss: 0.098229 | valid loss: 0.084662\n","Epoch:  3545 | train loss: 0.075048 | valid loss: 0.084650\n","Epoch:  3546 | train loss: 0.095771 | valid loss: 0.084756\n","Epoch:  3547 | train loss: 0.102780 | valid loss: 0.084603\n","Epoch:  3548 | train loss: 0.091465 | valid loss: 0.084726\n","Epoch:  3549 | train loss: 0.092199 | valid loss: 0.084726\n","Epoch:  3550 | train loss: 0.082183 | valid loss: 0.084655\n","Epoch:  3551 | train loss: 0.066485 | valid loss: 0.084759\n","Epoch:  3552 | train loss: 0.097892 | valid loss: 0.084803\n","Epoch:  3553 | train loss: 0.117602 | valid loss: 0.084829\n","Epoch:  3554 | train loss: 0.101665 | valid loss: 0.084768\n","Epoch:  3555 | train loss: 0.096815 | valid loss: 0.084766\n","Epoch:  3556 | train loss: 0.088628 | valid loss: 0.084755\n","Epoch:  3557 | train loss: 0.085987 | valid loss: 0.084738\n","Epoch:  3558 | train loss: 0.097458 | valid loss: 0.084707\n","Epoch:  3559 | train loss: 0.081999 | valid loss: 0.084713\n","Epoch:  3560 | train loss: 0.062808 | valid loss: 0.084706\n","Epoch:  3561 | train loss: 0.086739 | valid loss: 0.084788\n","Epoch:  3562 | train loss: 0.089834 | valid loss: 0.084688\n","Epoch:  3563 | train loss: 0.070903 | valid loss: 0.084684\n","Epoch:  3564 | train loss: 0.082836 | valid loss: 0.084709\n","Epoch:  3565 | train loss: 0.078935 | valid loss: 0.084760\n","Epoch:  3566 | train loss: 0.060478 | valid loss: 0.084760\n","Epoch:  3567 | train loss: 0.075184 | valid loss: 0.084765\n","Epoch:  3568 | train loss: 0.065173 | valid loss: 0.084751\n","Epoch:  3569 | train loss: 0.094070 | valid loss: 0.084653\n","Epoch:  3570 | train loss: 0.073105 | valid loss: 0.084703\n","Epoch:  3571 | train loss: 0.100217 | valid loss: 0.084689\n","Epoch:  3572 | train loss: 0.086989 | valid loss: 0.084742\n","Epoch:  3573 | train loss: 0.066294 | valid loss: 0.084754\n","Epoch:  3574 | train loss: 0.083237 | valid loss: 0.084822\n","Epoch:  3575 | train loss: 0.065430 | valid loss: 0.084740\n","Epoch:  3576 | train loss: 0.062894 | valid loss: 0.084740\n","Epoch:  3577 | train loss: 0.093505 | valid loss: 0.084795\n","Epoch:  3578 | train loss: 0.085875 | valid loss: 0.084716\n","Epoch:  3579 | train loss: 0.067165 | valid loss: 0.084623\n","Epoch:  3580 | train loss: 0.115333 | valid loss: 0.084868\n","Epoch:  3581 | train loss: 0.067369 | valid loss: 0.084629\n","Epoch:  3582 | train loss: 0.086806 | valid loss: 0.084770\n","Epoch:  3583 | train loss: 0.105663 | valid loss: 0.084681\n","Epoch:  3584 | train loss: 0.082501 | valid loss: 0.084764\n","Epoch:  3585 | train loss: 0.086025 | valid loss: 0.084708\n","Epoch:  3586 | train loss: 0.081511 | valid loss: 0.084607\n","Epoch:  3587 | train loss: 0.090871 | valid loss: 0.084638\n","Epoch:  3588 | train loss: 0.091072 | valid loss: 0.084674\n","Epoch:  3589 | train loss: 0.084522 | valid loss: 0.084678\n","Epoch:  3590 | train loss: 0.071673 | valid loss: 0.084594\n","Epoch:  3591 | train loss: 0.104398 | valid loss: 0.084687\n","Epoch:  3592 | train loss: 0.083047 | valid loss: 0.084640\n","Epoch:  3593 | train loss: 0.100462 | valid loss: 0.084722\n","Epoch:  3594 | train loss: 0.098277 | valid loss: 0.084762\n","Epoch:  3595 | train loss: 0.072401 | valid loss: 0.084616\n","Epoch:  3596 | train loss: 0.076333 | valid loss: 0.084644\n","Epoch:  3597 | train loss: 0.084308 | valid loss: 0.084710\n","Epoch:  3598 | train loss: 0.081009 | valid loss: 0.084712\n","Epoch:  3599 | train loss: 0.102346 | valid loss: 0.084671\n","Epoch:  3600 | train loss: 0.088967 | valid loss: 0.084658\n","Epoch:  3601 | train loss: 0.072331 | valid loss: 0.084641\n","Epoch:  3602 | train loss: 0.119927 | valid loss: 0.084684\n","Epoch:  3603 | train loss: 0.093070 | valid loss: 0.084609\n","Epoch:  3604 | train loss: 0.084335 | valid loss: 0.084700\n","Epoch:  3605 | train loss: 0.110671 | valid loss: 0.084598\n","Epoch:  3606 | train loss: 0.081511 | valid loss: 0.084652\n","Epoch:  3607 | train loss: 0.098450 | valid loss: 0.084565\n","Epoch:  3608 | train loss: 0.092412 | valid loss: 0.084674\n","Epoch:  3609 | train loss: 0.080877 | valid loss: 0.084721\n","Epoch:  3610 | train loss: 0.085330 | valid loss: 0.084648\n","Epoch:  3611 | train loss: 0.104534 | valid loss: 0.084607\n","Epoch:  3612 | train loss: 0.096037 | valid loss: 0.084603\n","Epoch:  3613 | train loss: 0.068834 | valid loss: 0.084697\n","Epoch:  3614 | train loss: 0.092351 | valid loss: 0.084779\n","Epoch:  3615 | train loss: 0.070138 | valid loss: 0.084802\n","Epoch:  3616 | train loss: 0.079809 | valid loss: 0.084726\n","Epoch:  3617 | train loss: 0.068845 | valid loss: 0.084648\n","Epoch:  3618 | train loss: 0.080457 | valid loss: 0.084547\n","Epoch:  3619 | train loss: 0.077505 | valid loss: 0.084678\n","Epoch:  3620 | train loss: 0.064973 | valid loss: 0.084564\n","Epoch:  3621 | train loss: 0.074662 | valid loss: 0.084834\n","Epoch:  3622 | train loss: 0.081071 | valid loss: 0.084639\n","Epoch:  3623 | train loss: 0.063908 | valid loss: 0.084620\n","Epoch:  3624 | train loss: 0.081311 | valid loss: 0.084657\n","Epoch:  3625 | train loss: 0.074001 | valid loss: 0.084665\n","Epoch:  3626 | train loss: 0.096419 | valid loss: 0.084704\n","Epoch:  3627 | train loss: 0.091286 | valid loss: 0.084653\n","Epoch:  3628 | train loss: 0.086418 | valid loss: 0.084668\n","Epoch:  3629 | train loss: 0.084405 | valid loss: 0.084627\n","Epoch:  3630 | train loss: 0.082339 | valid loss: 0.084553\n","Epoch:  3631 | train loss: 0.107940 | valid loss: 0.084642\n","Epoch:  3632 | train loss: 0.074918 | valid loss: 0.084629\n","Epoch:  3633 | train loss: 0.082825 | valid loss: 0.084603\n","Epoch:  3634 | train loss: 0.111562 | valid loss: 0.084682\n","Epoch:  3635 | train loss: 0.103927 | valid loss: 0.084759\n","Epoch:  3636 | train loss: 0.075686 | valid loss: 0.084610\n","Epoch:  3637 | train loss: 0.086747 | valid loss: 0.084738\n","Epoch:  3638 | train loss: 0.081317 | valid loss: 0.084780\n","Epoch:  3639 | train loss: 0.064412 | valid loss: 0.084634\n","Epoch:  3640 | train loss: 0.087334 | valid loss: 0.084612\n","Epoch:  3641 | train loss: 0.077534 | valid loss: 0.084608\n","Epoch:  3642 | train loss: 0.068882 | valid loss: 0.084648\n","Epoch:  3643 | train loss: 0.094438 | valid loss: 0.084571\n","Epoch:  3644 | train loss: 0.071921 | valid loss: 0.084577\n","Epoch:  3645 | train loss: 0.073122 | valid loss: 0.084575\n","Epoch:  3646 | train loss: 0.095760 | valid loss: 0.084594\n","Epoch:  3647 | train loss: 0.067953 | valid loss: 0.084628\n","Epoch:  3648 | train loss: 0.093891 | valid loss: 0.084609\n","Epoch:  3649 | train loss: 0.110423 | valid loss: 0.084642\n","Epoch:  3650 | train loss: 0.101342 | valid loss: 0.084666\n","Epoch:  3651 | train loss: 0.064436 | valid loss: 0.084544\n","Epoch:  3652 | train loss: 0.080975 | valid loss: 0.084562\n","Epoch:  3653 | train loss: 0.085072 | valid loss: 0.084652\n","Epoch:  3654 | train loss: 0.078293 | valid loss: 0.084526\n","Epoch:  3655 | train loss: 0.084364 | valid loss: 0.084646\n","Epoch:  3656 | train loss: 0.090775 | valid loss: 0.084672\n","Epoch:  3657 | train loss: 0.089499 | valid loss: 0.084672\n","Epoch:  3658 | train loss: 0.100172 | valid loss: 0.084628\n","Epoch:  3659 | train loss: 0.070229 | valid loss: 0.084603\n","Epoch:  3660 | train loss: 0.094862 | valid loss: 0.084658\n","Epoch:  3661 | train loss: 0.069948 | valid loss: 0.084591\n","Epoch:  3662 | train loss: 0.079117 | valid loss: 0.084606\n","Epoch:  3663 | train loss: 0.079430 | valid loss: 0.084676\n","Epoch:  3664 | train loss: 0.096838 | valid loss: 0.084631\n","Epoch:  3665 | train loss: 0.088063 | valid loss: 0.084502\n","Epoch:  3666 | train loss: 0.072216 | valid loss: 0.084610\n","Epoch:  3667 | train loss: 0.083573 | valid loss: 0.084606\n","Epoch:  3668 | train loss: 0.077160 | valid loss: 0.084639\n","Epoch:  3669 | train loss: 0.086744 | valid loss: 0.084562\n","Epoch:  3670 | train loss: 0.073333 | valid loss: 0.084656\n","Epoch:  3671 | train loss: 0.098114 | valid loss: 0.084639\n","Epoch:  3672 | train loss: 0.112764 | valid loss: 0.084674\n","Epoch:  3673 | train loss: 0.101455 | valid loss: 0.084676\n","Epoch:  3674 | train loss: 0.121276 | valid loss: 0.084597\n","Epoch:  3675 | train loss: 0.097516 | valid loss: 0.084519\n","Epoch:  3676 | train loss: 0.101552 | valid loss: 0.084581\n","Epoch:  3677 | train loss: 0.087733 | valid loss: 0.084646\n","Epoch:  3678 | train loss: 0.099246 | valid loss: 0.084661\n","Epoch:  3679 | train loss: 0.080350 | valid loss: 0.084653\n","Epoch:  3680 | train loss: 0.075177 | valid loss: 0.084559\n","Epoch:  3681 | train loss: 0.249231 | valid loss: 0.084556\n","Epoch:  3682 | train loss: 0.075192 | valid loss: 0.084698\n","Epoch:  3683 | train loss: 0.081331 | valid loss: 0.084538\n","Epoch:  3684 | train loss: 0.072004 | valid loss: 0.084543\n","Epoch:  3685 | train loss: 0.070171 | valid loss: 0.084594\n","Epoch:  3686 | train loss: 0.075546 | valid loss: 0.084608\n","Epoch:  3687 | train loss: 0.084479 | valid loss: 0.084551\n","Epoch:  3688 | train loss: 0.083207 | valid loss: 0.084625\n","Epoch:  3689 | train loss: 0.099028 | valid loss: 0.084534\n","Epoch:  3690 | train loss: 0.108137 | valid loss: 0.084593\n","Epoch:  3691 | train loss: 0.091405 | valid loss: 0.084625\n","Epoch:  3692 | train loss: 0.082603 | valid loss: 0.084590\n","Epoch:  3693 | train loss: 0.089715 | valid loss: 0.084673\n","Epoch:  3694 | train loss: 0.071930 | valid loss: 0.084559\n","Epoch:  3695 | train loss: 0.095217 | valid loss: 0.084603\n","Epoch:  3696 | train loss: 0.099831 | valid loss: 0.084562\n","Epoch:  3697 | train loss: 0.069088 | valid loss: 0.084613\n","Epoch:  3698 | train loss: 0.090958 | valid loss: 0.084585\n","Epoch:  3699 | train loss: 0.065984 | valid loss: 0.084685\n","Epoch:  3700 | train loss: 0.092027 | valid loss: 0.084599\n","Epoch:  3701 | train loss: 0.082069 | valid loss: 0.084484\n","Epoch:  3702 | train loss: 0.076972 | valid loss: 0.084539\n","Epoch:  3703 | train loss: 0.061920 | valid loss: 0.084582\n","Epoch:  3704 | train loss: 0.100925 | valid loss: 0.084583\n","Epoch:  3705 | train loss: 0.073698 | valid loss: 0.084497\n","Epoch:  3706 | train loss: 0.099627 | valid loss: 0.084578\n","Epoch:  3707 | train loss: 0.077772 | valid loss: 0.084548\n","Epoch:  3708 | train loss: 0.071577 | valid loss: 0.084601\n","Epoch:  3709 | train loss: 0.080110 | valid loss: 0.084485\n","Epoch:  3710 | train loss: 0.063774 | valid loss: 0.084535\n","Epoch:  3711 | train loss: 0.100748 | valid loss: 0.084614\n","Epoch:  3712 | train loss: 0.117298 | valid loss: 0.084641\n","Epoch:  3713 | train loss: 0.084362 | valid loss: 0.084549\n","Epoch:  3714 | train loss: 0.087659 | valid loss: 0.084614\n","Epoch:  3715 | train loss: 0.060578 | valid loss: 0.084543\n","Epoch:  3716 | train loss: 0.068785 | valid loss: 0.084634\n","Epoch:  3717 | train loss: 0.075948 | valid loss: 0.084578\n","Epoch:  3718 | train loss: 0.086721 | valid loss: 0.084607\n","Epoch:  3719 | train loss: 0.077166 | valid loss: 0.084561\n","Epoch:  3720 | train loss: 0.082136 | valid loss: 0.084598\n","Epoch:  3721 | train loss: 0.089715 | valid loss: 0.084606\n","Epoch:  3722 | train loss: 0.063206 | valid loss: 0.084546\n","Epoch:  3723 | train loss: 0.074829 | valid loss: 0.084635\n","Epoch:  3724 | train loss: 0.078787 | valid loss: 0.084496\n","Epoch:  3725 | train loss: 0.067785 | valid loss: 0.084557\n","Epoch:  3726 | train loss: 0.099016 | valid loss: 0.084529\n","Epoch:  3727 | train loss: 0.068141 | valid loss: 0.084517\n","Epoch:  3728 | train loss: 0.086663 | valid loss: 0.084605\n","Epoch:  3729 | train loss: 0.088126 | valid loss: 0.084551\n","Epoch:  3730 | train loss: 0.091431 | valid loss: 0.084569\n","Epoch:  3731 | train loss: 0.096865 | valid loss: 0.084609\n","Epoch:  3732 | train loss: 0.072826 | valid loss: 0.084627\n","Epoch:  3733 | train loss: 0.082289 | valid loss: 0.084617\n","Epoch:  3734 | train loss: 0.069618 | valid loss: 0.084553\n","Epoch:  3735 | train loss: 0.079839 | valid loss: 0.084567\n","Epoch:  3736 | train loss: 0.082288 | valid loss: 0.084596\n","Epoch:  3737 | train loss: 0.098672 | valid loss: 0.084569\n","Epoch:  3738 | train loss: 0.071596 | valid loss: 0.084503\n","Epoch:  3739 | train loss: 0.105589 | valid loss: 0.084629\n","Epoch:  3740 | train loss: 0.081505 | valid loss: 0.084532\n","Epoch:  3741 | train loss: 0.069441 | valid loss: 0.084688\n","Epoch:  3742 | train loss: 0.116995 | valid loss: 0.084497\n","Epoch:  3743 | train loss: 0.080480 | valid loss: 0.084494\n","Epoch:  3744 | train loss: 0.067320 | valid loss: 0.084577\n","Epoch:  3745 | train loss: 0.075388 | valid loss: 0.084488\n","Epoch:  3746 | train loss: 0.091158 | valid loss: 0.084601\n","Epoch:  3747 | train loss: 0.083757 | valid loss: 0.084508\n","Epoch:  3748 | train loss: 0.084812 | valid loss: 0.084560\n","Epoch:  3749 | train loss: 0.086967 | valid loss: 0.084561\n","Epoch:  3750 | train loss: 0.097174 | valid loss: 0.084585\n","Epoch:  3751 | train loss: 0.062484 | valid loss: 0.084471\n","Epoch:  3752 | train loss: 0.084043 | valid loss: 0.084759\n","Epoch:  3753 | train loss: 0.086360 | valid loss: 0.084594\n","Epoch:  3754 | train loss: 0.084102 | valid loss: 0.084571\n","Epoch:  3755 | train loss: 0.075006 | valid loss: 0.084475\n","Epoch:  3756 | train loss: 0.081692 | valid loss: 0.084532\n","Epoch:  3757 | train loss: 0.097433 | valid loss: 0.084617\n","Epoch:  3758 | train loss: 0.073779 | valid loss: 0.084539\n","Epoch:  3759 | train loss: 0.065920 | valid loss: 0.084571\n","Epoch:  3760 | train loss: 0.086961 | valid loss: 0.084528\n","Epoch:  3761 | train loss: 0.088029 | valid loss: 0.084505\n","Epoch:  3762 | train loss: 0.072945 | valid loss: 0.084552\n","Epoch:  3763 | train loss: 0.097362 | valid loss: 0.084515\n","Epoch:  3764 | train loss: 0.071615 | valid loss: 0.084631\n","Epoch:  3765 | train loss: 0.090983 | valid loss: 0.084529\n","Epoch:  3766 | train loss: 0.238308 | valid loss: 0.084492\n","Epoch:  3767 | train loss: 0.074127 | valid loss: 0.084531\n","Epoch:  3768 | train loss: 0.064754 | valid loss: 0.084547\n","Epoch:  3769 | train loss: 0.088116 | valid loss: 0.084470\n","Epoch:  3770 | train loss: 0.076761 | valid loss: 0.084502\n","Epoch:  3771 | train loss: 0.110337 | valid loss: 0.084522\n","Epoch:  3772 | train loss: 0.069905 | valid loss: 0.084556\n","Epoch:  3773 | train loss: 0.073330 | valid loss: 0.084532\n","Epoch:  3774 | train loss: 0.086379 | valid loss: 0.084531\n","Epoch:  3775 | train loss: 0.089525 | valid loss: 0.084572\n","Epoch:  3776 | train loss: 0.079093 | valid loss: 0.084601\n","Epoch:  3777 | train loss: 0.092816 | valid loss: 0.084485\n","Epoch:  3778 | train loss: 0.064491 | valid loss: 0.084514\n","Epoch:  3779 | train loss: 0.084517 | valid loss: 0.084545\n","Epoch:  3780 | train loss: 0.088812 | valid loss: 0.084597\n","Epoch:  3781 | train loss: 0.085724 | valid loss: 0.084538\n","Epoch:  3782 | train loss: 0.075876 | valid loss: 0.084577\n","Epoch:  3783 | train loss: 0.087138 | valid loss: 0.084521\n","Epoch:  3784 | train loss: 0.085522 | valid loss: 0.084522\n","Epoch:  3785 | train loss: 0.100738 | valid loss: 0.084567\n","Epoch:  3786 | train loss: 0.065370 | valid loss: 0.084497\n","Epoch:  3787 | train loss: 0.063818 | valid loss: 0.084498\n","Epoch:  3788 | train loss: 0.082266 | valid loss: 0.084566\n","Epoch:  3789 | train loss: 0.085474 | valid loss: 0.084524\n","Epoch:  3790 | train loss: 0.101717 | valid loss: 0.084680\n","Epoch:  3791 | train loss: 0.107022 | valid loss: 0.084456\n","Epoch:  3792 | train loss: 0.087822 | valid loss: 0.084580\n","Epoch:  3793 | train loss: 0.088458 | valid loss: 0.084581\n","Epoch:  3794 | train loss: 0.086163 | valid loss: 0.084451\n","Epoch:  3795 | train loss: 0.106222 | valid loss: 0.084572\n","Epoch:  3796 | train loss: 0.083261 | valid loss: 0.084630\n","Epoch:  3797 | train loss: 0.072659 | valid loss: 0.084464\n","Epoch:  3798 | train loss: 0.103179 | valid loss: 0.084463\n","Epoch:  3799 | train loss: 0.067950 | valid loss: 0.084579\n","Epoch:  3800 | train loss: 0.081367 | valid loss: 0.084461\n","Epoch:  3801 | train loss: 0.074435 | valid loss: 0.084501\n","Epoch:  3802 | train loss: 0.074887 | valid loss: 0.084540\n","Epoch:  3803 | train loss: 0.079962 | valid loss: 0.084473\n","Epoch:  3804 | train loss: 0.093497 | valid loss: 0.084543\n","Epoch:  3805 | train loss: 0.070056 | valid loss: 0.084654\n","Epoch:  3806 | train loss: 0.083979 | valid loss: 0.084556\n","Epoch:  3807 | train loss: 0.078154 | valid loss: 0.084583\n","Epoch:  3808 | train loss: 0.093861 | valid loss: 0.084582\n","Epoch:  3809 | train loss: 0.072040 | valid loss: 0.084561\n","Epoch:  3810 | train loss: 0.105128 | valid loss: 0.084584\n","Epoch:  3811 | train loss: 0.073873 | valid loss: 0.084552\n","Epoch:  3812 | train loss: 0.254562 | valid loss: 0.084459\n","Epoch:  3813 | train loss: 0.073136 | valid loss: 0.084543\n","Epoch:  3814 | train loss: 0.079726 | valid loss: 0.084530\n","Epoch:  3815 | train loss: 0.084279 | valid loss: 0.084536\n","Epoch:  3816 | train loss: 0.098446 | valid loss: 0.084524\n","Epoch:  3817 | train loss: 0.070111 | valid loss: 0.084584\n","Epoch:  3818 | train loss: 0.087903 | valid loss: 0.084544\n","Epoch:  3819 | train loss: 0.077836 | valid loss: 0.084428\n","Epoch:  3820 | train loss: 0.090084 | valid loss: 0.084446\n","Epoch:  3821 | train loss: 0.301961 | valid loss: 0.084517\n","Epoch:  3822 | train loss: 0.078340 | valid loss: 0.084466\n","Epoch:  3823 | train loss: 0.078997 | valid loss: 0.084541\n","Epoch:  3824 | train loss: 0.089804 | valid loss: 0.084502\n","Epoch:  3825 | train loss: 0.096350 | valid loss: 0.084547\n","Epoch:  3826 | train loss: 0.082452 | valid loss: 0.084498\n","Epoch:  3827 | train loss: 0.084904 | valid loss: 0.084428\n","Epoch:  3828 | train loss: 0.062799 | valid loss: 0.084609\n","Epoch:  3829 | train loss: 0.069186 | valid loss: 0.084516\n","Epoch:  3830 | train loss: 0.094534 | valid loss: 0.084567\n","Epoch:  3831 | train loss: 0.104716 | valid loss: 0.084530\n","Epoch:  3832 | train loss: 0.114758 | valid loss: 0.084561\n","Epoch:  3833 | train loss: 0.115822 | valid loss: 0.084573\n","Epoch:  3834 | train loss: 0.087224 | valid loss: 0.084459\n","Epoch:  3835 | train loss: 0.084350 | valid loss: 0.084496\n","Epoch:  3836 | train loss: 0.084119 | valid loss: 0.084392\n","Epoch:  3837 | train loss: 0.087552 | valid loss: 0.084450\n","Epoch:  3838 | train loss: 0.071334 | valid loss: 0.084489\n","Epoch:  3839 | train loss: 0.087318 | valid loss: 0.084630\n","Epoch:  3840 | train loss: 0.075404 | valid loss: 0.084555\n","Epoch:  3841 | train loss: 0.124653 | valid loss: 0.084543\n","Epoch:  3842 | train loss: 0.083068 | valid loss: 0.084492\n","Epoch:  3843 | train loss: 0.073124 | valid loss: 0.084554\n","Epoch:  3844 | train loss: 0.072342 | valid loss: 0.084465\n","Epoch:  3845 | train loss: 0.082524 | valid loss: 0.084522\n","Epoch:  3846 | train loss: 0.087503 | valid loss: 0.084499\n","Epoch:  3847 | train loss: 0.119733 | valid loss: 0.084489\n","Epoch:  3848 | train loss: 0.120554 | valid loss: 0.084484\n","Epoch:  3849 | train loss: 0.073636 | valid loss: 0.084546\n","Epoch:  3850 | train loss: 0.085604 | valid loss: 0.084441\n","Epoch:  3851 | train loss: 0.107128 | valid loss: 0.084524\n","Epoch:  3852 | train loss: 0.076175 | valid loss: 0.084521\n","Epoch:  3853 | train loss: 0.089157 | valid loss: 0.084543\n","Epoch:  3854 | train loss: 0.071987 | valid loss: 0.084521\n","Epoch:  3855 | train loss: 0.103542 | valid loss: 0.084552\n","Epoch:  3856 | train loss: 0.117065 | valid loss: 0.084535\n","Epoch:  3857 | train loss: 0.096874 | valid loss: 0.084609\n","Epoch:  3858 | train loss: 0.076287 | valid loss: 0.084505\n","Epoch:  3859 | train loss: 0.071506 | valid loss: 0.084517\n","Epoch:  3860 | train loss: 0.081867 | valid loss: 0.084450\n","Epoch:  3861 | train loss: 0.072706 | valid loss: 0.084555\n","Epoch:  3862 | train loss: 0.105211 | valid loss: 0.084546\n","Epoch:  3863 | train loss: 0.105911 | valid loss: 0.084439\n","Epoch:  3864 | train loss: 0.067320 | valid loss: 0.084547\n","Epoch:  3865 | train loss: 0.109225 | valid loss: 0.084583\n","Epoch:  3866 | train loss: 0.065713 | valid loss: 0.084416\n","Epoch:  3867 | train loss: 0.082495 | valid loss: 0.084422\n","Epoch:  3868 | train loss: 0.098378 | valid loss: 0.084425\n","Epoch:  3869 | train loss: 0.088153 | valid loss: 0.084605\n","Epoch:  3870 | train loss: 0.076272 | valid loss: 0.084517\n","Epoch:  3871 | train loss: 0.084185 | valid loss: 0.084508\n","Epoch:  3872 | train loss: 0.083838 | valid loss: 0.084606\n","Epoch:  3873 | train loss: 0.086685 | valid loss: 0.084572\n","Epoch:  3874 | train loss: 0.099396 | valid loss: 0.084552\n","Epoch:  3875 | train loss: 0.075460 | valid loss: 0.084472\n","Epoch:  3876 | train loss: 0.090297 | valid loss: 0.084489\n","Epoch:  3877 | train loss: 0.099196 | valid loss: 0.084584\n","Epoch:  3878 | train loss: 0.080909 | valid loss: 0.084470\n","Epoch:  3879 | train loss: 0.075039 | valid loss: 0.084458\n","Epoch:  3880 | train loss: 0.069927 | valid loss: 0.084537\n","Epoch:  3881 | train loss: 0.080671 | valid loss: 0.084406\n","Epoch:  3882 | train loss: 0.069292 | valid loss: 0.084522\n","Epoch:  3883 | train loss: 0.088862 | valid loss: 0.084540\n","Epoch:  3884 | train loss: 0.089492 | valid loss: 0.084566\n","Epoch:  3885 | train loss: 0.105449 | valid loss: 0.084453\n","Epoch:  3886 | train loss: 0.097048 | valid loss: 0.084517\n","Epoch:  3887 | train loss: 0.070604 | valid loss: 0.084543\n","Epoch:  3888 | train loss: 0.086108 | valid loss: 0.084556\n","Epoch:  3889 | train loss: 0.080238 | valid loss: 0.084560\n","Epoch:  3890 | train loss: 0.088175 | valid loss: 0.084525\n","Epoch:  3891 | train loss: 0.077467 | valid loss: 0.084475\n","Epoch:  3892 | train loss: 0.113366 | valid loss: 0.084492\n","Epoch:  3893 | train loss: 0.060085 | valid loss: 0.084600\n","Epoch:  3894 | train loss: 0.106570 | valid loss: 0.084446\n","Epoch:  3895 | train loss: 0.070169 | valid loss: 0.084459\n","Epoch:  3896 | train loss: 0.083101 | valid loss: 0.084461\n","Epoch:  3897 | train loss: 0.091266 | valid loss: 0.084487\n","Epoch:  3898 | train loss: 0.068466 | valid loss: 0.084467\n","Epoch:  3899 | train loss: 0.081620 | valid loss: 0.084516\n","Epoch:  3900 | train loss: 0.081139 | valid loss: 0.084426\n","Epoch:  3901 | train loss: 0.092068 | valid loss: 0.084571\n","Epoch:  3902 | train loss: 0.071292 | valid loss: 0.084494\n","Epoch:  3903 | train loss: 0.082738 | valid loss: 0.084459\n","Epoch:  3904 | train loss: 0.087062 | valid loss: 0.084629\n","Epoch:  3905 | train loss: 0.074437 | valid loss: 0.084406\n","Epoch:  3906 | train loss: 0.064636 | valid loss: 0.084581\n","Epoch:  3907 | train loss: 0.081385 | valid loss: 0.084397\n","Epoch:  3908 | train loss: 0.082845 | valid loss: 0.084546\n","Epoch:  3909 | train loss: 0.095991 | valid loss: 0.084552\n","Epoch:  3910 | train loss: 0.072454 | valid loss: 0.084556\n","Epoch:  3911 | train loss: 0.078808 | valid loss: 0.084491\n","Epoch:  3912 | train loss: 0.081441 | valid loss: 0.084462\n","Epoch:  3913 | train loss: 0.079406 | valid loss: 0.084442\n","Epoch:  3914 | train loss: 0.077361 | valid loss: 0.084399\n","Epoch:  3915 | train loss: 0.103946 | valid loss: 0.084421\n","Epoch:  3916 | train loss: 0.241599 | valid loss: 0.084659\n","Epoch:  3917 | train loss: 0.075700 | valid loss: 0.084535\n","Epoch:  3918 | train loss: 0.082622 | valid loss: 0.084519\n","Epoch:  3919 | train loss: 0.067370 | valid loss: 0.084508\n","Epoch:  3920 | train loss: 0.063280 | valid loss: 0.084577\n","Epoch:  3921 | train loss: 0.084736 | valid loss: 0.084448\n","Epoch:  3922 | train loss: 0.093834 | valid loss: 0.084414\n","Epoch:  3923 | train loss: 0.066364 | valid loss: 0.084436\n","Epoch:  3924 | train loss: 0.082111 | valid loss: 0.084414\n","Epoch:  3925 | train loss: 0.082834 | valid loss: 0.084514\n","Epoch:  3926 | train loss: 0.120143 | valid loss: 0.084383\n","Epoch:  3927 | train loss: 0.110799 | valid loss: 0.084542\n","Epoch:  3928 | train loss: 0.099266 | valid loss: 0.084475\n","Epoch:  3929 | train loss: 0.075893 | valid loss: 0.084453\n","Epoch:  3930 | train loss: 0.104666 | valid loss: 0.084522\n","Epoch:  3931 | train loss: 0.093298 | valid loss: 0.084424\n","Epoch:  3932 | train loss: 0.081595 | valid loss: 0.084522\n","Epoch:  3933 | train loss: 0.080337 | valid loss: 0.084583\n","Epoch:  3934 | train loss: 0.085200 | valid loss: 0.084381\n","Epoch:  3935 | train loss: 0.079601 | valid loss: 0.084477\n","Epoch:  3936 | train loss: 0.103001 | valid loss: 0.084445\n","Epoch:  3937 | train loss: 0.075294 | valid loss: 0.084444\n","Epoch:  3938 | train loss: 0.096047 | valid loss: 0.084619\n","Epoch:  3939 | train loss: 0.097652 | valid loss: 0.084532\n","Epoch:  3940 | train loss: 0.105058 | valid loss: 0.084509\n","Epoch:  3941 | train loss: 0.076937 | valid loss: 0.084495\n","Epoch:  3942 | train loss: 0.086018 | valid loss: 0.084407\n","Epoch:  3943 | train loss: 0.068896 | valid loss: 0.084420\n","Epoch:  3944 | train loss: 0.091690 | valid loss: 0.084510\n","Epoch:  3945 | train loss: 0.096139 | valid loss: 0.084516\n","Epoch:  3946 | train loss: 0.102836 | valid loss: 0.084525\n","Epoch:  3947 | train loss: 0.081528 | valid loss: 0.084527\n","Epoch:  3948 | train loss: 0.107042 | valid loss: 0.084527\n","Epoch:  3949 | train loss: 0.109256 | valid loss: 0.084437\n","Epoch:  3950 | train loss: 0.066119 | valid loss: 0.084438\n","Epoch:  3951 | train loss: 0.068082 | valid loss: 0.084471\n","Epoch:  3952 | train loss: 0.088431 | valid loss: 0.084410\n","Epoch:  3953 | train loss: 0.082676 | valid loss: 0.084451\n","Epoch:  3954 | train loss: 0.090794 | valid loss: 0.084373\n","Epoch:  3955 | train loss: 0.096509 | valid loss: 0.084462\n","Epoch:  3956 | train loss: 0.074122 | valid loss: 0.084420\n","Epoch:  3957 | train loss: 0.099696 | valid loss: 0.084430\n","Epoch:  3958 | train loss: 0.122350 | valid loss: 0.084442\n","Epoch:  3959 | train loss: 0.074991 | valid loss: 0.084530\n","Epoch:  3960 | train loss: 0.092952 | valid loss: 0.084478\n","Epoch:  3961 | train loss: 0.074014 | valid loss: 0.084466\n","Epoch:  3962 | train loss: 0.075209 | valid loss: 0.084542\n","Epoch:  3963 | train loss: 0.100063 | valid loss: 0.084480\n","Epoch:  3964 | train loss: 0.080490 | valid loss: 0.084467\n","Epoch:  3965 | train loss: 0.080361 | valid loss: 0.084438\n","Epoch:  3966 | train loss: 0.076303 | valid loss: 0.084497\n","Epoch:  3967 | train loss: 0.081541 | valid loss: 0.084463\n","Epoch:  3968 | train loss: 0.074089 | valid loss: 0.084535\n","Epoch:  3969 | train loss: 0.098347 | valid loss: 0.084440\n","Epoch:  3970 | train loss: 0.080525 | valid loss: 0.084479\n","Epoch:  3971 | train loss: 0.090988 | valid loss: 0.084540\n","Epoch:  3972 | train loss: 0.080153 | valid loss: 0.084409\n","Epoch:  3973 | train loss: 0.066095 | valid loss: 0.084433\n","Epoch:  3974 | train loss: 0.084982 | valid loss: 0.084457\n","Epoch:  3975 | train loss: 0.089241 | valid loss: 0.084462\n","Epoch:  3976 | train loss: 0.262792 | valid loss: 0.084511\n","Epoch:  3977 | train loss: 0.080066 | valid loss: 0.084503\n","Epoch:  3978 | train loss: 0.080395 | valid loss: 0.084423\n","Epoch:  3979 | train loss: 0.076980 | valid loss: 0.084494\n","Epoch:  3980 | train loss: 0.090896 | valid loss: 0.084559\n","Epoch:  3981 | train loss: 0.079501 | valid loss: 0.084549\n","Epoch:  3982 | train loss: 0.063171 | valid loss: 0.084447\n","Epoch:  3983 | train loss: 0.080249 | valid loss: 0.084431\n","Epoch:  3984 | train loss: 0.094524 | valid loss: 0.084389\n","Epoch:  3985 | train loss: 0.076818 | valid loss: 0.084499\n","Epoch:  3986 | train loss: 0.099227 | valid loss: 0.084521\n","Epoch:  3987 | train loss: 0.085352 | valid loss: 0.084569\n","Epoch:  3988 | train loss: 0.076579 | valid loss: 0.084402\n","Epoch:  3989 | train loss: 0.111770 | valid loss: 0.084430\n","Epoch:  3990 | train loss: 0.076043 | valid loss: 0.084439\n","Epoch:  3991 | train loss: 0.079735 | valid loss: 0.084428\n","Epoch:  3992 | train loss: 0.130536 | valid loss: 0.084452\n","Epoch:  3993 | train loss: 0.077125 | valid loss: 0.084490\n","Epoch:  3994 | train loss: 0.065487 | valid loss: 0.084427\n","Epoch:  3995 | train loss: 0.094337 | valid loss: 0.084418\n","Epoch:  3996 | train loss: 0.074002 | valid loss: 0.084433\n","Epoch:  3997 | train loss: 0.099458 | valid loss: 0.084349\n","Epoch:  3998 | train loss: 0.094679 | valid loss: 0.084455\n","Epoch:  3999 | train loss: 0.089209 | valid loss: 0.084580\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvCI0FNbdUJk","executionInfo":{"status":"ok","timestamp":1629655306747,"user_tz":-60,"elapsed":50,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"c6d26843-4691-454c-c450-612c64c95dc7"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Train time: 544.9603374004364\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"GIVslDntcXha","executionInfo":{"status":"ok","timestamp":1629655306755,"user_tz":-60,"elapsed":26,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"adf9e7e9-bfad-4fcf-f91a-9be4066d652f"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":78},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXUv2whGL6v8","executionInfo":{"status":"ok","timestamp":1629655314703,"user_tz":-60,"elapsed":7214,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"06a0294c-1c47-4efd-9931-24743e3761a5"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":79,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 0.003366164768415443\n","MSE_err of valid data 0.0032928731292398905\n","MSE_err of test data 0.0030891863707805285\n","MSE_err of total data 0.003331137764734397\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"p3cd6XnAv0iK"},"source":["#### 4 variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeZWS1Rdy9uR","executionInfo":{"status":"ok","timestamp":1629653111205,"user_tz":-60,"elapsed":25,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"fc4be722-783c-4c7a-916a-cf9c800e0a75"},"source":["print(\"compress to 4\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 2000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["compress to 4\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kN3LaXSbfrmA","executionInfo":{"status":"ok","timestamp":1629653347519,"user_tz":-60,"elapsed":236335,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"59a74d4d-0574-4996-a62c-a66871537f9f"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(4).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 1.836691 | valid loss: 1.820652\n","Epoch:  1 | train loss: 1.728661 | valid loss: 1.683463\n","Epoch:  2 | train loss: 1.439858 | valid loss: 1.454947\n","Epoch:  3 | train loss: 1.222590 | valid loss: 1.187183\n","Epoch:  4 | train loss: 0.914699 | valid loss: 0.899866\n","Epoch:  5 | train loss: 0.672735 | valid loss: 0.638720\n","Epoch:  6 | train loss: 0.423525 | valid loss: 0.430790\n","Epoch:  7 | train loss: 0.311230 | valid loss: 0.287448\n","Epoch:  8 | train loss: 0.229511 | valid loss: 0.201431\n","Epoch:  9 | train loss: 0.161116 | valid loss: 0.154255\n","Epoch:  10 | train loss: 0.149023 | valid loss: 0.130723\n","Epoch:  11 | train loss: 0.103729 | valid loss: 0.118028\n","Epoch:  12 | train loss: 0.102501 | valid loss: 0.110753\n","Epoch:  13 | train loss: 0.110024 | valid loss: 0.105592\n","Epoch:  14 | train loss: 0.116104 | valid loss: 0.102343\n","Epoch:  15 | train loss: 0.085987 | valid loss: 0.099402\n","Epoch:  16 | train loss: 0.085494 | valid loss: 0.097364\n","Epoch:  17 | train loss: 0.089345 | valid loss: 0.095866\n","Epoch:  18 | train loss: 0.089174 | valid loss: 0.093841\n","Epoch:  19 | train loss: 0.081353 | valid loss: 0.093040\n","Epoch:  20 | train loss: 0.074265 | valid loss: 0.091262\n","Epoch:  21 | train loss: 0.068196 | valid loss: 0.090343\n","Epoch:  22 | train loss: 0.078561 | valid loss: 0.089175\n","Epoch:  23 | train loss: 0.099442 | valid loss: 0.088193\n","Epoch:  24 | train loss: 0.068438 | valid loss: 0.087010\n","Epoch:  25 | train loss: 0.094587 | valid loss: 0.085547\n","Epoch:  26 | train loss: 0.068433 | valid loss: 0.084487\n","Epoch:  27 | train loss: 0.074619 | valid loss: 0.083088\n","Epoch:  28 | train loss: 0.065226 | valid loss: 0.081862\n","Epoch:  29 | train loss: 0.078262 | valid loss: 0.080948\n","Epoch:  30 | train loss: 0.092922 | valid loss: 0.079895\n","Epoch:  31 | train loss: 0.115800 | valid loss: 0.079121\n","Epoch:  32 | train loss: 0.082388 | valid loss: 0.078582\n","Epoch:  33 | train loss: 0.070093 | valid loss: 0.077955\n","Epoch:  34 | train loss: 0.114275 | valid loss: 0.077641\n","Epoch:  35 | train loss: 0.116345 | valid loss: 0.076830\n","Epoch:  36 | train loss: 0.100761 | valid loss: 0.076341\n","Epoch:  37 | train loss: 0.066005 | valid loss: 0.076110\n","Epoch:  38 | train loss: 0.067542 | valid loss: 0.075361\n","Epoch:  39 | train loss: 0.052320 | valid loss: 0.075168\n","Epoch:  40 | train loss: 0.073792 | valid loss: 0.074818\n","Epoch:  41 | train loss: 0.074355 | valid loss: 0.074864\n","Epoch:  42 | train loss: 0.067464 | valid loss: 0.074093\n","Epoch:  43 | train loss: 0.067003 | valid loss: 0.073960\n","Epoch:  44 | train loss: 0.087246 | valid loss: 0.073514\n","Epoch:  45 | train loss: 0.076284 | valid loss: 0.073501\n","Epoch:  46 | train loss: 0.054262 | valid loss: 0.073135\n","Epoch:  47 | train loss: 0.051605 | valid loss: 0.073035\n","Epoch:  48 | train loss: 0.076780 | valid loss: 0.072678\n","Epoch:  49 | train loss: 0.095740 | valid loss: 0.072428\n","Epoch:  50 | train loss: 0.077601 | valid loss: 0.072085\n","Epoch:  51 | train loss: 0.066378 | valid loss: 0.072302\n","Epoch:  52 | train loss: 0.093360 | valid loss: 0.071779\n","Epoch:  53 | train loss: 0.084563 | valid loss: 0.071679\n","Epoch:  54 | train loss: 0.090547 | valid loss: 0.071703\n","Epoch:  55 | train loss: 0.077111 | valid loss: 0.071469\n","Epoch:  56 | train loss: 0.059458 | valid loss: 0.071238\n","Epoch:  57 | train loss: 0.081659 | valid loss: 0.070851\n","Epoch:  58 | train loss: 0.081570 | valid loss: 0.070918\n","Epoch:  59 | train loss: 0.063599 | valid loss: 0.070785\n","Epoch:  60 | train loss: 0.087559 | valid loss: 0.070644\n","Epoch:  61 | train loss: 0.077167 | valid loss: 0.070677\n","Epoch:  62 | train loss: 0.079981 | valid loss: 0.070363\n","Epoch:  63 | train loss: 0.064833 | valid loss: 0.070488\n","Epoch:  64 | train loss: 0.068491 | valid loss: 0.070104\n","Epoch:  65 | train loss: 0.062060 | valid loss: 0.069939\n","Epoch:  66 | train loss: 0.068076 | valid loss: 0.069870\n","Epoch:  67 | train loss: 0.072703 | valid loss: 0.069812\n","Epoch:  68 | train loss: 0.075689 | valid loss: 0.069914\n","Epoch:  69 | train loss: 0.081616 | valid loss: 0.069680\n","Epoch:  70 | train loss: 0.089453 | valid loss: 0.069564\n","Epoch:  71 | train loss: 0.064946 | valid loss: 0.069525\n","Epoch:  72 | train loss: 0.066654 | valid loss: 0.069401\n","Epoch:  73 | train loss: 0.073322 | valid loss: 0.069423\n","Epoch:  74 | train loss: 0.066401 | valid loss: 0.069440\n","Epoch:  75 | train loss: 0.065018 | valid loss: 0.069062\n","Epoch:  76 | train loss: 0.089036 | valid loss: 0.068987\n","Epoch:  77 | train loss: 0.071202 | valid loss: 0.069305\n","Epoch:  78 | train loss: 0.083346 | valid loss: 0.069243\n","Epoch:  79 | train loss: 0.066399 | valid loss: 0.069062\n","Epoch:  80 | train loss: 0.072344 | valid loss: 0.068779\n","Epoch:  81 | train loss: 0.071768 | valid loss: 0.068698\n","Epoch:  82 | train loss: 0.062128 | valid loss: 0.068775\n","Epoch:  83 | train loss: 0.062956 | valid loss: 0.068853\n","Epoch:  84 | train loss: 0.091178 | valid loss: 0.068556\n","Epoch:  85 | train loss: 0.070288 | valid loss: 0.068384\n","Epoch:  86 | train loss: 0.046168 | valid loss: 0.068335\n","Epoch:  87 | train loss: 0.062693 | valid loss: 0.068439\n","Epoch:  88 | train loss: 0.078146 | valid loss: 0.068410\n","Epoch:  89 | train loss: 0.080004 | valid loss: 0.068277\n","Epoch:  90 | train loss: 0.071302 | valid loss: 0.068309\n","Epoch:  91 | train loss: 0.075495 | valid loss: 0.068126\n","Epoch:  92 | train loss: 0.063774 | valid loss: 0.068263\n","Epoch:  93 | train loss: 0.070469 | valid loss: 0.068240\n","Epoch:  94 | train loss: 0.066219 | valid loss: 0.068294\n","Epoch:  95 | train loss: 0.069294 | valid loss: 0.068253\n","Epoch:  96 | train loss: 0.055949 | valid loss: 0.068065\n","Epoch:  97 | train loss: 0.059031 | valid loss: 0.068135\n","Epoch:  98 | train loss: 0.060006 | valid loss: 0.068113\n","Epoch:  99 | train loss: 0.079710 | valid loss: 0.068459\n","Epoch:  100 | train loss: 0.071268 | valid loss: 0.068346\n","Epoch:  101 | train loss: 0.075035 | valid loss: 0.067943\n","Epoch:  102 | train loss: 0.064182 | valid loss: 0.067893\n","Epoch:  103 | train loss: 0.066360 | valid loss: 0.067752\n","Epoch:  104 | train loss: 0.063772 | valid loss: 0.068227\n","Epoch:  105 | train loss: 0.070070 | valid loss: 0.067723\n","Epoch:  106 | train loss: 0.061071 | valid loss: 0.067687\n","Epoch:  107 | train loss: 0.078374 | valid loss: 0.067612\n","Epoch:  108 | train loss: 0.089860 | valid loss: 0.067836\n","Epoch:  109 | train loss: 0.066641 | valid loss: 0.067786\n","Epoch:  110 | train loss: 0.082059 | valid loss: 0.067968\n","Epoch:  111 | train loss: 0.076155 | valid loss: 0.067556\n","Epoch:  112 | train loss: 0.068963 | valid loss: 0.067722\n","Epoch:  113 | train loss: 0.072852 | valid loss: 0.067677\n","Epoch:  114 | train loss: 0.072662 | valid loss: 0.067874\n","Epoch:  115 | train loss: 0.074786 | valid loss: 0.067787\n","Epoch:  116 | train loss: 0.084936 | valid loss: 0.067768\n","Epoch:  117 | train loss: 0.069639 | valid loss: 0.067689\n","Epoch:  118 | train loss: 0.056368 | valid loss: 0.067552\n","Epoch:  119 | train loss: 0.055444 | valid loss: 0.067589\n","Epoch:  120 | train loss: 0.052003 | valid loss: 0.067583\n","Epoch:  121 | train loss: 0.055220 | valid loss: 0.067499\n","Epoch:  122 | train loss: 0.067518 | valid loss: 0.067656\n","Epoch:  123 | train loss: 0.064508 | valid loss: 0.067447\n","Epoch:  124 | train loss: 0.074566 | valid loss: 0.067365\n","Epoch:  125 | train loss: 0.080622 | valid loss: 0.067576\n","Epoch:  126 | train loss: 0.065927 | valid loss: 0.067517\n","Epoch:  127 | train loss: 0.075577 | valid loss: 0.067527\n","Epoch:  128 | train loss: 0.074422 | valid loss: 0.067573\n","Epoch:  129 | train loss: 0.063901 | valid loss: 0.067860\n","Epoch:  130 | train loss: 0.067221 | valid loss: 0.067478\n","Epoch:  131 | train loss: 0.079732 | valid loss: 0.067291\n","Epoch:  132 | train loss: 0.066477 | valid loss: 0.067267\n","Epoch:  133 | train loss: 0.056775 | valid loss: 0.067385\n","Epoch:  134 | train loss: 0.071029 | valid loss: 0.067703\n","Epoch:  135 | train loss: 0.093918 | valid loss: 0.067459\n","Epoch:  136 | train loss: 0.053254 | valid loss: 0.067430\n","Epoch:  137 | train loss: 0.062750 | valid loss: 0.067483\n","Epoch:  138 | train loss: 0.070703 | valid loss: 0.067669\n","Epoch:  139 | train loss: 0.083085 | valid loss: 0.067376\n","Epoch:  140 | train loss: 0.091475 | valid loss: 0.067506\n","Epoch:  141 | train loss: 0.072274 | valid loss: 0.067200\n","Epoch:  142 | train loss: 0.053005 | valid loss: 0.067421\n","Epoch:  143 | train loss: 0.071704 | valid loss: 0.067402\n","Epoch:  144 | train loss: 0.052619 | valid loss: 0.067516\n","Epoch:  145 | train loss: 0.075666 | valid loss: 0.067533\n","Epoch:  146 | train loss: 0.065087 | valid loss: 0.067275\n","Epoch:  147 | train loss: 0.069165 | valid loss: 0.067545\n","Epoch:  148 | train loss: 0.117744 | valid loss: 0.067436\n","Epoch:  149 | train loss: 0.080246 | valid loss: 0.067465\n","Epoch:  150 | train loss: 0.093571 | valid loss: 0.067609\n","Epoch:  151 | train loss: 0.053264 | valid loss: 0.067308\n","Epoch:  152 | train loss: 0.067219 | valid loss: 0.067430\n","Epoch:  153 | train loss: 0.068160 | valid loss: 0.067332\n","Epoch:  154 | train loss: 0.059078 | valid loss: 0.067306\n","Epoch:  155 | train loss: 0.070429 | valid loss: 0.067290\n","Epoch:  156 | train loss: 0.068881 | valid loss: 0.067328\n","Epoch:  157 | train loss: 0.055217 | valid loss: 0.067183\n","Epoch:  158 | train loss: 0.053225 | valid loss: 0.067493\n","Epoch:  159 | train loss: 0.080352 | valid loss: 0.067485\n","Epoch:  160 | train loss: 0.096008 | valid loss: 0.067535\n","Epoch:  161 | train loss: 0.051291 | valid loss: 0.067323\n","Epoch:  162 | train loss: 0.070326 | valid loss: 0.067363\n","Epoch:  163 | train loss: 0.106154 | valid loss: 0.067392\n","Epoch:  164 | train loss: 0.078000 | valid loss: 0.067573\n","Epoch:  165 | train loss: 0.071030 | valid loss: 0.067576\n","Epoch:  166 | train loss: 0.060270 | valid loss: 0.067303\n","Epoch:  167 | train loss: 0.077254 | valid loss: 0.067463\n","Epoch:  168 | train loss: 0.059919 | valid loss: 0.067483\n","Epoch:  169 | train loss: 0.067268 | valid loss: 0.067167\n","Epoch:  170 | train loss: 0.065047 | valid loss: 0.067623\n","Epoch:  171 | train loss: 0.096358 | valid loss: 0.067442\n","Epoch:  172 | train loss: 0.065765 | valid loss: 0.067240\n","Epoch:  173 | train loss: 0.074821 | valid loss: 0.067332\n","Epoch:  174 | train loss: 0.050147 | valid loss: 0.067435\n","Epoch:  175 | train loss: 0.057887 | valid loss: 0.067399\n","Epoch:  176 | train loss: 0.076423 | valid loss: 0.067693\n","Epoch:  177 | train loss: 0.059282 | valid loss: 0.067393\n","Epoch:  178 | train loss: 0.057370 | valid loss: 0.067390\n","Epoch:  179 | train loss: 0.079925 | valid loss: 0.067244\n","Epoch:  180 | train loss: 0.060749 | valid loss: 0.067303\n","Epoch:  181 | train loss: 0.062573 | valid loss: 0.067318\n","Epoch:  182 | train loss: 0.084056 | valid loss: 0.067479\n","Epoch:  183 | train loss: 0.063657 | valid loss: 0.067491\n","Epoch:  184 | train loss: 0.095703 | valid loss: 0.067239\n","Epoch:  185 | train loss: 0.060339 | valid loss: 0.067248\n","Epoch:  186 | train loss: 0.057120 | valid loss: 0.067243\n","Epoch:  187 | train loss: 0.062733 | valid loss: 0.067174\n","Epoch:  188 | train loss: 0.072647 | valid loss: 0.067162\n","Epoch:  189 | train loss: 0.066013 | valid loss: 0.067315\n","Epoch:  190 | train loss: 0.074882 | valid loss: 0.067389\n","Epoch:  191 | train loss: 0.076647 | valid loss: 0.067244\n","Epoch:  192 | train loss: 0.052370 | valid loss: 0.067432\n","Epoch:  193 | train loss: 0.064321 | valid loss: 0.067308\n","Epoch:  194 | train loss: 0.051363 | valid loss: 0.067439\n","Epoch:  195 | train loss: 0.065944 | valid loss: 0.067231\n","Epoch:  196 | train loss: 0.064777 | valid loss: 0.067562\n","Epoch:  197 | train loss: 0.070903 | valid loss: 0.067360\n","Epoch:  198 | train loss: 0.074567 | valid loss: 0.067425\n","Epoch:  199 | train loss: 0.059747 | valid loss: 0.067327\n","Epoch:  200 | train loss: 0.051674 | valid loss: 0.067331\n","Epoch:  201 | train loss: 0.070055 | valid loss: 0.067240\n","Epoch:  202 | train loss: 0.061191 | valid loss: 0.067438\n","Epoch:  203 | train loss: 0.069324 | valid loss: 0.067342\n","Epoch:  204 | train loss: 0.089936 | valid loss: 0.067151\n","Epoch:  205 | train loss: 0.086366 | valid loss: 0.067217\n","Epoch:  206 | train loss: 0.053577 | valid loss: 0.067233\n","Epoch:  207 | train loss: 0.063902 | valid loss: 0.067387\n","Epoch:  208 | train loss: 0.068225 | valid loss: 0.067330\n","Epoch:  209 | train loss: 0.063811 | valid loss: 0.067317\n","Epoch:  210 | train loss: 0.071801 | valid loss: 0.067276\n","Epoch:  211 | train loss: 0.056007 | valid loss: 0.067239\n","Epoch:  212 | train loss: 0.074465 | valid loss: 0.067337\n","Epoch:  213 | train loss: 0.051778 | valid loss: 0.067315\n","Epoch:  214 | train loss: 0.069463 | valid loss: 0.067297\n","Epoch:  215 | train loss: 0.082512 | valid loss: 0.067213\n","Epoch:  216 | train loss: 0.072108 | valid loss: 0.067377\n","Epoch:  217 | train loss: 0.074464 | valid loss: 0.067368\n","Epoch:  218 | train loss: 0.080001 | valid loss: 0.067463\n","Epoch:  219 | train loss: 0.058578 | valid loss: 0.067257\n","Epoch:  220 | train loss: 0.062849 | valid loss: 0.067319\n","Epoch:  221 | train loss: 0.104796 | valid loss: 0.067252\n","Epoch:  222 | train loss: 0.068221 | valid loss: 0.067384\n","Epoch:  223 | train loss: 0.070775 | valid loss: 0.067391\n","Epoch:  224 | train loss: 0.078010 | valid loss: 0.067277\n","Epoch:  225 | train loss: 0.072417 | valid loss: 0.067276\n","Epoch:  226 | train loss: 0.068221 | valid loss: 0.067260\n","Epoch:  227 | train loss: 0.088143 | valid loss: 0.067301\n","Epoch:  228 | train loss: 0.067850 | valid loss: 0.067202\n","Epoch:  229 | train loss: 0.052370 | valid loss: 0.067388\n","Epoch:  230 | train loss: 0.063023 | valid loss: 0.067391\n","Epoch:  231 | train loss: 0.073313 | valid loss: 0.067193\n","Epoch:  232 | train loss: 0.076140 | valid loss: 0.067391\n","Epoch:  233 | train loss: 0.070852 | valid loss: 0.067434\n","Epoch:  234 | train loss: 0.047343 | valid loss: 0.067210\n","Epoch:  235 | train loss: 0.061548 | valid loss: 0.067237\n","Epoch:  236 | train loss: 0.078976 | valid loss: 0.067312\n","Epoch:  237 | train loss: 0.081797 | valid loss: 0.067215\n","Epoch:  238 | train loss: 0.055743 | valid loss: 0.067399\n","Epoch:  239 | train loss: 0.067959 | valid loss: 0.067293\n","Epoch:  240 | train loss: 0.054941 | valid loss: 0.067208\n","Epoch:  241 | train loss: 0.076643 | valid loss: 0.067430\n","Epoch:  242 | train loss: 0.046602 | valid loss: 0.067370\n","Epoch:  243 | train loss: 0.062084 | valid loss: 0.067512\n","Epoch:  244 | train loss: 0.079990 | valid loss: 0.067346\n","Epoch:  245 | train loss: 0.074707 | valid loss: 0.067378\n","Epoch:  246 | train loss: 0.071597 | valid loss: 0.067693\n","Epoch:  247 | train loss: 0.097381 | valid loss: 0.067381\n","Epoch:  248 | train loss: 0.056677 | valid loss: 0.067256\n","Epoch:  249 | train loss: 0.107305 | valid loss: 0.067210\n","Epoch:  250 | train loss: 0.050875 | valid loss: 0.067280\n","Epoch:  251 | train loss: 0.080694 | valid loss: 0.067248\n","Epoch:  252 | train loss: 0.089759 | valid loss: 0.067303\n","Epoch:  253 | train loss: 0.047109 | valid loss: 0.067191\n","Epoch:  254 | train loss: 0.073168 | valid loss: 0.067169\n","Epoch:  255 | train loss: 0.071584 | valid loss: 0.067210\n","Epoch:  256 | train loss: 0.055831 | valid loss: 0.067228\n","Epoch:  257 | train loss: 0.061649 | valid loss: 0.067158\n","Epoch:  258 | train loss: 0.069567 | valid loss: 0.067474\n","Epoch:  259 | train loss: 0.070224 | valid loss: 0.067209\n","Epoch:  260 | train loss: 0.053853 | valid loss: 0.067310\n","Epoch:  261 | train loss: 0.049471 | valid loss: 0.067291\n","Epoch:  262 | train loss: 0.067562 | valid loss: 0.067331\n","Epoch:  263 | train loss: 0.056740 | valid loss: 0.067228\n","Epoch:  264 | train loss: 0.075748 | valid loss: 0.067315\n","Epoch:  265 | train loss: 0.046349 | valid loss: 0.067245\n","Epoch:  266 | train loss: 0.076010 | valid loss: 0.067327\n","Epoch:  267 | train loss: 0.084209 | valid loss: 0.067150\n","Epoch:  268 | train loss: 0.048414 | valid loss: 0.067306\n","Epoch:  269 | train loss: 0.056964 | valid loss: 0.067255\n","Epoch:  270 | train loss: 0.058672 | valid loss: 0.067200\n","Epoch:  271 | train loss: 0.059732 | valid loss: 0.067287\n","Epoch:  272 | train loss: 0.059068 | valid loss: 0.067243\n","Epoch:  273 | train loss: 0.056611 | valid loss: 0.067210\n","Epoch:  274 | train loss: 0.047726 | valid loss: 0.067160\n","Epoch:  275 | train loss: 0.055649 | valid loss: 0.067260\n","Epoch:  276 | train loss: 0.057935 | valid loss: 0.067333\n","Epoch:  277 | train loss: 0.080900 | valid loss: 0.067341\n","Epoch:  278 | train loss: 0.055162 | valid loss: 0.067259\n","Epoch:  279 | train loss: 0.051430 | valid loss: 0.067367\n","Epoch:  280 | train loss: 0.056999 | valid loss: 0.067234\n","Epoch:  281 | train loss: 0.071894 | valid loss: 0.067282\n","Epoch:  282 | train loss: 0.086712 | valid loss: 0.067261\n","Epoch:  283 | train loss: 0.051048 | valid loss: 0.067214\n","Epoch:  284 | train loss: 0.070943 | valid loss: 0.067251\n","Epoch:  285 | train loss: 0.067756 | valid loss: 0.067368\n","Epoch:  286 | train loss: 0.068218 | valid loss: 0.067435\n","Epoch:  287 | train loss: 0.050249 | valid loss: 0.067273\n","Epoch:  288 | train loss: 0.074751 | valid loss: 0.067236\n","Epoch:  289 | train loss: 0.060660 | valid loss: 0.067318\n","Epoch:  290 | train loss: 0.074933 | valid loss: 0.067335\n","Epoch:  291 | train loss: 0.083744 | valid loss: 0.067361\n","Epoch:  292 | train loss: 0.063151 | valid loss: 0.067357\n","Epoch:  293 | train loss: 0.058425 | valid loss: 0.067262\n","Epoch:  294 | train loss: 0.061957 | valid loss: 0.067310\n","Epoch:  295 | train loss: 0.055786 | valid loss: 0.067340\n","Epoch:  296 | train loss: 0.049812 | valid loss: 0.067354\n","Epoch:  297 | train loss: 0.059734 | valid loss: 0.067390\n","Epoch:  298 | train loss: 0.058827 | valid loss: 0.067408\n","Epoch:  299 | train loss: 0.077989 | valid loss: 0.067227\n","Epoch:  300 | train loss: 0.067861 | valid loss: 0.067247\n","Epoch:  301 | train loss: 0.069070 | valid loss: 0.067275\n","Epoch:  302 | train loss: 0.065864 | valid loss: 0.067167\n","Epoch:  303 | train loss: 0.059111 | valid loss: 0.067272\n","Epoch:  304 | train loss: 0.047244 | valid loss: 0.067194\n","Epoch:  305 | train loss: 0.067418 | valid loss: 0.067176\n","Epoch:  306 | train loss: 0.070090 | valid loss: 0.067279\n","Epoch:  307 | train loss: 0.074610 | valid loss: 0.067416\n","Epoch:  308 | train loss: 0.065962 | valid loss: 0.067065\n","Epoch:  309 | train loss: 0.077212 | valid loss: 0.067112\n","Epoch:  310 | train loss: 0.076152 | valid loss: 0.067285\n","Epoch:  311 | train loss: 0.046416 | valid loss: 0.067392\n","Epoch:  312 | train loss: 0.082435 | valid loss: 0.067184\n","Epoch:  313 | train loss: 0.074968 | valid loss: 0.067268\n","Epoch:  314 | train loss: 0.104795 | valid loss: 0.067347\n","Epoch:  315 | train loss: 0.062170 | valid loss: 0.067307\n","Epoch:  316 | train loss: 0.066809 | valid loss: 0.067206\n","Epoch:  317 | train loss: 0.073453 | valid loss: 0.067285\n","Epoch:  318 | train loss: 0.093115 | valid loss: 0.067253\n","Epoch:  319 | train loss: 0.067905 | valid loss: 0.067299\n","Epoch:  320 | train loss: 0.065905 | valid loss: 0.067156\n","Epoch:  321 | train loss: 0.079590 | valid loss: 0.067292\n","Epoch:  322 | train loss: 0.067481 | valid loss: 0.067218\n","Epoch:  323 | train loss: 0.076319 | valid loss: 0.067160\n","Epoch:  324 | train loss: 0.075207 | valid loss: 0.067270\n","Epoch:  325 | train loss: 0.060888 | valid loss: 0.067215\n","Epoch:  326 | train loss: 0.078333 | valid loss: 0.067402\n","Epoch:  327 | train loss: 0.052435 | valid loss: 0.067121\n","Epoch:  328 | train loss: 0.087433 | valid loss: 0.067170\n","Epoch:  329 | train loss: 0.076090 | valid loss: 0.067310\n","Epoch:  330 | train loss: 0.071119 | valid loss: 0.067223\n","Epoch:  331 | train loss: 0.069627 | valid loss: 0.067338\n","Epoch:  332 | train loss: 0.064453 | valid loss: 0.067384\n","Epoch:  333 | train loss: 0.092074 | valid loss: 0.067259\n","Epoch:  334 | train loss: 0.055733 | valid loss: 0.067134\n","Epoch:  335 | train loss: 0.065463 | valid loss: 0.067163\n","Epoch:  336 | train loss: 0.064306 | valid loss: 0.067332\n","Epoch:  337 | train loss: 0.083724 | valid loss: 0.067249\n","Epoch:  338 | train loss: 0.044689 | valid loss: 0.067265\n","Epoch:  339 | train loss: 0.069073 | valid loss: 0.067266\n","Epoch:  340 | train loss: 0.066401 | valid loss: 0.067296\n","Epoch:  341 | train loss: 0.080509 | valid loss: 0.067311\n","Epoch:  342 | train loss: 0.075181 | valid loss: 0.067238\n","Epoch:  343 | train loss: 0.056629 | valid loss: 0.067306\n","Epoch:  344 | train loss: 0.061289 | valid loss: 0.067154\n","Epoch:  345 | train loss: 0.066834 | valid loss: 0.067180\n","Epoch:  346 | train loss: 0.078601 | valid loss: 0.067291\n","Epoch:  347 | train loss: 0.071443 | valid loss: 0.067180\n","Epoch:  348 | train loss: 0.067923 | valid loss: 0.067361\n","Epoch:  349 | train loss: 0.052307 | valid loss: 0.067353\n","Epoch:  350 | train loss: 0.088383 | valid loss: 0.067182\n","Epoch:  351 | train loss: 0.059021 | valid loss: 0.067183\n","Epoch:  352 | train loss: 0.070946 | valid loss: 0.067386\n","Epoch:  353 | train loss: 0.077188 | valid loss: 0.067239\n","Epoch:  354 | train loss: 0.084442 | valid loss: 0.067224\n","Epoch:  355 | train loss: 0.078633 | valid loss: 0.067189\n","Epoch:  356 | train loss: 0.050456 | valid loss: 0.067352\n","Epoch:  357 | train loss: 0.072980 | valid loss: 0.067336\n","Epoch:  358 | train loss: 0.090585 | valid loss: 0.067234\n","Epoch:  359 | train loss: 0.062003 | valid loss: 0.067155\n","Epoch:  360 | train loss: 0.074790 | valid loss: 0.067207\n","Epoch:  361 | train loss: 0.059831 | valid loss: 0.067243\n","Epoch:  362 | train loss: 0.068198 | valid loss: 0.067281\n","Epoch:  363 | train loss: 0.057680 | valid loss: 0.067211\n","Epoch:  364 | train loss: 0.060123 | valid loss: 0.067269\n","Epoch:  365 | train loss: 0.050724 | valid loss: 0.067192\n","Epoch:  366 | train loss: 0.065365 | valid loss: 0.067451\n","Epoch:  367 | train loss: 0.071597 | valid loss: 0.067413\n","Epoch:  368 | train loss: 0.050020 | valid loss: 0.067171\n","Epoch:  369 | train loss: 0.069932 | valid loss: 0.067192\n","Epoch:  370 | train loss: 0.073926 | valid loss: 0.067350\n","Epoch:  371 | train loss: 0.052103 | valid loss: 0.067302\n","Epoch:  372 | train loss: 0.049710 | valid loss: 0.067254\n","Epoch:  373 | train loss: 0.082575 | valid loss: 0.067183\n","Epoch:  374 | train loss: 0.090645 | valid loss: 0.067196\n","Epoch:  375 | train loss: 0.078089 | valid loss: 0.067211\n","Epoch:  376 | train loss: 0.060269 | valid loss: 0.067281\n","Epoch:  377 | train loss: 0.064832 | valid loss: 0.067328\n","Epoch:  378 | train loss: 0.079163 | valid loss: 0.067293\n","Epoch:  379 | train loss: 0.072753 | valid loss: 0.067231\n","Epoch:  380 | train loss: 0.074233 | valid loss: 0.067180\n","Epoch:  381 | train loss: 0.085474 | valid loss: 0.067484\n","Epoch:  382 | train loss: 0.052009 | valid loss: 0.067290\n","Epoch:  383 | train loss: 0.073669 | valid loss: 0.067328\n","Epoch:  384 | train loss: 0.070568 | valid loss: 0.067152\n","Epoch:  385 | train loss: 0.066026 | valid loss: 0.067257\n","Epoch:  386 | train loss: 0.058545 | valid loss: 0.067164\n","Epoch:  387 | train loss: 0.051838 | valid loss: 0.067288\n","Epoch:  388 | train loss: 0.068280 | valid loss: 0.067287\n","Epoch:  389 | train loss: 0.067099 | valid loss: 0.067135\n","Epoch:  390 | train loss: 0.052967 | valid loss: 0.067339\n","Epoch:  391 | train loss: 0.055130 | valid loss: 0.067179\n","Epoch:  392 | train loss: 0.052629 | valid loss: 0.067143\n","Epoch:  393 | train loss: 0.053110 | valid loss: 0.067142\n","Epoch:  394 | train loss: 0.092851 | valid loss: 0.067247\n","Epoch:  395 | train loss: 0.073503 | valid loss: 0.067298\n","Epoch:  396 | train loss: 0.082797 | valid loss: 0.067274\n","Epoch:  397 | train loss: 0.047531 | valid loss: 0.067199\n","Epoch:  398 | train loss: 0.087804 | valid loss: 0.067357\n","Epoch:  399 | train loss: 0.064972 | valid loss: 0.067168\n","Epoch:  400 | train loss: 0.082343 | valid loss: 0.067227\n","Epoch:  401 | train loss: 0.061860 | valid loss: 0.067097\n","Epoch:  402 | train loss: 0.077243 | valid loss: 0.067305\n","Epoch:  403 | train loss: 0.057605 | valid loss: 0.067151\n","Epoch:  404 | train loss: 0.065832 | valid loss: 0.067197\n","Epoch:  405 | train loss: 0.073226 | valid loss: 0.067258\n","Epoch:  406 | train loss: 0.072878 | valid loss: 0.067244\n","Epoch:  407 | train loss: 0.059982 | valid loss: 0.067195\n","Epoch:  408 | train loss: 0.065952 | valid loss: 0.067395\n","Epoch:  409 | train loss: 0.050905 | valid loss: 0.067187\n","Epoch:  410 | train loss: 0.067416 | valid loss: 0.067251\n","Epoch:  411 | train loss: 0.087518 | valid loss: 0.067288\n","Epoch:  412 | train loss: 0.048645 | valid loss: 0.067236\n","Epoch:  413 | train loss: 0.057774 | valid loss: 0.067251\n","Epoch:  414 | train loss: 0.051443 | valid loss: 0.067252\n","Epoch:  415 | train loss: 0.092821 | valid loss: 0.067209\n","Epoch:  416 | train loss: 0.060615 | valid loss: 0.067297\n","Epoch:  417 | train loss: 0.068627 | valid loss: 0.067153\n","Epoch:  418 | train loss: 0.069903 | valid loss: 0.067182\n","Epoch:  419 | train loss: 0.057625 | valid loss: 0.067146\n","Epoch:  420 | train loss: 0.064849 | valid loss: 0.067403\n","Epoch:  421 | train loss: 0.066759 | valid loss: 0.067237\n","Epoch:  422 | train loss: 0.080762 | valid loss: 0.067171\n","Epoch:  423 | train loss: 0.086199 | valid loss: 0.067146\n","Epoch:  424 | train loss: 0.087984 | valid loss: 0.067249\n","Epoch:  425 | train loss: 0.062080 | valid loss: 0.067272\n","Epoch:  426 | train loss: 0.071563 | valid loss: 0.067306\n","Epoch:  427 | train loss: 0.067100 | valid loss: 0.067211\n","Epoch:  428 | train loss: 0.072616 | valid loss: 0.067222\n","Epoch:  429 | train loss: 0.088530 | valid loss: 0.067276\n","Epoch:  430 | train loss: 0.054443 | valid loss: 0.067204\n","Epoch:  431 | train loss: 0.057139 | valid loss: 0.067133\n","Epoch:  432 | train loss: 0.059861 | valid loss: 0.067238\n","Epoch:  433 | train loss: 0.066851 | valid loss: 0.067339\n","Epoch:  434 | train loss: 0.060362 | valid loss: 0.067124\n","Epoch:  435 | train loss: 0.057959 | valid loss: 0.067256\n","Epoch:  436 | train loss: 0.075285 | valid loss: 0.067245\n","Epoch:  437 | train loss: 0.067299 | valid loss: 0.067360\n","Epoch:  438 | train loss: 0.060413 | valid loss: 0.067139\n","Epoch:  439 | train loss: 0.064847 | valid loss: 0.067188\n","Epoch:  440 | train loss: 0.078466 | valid loss: 0.067220\n","Epoch:  441 | train loss: 0.051666 | valid loss: 0.067254\n","Epoch:  442 | train loss: 0.072244 | valid loss: 0.067314\n","Epoch:  443 | train loss: 0.066545 | valid loss: 0.067158\n","Epoch:  444 | train loss: 0.066511 | valid loss: 0.067225\n","Epoch:  445 | train loss: 0.070875 | valid loss: 0.067122\n","Epoch:  446 | train loss: 0.075131 | valid loss: 0.067337\n","Epoch:  447 | train loss: 0.058295 | valid loss: 0.067234\n","Epoch:  448 | train loss: 0.054631 | valid loss: 0.067247\n","Epoch:  449 | train loss: 0.064106 | valid loss: 0.067205\n","Epoch:  450 | train loss: 0.055945 | valid loss: 0.067225\n","Epoch:  451 | train loss: 0.073257 | valid loss: 0.067282\n","Epoch:  452 | train loss: 0.072702 | valid loss: 0.067229\n","Epoch:  453 | train loss: 0.062410 | valid loss: 0.067208\n","Epoch:  454 | train loss: 0.049591 | valid loss: 0.067284\n","Epoch:  455 | train loss: 0.086331 | valid loss: 0.067280\n","Epoch:  456 | train loss: 0.055359 | valid loss: 0.067275\n","Epoch:  457 | train loss: 0.071222 | valid loss: 0.067265\n","Epoch:  458 | train loss: 0.072223 | valid loss: 0.067236\n","Epoch:  459 | train loss: 0.069907 | valid loss: 0.067250\n","Epoch:  460 | train loss: 0.100480 | valid loss: 0.067327\n","Epoch:  461 | train loss: 0.066667 | valid loss: 0.067340\n","Epoch:  462 | train loss: 0.077927 | valid loss: 0.067256\n","Epoch:  463 | train loss: 0.062927 | valid loss: 0.067278\n","Epoch:  464 | train loss: 0.060219 | valid loss: 0.067170\n","Epoch:  465 | train loss: 0.081606 | valid loss: 0.067122\n","Epoch:  466 | train loss: 0.073599 | valid loss: 0.067282\n","Epoch:  467 | train loss: 0.065028 | valid loss: 0.067365\n","Epoch:  468 | train loss: 0.076794 | valid loss: 0.067328\n","Epoch:  469 | train loss: 0.074412 | valid loss: 0.067193\n","Epoch:  470 | train loss: 0.075736 | valid loss: 0.067269\n","Epoch:  471 | train loss: 0.064667 | valid loss: 0.067418\n","Epoch:  472 | train loss: 0.068381 | valid loss: 0.067203\n","Epoch:  473 | train loss: 0.058495 | valid loss: 0.067178\n","Epoch:  474 | train loss: 0.120972 | valid loss: 0.067236\n","Epoch:  475 | train loss: 0.061489 | valid loss: 0.067327\n","Epoch:  476 | train loss: 0.050441 | valid loss: 0.067257\n","Epoch:  477 | train loss: 0.089483 | valid loss: 0.067337\n","Epoch:  478 | train loss: 0.075113 | valid loss: 0.067352\n","Epoch:  479 | train loss: 0.071601 | valid loss: 0.067344\n","Epoch:  480 | train loss: 0.052204 | valid loss: 0.067287\n","Epoch:  481 | train loss: 0.073256 | valid loss: 0.067281\n","Epoch:  482 | train loss: 0.050747 | valid loss: 0.067207\n","Epoch:  483 | train loss: 0.066449 | valid loss: 0.067228\n","Epoch:  484 | train loss: 0.052885 | valid loss: 0.067287\n","Epoch:  485 | train loss: 0.064039 | valid loss: 0.067242\n","Epoch:  486 | train loss: 0.071808 | valid loss: 0.067236\n","Epoch:  487 | train loss: 0.076392 | valid loss: 0.067293\n","Epoch:  488 | train loss: 0.081036 | valid loss: 0.067382\n","Epoch:  489 | train loss: 0.047673 | valid loss: 0.067259\n","Epoch:  490 | train loss: 0.057071 | valid loss: 0.067371\n","Epoch:  491 | train loss: 0.064143 | valid loss: 0.067248\n","Epoch:  492 | train loss: 0.066204 | valid loss: 0.067155\n","Epoch:  493 | train loss: 0.059982 | valid loss: 0.067108\n","Epoch:  494 | train loss: 0.070577 | valid loss: 0.067258\n","Epoch:  495 | train loss: 0.061633 | valid loss: 0.067314\n","Epoch:  496 | train loss: 0.061939 | valid loss: 0.067257\n","Epoch:  497 | train loss: 0.059157 | valid loss: 0.067270\n","Epoch:  498 | train loss: 0.093085 | valid loss: 0.067264\n","Epoch:  499 | train loss: 0.082142 | valid loss: 0.067308\n","Epoch:  500 | train loss: 0.086686 | valid loss: 0.067268\n","Epoch:  501 | train loss: 0.076299 | valid loss: 0.067205\n","Epoch:  502 | train loss: 0.050685 | valid loss: 0.067300\n","Epoch:  503 | train loss: 0.065310 | valid loss: 0.067252\n","Epoch:  504 | train loss: 0.070803 | valid loss: 0.067217\n","Epoch:  505 | train loss: 0.060927 | valid loss: 0.067155\n","Epoch:  506 | train loss: 0.074150 | valid loss: 0.067226\n","Epoch:  507 | train loss: 0.065278 | valid loss: 0.067297\n","Epoch:  508 | train loss: 0.074211 | valid loss: 0.067090\n","Epoch:  509 | train loss: 0.074302 | valid loss: 0.067297\n","Epoch:  510 | train loss: 0.061974 | valid loss: 0.067335\n","Epoch:  511 | train loss: 0.063982 | valid loss: 0.067254\n","Epoch:  512 | train loss: 0.072345 | valid loss: 0.067410\n","Epoch:  513 | train loss: 0.061914 | valid loss: 0.067317\n","Epoch:  514 | train loss: 0.057547 | valid loss: 0.067132\n","Epoch:  515 | train loss: 0.067030 | valid loss: 0.067309\n","Epoch:  516 | train loss: 0.051029 | valid loss: 0.067255\n","Epoch:  517 | train loss: 0.065801 | valid loss: 0.067325\n","Epoch:  518 | train loss: 0.063674 | valid loss: 0.067221\n","Epoch:  519 | train loss: 0.063100 | valid loss: 0.067130\n","Epoch:  520 | train loss: 0.048077 | valid loss: 0.067307\n","Epoch:  521 | train loss: 0.065898 | valid loss: 0.067157\n","Epoch:  522 | train loss: 0.056279 | valid loss: 0.067209\n","Epoch:  523 | train loss: 0.052864 | valid loss: 0.067122\n","Epoch:  524 | train loss: 0.064583 | valid loss: 0.067244\n","Epoch:  525 | train loss: 0.073958 | valid loss: 0.067125\n","Epoch:  526 | train loss: 0.079198 | valid loss: 0.067230\n","Epoch:  527 | train loss: 0.049502 | valid loss: 0.067123\n","Epoch:  528 | train loss: 0.064674 | valid loss: 0.067254\n","Epoch:  529 | train loss: 0.064730 | valid loss: 0.067193\n","Epoch:  530 | train loss: 0.072905 | valid loss: 0.067330\n","Epoch:  531 | train loss: 0.061454 | valid loss: 0.067233\n","Epoch:  532 | train loss: 0.048656 | valid loss: 0.067231\n","Epoch:  533 | train loss: 0.073142 | valid loss: 0.067292\n","Epoch:  534 | train loss: 0.065764 | valid loss: 0.067217\n","Epoch:  535 | train loss: 0.064792 | valid loss: 0.067216\n","Epoch:  536 | train loss: 0.054216 | valid loss: 0.067256\n","Epoch:  537 | train loss: 0.052979 | valid loss: 0.067362\n","Epoch:  538 | train loss: 0.095914 | valid loss: 0.067249\n","Epoch:  539 | train loss: 0.081252 | valid loss: 0.067293\n","Epoch:  540 | train loss: 0.073112 | valid loss: 0.067213\n","Epoch:  541 | train loss: 0.059883 | valid loss: 0.067302\n","Epoch:  542 | train loss: 0.075268 | valid loss: 0.067399\n","Epoch:  543 | train loss: 0.078331 | valid loss: 0.067283\n","Epoch:  544 | train loss: 0.058528 | valid loss: 0.067318\n","Epoch:  545 | train loss: 0.093746 | valid loss: 0.067228\n","Epoch:  546 | train loss: 0.074651 | valid loss: 0.067137\n","Epoch:  547 | train loss: 0.062203 | valid loss: 0.067166\n","Epoch:  548 | train loss: 0.065733 | valid loss: 0.067332\n","Epoch:  549 | train loss: 0.073720 | valid loss: 0.067313\n","Epoch:  550 | train loss: 0.073609 | valid loss: 0.067210\n","Epoch:  551 | train loss: 0.092380 | valid loss: 0.067258\n","Epoch:  552 | train loss: 0.048396 | valid loss: 0.067255\n","Epoch:  553 | train loss: 0.082282 | valid loss: 0.067312\n","Epoch:  554 | train loss: 0.050227 | valid loss: 0.067289\n","Epoch:  555 | train loss: 0.066038 | valid loss: 0.067188\n","Epoch:  556 | train loss: 0.086968 | valid loss: 0.067270\n","Epoch:  557 | train loss: 0.072310 | valid loss: 0.067206\n","Epoch:  558 | train loss: 0.056559 | valid loss: 0.067140\n","Epoch:  559 | train loss: 0.081062 | valid loss: 0.067161\n","Epoch:  560 | train loss: 0.067594 | valid loss: 0.067218\n","Epoch:  561 | train loss: 0.056782 | valid loss: 0.067181\n","Epoch:  562 | train loss: 0.061289 | valid loss: 0.067188\n","Epoch:  563 | train loss: 0.075182 | valid loss: 0.067330\n","Epoch:  564 | train loss: 0.060433 | valid loss: 0.067239\n","Epoch:  565 | train loss: 0.073868 | valid loss: 0.067164\n","Epoch:  566 | train loss: 0.079829 | valid loss: 0.067308\n","Epoch:  567 | train loss: 0.074859 | valid loss: 0.067134\n","Epoch:  568 | train loss: 0.063707 | valid loss: 0.067183\n","Epoch:  569 | train loss: 0.091726 | valid loss: 0.067292\n","Epoch:  570 | train loss: 0.066732 | valid loss: 0.067179\n","Epoch:  571 | train loss: 0.084368 | valid loss: 0.067225\n","Epoch:  572 | train loss: 0.059726 | valid loss: 0.067273\n","Epoch:  573 | train loss: 0.073982 | valid loss: 0.067113\n","Epoch:  574 | train loss: 0.065603 | valid loss: 0.067226\n","Epoch:  575 | train loss: 0.099926 | valid loss: 0.067337\n","Epoch:  576 | train loss: 0.067184 | valid loss: 0.067268\n","Epoch:  577 | train loss: 0.066297 | valid loss: 0.067313\n","Epoch:  578 | train loss: 0.045594 | valid loss: 0.067265\n","Epoch:  579 | train loss: 0.051983 | valid loss: 0.067290\n","Epoch:  580 | train loss: 0.068011 | valid loss: 0.067250\n","Epoch:  581 | train loss: 0.066268 | valid loss: 0.067278\n","Epoch:  582 | train loss: 0.102730 | valid loss: 0.067251\n","Epoch:  583 | train loss: 0.045484 | valid loss: 0.067347\n","Epoch:  584 | train loss: 0.070144 | valid loss: 0.067180\n","Epoch:  585 | train loss: 0.060225 | valid loss: 0.067358\n","Epoch:  586 | train loss: 0.072364 | valid loss: 0.067236\n","Epoch:  587 | train loss: 0.065388 | valid loss: 0.067160\n","Epoch:  588 | train loss: 0.066480 | valid loss: 0.067155\n","Epoch:  589 | train loss: 0.063115 | valid loss: 0.067335\n","Epoch:  590 | train loss: 0.055081 | valid loss: 0.067242\n","Epoch:  591 | train loss: 0.067139 | valid loss: 0.067274\n","Epoch:  592 | train loss: 0.074325 | valid loss: 0.067132\n","Epoch:  593 | train loss: 0.053908 | valid loss: 0.067263\n","Epoch:  594 | train loss: 0.075870 | valid loss: 0.067275\n","Epoch:  595 | train loss: 0.076724 | valid loss: 0.067152\n","Epoch:  596 | train loss: 0.061778 | valid loss: 0.067184\n","Epoch:  597 | train loss: 0.076746 | valid loss: 0.067359\n","Epoch:  598 | train loss: 0.052202 | valid loss: 0.067285\n","Epoch:  599 | train loss: 0.074481 | valid loss: 0.067281\n","Epoch:  600 | train loss: 0.058462 | valid loss: 0.067168\n","Epoch:  601 | train loss: 0.049652 | valid loss: 0.067250\n","Epoch:  602 | train loss: 0.058935 | valid loss: 0.067211\n","Epoch:  603 | train loss: 0.058523 | valid loss: 0.067259\n","Epoch:  604 | train loss: 0.066717 | valid loss: 0.067232\n","Epoch:  605 | train loss: 0.059985 | valid loss: 0.067202\n","Epoch:  606 | train loss: 0.071724 | valid loss: 0.067282\n","Epoch:  607 | train loss: 0.095333 | valid loss: 0.067285\n","Epoch:  608 | train loss: 0.058263 | valid loss: 0.067325\n","Epoch:  609 | train loss: 0.098057 | valid loss: 0.067249\n","Epoch:  610 | train loss: 0.097086 | valid loss: 0.067235\n","Epoch:  611 | train loss: 0.080139 | valid loss: 0.067255\n","Epoch:  612 | train loss: 0.072710 | valid loss: 0.067163\n","Epoch:  613 | train loss: 0.062115 | valid loss: 0.067132\n","Epoch:  614 | train loss: 0.075751 | valid loss: 0.067219\n","Epoch:  615 | train loss: 0.065529 | valid loss: 0.067204\n","Epoch:  616 | train loss: 0.067906 | valid loss: 0.067209\n","Epoch:  617 | train loss: 0.060913 | valid loss: 0.067253\n","Epoch:  618 | train loss: 0.085598 | valid loss: 0.067281\n","Epoch:  619 | train loss: 0.060289 | valid loss: 0.067327\n","Epoch:  620 | train loss: 0.085463 | valid loss: 0.067247\n","Epoch:  621 | train loss: 0.068475 | valid loss: 0.067195\n","Epoch:  622 | train loss: 0.104577 | valid loss: 0.067291\n","Epoch:  623 | train loss: 0.057199 | valid loss: 0.067269\n","Epoch:  624 | train loss: 0.068404 | valid loss: 0.067273\n","Epoch:  625 | train loss: 0.084317 | valid loss: 0.067231\n","Epoch:  626 | train loss: 0.072091 | valid loss: 0.067169\n","Epoch:  627 | train loss: 0.054592 | valid loss: 0.067242\n","Epoch:  628 | train loss: 0.086187 | valid loss: 0.067161\n","Epoch:  629 | train loss: 0.093915 | valid loss: 0.067252\n","Epoch:  630 | train loss: 0.065595 | valid loss: 0.067238\n","Epoch:  631 | train loss: 0.059735 | valid loss: 0.067181\n","Epoch:  632 | train loss: 0.054808 | valid loss: 0.067209\n","Epoch:  633 | train loss: 0.069161 | valid loss: 0.067202\n","Epoch:  634 | train loss: 0.046309 | valid loss: 0.067329\n","Epoch:  635 | train loss: 0.064182 | valid loss: 0.067133\n","Epoch:  636 | train loss: 0.069384 | valid loss: 0.067304\n","Epoch:  637 | train loss: 0.051435 | valid loss: 0.067177\n","Epoch:  638 | train loss: 0.083601 | valid loss: 0.067203\n","Epoch:  639 | train loss: 0.079571 | valid loss: 0.067327\n","Epoch:  640 | train loss: 0.060812 | valid loss: 0.067187\n","Epoch:  641 | train loss: 0.073267 | valid loss: 0.067324\n","Epoch:  642 | train loss: 0.047713 | valid loss: 0.067276\n","Epoch:  643 | train loss: 0.057431 | valid loss: 0.067162\n","Epoch:  644 | train loss: 0.085554 | valid loss: 0.067153\n","Epoch:  645 | train loss: 0.059700 | valid loss: 0.067250\n","Epoch:  646 | train loss: 0.061281 | valid loss: 0.067285\n","Epoch:  647 | train loss: 0.061246 | valid loss: 0.067310\n","Epoch:  648 | train loss: 0.063959 | valid loss: 0.067204\n","Epoch:  649 | train loss: 0.059927 | valid loss: 0.067189\n","Epoch:  650 | train loss: 0.077323 | valid loss: 0.067299\n","Epoch:  651 | train loss: 0.058601 | valid loss: 0.067140\n","Epoch:  652 | train loss: 0.050743 | valid loss: 0.067243\n","Epoch:  653 | train loss: 0.073627 | valid loss: 0.067118\n","Epoch:  654 | train loss: 0.060594 | valid loss: 0.067197\n","Epoch:  655 | train loss: 0.056640 | valid loss: 0.067276\n","Epoch:  656 | train loss: 0.072175 | valid loss: 0.067355\n","Epoch:  657 | train loss: 0.062113 | valid loss: 0.067245\n","Epoch:  658 | train loss: 0.054420 | valid loss: 0.067340\n","Epoch:  659 | train loss: 0.084840 | valid loss: 0.067239\n","Epoch:  660 | train loss: 0.080427 | valid loss: 0.067275\n","Epoch:  661 | train loss: 0.077013 | valid loss: 0.067412\n","Epoch:  662 | train loss: 0.059170 | valid loss: 0.067208\n","Epoch:  663 | train loss: 0.060374 | valid loss: 0.067265\n","Epoch:  664 | train loss: 0.057361 | valid loss: 0.067317\n","Epoch:  665 | train loss: 0.069476 | valid loss: 0.067151\n","Epoch:  666 | train loss: 0.054263 | valid loss: 0.067201\n","Epoch:  667 | train loss: 0.071131 | valid loss: 0.067232\n","Epoch:  668 | train loss: 0.059915 | valid loss: 0.067322\n","Epoch:  669 | train loss: 0.064921 | valid loss: 0.067302\n","Epoch:  670 | train loss: 0.082144 | valid loss: 0.067333\n","Epoch:  671 | train loss: 0.069766 | valid loss: 0.067214\n","Epoch:  672 | train loss: 0.064513 | valid loss: 0.067289\n","Epoch:  673 | train loss: 0.101660 | valid loss: 0.067319\n","Epoch:  674 | train loss: 0.077458 | valid loss: 0.067241\n","Epoch:  675 | train loss: 0.080504 | valid loss: 0.067208\n","Epoch:  676 | train loss: 0.073454 | valid loss: 0.067329\n","Epoch:  677 | train loss: 0.066241 | valid loss: 0.067214\n","Epoch:  678 | train loss: 0.095769 | valid loss: 0.067185\n","Epoch:  679 | train loss: 0.066150 | valid loss: 0.067345\n","Epoch:  680 | train loss: 0.070440 | valid loss: 0.067199\n","Epoch:  681 | train loss: 0.062848 | valid loss: 0.067234\n","Epoch:  682 | train loss: 0.060310 | valid loss: 0.067171\n","Epoch:  683 | train loss: 0.050274 | valid loss: 0.067264\n","Epoch:  684 | train loss: 0.053543 | valid loss: 0.067196\n","Epoch:  685 | train loss: 0.072880 | valid loss: 0.067279\n","Epoch:  686 | train loss: 0.066562 | valid loss: 0.067225\n","Epoch:  687 | train loss: 0.057491 | valid loss: 0.067202\n","Epoch:  688 | train loss: 0.058247 | valid loss: 0.067231\n","Epoch:  689 | train loss: 0.059366 | valid loss: 0.067412\n","Epoch:  690 | train loss: 0.079593 | valid loss: 0.067237\n","Epoch:  691 | train loss: 0.081006 | valid loss: 0.067270\n","Epoch:  692 | train loss: 0.065689 | valid loss: 0.067229\n","Epoch:  693 | train loss: 0.059406 | valid loss: 0.067194\n","Epoch:  694 | train loss: 0.055291 | valid loss: 0.067239\n","Epoch:  695 | train loss: 0.079742 | valid loss: 0.067162\n","Epoch:  696 | train loss: 0.055285 | valid loss: 0.067245\n","Epoch:  697 | train loss: 0.057914 | valid loss: 0.067409\n","Epoch:  698 | train loss: 0.042957 | valid loss: 0.067175\n","Epoch:  699 | train loss: 0.091460 | valid loss: 0.067264\n","Epoch:  700 | train loss: 0.057425 | valid loss: 0.067167\n","Epoch:  701 | train loss: 0.059772 | valid loss: 0.067145\n","Epoch:  702 | train loss: 0.050687 | valid loss: 0.067283\n","Epoch:  703 | train loss: 0.065013 | valid loss: 0.067234\n","Epoch:  704 | train loss: 0.050303 | valid loss: 0.067270\n","Epoch:  705 | train loss: 0.068107 | valid loss: 0.067300\n","Epoch:  706 | train loss: 0.052315 | valid loss: 0.067408\n","Epoch:  707 | train loss: 0.063444 | valid loss: 0.067239\n","Epoch:  708 | train loss: 0.067162 | valid loss: 0.067252\n","Epoch:  709 | train loss: 0.087808 | valid loss: 0.067252\n","Epoch:  710 | train loss: 0.070304 | valid loss: 0.067325\n","Epoch:  711 | train loss: 0.063515 | valid loss: 0.067301\n","Epoch:  712 | train loss: 0.093730 | valid loss: 0.067266\n","Epoch:  713 | train loss: 0.057191 | valid loss: 0.067228\n","Epoch:  714 | train loss: 0.056041 | valid loss: 0.067232\n","Epoch:  715 | train loss: 0.086572 | valid loss: 0.067307\n","Epoch:  716 | train loss: 0.073679 | valid loss: 0.067193\n","Epoch:  717 | train loss: 0.050684 | valid loss: 0.067279\n","Epoch:  718 | train loss: 0.070489 | valid loss: 0.067256\n","Epoch:  719 | train loss: 0.051739 | valid loss: 0.067233\n","Epoch:  720 | train loss: 0.063164 | valid loss: 0.067164\n","Epoch:  721 | train loss: 0.051825 | valid loss: 0.067076\n","Epoch:  722 | train loss: 0.085074 | valid loss: 0.067263\n","Epoch:  723 | train loss: 0.083715 | valid loss: 0.067241\n","Epoch:  724 | train loss: 0.058862 | valid loss: 0.067236\n","Epoch:  725 | train loss: 0.065374 | valid loss: 0.067182\n","Epoch:  726 | train loss: 0.063628 | valid loss: 0.067277\n","Epoch:  727 | train loss: 0.058299 | valid loss: 0.067278\n","Epoch:  728 | train loss: 0.074775 | valid loss: 0.067294\n","Epoch:  729 | train loss: 0.075565 | valid loss: 0.067280\n","Epoch:  730 | train loss: 0.088157 | valid loss: 0.067351\n","Epoch:  731 | train loss: 0.071933 | valid loss: 0.067276\n","Epoch:  732 | train loss: 0.058029 | valid loss: 0.067271\n","Epoch:  733 | train loss: 0.084536 | valid loss: 0.067241\n","Epoch:  734 | train loss: 0.076111 | valid loss: 0.067309\n","Epoch:  735 | train loss: 0.079800 | valid loss: 0.067271\n","Epoch:  736 | train loss: 0.061542 | valid loss: 0.067194\n","Epoch:  737 | train loss: 0.048496 | valid loss: 0.067196\n","Epoch:  738 | train loss: 0.069067 | valid loss: 0.067354\n","Epoch:  739 | train loss: 0.056757 | valid loss: 0.067211\n","Epoch:  740 | train loss: 0.060222 | valid loss: 0.067241\n","Epoch:  741 | train loss: 0.044490 | valid loss: 0.067353\n","Epoch:  742 | train loss: 0.074677 | valid loss: 0.067328\n","Epoch:  743 | train loss: 0.075309 | valid loss: 0.067228\n","Epoch:  744 | train loss: 0.077640 | valid loss: 0.067288\n","Epoch:  745 | train loss: 0.079063 | valid loss: 0.067339\n","Epoch:  746 | train loss: 0.052809 | valid loss: 0.067241\n","Epoch:  747 | train loss: 0.075478 | valid loss: 0.067210\n","Epoch:  748 | train loss: 0.066317 | valid loss: 0.067333\n","Epoch:  749 | train loss: 0.055309 | valid loss: 0.067296\n","Epoch:  750 | train loss: 0.092656 | valid loss: 0.067278\n","Epoch:  751 | train loss: 0.056907 | valid loss: 0.067214\n","Epoch:  752 | train loss: 0.065664 | valid loss: 0.067285\n","Epoch:  753 | train loss: 0.065675 | valid loss: 0.067198\n","Epoch:  754 | train loss: 0.081778 | valid loss: 0.067182\n","Epoch:  755 | train loss: 0.079331 | valid loss: 0.067312\n","Epoch:  756 | train loss: 0.069539 | valid loss: 0.067161\n","Epoch:  757 | train loss: 0.059600 | valid loss: 0.067178\n","Epoch:  758 | train loss: 0.047808 | valid loss: 0.067282\n","Epoch:  759 | train loss: 0.054042 | valid loss: 0.067287\n","Epoch:  760 | train loss: 0.071322 | valid loss: 0.067283\n","Epoch:  761 | train loss: 0.075144 | valid loss: 0.067181\n","Epoch:  762 | train loss: 0.061166 | valid loss: 0.067138\n","Epoch:  763 | train loss: 0.073831 | valid loss: 0.067203\n","Epoch:  764 | train loss: 0.077919 | valid loss: 0.067202\n","Epoch:  765 | train loss: 0.076120 | valid loss: 0.067316\n","Epoch:  766 | train loss: 0.093097 | valid loss: 0.067307\n","Epoch:  767 | train loss: 0.062799 | valid loss: 0.067250\n","Epoch:  768 | train loss: 0.053666 | valid loss: 0.067163\n","Epoch:  769 | train loss: 0.071253 | valid loss: 0.067194\n","Epoch:  770 | train loss: 0.072017 | valid loss: 0.067289\n","Epoch:  771 | train loss: 0.076046 | valid loss: 0.067172\n","Epoch:  772 | train loss: 0.068733 | valid loss: 0.067302\n","Epoch:  773 | train loss: 0.070391 | valid loss: 0.067300\n","Epoch:  774 | train loss: 0.070453 | valid loss: 0.067273\n","Epoch:  775 | train loss: 0.066035 | valid loss: 0.067272\n","Epoch:  776 | train loss: 0.076582 | valid loss: 0.067239\n","Epoch:  777 | train loss: 0.057898 | valid loss: 0.067351\n","Epoch:  778 | train loss: 0.064861 | valid loss: 0.067180\n","Epoch:  779 | train loss: 0.075896 | valid loss: 0.067250\n","Epoch:  780 | train loss: 0.062939 | valid loss: 0.067269\n","Epoch:  781 | train loss: 0.059954 | valid loss: 0.067122\n","Epoch:  782 | train loss: 0.066884 | valid loss: 0.067242\n","Epoch:  783 | train loss: 0.064963 | valid loss: 0.067322\n","Epoch:  784 | train loss: 0.062188 | valid loss: 0.067175\n","Epoch:  785 | train loss: 0.077290 | valid loss: 0.067269\n","Epoch:  786 | train loss: 0.076206 | valid loss: 0.067271\n","Epoch:  787 | train loss: 0.075968 | valid loss: 0.067261\n","Epoch:  788 | train loss: 0.070957 | valid loss: 0.067198\n","Epoch:  789 | train loss: 0.072750 | valid loss: 0.067227\n","Epoch:  790 | train loss: 0.065283 | valid loss: 0.067214\n","Epoch:  791 | train loss: 0.074113 | valid loss: 0.067246\n","Epoch:  792 | train loss: 0.066249 | valid loss: 0.067254\n","Epoch:  793 | train loss: 0.051742 | valid loss: 0.067333\n","Epoch:  794 | train loss: 0.097145 | valid loss: 0.067241\n","Epoch:  795 | train loss: 0.077559 | valid loss: 0.067277\n","Epoch:  796 | train loss: 0.090346 | valid loss: 0.067213\n","Epoch:  797 | train loss: 0.065127 | valid loss: 0.067310\n","Epoch:  798 | train loss: 0.057358 | valid loss: 0.067195\n","Epoch:  799 | train loss: 0.054746 | valid loss: 0.067345\n","Epoch:  800 | train loss: 0.089094 | valid loss: 0.067228\n","Epoch:  801 | train loss: 0.065962 | valid loss: 0.067341\n","Epoch:  802 | train loss: 0.057195 | valid loss: 0.067268\n","Epoch:  803 | train loss: 0.072321 | valid loss: 0.067289\n","Epoch:  804 | train loss: 0.056525 | valid loss: 0.067242\n","Epoch:  805 | train loss: 0.093213 | valid loss: 0.067213\n","Epoch:  806 | train loss: 0.077985 | valid loss: 0.067290\n","Epoch:  807 | train loss: 0.075866 | valid loss: 0.067195\n","Epoch:  808 | train loss: 0.061337 | valid loss: 0.067282\n","Epoch:  809 | train loss: 0.100611 | valid loss: 0.067343\n","Epoch:  810 | train loss: 0.074791 | valid loss: 0.067242\n","Epoch:  811 | train loss: 0.073894 | valid loss: 0.067237\n","Epoch:  812 | train loss: 0.046605 | valid loss: 0.067252\n","Epoch:  813 | train loss: 0.085037 | valid loss: 0.067113\n","Epoch:  814 | train loss: 0.089775 | valid loss: 0.067253\n","Epoch:  815 | train loss: 0.073058 | valid loss: 0.067280\n","Epoch:  816 | train loss: 0.076168 | valid loss: 0.067241\n","Epoch:  817 | train loss: 0.087021 | valid loss: 0.067265\n","Epoch:  818 | train loss: 0.063082 | valid loss: 0.067212\n","Epoch:  819 | train loss: 0.063802 | valid loss: 0.067236\n","Epoch:  820 | train loss: 0.088936 | valid loss: 0.067206\n","Epoch:  821 | train loss: 0.077822 | valid loss: 0.067195\n","Epoch:  822 | train loss: 0.069832 | valid loss: 0.067273\n","Epoch:  823 | train loss: 0.062005 | valid loss: 0.067204\n","Epoch:  824 | train loss: 0.059169 | valid loss: 0.067227\n","Epoch:  825 | train loss: 0.093153 | valid loss: 0.067339\n","Epoch:  826 | train loss: 0.080219 | valid loss: 0.067303\n","Epoch:  827 | train loss: 0.068593 | valid loss: 0.067274\n","Epoch:  828 | train loss: 0.079813 | valid loss: 0.067181\n","Epoch:  829 | train loss: 0.054501 | valid loss: 0.067331\n","Epoch:  830 | train loss: 0.068382 | valid loss: 0.067335\n","Epoch:  831 | train loss: 0.057527 | valid loss: 0.067291\n","Epoch:  832 | train loss: 0.068693 | valid loss: 0.067312\n","Epoch:  833 | train loss: 0.079209 | valid loss: 0.067295\n","Epoch:  834 | train loss: 0.068443 | valid loss: 0.067251\n","Epoch:  835 | train loss: 0.069020 | valid loss: 0.067304\n","Epoch:  836 | train loss: 0.051848 | valid loss: 0.067236\n","Epoch:  837 | train loss: 0.102880 | valid loss: 0.067292\n","Epoch:  838 | train loss: 0.065438 | valid loss: 0.067214\n","Epoch:  839 | train loss: 0.083388 | valid loss: 0.067263\n","Epoch:  840 | train loss: 0.063795 | valid loss: 0.067247\n","Epoch:  841 | train loss: 0.058585 | valid loss: 0.067228\n","Epoch:  842 | train loss: 0.045384 | valid loss: 0.067259\n","Epoch:  843 | train loss: 0.076765 | valid loss: 0.067232\n","Epoch:  844 | train loss: 0.063468 | valid loss: 0.067167\n","Epoch:  845 | train loss: 0.071540 | valid loss: 0.067187\n","Epoch:  846 | train loss: 0.057446 | valid loss: 0.067234\n","Epoch:  847 | train loss: 0.065150 | valid loss: 0.067238\n","Epoch:  848 | train loss: 0.072160 | valid loss: 0.067281\n","Epoch:  849 | train loss: 0.062046 | valid loss: 0.067210\n","Epoch:  850 | train loss: 0.071395 | valid loss: 0.067276\n","Epoch:  851 | train loss: 0.067151 | valid loss: 0.067331\n","Epoch:  852 | train loss: 0.068165 | valid loss: 0.067274\n","Epoch:  853 | train loss: 0.056896 | valid loss: 0.067357\n","Epoch:  854 | train loss: 0.072164 | valid loss: 0.067253\n","Epoch:  855 | train loss: 0.083906 | valid loss: 0.067325\n","Epoch:  856 | train loss: 0.071441 | valid loss: 0.067265\n","Epoch:  857 | train loss: 0.064070 | valid loss: 0.067339\n","Epoch:  858 | train loss: 0.050103 | valid loss: 0.067297\n","Epoch:  859 | train loss: 0.070271 | valid loss: 0.067220\n","Epoch:  860 | train loss: 0.082011 | valid loss: 0.067298\n","Epoch:  861 | train loss: 0.073056 | valid loss: 0.067226\n","Epoch:  862 | train loss: 0.071841 | valid loss: 0.067307\n","Epoch:  863 | train loss: 0.060517 | valid loss: 0.067299\n","Epoch:  864 | train loss: 0.067362 | valid loss: 0.067321\n","Epoch:  865 | train loss: 0.047051 | valid loss: 0.067263\n","Epoch:  866 | train loss: 0.079404 | valid loss: 0.067263\n","Epoch:  867 | train loss: 0.069752 | valid loss: 0.067231\n","Epoch:  868 | train loss: 0.056105 | valid loss: 0.067235\n","Epoch:  869 | train loss: 0.065839 | valid loss: 0.067146\n","Epoch:  870 | train loss: 0.049846 | valid loss: 0.067219\n","Epoch:  871 | train loss: 0.061475 | valid loss: 0.067192\n","Epoch:  872 | train loss: 0.058829 | valid loss: 0.067192\n","Epoch:  873 | train loss: 0.064407 | valid loss: 0.067319\n","Epoch:  874 | train loss: 0.072249 | valid loss: 0.067275\n","Epoch:  875 | train loss: 0.061801 | valid loss: 0.067253\n","Epoch:  876 | train loss: 0.059177 | valid loss: 0.067258\n","Epoch:  877 | train loss: 0.061643 | valid loss: 0.067258\n","Epoch:  878 | train loss: 0.061691 | valid loss: 0.067148\n","Epoch:  879 | train loss: 0.055528 | valid loss: 0.067260\n","Epoch:  880 | train loss: 0.049961 | valid loss: 0.067306\n","Epoch:  881 | train loss: 0.060037 | valid loss: 0.067340\n","Epoch:  882 | train loss: 0.067778 | valid loss: 0.067377\n","Epoch:  883 | train loss: 0.059510 | valid loss: 0.067276\n","Epoch:  884 | train loss: 0.065470 | valid loss: 0.067198\n","Epoch:  885 | train loss: 0.057972 | valid loss: 0.067261\n","Epoch:  886 | train loss: 0.060564 | valid loss: 0.067252\n","Epoch:  887 | train loss: 0.069341 | valid loss: 0.067328\n","Epoch:  888 | train loss: 0.082712 | valid loss: 0.067277\n","Epoch:  889 | train loss: 0.049444 | valid loss: 0.067314\n","Epoch:  890 | train loss: 0.095533 | valid loss: 0.067247\n","Epoch:  891 | train loss: 0.069017 | valid loss: 0.067236\n","Epoch:  892 | train loss: 0.073994 | valid loss: 0.067187\n","Epoch:  893 | train loss: 0.064041 | valid loss: 0.067154\n","Epoch:  894 | train loss: 0.070336 | valid loss: 0.067188\n","Epoch:  895 | train loss: 0.060846 | valid loss: 0.067246\n","Epoch:  896 | train loss: 0.050167 | valid loss: 0.067335\n","Epoch:  897 | train loss: 0.084938 | valid loss: 0.067321\n","Epoch:  898 | train loss: 0.078401 | valid loss: 0.067438\n","Epoch:  899 | train loss: 0.113553 | valid loss: 0.067322\n","Epoch:  900 | train loss: 0.080358 | valid loss: 0.067361\n","Epoch:  901 | train loss: 0.070312 | valid loss: 0.067212\n","Epoch:  902 | train loss: 0.072480 | valid loss: 0.067202\n","Epoch:  903 | train loss: 0.066488 | valid loss: 0.067324\n","Epoch:  904 | train loss: 0.078608 | valid loss: 0.067248\n","Epoch:  905 | train loss: 0.092524 | valid loss: 0.067287\n","Epoch:  906 | train loss: 0.056386 | valid loss: 0.067230\n","Epoch:  907 | train loss: 0.064870 | valid loss: 0.067230\n","Epoch:  908 | train loss: 0.072540 | valid loss: 0.067251\n","Epoch:  909 | train loss: 0.066180 | valid loss: 0.067170\n","Epoch:  910 | train loss: 0.080350 | valid loss: 0.067241\n","Epoch:  911 | train loss: 0.064214 | valid loss: 0.067296\n","Epoch:  912 | train loss: 0.083161 | valid loss: 0.067174\n","Epoch:  913 | train loss: 0.071246 | valid loss: 0.067264\n","Epoch:  914 | train loss: 0.055656 | valid loss: 0.067246\n","Epoch:  915 | train loss: 0.067479 | valid loss: 0.067405\n","Epoch:  916 | train loss: 0.083413 | valid loss: 0.067264\n","Epoch:  917 | train loss: 0.051142 | valid loss: 0.067291\n","Epoch:  918 | train loss: 0.059150 | valid loss: 0.067270\n","Epoch:  919 | train loss: 0.068248 | valid loss: 0.067258\n","Epoch:  920 | train loss: 0.073453 | valid loss: 0.067208\n","Epoch:  921 | train loss: 0.089427 | valid loss: 0.067272\n","Epoch:  922 | train loss: 0.057947 | valid loss: 0.067305\n","Epoch:  923 | train loss: 0.044098 | valid loss: 0.067231\n","Epoch:  924 | train loss: 0.067441 | valid loss: 0.067269\n","Epoch:  925 | train loss: 0.051516 | valid loss: 0.067227\n","Epoch:  926 | train loss: 0.056423 | valid loss: 0.067308\n","Epoch:  927 | train loss: 0.063247 | valid loss: 0.067271\n","Epoch:  928 | train loss: 0.081245 | valid loss: 0.067316\n","Epoch:  929 | train loss: 0.051593 | valid loss: 0.067334\n","Epoch:  930 | train loss: 0.054707 | valid loss: 0.067315\n","Epoch:  931 | train loss: 0.079057 | valid loss: 0.067207\n","Epoch:  932 | train loss: 0.061322 | valid loss: 0.067318\n","Epoch:  933 | train loss: 0.081437 | valid loss: 0.067275\n","Epoch:  934 | train loss: 0.076380 | valid loss: 0.067274\n","Epoch:  935 | train loss: 0.069662 | valid loss: 0.067208\n","Epoch:  936 | train loss: 0.090396 | valid loss: 0.067244\n","Epoch:  937 | train loss: 0.062905 | valid loss: 0.067348\n","Epoch:  938 | train loss: 0.069284 | valid loss: 0.067216\n","Epoch:  939 | train loss: 0.075645 | valid loss: 0.067191\n","Epoch:  940 | train loss: 0.077203 | valid loss: 0.067278\n","Epoch:  941 | train loss: 0.052181 | valid loss: 0.067234\n","Epoch:  942 | train loss: 0.066120 | valid loss: 0.067243\n","Epoch:  943 | train loss: 0.077555 | valid loss: 0.067251\n","Epoch:  944 | train loss: 0.066116 | valid loss: 0.067280\n","Epoch:  945 | train loss: 0.062416 | valid loss: 0.067286\n","Epoch:  946 | train loss: 0.060800 | valid loss: 0.067271\n","Epoch:  947 | train loss: 0.074222 | valid loss: 0.067149\n","Epoch:  948 | train loss: 0.097065 | valid loss: 0.067240\n","Epoch:  949 | train loss: 0.109696 | valid loss: 0.067279\n","Epoch:  950 | train loss: 0.047046 | valid loss: 0.067246\n","Epoch:  951 | train loss: 0.059805 | valid loss: 0.067247\n","Epoch:  952 | train loss: 0.077663 | valid loss: 0.067180\n","Epoch:  953 | train loss: 0.055446 | valid loss: 0.067243\n","Epoch:  954 | train loss: 0.059758 | valid loss: 0.067262\n","Epoch:  955 | train loss: 0.083613 | valid loss: 0.067382\n","Epoch:  956 | train loss: 0.050657 | valid loss: 0.067319\n","Epoch:  957 | train loss: 0.049566 | valid loss: 0.067443\n","Epoch:  958 | train loss: 0.055843 | valid loss: 0.067271\n","Epoch:  959 | train loss: 0.060097 | valid loss: 0.067322\n","Epoch:  960 | train loss: 0.063913 | valid loss: 0.067329\n","Epoch:  961 | train loss: 0.089272 | valid loss: 0.067206\n","Epoch:  962 | train loss: 0.069726 | valid loss: 0.067185\n","Epoch:  963 | train loss: 0.064929 | valid loss: 0.067354\n","Epoch:  964 | train loss: 0.059016 | valid loss: 0.067234\n","Epoch:  965 | train loss: 0.076637 | valid loss: 0.067218\n","Epoch:  966 | train loss: 0.045704 | valid loss: 0.067210\n","Epoch:  967 | train loss: 0.050844 | valid loss: 0.067231\n","Epoch:  968 | train loss: 0.084913 | valid loss: 0.067202\n","Epoch:  969 | train loss: 0.083419 | valid loss: 0.067266\n","Epoch:  970 | train loss: 0.072902 | valid loss: 0.067217\n","Epoch:  971 | train loss: 0.065921 | valid loss: 0.067282\n","Epoch:  972 | train loss: 0.069001 | valid loss: 0.067278\n","Epoch:  973 | train loss: 0.081016 | valid loss: 0.067240\n","Epoch:  974 | train loss: 0.050791 | valid loss: 0.067232\n","Epoch:  975 | train loss: 0.054324 | valid loss: 0.067128\n","Epoch:  976 | train loss: 0.058913 | valid loss: 0.067304\n","Epoch:  977 | train loss: 0.053785 | valid loss: 0.067243\n","Epoch:  978 | train loss: 0.072228 | valid loss: 0.067346\n","Epoch:  979 | train loss: 0.067217 | valid loss: 0.067229\n","Epoch:  980 | train loss: 0.054400 | valid loss: 0.067169\n","Epoch:  981 | train loss: 0.074063 | valid loss: 0.067314\n","Epoch:  982 | train loss: 0.074357 | valid loss: 0.067309\n","Epoch:  983 | train loss: 0.073202 | valid loss: 0.067249\n","Epoch:  984 | train loss: 0.083078 | valid loss: 0.067329\n","Epoch:  985 | train loss: 0.057195 | valid loss: 0.067344\n","Epoch:  986 | train loss: 0.056529 | valid loss: 0.067252\n","Epoch:  987 | train loss: 0.073850 | valid loss: 0.067326\n","Epoch:  988 | train loss: 0.064081 | valid loss: 0.067274\n","Epoch:  989 | train loss: 0.061708 | valid loss: 0.067245\n","Epoch:  990 | train loss: 0.068566 | valid loss: 0.067283\n","Epoch:  991 | train loss: 0.065703 | valid loss: 0.067382\n","Epoch:  992 | train loss: 0.072686 | valid loss: 0.067297\n","Epoch:  993 | train loss: 0.069832 | valid loss: 0.067296\n","Epoch:  994 | train loss: 0.055208 | valid loss: 0.067263\n","Epoch:  995 | train loss: 0.065763 | valid loss: 0.067355\n","Epoch:  996 | train loss: 0.085924 | valid loss: 0.067272\n","Epoch:  997 | train loss: 0.073994 | valid loss: 0.067313\n","Epoch:  998 | train loss: 0.087560 | valid loss: 0.067226\n","Epoch:  999 | train loss: 0.048666 | valid loss: 0.067211\n","Epoch:  1000 | train loss: 0.068967 | valid loss: 0.067288\n","Epoch:  1001 | train loss: 0.062940 | valid loss: 0.067248\n","Epoch:  1002 | train loss: 0.059719 | valid loss: 0.067238\n","Epoch:  1003 | train loss: 0.065974 | valid loss: 0.067318\n","Epoch:  1004 | train loss: 0.063315 | valid loss: 0.067299\n","Epoch:  1005 | train loss: 0.060932 | valid loss: 0.067331\n","Epoch:  1006 | train loss: 0.061364 | valid loss: 0.067233\n","Epoch:  1007 | train loss: 0.061444 | valid loss: 0.067261\n","Epoch:  1008 | train loss: 0.057462 | valid loss: 0.067301\n","Epoch:  1009 | train loss: 0.060144 | valid loss: 0.067175\n","Epoch:  1010 | train loss: 0.084069 | valid loss: 0.067272\n","Epoch:  1011 | train loss: 0.100124 | valid loss: 0.067267\n","Epoch:  1012 | train loss: 0.061666 | valid loss: 0.067174\n","Epoch:  1013 | train loss: 0.077330 | valid loss: 0.067269\n","Epoch:  1014 | train loss: 0.067231 | valid loss: 0.067233\n","Epoch:  1015 | train loss: 0.044093 | valid loss: 0.067252\n","Epoch:  1016 | train loss: 0.062486 | valid loss: 0.067259\n","Epoch:  1017 | train loss: 0.054297 | valid loss: 0.067344\n","Epoch:  1018 | train loss: 0.065185 | valid loss: 0.067215\n","Epoch:  1019 | train loss: 0.066661 | valid loss: 0.067220\n","Epoch:  1020 | train loss: 0.060605 | valid loss: 0.067309\n","Epoch:  1021 | train loss: 0.049452 | valid loss: 0.067256\n","Epoch:  1022 | train loss: 0.059302 | valid loss: 0.067295\n","Epoch:  1023 | train loss: 0.055509 | valid loss: 0.067281\n","Epoch:  1024 | train loss: 0.061116 | valid loss: 0.067315\n","Epoch:  1025 | train loss: 0.099562 | valid loss: 0.067308\n","Epoch:  1026 | train loss: 0.067028 | valid loss: 0.067298\n","Epoch:  1027 | train loss: 0.065004 | valid loss: 0.067262\n","Epoch:  1028 | train loss: 0.075157 | valid loss: 0.067304\n","Epoch:  1029 | train loss: 0.062029 | valid loss: 0.067325\n","Epoch:  1030 | train loss: 0.070725 | valid loss: 0.067371\n","Epoch:  1031 | train loss: 0.082207 | valid loss: 0.067276\n","Epoch:  1032 | train loss: 0.063354 | valid loss: 0.067209\n","Epoch:  1033 | train loss: 0.080068 | valid loss: 0.067269\n","Epoch:  1034 | train loss: 0.050658 | valid loss: 0.067236\n","Epoch:  1035 | train loss: 0.061254 | valid loss: 0.067176\n","Epoch:  1036 | train loss: 0.063422 | valid loss: 0.067370\n","Epoch:  1037 | train loss: 0.066717 | valid loss: 0.067240\n","Epoch:  1038 | train loss: 0.089855 | valid loss: 0.067244\n","Epoch:  1039 | train loss: 0.059789 | valid loss: 0.067187\n","Epoch:  1040 | train loss: 0.082110 | valid loss: 0.067189\n","Epoch:  1041 | train loss: 0.068020 | valid loss: 0.067469\n","Epoch:  1042 | train loss: 0.058283 | valid loss: 0.067248\n","Epoch:  1043 | train loss: 0.077685 | valid loss: 0.067229\n","Epoch:  1044 | train loss: 0.049863 | valid loss: 0.067297\n","Epoch:  1045 | train loss: 0.053247 | valid loss: 0.067272\n","Epoch:  1046 | train loss: 0.047496 | valid loss: 0.067190\n","Epoch:  1047 | train loss: 0.058341 | valid loss: 0.067276\n","Epoch:  1048 | train loss: 0.069401 | valid loss: 0.067216\n","Epoch:  1049 | train loss: 0.056903 | valid loss: 0.067247\n","Epoch:  1050 | train loss: 0.097118 | valid loss: 0.067297\n","Epoch:  1051 | train loss: 0.081224 | valid loss: 0.067318\n","Epoch:  1052 | train loss: 0.070381 | valid loss: 0.067255\n","Epoch:  1053 | train loss: 0.072203 | valid loss: 0.067236\n","Epoch:  1054 | train loss: 0.074722 | valid loss: 0.067373\n","Epoch:  1055 | train loss: 0.071172 | valid loss: 0.067329\n","Epoch:  1056 | train loss: 0.060362 | valid loss: 0.067303\n","Epoch:  1057 | train loss: 0.050362 | valid loss: 0.067321\n","Epoch:  1058 | train loss: 0.075228 | valid loss: 0.067307\n","Epoch:  1059 | train loss: 0.050916 | valid loss: 0.067157\n","Epoch:  1060 | train loss: 0.079862 | valid loss: 0.067268\n","Epoch:  1061 | train loss: 0.080581 | valid loss: 0.067271\n","Epoch:  1062 | train loss: 0.067969 | valid loss: 0.067265\n","Epoch:  1063 | train loss: 0.067199 | valid loss: 0.067227\n","Epoch:  1064 | train loss: 0.051729 | valid loss: 0.067201\n","Epoch:  1065 | train loss: 0.067613 | valid loss: 0.067238\n","Epoch:  1066 | train loss: 0.084014 | valid loss: 0.067248\n","Epoch:  1067 | train loss: 0.090101 | valid loss: 0.067249\n","Epoch:  1068 | train loss: 0.064937 | valid loss: 0.067193\n","Epoch:  1069 | train loss: 0.067054 | valid loss: 0.067247\n","Epoch:  1070 | train loss: 0.064049 | valid loss: 0.067315\n","Epoch:  1071 | train loss: 0.076754 | valid loss: 0.067272\n","Epoch:  1072 | train loss: 0.058694 | valid loss: 0.067363\n","Epoch:  1073 | train loss: 0.063865 | valid loss: 0.067282\n","Epoch:  1074 | train loss: 0.059969 | valid loss: 0.067308\n","Epoch:  1075 | train loss: 0.073326 | valid loss: 0.067288\n","Epoch:  1076 | train loss: 0.083541 | valid loss: 0.067282\n","Epoch:  1077 | train loss: 0.065822 | valid loss: 0.067347\n","Epoch:  1078 | train loss: 0.064416 | valid loss: 0.067265\n","Epoch:  1079 | train loss: 0.053243 | valid loss: 0.067335\n","Epoch:  1080 | train loss: 0.065657 | valid loss: 0.067302\n","Epoch:  1081 | train loss: 0.058778 | valid loss: 0.067307\n","Epoch:  1082 | train loss: 0.068313 | valid loss: 0.067286\n","Epoch:  1083 | train loss: 0.087788 | valid loss: 0.067436\n","Epoch:  1084 | train loss: 0.045940 | valid loss: 0.067316\n","Epoch:  1085 | train loss: 0.080988 | valid loss: 0.067250\n","Epoch:  1086 | train loss: 0.053695 | valid loss: 0.067286\n","Epoch:  1087 | train loss: 0.082640 | valid loss: 0.067206\n","Epoch:  1088 | train loss: 0.072327 | valid loss: 0.067249\n","Epoch:  1089 | train loss: 0.071944 | valid loss: 0.067274\n","Epoch:  1090 | train loss: 0.076770 | valid loss: 0.067298\n","Epoch:  1091 | train loss: 0.081614 | valid loss: 0.067275\n","Epoch:  1092 | train loss: 0.067742 | valid loss: 0.067329\n","Epoch:  1093 | train loss: 0.054816 | valid loss: 0.067234\n","Epoch:  1094 | train loss: 0.068688 | valid loss: 0.067253\n","Epoch:  1095 | train loss: 0.075822 | valid loss: 0.067256\n","Epoch:  1096 | train loss: 0.052329 | valid loss: 0.067234\n","Epoch:  1097 | train loss: 0.068537 | valid loss: 0.067236\n","Epoch:  1098 | train loss: 0.078261 | valid loss: 0.067228\n","Epoch:  1099 | train loss: 0.084109 | valid loss: 0.067242\n","Epoch:  1100 | train loss: 0.087533 | valid loss: 0.067263\n","Epoch:  1101 | train loss: 0.058264 | valid loss: 0.067318\n","Epoch:  1102 | train loss: 0.051944 | valid loss: 0.067320\n","Epoch:  1103 | train loss: 0.067102 | valid loss: 0.067260\n","Epoch:  1104 | train loss: 0.070199 | valid loss: 0.067193\n","Epoch:  1105 | train loss: 0.083003 | valid loss: 0.067365\n","Epoch:  1106 | train loss: 0.051536 | valid loss: 0.067264\n","Epoch:  1107 | train loss: 0.050836 | valid loss: 0.067288\n","Epoch:  1108 | train loss: 0.055924 | valid loss: 0.067297\n","Epoch:  1109 | train loss: 0.073377 | valid loss: 0.067362\n","Epoch:  1110 | train loss: 0.063520 | valid loss: 0.067247\n","Epoch:  1111 | train loss: 0.070724 | valid loss: 0.067315\n","Epoch:  1112 | train loss: 0.065783 | valid loss: 0.067427\n","Epoch:  1113 | train loss: 0.048633 | valid loss: 0.067246\n","Epoch:  1114 | train loss: 0.063115 | valid loss: 0.067353\n","Epoch:  1115 | train loss: 0.060154 | valid loss: 0.067375\n","Epoch:  1116 | train loss: 0.051036 | valid loss: 0.067230\n","Epoch:  1117 | train loss: 0.051551 | valid loss: 0.067265\n","Epoch:  1118 | train loss: 0.077158 | valid loss: 0.067266\n","Epoch:  1119 | train loss: 0.061872 | valid loss: 0.067375\n","Epoch:  1120 | train loss: 0.069005 | valid loss: 0.067339\n","Epoch:  1121 | train loss: 0.095429 | valid loss: 0.067273\n","Epoch:  1122 | train loss: 0.071669 | valid loss: 0.067185\n","Epoch:  1123 | train loss: 0.056538 | valid loss: 0.067203\n","Epoch:  1124 | train loss: 0.054097 | valid loss: 0.067194\n","Epoch:  1125 | train loss: 0.076577 | valid loss: 0.067274\n","Epoch:  1126 | train loss: 0.065941 | valid loss: 0.067341\n","Epoch:  1127 | train loss: 0.079205 | valid loss: 0.067368\n","Epoch:  1128 | train loss: 0.086287 | valid loss: 0.067347\n","Epoch:  1129 | train loss: 0.074801 | valid loss: 0.067260\n","Epoch:  1130 | train loss: 0.065781 | valid loss: 0.067331\n","Epoch:  1131 | train loss: 0.071271 | valid loss: 0.067343\n","Epoch:  1132 | train loss: 0.063835 | valid loss: 0.067294\n","Epoch:  1133 | train loss: 0.058486 | valid loss: 0.067229\n","Epoch:  1134 | train loss: 0.063713 | valid loss: 0.067416\n","Epoch:  1135 | train loss: 0.063716 | valid loss: 0.067307\n","Epoch:  1136 | train loss: 0.060057 | valid loss: 0.067266\n","Epoch:  1137 | train loss: 0.091262 | valid loss: 0.067355\n","Epoch:  1138 | train loss: 0.058711 | valid loss: 0.067188\n","Epoch:  1139 | train loss: 0.049881 | valid loss: 0.067331\n","Epoch:  1140 | train loss: 0.084884 | valid loss: 0.067325\n","Epoch:  1141 | train loss: 0.048891 | valid loss: 0.067304\n","Epoch:  1142 | train loss: 0.062919 | valid loss: 0.067315\n","Epoch:  1143 | train loss: 0.076899 | valid loss: 0.067277\n","Epoch:  1144 | train loss: 0.055653 | valid loss: 0.067361\n","Epoch:  1145 | train loss: 0.097991 | valid loss: 0.067353\n","Epoch:  1146 | train loss: 0.054989 | valid loss: 0.067322\n","Epoch:  1147 | train loss: 0.048084 | valid loss: 0.067257\n","Epoch:  1148 | train loss: 0.048960 | valid loss: 0.067285\n","Epoch:  1149 | train loss: 0.068401 | valid loss: 0.067335\n","Epoch:  1150 | train loss: 0.076565 | valid loss: 0.067307\n","Epoch:  1151 | train loss: 0.066884 | valid loss: 0.067362\n","Epoch:  1152 | train loss: 0.068922 | valid loss: 0.067342\n","Epoch:  1153 | train loss: 0.070453 | valid loss: 0.067360\n","Epoch:  1154 | train loss: 0.065299 | valid loss: 0.067383\n","Epoch:  1155 | train loss: 0.078391 | valid loss: 0.067313\n","Epoch:  1156 | train loss: 0.083836 | valid loss: 0.067296\n","Epoch:  1157 | train loss: 0.070554 | valid loss: 0.067480\n","Epoch:  1158 | train loss: 0.073041 | valid loss: 0.067368\n","Epoch:  1159 | train loss: 0.075529 | valid loss: 0.067352\n","Epoch:  1160 | train loss: 0.084316 | valid loss: 0.067248\n","Epoch:  1161 | train loss: 0.083168 | valid loss: 0.067339\n","Epoch:  1162 | train loss: 0.053740 | valid loss: 0.067349\n","Epoch:  1163 | train loss: 0.090040 | valid loss: 0.067227\n","Epoch:  1164 | train loss: 0.061995 | valid loss: 0.067363\n","Epoch:  1165 | train loss: 0.061929 | valid loss: 0.067294\n","Epoch:  1166 | train loss: 0.060833 | valid loss: 0.067201\n","Epoch:  1167 | train loss: 0.055213 | valid loss: 0.067229\n","Epoch:  1168 | train loss: 0.073201 | valid loss: 0.067355\n","Epoch:  1169 | train loss: 0.053893 | valid loss: 0.067201\n","Epoch:  1170 | train loss: 0.066592 | valid loss: 0.067322\n","Epoch:  1171 | train loss: 0.063721 | valid loss: 0.067459\n","Epoch:  1172 | train loss: 0.050283 | valid loss: 0.067281\n","Epoch:  1173 | train loss: 0.055708 | valid loss: 0.067332\n","Epoch:  1174 | train loss: 0.078701 | valid loss: 0.067295\n","Epoch:  1175 | train loss: 0.063467 | valid loss: 0.067260\n","Epoch:  1176 | train loss: 0.055829 | valid loss: 0.067265\n","Epoch:  1177 | train loss: 0.066975 | valid loss: 0.067391\n","Epoch:  1178 | train loss: 0.068769 | valid loss: 0.067372\n","Epoch:  1179 | train loss: 0.056617 | valid loss: 0.067277\n","Epoch:  1180 | train loss: 0.054064 | valid loss: 0.067252\n","Epoch:  1181 | train loss: 0.052031 | valid loss: 0.067261\n","Epoch:  1182 | train loss: 0.058083 | valid loss: 0.067240\n","Epoch:  1183 | train loss: 0.099247 | valid loss: 0.067405\n","Epoch:  1184 | train loss: 0.046536 | valid loss: 0.067214\n","Epoch:  1185 | train loss: 0.062503 | valid loss: 0.067224\n","Epoch:  1186 | train loss: 0.052544 | valid loss: 0.067283\n","Epoch:  1187 | train loss: 0.077758 | valid loss: 0.067251\n","Epoch:  1188 | train loss: 0.057944 | valid loss: 0.067284\n","Epoch:  1189 | train loss: 0.073009 | valid loss: 0.067308\n","Epoch:  1190 | train loss: 0.074338 | valid loss: 0.067328\n","Epoch:  1191 | train loss: 0.050444 | valid loss: 0.067310\n","Epoch:  1192 | train loss: 0.054806 | valid loss: 0.067271\n","Epoch:  1193 | train loss: 0.070584 | valid loss: 0.067400\n","Epoch:  1194 | train loss: 0.092768 | valid loss: 0.067280\n","Epoch:  1195 | train loss: 0.075415 | valid loss: 0.067330\n","Epoch:  1196 | train loss: 0.064106 | valid loss: 0.067256\n","Epoch:  1197 | train loss: 0.064992 | valid loss: 0.067335\n","Epoch:  1198 | train loss: 0.077347 | valid loss: 0.067266\n","Epoch:  1199 | train loss: 0.073103 | valid loss: 0.067401\n","Epoch:  1200 | train loss: 0.081396 | valid loss: 0.067288\n","Epoch:  1201 | train loss: 0.064705 | valid loss: 0.067266\n","Epoch:  1202 | train loss: 0.091921 | valid loss: 0.067362\n","Epoch:  1203 | train loss: 0.063082 | valid loss: 0.067300\n","Epoch:  1204 | train loss: 0.073382 | valid loss: 0.067229\n","Epoch:  1205 | train loss: 0.077744 | valid loss: 0.067325\n","Epoch:  1206 | train loss: 0.084866 | valid loss: 0.067310\n","Epoch:  1207 | train loss: 0.050219 | valid loss: 0.067368\n","Epoch:  1208 | train loss: 0.091554 | valid loss: 0.067353\n","Epoch:  1209 | train loss: 0.085584 | valid loss: 0.067418\n","Epoch:  1210 | train loss: 0.077107 | valid loss: 0.067359\n","Epoch:  1211 | train loss: 0.074514 | valid loss: 0.067228\n","Epoch:  1212 | train loss: 0.097196 | valid loss: 0.067234\n","Epoch:  1213 | train loss: 0.074036 | valid loss: 0.067243\n","Epoch:  1214 | train loss: 0.072606 | valid loss: 0.067250\n","Epoch:  1215 | train loss: 0.062373 | valid loss: 0.067275\n","Epoch:  1216 | train loss: 0.056097 | valid loss: 0.067252\n","Epoch:  1217 | train loss: 0.079823 | valid loss: 0.067312\n","Epoch:  1218 | train loss: 0.048041 | valid loss: 0.067302\n","Epoch:  1219 | train loss: 0.064057 | valid loss: 0.067401\n","Epoch:  1220 | train loss: 0.058597 | valid loss: 0.067387\n","Epoch:  1221 | train loss: 0.066773 | valid loss: 0.067284\n","Epoch:  1222 | train loss: 0.058760 | valid loss: 0.067298\n","Epoch:  1223 | train loss: 0.052390 | valid loss: 0.067270\n","Epoch:  1224 | train loss: 0.062720 | valid loss: 0.067300\n","Epoch:  1225 | train loss: 0.072575 | valid loss: 0.067355\n","Epoch:  1226 | train loss: 0.081085 | valid loss: 0.067361\n","Epoch:  1227 | train loss: 0.045862 | valid loss: 0.067325\n","Epoch:  1228 | train loss: 0.072233 | valid loss: 0.067294\n","Epoch:  1229 | train loss: 0.075152 | valid loss: 0.067332\n","Epoch:  1230 | train loss: 0.065657 | valid loss: 0.067289\n","Epoch:  1231 | train loss: 0.067219 | valid loss: 0.067272\n","Epoch:  1232 | train loss: 0.063424 | valid loss: 0.067273\n","Epoch:  1233 | train loss: 0.063241 | valid loss: 0.067284\n","Epoch:  1234 | train loss: 0.078413 | valid loss: 0.067281\n","Epoch:  1235 | train loss: 0.068887 | valid loss: 0.067340\n","Epoch:  1236 | train loss: 0.071217 | valid loss: 0.067301\n","Epoch:  1237 | train loss: 0.078942 | valid loss: 0.067320\n","Epoch:  1238 | train loss: 0.085061 | valid loss: 0.067405\n","Epoch:  1239 | train loss: 0.063760 | valid loss: 0.067375\n","Epoch:  1240 | train loss: 0.082825 | valid loss: 0.067443\n","Epoch:  1241 | train loss: 0.068469 | valid loss: 0.067351\n","Epoch:  1242 | train loss: 0.069301 | valid loss: 0.067331\n","Epoch:  1243 | train loss: 0.083663 | valid loss: 0.067295\n","Epoch:  1244 | train loss: 0.055084 | valid loss: 0.067353\n","Epoch:  1245 | train loss: 0.054757 | valid loss: 0.067309\n","Epoch:  1246 | train loss: 0.085713 | valid loss: 0.067365\n","Epoch:  1247 | train loss: 0.058087 | valid loss: 0.067324\n","Epoch:  1248 | train loss: 0.086609 | valid loss: 0.067318\n","Epoch:  1249 | train loss: 0.087980 | valid loss: 0.067256\n","Epoch:  1250 | train loss: 0.068235 | valid loss: 0.067282\n","Epoch:  1251 | train loss: 0.046381 | valid loss: 0.067311\n","Epoch:  1252 | train loss: 0.073404 | valid loss: 0.067283\n","Epoch:  1253 | train loss: 0.080922 | valid loss: 0.067413\n","Epoch:  1254 | train loss: 0.069175 | valid loss: 0.067302\n","Epoch:  1255 | train loss: 0.070270 | valid loss: 0.067322\n","Epoch:  1256 | train loss: 0.084546 | valid loss: 0.067264\n","Epoch:  1257 | train loss: 0.067971 | valid loss: 0.067304\n","Epoch:  1258 | train loss: 0.051292 | valid loss: 0.067326\n","Epoch:  1259 | train loss: 0.049414 | valid loss: 0.067378\n","Epoch:  1260 | train loss: 0.097355 | valid loss: 0.067264\n","Epoch:  1261 | train loss: 0.065862 | valid loss: 0.067256\n","Epoch:  1262 | train loss: 0.077495 | valid loss: 0.067293\n","Epoch:  1263 | train loss: 0.061115 | valid loss: 0.067381\n","Epoch:  1264 | train loss: 0.060017 | valid loss: 0.067285\n","Epoch:  1265 | train loss: 0.061273 | valid loss: 0.067315\n","Epoch:  1266 | train loss: 0.077207 | valid loss: 0.067361\n","Epoch:  1267 | train loss: 0.073652 | valid loss: 0.067275\n","Epoch:  1268 | train loss: 0.061337 | valid loss: 0.067349\n","Epoch:  1269 | train loss: 0.085317 | valid loss: 0.067274\n","Epoch:  1270 | train loss: 0.059726 | valid loss: 0.067376\n","Epoch:  1271 | train loss: 0.080888 | valid loss: 0.067367\n","Epoch:  1272 | train loss: 0.064355 | valid loss: 0.067339\n","Epoch:  1273 | train loss: 0.058892 | valid loss: 0.067318\n","Epoch:  1274 | train loss: 0.089028 | valid loss: 0.067417\n","Epoch:  1275 | train loss: 0.065567 | valid loss: 0.067423\n","Epoch:  1276 | train loss: 0.076866 | valid loss: 0.067316\n","Epoch:  1277 | train loss: 0.064033 | valid loss: 0.067250\n","Epoch:  1278 | train loss: 0.057255 | valid loss: 0.067389\n","Epoch:  1279 | train loss: 0.059692 | valid loss: 0.067390\n","Epoch:  1280 | train loss: 0.080034 | valid loss: 0.067364\n","Epoch:  1281 | train loss: 0.051613 | valid loss: 0.067333\n","Epoch:  1282 | train loss: 0.075515 | valid loss: 0.067340\n","Epoch:  1283 | train loss: 0.060173 | valid loss: 0.067298\n","Epoch:  1284 | train loss: 0.086100 | valid loss: 0.067419\n","Epoch:  1285 | train loss: 0.063720 | valid loss: 0.067375\n","Epoch:  1286 | train loss: 0.075145 | valid loss: 0.067323\n","Epoch:  1287 | train loss: 0.072295 | valid loss: 0.067317\n","Epoch:  1288 | train loss: 0.073857 | valid loss: 0.067321\n","Epoch:  1289 | train loss: 0.066701 | valid loss: 0.067401\n","Epoch:  1290 | train loss: 0.076056 | valid loss: 0.067292\n","Epoch:  1291 | train loss: 0.048817 | valid loss: 0.067379\n","Epoch:  1292 | train loss: 0.063348 | valid loss: 0.067336\n","Epoch:  1293 | train loss: 0.054460 | valid loss: 0.067319\n","Epoch:  1294 | train loss: 0.095292 | valid loss: 0.067352\n","Epoch:  1295 | train loss: 0.084873 | valid loss: 0.067329\n","Epoch:  1296 | train loss: 0.065836 | valid loss: 0.067244\n","Epoch:  1297 | train loss: 0.066714 | valid loss: 0.067291\n","Epoch:  1298 | train loss: 0.065725 | valid loss: 0.067278\n","Epoch:  1299 | train loss: 0.095602 | valid loss: 0.067313\n","Epoch:  1300 | train loss: 0.056140 | valid loss: 0.067351\n","Epoch:  1301 | train loss: 0.064720 | valid loss: 0.067261\n","Epoch:  1302 | train loss: 0.063059 | valid loss: 0.067262\n","Epoch:  1303 | train loss: 0.068801 | valid loss: 0.067283\n","Epoch:  1304 | train loss: 0.062586 | valid loss: 0.067358\n","Epoch:  1305 | train loss: 0.065627 | valid loss: 0.067337\n","Epoch:  1306 | train loss: 0.084951 | valid loss: 0.067246\n","Epoch:  1307 | train loss: 0.058578 | valid loss: 0.067325\n","Epoch:  1308 | train loss: 0.072016 | valid loss: 0.067259\n","Epoch:  1309 | train loss: 0.068668 | valid loss: 0.067263\n","Epoch:  1310 | train loss: 0.086411 | valid loss: 0.067384\n","Epoch:  1311 | train loss: 0.057228 | valid loss: 0.067307\n","Epoch:  1312 | train loss: 0.070939 | valid loss: 0.067254\n","Epoch:  1313 | train loss: 0.065699 | valid loss: 0.067219\n","Epoch:  1314 | train loss: 0.053246 | valid loss: 0.067257\n","Epoch:  1315 | train loss: 0.045087 | valid loss: 0.067194\n","Epoch:  1316 | train loss: 0.061219 | valid loss: 0.067369\n","Epoch:  1317 | train loss: 0.066530 | valid loss: 0.067298\n","Epoch:  1318 | train loss: 0.073693 | valid loss: 0.067257\n","Epoch:  1319 | train loss: 0.069816 | valid loss: 0.067384\n","Epoch:  1320 | train loss: 0.061185 | valid loss: 0.067330\n","Epoch:  1321 | train loss: 0.059919 | valid loss: 0.067347\n","Epoch:  1322 | train loss: 0.049748 | valid loss: 0.067263\n","Epoch:  1323 | train loss: 0.058764 | valid loss: 0.067407\n","Epoch:  1324 | train loss: 0.076892 | valid loss: 0.067390\n","Epoch:  1325 | train loss: 0.061957 | valid loss: 0.067203\n","Epoch:  1326 | train loss: 0.068080 | valid loss: 0.067348\n","Epoch:  1327 | train loss: 0.058391 | valid loss: 0.067281\n","Epoch:  1328 | train loss: 0.083291 | valid loss: 0.067247\n","Epoch:  1329 | train loss: 0.058146 | valid loss: 0.067349\n","Epoch:  1330 | train loss: 0.086574 | valid loss: 0.067298\n","Epoch:  1331 | train loss: 0.066926 | valid loss: 0.067278\n","Epoch:  1332 | train loss: 0.076707 | valid loss: 0.067318\n","Epoch:  1333 | train loss: 0.064624 | valid loss: 0.067347\n","Epoch:  1334 | train loss: 0.055330 | valid loss: 0.067334\n","Epoch:  1335 | train loss: 0.073461 | valid loss: 0.067323\n","Epoch:  1336 | train loss: 0.062475 | valid loss: 0.067443\n","Epoch:  1337 | train loss: 0.054740 | valid loss: 0.067291\n","Epoch:  1338 | train loss: 0.092185 | valid loss: 0.067304\n","Epoch:  1339 | train loss: 0.065467 | valid loss: 0.067318\n","Epoch:  1340 | train loss: 0.072602 | valid loss: 0.067436\n","Epoch:  1341 | train loss: 0.073049 | valid loss: 0.067328\n","Epoch:  1342 | train loss: 0.060422 | valid loss: 0.067344\n","Epoch:  1343 | train loss: 0.080493 | valid loss: 0.067341\n","Epoch:  1344 | train loss: 0.077264 | valid loss: 0.067391\n","Epoch:  1345 | train loss: 0.062179 | valid loss: 0.067260\n","Epoch:  1346 | train loss: 0.059329 | valid loss: 0.067346\n","Epoch:  1347 | train loss: 0.071184 | valid loss: 0.067339\n","Epoch:  1348 | train loss: 0.081575 | valid loss: 0.067385\n","Epoch:  1349 | train loss: 0.097733 | valid loss: 0.067398\n","Epoch:  1350 | train loss: 0.101476 | valid loss: 0.067415\n","Epoch:  1351 | train loss: 0.070587 | valid loss: 0.067282\n","Epoch:  1352 | train loss: 0.064706 | valid loss: 0.067305\n","Epoch:  1353 | train loss: 0.078305 | valid loss: 0.067503\n","Epoch:  1354 | train loss: 0.103666 | valid loss: 0.067328\n","Epoch:  1355 | train loss: 0.071310 | valid loss: 0.067287\n","Epoch:  1356 | train loss: 0.065662 | valid loss: 0.067320\n","Epoch:  1357 | train loss: 0.066195 | valid loss: 0.067297\n","Epoch:  1358 | train loss: 0.078983 | valid loss: 0.067323\n","Epoch:  1359 | train loss: 0.058216 | valid loss: 0.067295\n","Epoch:  1360 | train loss: 0.056387 | valid loss: 0.067372\n","Epoch:  1361 | train loss: 0.081446 | valid loss: 0.067426\n","Epoch:  1362 | train loss: 0.069481 | valid loss: 0.067373\n","Epoch:  1363 | train loss: 0.086882 | valid loss: 0.067348\n","Epoch:  1364 | train loss: 0.060802 | valid loss: 0.067270\n","Epoch:  1365 | train loss: 0.059958 | valid loss: 0.067343\n","Epoch:  1366 | train loss: 0.075457 | valid loss: 0.067291\n","Epoch:  1367 | train loss: 0.053502 | valid loss: 0.067312\n","Epoch:  1368 | train loss: 0.073526 | valid loss: 0.067340\n","Epoch:  1369 | train loss: 0.053520 | valid loss: 0.067319\n","Epoch:  1370 | train loss: 0.060342 | valid loss: 0.067365\n","Epoch:  1371 | train loss: 0.080441 | valid loss: 0.067338\n","Epoch:  1372 | train loss: 0.082277 | valid loss: 0.067414\n","Epoch:  1373 | train loss: 0.056521 | valid loss: 0.067263\n","Epoch:  1374 | train loss: 0.067973 | valid loss: 0.067284\n","Epoch:  1375 | train loss: 0.055415 | valid loss: 0.067303\n","Epoch:  1376 | train loss: 0.049398 | valid loss: 0.067264\n","Epoch:  1377 | train loss: 0.059684 | valid loss: 0.067305\n","Epoch:  1378 | train loss: 0.073650 | valid loss: 0.067368\n","Epoch:  1379 | train loss: 0.068512 | valid loss: 0.067321\n","Epoch:  1380 | train loss: 0.091461 | valid loss: 0.067438\n","Epoch:  1381 | train loss: 0.064914 | valid loss: 0.067313\n","Epoch:  1382 | train loss: 0.065983 | valid loss: 0.067338\n","Epoch:  1383 | train loss: 0.083167 | valid loss: 0.067345\n","Epoch:  1384 | train loss: 0.084926 | valid loss: 0.067316\n","Epoch:  1385 | train loss: 0.066735 | valid loss: 0.067343\n","Epoch:  1386 | train loss: 0.067727 | valid loss: 0.067372\n","Epoch:  1387 | train loss: 0.084772 | valid loss: 0.067400\n","Epoch:  1388 | train loss: 0.068194 | valid loss: 0.067359\n","Epoch:  1389 | train loss: 0.071307 | valid loss: 0.067323\n","Epoch:  1390 | train loss: 0.063923 | valid loss: 0.067355\n","Epoch:  1391 | train loss: 0.070672 | valid loss: 0.067361\n","Epoch:  1392 | train loss: 0.064928 | valid loss: 0.067429\n","Epoch:  1393 | train loss: 0.065606 | valid loss: 0.067424\n","Epoch:  1394 | train loss: 0.077215 | valid loss: 0.067257\n","Epoch:  1395 | train loss: 0.076107 | valid loss: 0.067371\n","Epoch:  1396 | train loss: 0.076049 | valid loss: 0.067339\n","Epoch:  1397 | train loss: 0.068565 | valid loss: 0.067315\n","Epoch:  1398 | train loss: 0.058132 | valid loss: 0.067266\n","Epoch:  1399 | train loss: 0.066977 | valid loss: 0.067373\n","Epoch:  1400 | train loss: 0.058454 | valid loss: 0.067279\n","Epoch:  1401 | train loss: 0.063170 | valid loss: 0.067266\n","Epoch:  1402 | train loss: 0.052434 | valid loss: 0.067323\n","Epoch:  1403 | train loss: 0.088081 | valid loss: 0.067330\n","Epoch:  1404 | train loss: 0.050517 | valid loss: 0.067381\n","Epoch:  1405 | train loss: 0.062523 | valid loss: 0.067338\n","Epoch:  1406 | train loss: 0.067376 | valid loss: 0.067387\n","Epoch:  1407 | train loss: 0.072357 | valid loss: 0.067404\n","Epoch:  1408 | train loss: 0.083928 | valid loss: 0.067331\n","Epoch:  1409 | train loss: 0.042526 | valid loss: 0.067329\n","Epoch:  1410 | train loss: 0.071535 | valid loss: 0.067436\n","Epoch:  1411 | train loss: 0.064972 | valid loss: 0.067405\n","Epoch:  1412 | train loss: 0.085866 | valid loss: 0.067453\n","Epoch:  1413 | train loss: 0.079426 | valid loss: 0.067311\n","Epoch:  1414 | train loss: 0.075883 | valid loss: 0.067378\n","Epoch:  1415 | train loss: 0.084469 | valid loss: 0.067324\n","Epoch:  1416 | train loss: 0.054119 | valid loss: 0.067399\n","Epoch:  1417 | train loss: 0.058861 | valid loss: 0.067394\n","Epoch:  1418 | train loss: 0.061388 | valid loss: 0.067264\n","Epoch:  1419 | train loss: 0.069664 | valid loss: 0.067439\n","Epoch:  1420 | train loss: 0.057316 | valid loss: 0.067250\n","Epoch:  1421 | train loss: 0.085426 | valid loss: 0.067385\n","Epoch:  1422 | train loss: 0.089405 | valid loss: 0.067418\n","Epoch:  1423 | train loss: 0.074199 | valid loss: 0.067315\n","Epoch:  1424 | train loss: 0.070734 | valid loss: 0.067357\n","Epoch:  1425 | train loss: 0.099011 | valid loss: 0.067297\n","Epoch:  1426 | train loss: 0.079443 | valid loss: 0.067325\n","Epoch:  1427 | train loss: 0.056699 | valid loss: 0.067345\n","Epoch:  1428 | train loss: 0.061303 | valid loss: 0.067276\n","Epoch:  1429 | train loss: 0.072351 | valid loss: 0.067373\n","Epoch:  1430 | train loss: 0.065026 | valid loss: 0.067264\n","Epoch:  1431 | train loss: 0.058800 | valid loss: 0.067358\n","Epoch:  1432 | train loss: 0.057424 | valid loss: 0.067361\n","Epoch:  1433 | train loss: 0.074986 | valid loss: 0.067344\n","Epoch:  1434 | train loss: 0.066743 | valid loss: 0.067267\n","Epoch:  1435 | train loss: 0.048806 | valid loss: 0.067419\n","Epoch:  1436 | train loss: 0.061637 | valid loss: 0.067372\n","Epoch:  1437 | train loss: 0.075402 | valid loss: 0.067286\n","Epoch:  1438 | train loss: 0.086387 | valid loss: 0.067450\n","Epoch:  1439 | train loss: 0.068695 | valid loss: 0.067324\n","Epoch:  1440 | train loss: 0.071530 | valid loss: 0.067303\n","Epoch:  1441 | train loss: 0.076941 | valid loss: 0.067372\n","Epoch:  1442 | train loss: 0.049499 | valid loss: 0.067369\n","Epoch:  1443 | train loss: 0.071331 | valid loss: 0.067333\n","Epoch:  1444 | train loss: 0.077144 | valid loss: 0.067452\n","Epoch:  1445 | train loss: 0.060555 | valid loss: 0.067304\n","Epoch:  1446 | train loss: 0.046176 | valid loss: 0.067401\n","Epoch:  1447 | train loss: 0.062152 | valid loss: 0.067480\n","Epoch:  1448 | train loss: 0.086921 | valid loss: 0.067406\n","Epoch:  1449 | train loss: 0.069124 | valid loss: 0.067382\n","Epoch:  1450 | train loss: 0.065441 | valid loss: 0.067271\n","Epoch:  1451 | train loss: 0.075035 | valid loss: 0.067455\n","Epoch:  1452 | train loss: 0.091313 | valid loss: 0.067409\n","Epoch:  1453 | train loss: 0.073803 | valid loss: 0.067365\n","Epoch:  1454 | train loss: 0.045973 | valid loss: 0.067379\n","Epoch:  1455 | train loss: 0.066222 | valid loss: 0.067410\n","Epoch:  1456 | train loss: 0.049816 | valid loss: 0.067467\n","Epoch:  1457 | train loss: 0.100024 | valid loss: 0.067363\n","Epoch:  1458 | train loss: 0.066903 | valid loss: 0.067330\n","Epoch:  1459 | train loss: 0.057131 | valid loss: 0.067352\n","Epoch:  1460 | train loss: 0.077127 | valid loss: 0.067366\n","Epoch:  1461 | train loss: 0.055213 | valid loss: 0.067399\n","Epoch:  1462 | train loss: 0.053750 | valid loss: 0.067243\n","Epoch:  1463 | train loss: 0.049297 | valid loss: 0.067361\n","Epoch:  1464 | train loss: 0.064735 | valid loss: 0.067347\n","Epoch:  1465 | train loss: 0.067156 | valid loss: 0.067481\n","Epoch:  1466 | train loss: 0.079717 | valid loss: 0.067316\n","Epoch:  1467 | train loss: 0.079681 | valid loss: 0.067386\n","Epoch:  1468 | train loss: 0.068820 | valid loss: 0.067323\n","Epoch:  1469 | train loss: 0.091040 | valid loss: 0.067332\n","Epoch:  1470 | train loss: 0.069581 | valid loss: 0.067406\n","Epoch:  1471 | train loss: 0.066716 | valid loss: 0.067424\n","Epoch:  1472 | train loss: 0.068131 | valid loss: 0.067431\n","Epoch:  1473 | train loss: 0.055500 | valid loss: 0.067323\n","Epoch:  1474 | train loss: 0.079523 | valid loss: 0.067322\n","Epoch:  1475 | train loss: 0.074178 | valid loss: 0.067338\n","Epoch:  1476 | train loss: 0.057856 | valid loss: 0.067454\n","Epoch:  1477 | train loss: 0.062662 | valid loss: 0.067365\n","Epoch:  1478 | train loss: 0.072372 | valid loss: 0.067324\n","Epoch:  1479 | train loss: 0.073499 | valid loss: 0.067315\n","Epoch:  1480 | train loss: 0.074527 | valid loss: 0.067334\n","Epoch:  1481 | train loss: 0.069462 | valid loss: 0.067338\n","Epoch:  1482 | train loss: 0.081125 | valid loss: 0.067293\n","Epoch:  1483 | train loss: 0.063829 | valid loss: 0.067337\n","Epoch:  1484 | train loss: 0.076004 | valid loss: 0.067315\n","Epoch:  1485 | train loss: 0.065171 | valid loss: 0.067322\n","Epoch:  1486 | train loss: 0.054447 | valid loss: 0.067321\n","Epoch:  1487 | train loss: 0.086025 | valid loss: 0.067331\n","Epoch:  1488 | train loss: 0.085262 | valid loss: 0.067306\n","Epoch:  1489 | train loss: 0.047736 | valid loss: 0.067290\n","Epoch:  1490 | train loss: 0.070309 | valid loss: 0.067386\n","Epoch:  1491 | train loss: 0.048424 | valid loss: 0.067362\n","Epoch:  1492 | train loss: 0.058914 | valid loss: 0.067286\n","Epoch:  1493 | train loss: 0.062198 | valid loss: 0.067369\n","Epoch:  1494 | train loss: 0.074466 | valid loss: 0.067389\n","Epoch:  1495 | train loss: 0.059248 | valid loss: 0.067373\n","Epoch:  1496 | train loss: 0.062060 | valid loss: 0.067423\n","Epoch:  1497 | train loss: 0.083209 | valid loss: 0.067274\n","Epoch:  1498 | train loss: 0.091786 | valid loss: 0.067381\n","Epoch:  1499 | train loss: 0.079216 | valid loss: 0.067373\n","Epoch:  1500 | train loss: 0.066847 | valid loss: 0.067344\n","Epoch:  1501 | train loss: 0.063396 | valid loss: 0.067341\n","Epoch:  1502 | train loss: 0.056988 | valid loss: 0.067374\n","Epoch:  1503 | train loss: 0.069920 | valid loss: 0.067355\n","Epoch:  1504 | train loss: 0.079009 | valid loss: 0.067368\n","Epoch:  1505 | train loss: 0.088870 | valid loss: 0.067402\n","Epoch:  1506 | train loss: 0.064055 | valid loss: 0.067371\n","Epoch:  1507 | train loss: 0.050185 | valid loss: 0.067454\n","Epoch:  1508 | train loss: 0.072535 | valid loss: 0.067394\n","Epoch:  1509 | train loss: 0.060859 | valid loss: 0.067412\n","Epoch:  1510 | train loss: 0.062411 | valid loss: 0.067399\n","Epoch:  1511 | train loss: 0.061105 | valid loss: 0.067383\n","Epoch:  1512 | train loss: 0.095832 | valid loss: 0.067394\n","Epoch:  1513 | train loss: 0.055730 | valid loss: 0.067346\n","Epoch:  1514 | train loss: 0.095608 | valid loss: 0.067361\n","Epoch:  1515 | train loss: 0.060374 | valid loss: 0.067378\n","Epoch:  1516 | train loss: 0.073870 | valid loss: 0.067392\n","Epoch:  1517 | train loss: 0.067292 | valid loss: 0.067406\n","Epoch:  1518 | train loss: 0.071632 | valid loss: 0.067359\n","Epoch:  1519 | train loss: 0.056209 | valid loss: 0.067397\n","Epoch:  1520 | train loss: 0.073561 | valid loss: 0.067427\n","Epoch:  1521 | train loss: 0.064038 | valid loss: 0.067441\n","Epoch:  1522 | train loss: 0.063879 | valid loss: 0.067338\n","Epoch:  1523 | train loss: 0.048380 | valid loss: 0.067356\n","Epoch:  1524 | train loss: 0.057374 | valid loss: 0.067316\n","Epoch:  1525 | train loss: 0.067103 | valid loss: 0.067345\n","Epoch:  1526 | train loss: 0.101696 | valid loss: 0.067365\n","Epoch:  1527 | train loss: 0.081784 | valid loss: 0.067459\n","Epoch:  1528 | train loss: 0.059868 | valid loss: 0.067381\n","Epoch:  1529 | train loss: 0.058000 | valid loss: 0.067403\n","Epoch:  1530 | train loss: 0.059127 | valid loss: 0.067352\n","Epoch:  1531 | train loss: 0.050694 | valid loss: 0.067415\n","Epoch:  1532 | train loss: 0.043961 | valid loss: 0.067418\n","Epoch:  1533 | train loss: 0.055497 | valid loss: 0.067443\n","Epoch:  1534 | train loss: 0.069127 | valid loss: 0.067347\n","Epoch:  1535 | train loss: 0.073644 | valid loss: 0.067362\n","Epoch:  1536 | train loss: 0.065851 | valid loss: 0.067432\n","Epoch:  1537 | train loss: 0.067488 | valid loss: 0.067309\n","Epoch:  1538 | train loss: 0.076321 | valid loss: 0.067403\n","Epoch:  1539 | train loss: 0.082919 | valid loss: 0.067405\n","Epoch:  1540 | train loss: 0.068850 | valid loss: 0.067441\n","Epoch:  1541 | train loss: 0.075477 | valid loss: 0.067372\n","Epoch:  1542 | train loss: 0.080585 | valid loss: 0.067293\n","Epoch:  1543 | train loss: 0.047224 | valid loss: 0.067382\n","Epoch:  1544 | train loss: 0.056706 | valid loss: 0.067502\n","Epoch:  1545 | train loss: 0.065028 | valid loss: 0.067411\n","Epoch:  1546 | train loss: 0.091909 | valid loss: 0.067386\n","Epoch:  1547 | train loss: 0.062898 | valid loss: 0.067302\n","Epoch:  1548 | train loss: 0.059059 | valid loss: 0.067287\n","Epoch:  1549 | train loss: 0.050645 | valid loss: 0.067336\n","Epoch:  1550 | train loss: 0.049549 | valid loss: 0.067391\n","Epoch:  1551 | train loss: 0.053643 | valid loss: 0.067434\n","Epoch:  1552 | train loss: 0.070498 | valid loss: 0.067342\n","Epoch:  1553 | train loss: 0.086138 | valid loss: 0.067442\n","Epoch:  1554 | train loss: 0.068934 | valid loss: 0.067394\n","Epoch:  1555 | train loss: 0.101571 | valid loss: 0.067320\n","Epoch:  1556 | train loss: 0.058396 | valid loss: 0.067372\n","Epoch:  1557 | train loss: 0.090085 | valid loss: 0.067468\n","Epoch:  1558 | train loss: 0.079062 | valid loss: 0.067337\n","Epoch:  1559 | train loss: 0.084470 | valid loss: 0.067291\n","Epoch:  1560 | train loss: 0.062265 | valid loss: 0.067324\n","Epoch:  1561 | train loss: 0.082248 | valid loss: 0.067355\n","Epoch:  1562 | train loss: 0.075320 | valid loss: 0.067288\n","Epoch:  1563 | train loss: 0.050981 | valid loss: 0.067391\n","Epoch:  1564 | train loss: 0.052428 | valid loss: 0.067368\n","Epoch:  1565 | train loss: 0.060052 | valid loss: 0.067426\n","Epoch:  1566 | train loss: 0.062361 | valid loss: 0.067336\n","Epoch:  1567 | train loss: 0.051658 | valid loss: 0.067343\n","Epoch:  1568 | train loss: 0.074335 | valid loss: 0.067356\n","Epoch:  1569 | train loss: 0.090276 | valid loss: 0.067348\n","Epoch:  1570 | train loss: 0.080998 | valid loss: 0.067389\n","Epoch:  1571 | train loss: 0.072171 | valid loss: 0.067373\n","Epoch:  1572 | train loss: 0.079899 | valid loss: 0.067413\n","Epoch:  1573 | train loss: 0.075553 | valid loss: 0.067517\n","Epoch:  1574 | train loss: 0.068202 | valid loss: 0.067348\n","Epoch:  1575 | train loss: 0.066417 | valid loss: 0.067526\n","Epoch:  1576 | train loss: 0.068644 | valid loss: 0.067378\n","Epoch:  1577 | train loss: 0.092888 | valid loss: 0.067625\n","Epoch:  1578 | train loss: 0.052766 | valid loss: 0.067451\n","Epoch:  1579 | train loss: 0.059617 | valid loss: 0.067462\n","Epoch:  1580 | train loss: 0.079699 | valid loss: 0.067388\n","Epoch:  1581 | train loss: 0.066706 | valid loss: 0.067337\n","Epoch:  1582 | train loss: 0.068097 | valid loss: 0.067348\n","Epoch:  1583 | train loss: 0.101505 | valid loss: 0.067501\n","Epoch:  1584 | train loss: 0.087981 | valid loss: 0.067435\n","Epoch:  1585 | train loss: 0.074765 | valid loss: 0.067420\n","Epoch:  1586 | train loss: 0.060464 | valid loss: 0.067440\n","Epoch:  1587 | train loss: 0.074412 | valid loss: 0.067411\n","Epoch:  1588 | train loss: 0.069238 | valid loss: 0.067396\n","Epoch:  1589 | train loss: 0.062291 | valid loss: 0.067436\n","Epoch:  1590 | train loss: 0.073694 | valid loss: 0.067429\n","Epoch:  1591 | train loss: 0.090917 | valid loss: 0.067366\n","Epoch:  1592 | train loss: 0.058568 | valid loss: 0.067392\n","Epoch:  1593 | train loss: 0.066526 | valid loss: 0.067448\n","Epoch:  1594 | train loss: 0.058819 | valid loss: 0.067402\n","Epoch:  1595 | train loss: 0.078627 | valid loss: 0.067483\n","Epoch:  1596 | train loss: 0.067618 | valid loss: 0.067414\n","Epoch:  1597 | train loss: 0.060037 | valid loss: 0.067389\n","Epoch:  1598 | train loss: 0.048526 | valid loss: 0.067366\n","Epoch:  1599 | train loss: 0.060875 | valid loss: 0.067388\n","Epoch:  1600 | train loss: 0.064812 | valid loss: 0.067356\n","Epoch:  1601 | train loss: 0.060585 | valid loss: 0.067430\n","Epoch:  1602 | train loss: 0.073572 | valid loss: 0.067349\n","Epoch:  1603 | train loss: 0.054768 | valid loss: 0.067390\n","Epoch:  1604 | train loss: 0.058230 | valid loss: 0.067465\n","Epoch:  1605 | train loss: 0.074880 | valid loss: 0.067409\n","Epoch:  1606 | train loss: 0.062090 | valid loss: 0.067503\n","Epoch:  1607 | train loss: 0.065983 | valid loss: 0.067385\n","Epoch:  1608 | train loss: 0.095506 | valid loss: 0.067407\n","Epoch:  1609 | train loss: 0.062939 | valid loss: 0.067325\n","Epoch:  1610 | train loss: 0.050745 | valid loss: 0.067388\n","Epoch:  1611 | train loss: 0.066050 | valid loss: 0.067382\n","Epoch:  1612 | train loss: 0.057354 | valid loss: 0.067424\n","Epoch:  1613 | train loss: 0.053561 | valid loss: 0.067393\n","Epoch:  1614 | train loss: 0.076774 | valid loss: 0.067442\n","Epoch:  1615 | train loss: 0.080837 | valid loss: 0.067425\n","Epoch:  1616 | train loss: 0.063290 | valid loss: 0.067524\n","Epoch:  1617 | train loss: 0.056176 | valid loss: 0.067401\n","Epoch:  1618 | train loss: 0.091248 | valid loss: 0.067345\n","Epoch:  1619 | train loss: 0.085895 | valid loss: 0.067527\n","Epoch:  1620 | train loss: 0.063936 | valid loss: 0.067402\n","Epoch:  1621 | train loss: 0.068787 | valid loss: 0.067466\n","Epoch:  1622 | train loss: 0.088195 | valid loss: 0.067411\n","Epoch:  1623 | train loss: 0.063667 | valid loss: 0.067421\n","Epoch:  1624 | train loss: 0.048976 | valid loss: 0.067349\n","Epoch:  1625 | train loss: 0.075396 | valid loss: 0.067409\n","Epoch:  1626 | train loss: 0.047070 | valid loss: 0.067388\n","Epoch:  1627 | train loss: 0.062372 | valid loss: 0.067400\n","Epoch:  1628 | train loss: 0.076043 | valid loss: 0.067374\n","Epoch:  1629 | train loss: 0.050515 | valid loss: 0.067377\n","Epoch:  1630 | train loss: 0.065850 | valid loss: 0.067492\n","Epoch:  1631 | train loss: 0.057946 | valid loss: 0.067374\n","Epoch:  1632 | train loss: 0.066519 | valid loss: 0.067312\n","Epoch:  1633 | train loss: 0.046974 | valid loss: 0.067410\n","Epoch:  1634 | train loss: 0.076629 | valid loss: 0.067426\n","Epoch:  1635 | train loss: 0.073836 | valid loss: 0.067392\n","Epoch:  1636 | train loss: 0.068979 | valid loss: 0.067467\n","Epoch:  1637 | train loss: 0.059318 | valid loss: 0.067411\n","Epoch:  1638 | train loss: 0.054395 | valid loss: 0.067466\n","Epoch:  1639 | train loss: 0.054598 | valid loss: 0.067431\n","Epoch:  1640 | train loss: 0.083169 | valid loss: 0.067418\n","Epoch:  1641 | train loss: 0.057253 | valid loss: 0.067423\n","Epoch:  1642 | train loss: 0.061054 | valid loss: 0.067371\n","Epoch:  1643 | train loss: 0.080299 | valid loss: 0.067463\n","Epoch:  1644 | train loss: 0.063185 | valid loss: 0.067498\n","Epoch:  1645 | train loss: 0.059293 | valid loss: 0.067462\n","Epoch:  1646 | train loss: 0.104010 | valid loss: 0.067454\n","Epoch:  1647 | train loss: 0.085946 | valid loss: 0.067380\n","Epoch:  1648 | train loss: 0.067642 | valid loss: 0.067500\n","Epoch:  1649 | train loss: 0.066878 | valid loss: 0.067416\n","Epoch:  1650 | train loss: 0.083106 | valid loss: 0.067447\n","Epoch:  1651 | train loss: 0.071672 | valid loss: 0.067256\n","Epoch:  1652 | train loss: 0.067086 | valid loss: 0.067380\n","Epoch:  1653 | train loss: 0.061429 | valid loss: 0.067323\n","Epoch:  1654 | train loss: 0.086398 | valid loss: 0.067368\n","Epoch:  1655 | train loss: 0.068770 | valid loss: 0.067407\n","Epoch:  1656 | train loss: 0.065425 | valid loss: 0.067493\n","Epoch:  1657 | train loss: 0.086171 | valid loss: 0.067368\n","Epoch:  1658 | train loss: 0.058077 | valid loss: 0.067522\n","Epoch:  1659 | train loss: 0.079530 | valid loss: 0.067444\n","Epoch:  1660 | train loss: 0.087871 | valid loss: 0.067394\n","Epoch:  1661 | train loss: 0.050935 | valid loss: 0.067487\n","Epoch:  1662 | train loss: 0.076408 | valid loss: 0.067420\n","Epoch:  1663 | train loss: 0.081563 | valid loss: 0.067326\n","Epoch:  1664 | train loss: 0.073335 | valid loss: 0.067351\n","Epoch:  1665 | train loss: 0.074430 | valid loss: 0.067363\n","Epoch:  1666 | train loss: 0.058540 | valid loss: 0.067438\n","Epoch:  1667 | train loss: 0.051596 | valid loss: 0.067380\n","Epoch:  1668 | train loss: 0.078899 | valid loss: 0.067457\n","Epoch:  1669 | train loss: 0.064705 | valid loss: 0.067439\n","Epoch:  1670 | train loss: 0.060540 | valid loss: 0.067381\n","Epoch:  1671 | train loss: 0.079809 | valid loss: 0.067479\n","Epoch:  1672 | train loss: 0.068328 | valid loss: 0.067442\n","Epoch:  1673 | train loss: 0.083838 | valid loss: 0.067285\n","Epoch:  1674 | train loss: 0.083967 | valid loss: 0.067468\n","Epoch:  1675 | train loss: 0.069383 | valid loss: 0.067387\n","Epoch:  1676 | train loss: 0.074355 | valid loss: 0.067424\n","Epoch:  1677 | train loss: 0.070752 | valid loss: 0.067408\n","Epoch:  1678 | train loss: 0.047855 | valid loss: 0.067403\n","Epoch:  1679 | train loss: 0.060154 | valid loss: 0.067431\n","Epoch:  1680 | train loss: 0.057053 | valid loss: 0.067415\n","Epoch:  1681 | train loss: 0.064867 | valid loss: 0.067394\n","Epoch:  1682 | train loss: 0.084163 | valid loss: 0.067357\n","Epoch:  1683 | train loss: 0.064058 | valid loss: 0.067414\n","Epoch:  1684 | train loss: 0.053388 | valid loss: 0.067500\n","Epoch:  1685 | train loss: 0.058520 | valid loss: 0.067436\n","Epoch:  1686 | train loss: 0.069752 | valid loss: 0.067414\n","Epoch:  1687 | train loss: 0.066723 | valid loss: 0.067442\n","Epoch:  1688 | train loss: 0.075642 | valid loss: 0.067396\n","Epoch:  1689 | train loss: 0.068484 | valid loss: 0.067485\n","Epoch:  1690 | train loss: 0.103844 | valid loss: 0.067454\n","Epoch:  1691 | train loss: 0.060213 | valid loss: 0.067368\n","Epoch:  1692 | train loss: 0.083216 | valid loss: 0.067480\n","Epoch:  1693 | train loss: 0.081535 | valid loss: 0.067397\n","Epoch:  1694 | train loss: 0.076216 | valid loss: 0.067507\n","Epoch:  1695 | train loss: 0.058789 | valid loss: 0.067467\n","Epoch:  1696 | train loss: 0.058309 | valid loss: 0.067402\n","Epoch:  1697 | train loss: 0.079018 | valid loss: 0.067393\n","Epoch:  1698 | train loss: 0.080686 | valid loss: 0.067438\n","Epoch:  1699 | train loss: 0.079618 | valid loss: 0.067357\n","Epoch:  1700 | train loss: 0.070529 | valid loss: 0.067417\n","Epoch:  1701 | train loss: 0.064499 | valid loss: 0.067394\n","Epoch:  1702 | train loss: 0.048837 | valid loss: 0.067469\n","Epoch:  1703 | train loss: 0.085477 | valid loss: 0.067446\n","Epoch:  1704 | train loss: 0.051222 | valid loss: 0.067396\n","Epoch:  1705 | train loss: 0.067993 | valid loss: 0.067431\n","Epoch:  1706 | train loss: 0.074678 | valid loss: 0.067424\n","Epoch:  1707 | train loss: 0.059435 | valid loss: 0.067457\n","Epoch:  1708 | train loss: 0.055006 | valid loss: 0.067342\n","Epoch:  1709 | train loss: 0.066076 | valid loss: 0.067405\n","Epoch:  1710 | train loss: 0.064347 | valid loss: 0.067339\n","Epoch:  1711 | train loss: 0.092331 | valid loss: 0.067343\n","Epoch:  1712 | train loss: 0.064889 | valid loss: 0.067438\n","Epoch:  1713 | train loss: 0.072526 | valid loss: 0.067518\n","Epoch:  1714 | train loss: 0.062154 | valid loss: 0.067379\n","Epoch:  1715 | train loss: 0.097113 | valid loss: 0.067516\n","Epoch:  1716 | train loss: 0.045097 | valid loss: 0.067515\n","Epoch:  1717 | train loss: 0.068801 | valid loss: 0.067378\n","Epoch:  1718 | train loss: 0.058645 | valid loss: 0.067380\n","Epoch:  1719 | train loss: 0.085949 | valid loss: 0.067415\n","Epoch:  1720 | train loss: 0.052968 | valid loss: 0.067422\n","Epoch:  1721 | train loss: 0.062863 | valid loss: 0.067361\n","Epoch:  1722 | train loss: 0.051011 | valid loss: 0.067469\n","Epoch:  1723 | train loss: 0.081608 | valid loss: 0.067413\n","Epoch:  1724 | train loss: 0.085046 | valid loss: 0.067411\n","Epoch:  1725 | train loss: 0.066644 | valid loss: 0.067430\n","Epoch:  1726 | train loss: 0.082307 | valid loss: 0.067400\n","Epoch:  1727 | train loss: 0.050648 | valid loss: 0.067337\n","Epoch:  1728 | train loss: 0.058443 | valid loss: 0.067421\n","Epoch:  1729 | train loss: 0.074242 | valid loss: 0.067430\n","Epoch:  1730 | train loss: 0.062524 | valid loss: 0.067487\n","Epoch:  1731 | train loss: 0.062082 | valid loss: 0.067419\n","Epoch:  1732 | train loss: 0.066061 | valid loss: 0.067438\n","Epoch:  1733 | train loss: 0.055735 | valid loss: 0.067420\n","Epoch:  1734 | train loss: 0.067011 | valid loss: 0.067529\n","Epoch:  1735 | train loss: 0.081490 | valid loss: 0.067413\n","Epoch:  1736 | train loss: 0.059149 | valid loss: 0.067391\n","Epoch:  1737 | train loss: 0.071177 | valid loss: 0.067451\n","Epoch:  1738 | train loss: 0.093050 | valid loss: 0.067456\n","Epoch:  1739 | train loss: 0.078495 | valid loss: 0.067377\n","Epoch:  1740 | train loss: 0.065484 | valid loss: 0.067399\n","Epoch:  1741 | train loss: 0.050307 | valid loss: 0.067434\n","Epoch:  1742 | train loss: 0.069431 | valid loss: 0.067325\n","Epoch:  1743 | train loss: 0.053125 | valid loss: 0.067427\n","Epoch:  1744 | train loss: 0.086049 | valid loss: 0.067437\n","Epoch:  1745 | train loss: 0.054077 | valid loss: 0.067421\n","Epoch:  1746 | train loss: 0.059851 | valid loss: 0.067500\n","Epoch:  1747 | train loss: 0.052793 | valid loss: 0.067375\n","Epoch:  1748 | train loss: 0.058024 | valid loss: 0.067454\n","Epoch:  1749 | train loss: 0.073384 | valid loss: 0.067504\n","Epoch:  1750 | train loss: 0.059798 | valid loss: 0.067396\n","Epoch:  1751 | train loss: 0.072512 | valid loss: 0.067457\n","Epoch:  1752 | train loss: 0.074743 | valid loss: 0.067405\n","Epoch:  1753 | train loss: 0.055618 | valid loss: 0.067388\n","Epoch:  1754 | train loss: 0.055901 | valid loss: 0.067438\n","Epoch:  1755 | train loss: 0.060507 | valid loss: 0.067521\n","Epoch:  1756 | train loss: 0.045407 | valid loss: 0.067495\n","Epoch:  1757 | train loss: 0.044916 | valid loss: 0.067478\n","Epoch:  1758 | train loss: 0.050235 | valid loss: 0.067393\n","Epoch:  1759 | train loss: 0.073159 | valid loss: 0.067355\n","Epoch:  1760 | train loss: 0.087374 | valid loss: 0.067406\n","Epoch:  1761 | train loss: 0.055315 | valid loss: 0.067450\n","Epoch:  1762 | train loss: 0.075144 | valid loss: 0.067503\n","Epoch:  1763 | train loss: 0.057997 | valid loss: 0.067449\n","Epoch:  1764 | train loss: 0.067656 | valid loss: 0.067390\n","Epoch:  1765 | train loss: 0.066360 | valid loss: 0.067411\n","Epoch:  1766 | train loss: 0.079403 | valid loss: 0.067424\n","Epoch:  1767 | train loss: 0.081036 | valid loss: 0.067467\n","Epoch:  1768 | train loss: 0.057654 | valid loss: 0.067405\n","Epoch:  1769 | train loss: 0.064902 | valid loss: 0.067426\n","Epoch:  1770 | train loss: 0.076464 | valid loss: 0.067475\n","Epoch:  1771 | train loss: 0.082781 | valid loss: 0.067467\n","Epoch:  1772 | train loss: 0.080557 | valid loss: 0.067436\n","Epoch:  1773 | train loss: 0.076452 | valid loss: 0.067484\n","Epoch:  1774 | train loss: 0.081675 | valid loss: 0.067448\n","Epoch:  1775 | train loss: 0.074117 | valid loss: 0.067434\n","Epoch:  1776 | train loss: 0.073366 | valid loss: 0.067445\n","Epoch:  1777 | train loss: 0.074799 | valid loss: 0.067490\n","Epoch:  1778 | train loss: 0.062630 | valid loss: 0.067573\n","Epoch:  1779 | train loss: 0.062455 | valid loss: 0.067439\n","Epoch:  1780 | train loss: 0.063760 | valid loss: 0.067505\n","Epoch:  1781 | train loss: 0.064749 | valid loss: 0.067600\n","Epoch:  1782 | train loss: 0.086307 | valid loss: 0.067456\n","Epoch:  1783 | train loss: 0.072987 | valid loss: 0.067446\n","Epoch:  1784 | train loss: 0.054984 | valid loss: 0.067486\n","Epoch:  1785 | train loss: 0.059198 | valid loss: 0.067403\n","Epoch:  1786 | train loss: 0.051262 | valid loss: 0.067399\n","Epoch:  1787 | train loss: 0.056941 | valid loss: 0.067405\n","Epoch:  1788 | train loss: 0.067208 | valid loss: 0.067513\n","Epoch:  1789 | train loss: 0.073189 | valid loss: 0.067472\n","Epoch:  1790 | train loss: 0.047929 | valid loss: 0.067454\n","Epoch:  1791 | train loss: 0.064385 | valid loss: 0.067488\n","Epoch:  1792 | train loss: 0.082685 | valid loss: 0.067446\n","Epoch:  1793 | train loss: 0.060107 | valid loss: 0.067504\n","Epoch:  1794 | train loss: 0.095999 | valid loss: 0.067414\n","Epoch:  1795 | train loss: 0.068153 | valid loss: 0.067471\n","Epoch:  1796 | train loss: 0.084950 | valid loss: 0.067491\n","Epoch:  1797 | train loss: 0.065411 | valid loss: 0.067534\n","Epoch:  1798 | train loss: 0.059273 | valid loss: 0.067499\n","Epoch:  1799 | train loss: 0.056345 | valid loss: 0.067425\n","Epoch:  1800 | train loss: 0.062844 | valid loss: 0.067478\n","Epoch:  1801 | train loss: 0.093565 | valid loss: 0.067435\n","Epoch:  1802 | train loss: 0.091388 | valid loss: 0.067485\n","Epoch:  1803 | train loss: 0.070910 | valid loss: 0.067494\n","Epoch:  1804 | train loss: 0.076563 | valid loss: 0.067475\n","Epoch:  1805 | train loss: 0.095163 | valid loss: 0.067582\n","Epoch:  1806 | train loss: 0.081147 | valid loss: 0.067466\n","Epoch:  1807 | train loss: 0.059474 | valid loss: 0.067435\n","Epoch:  1808 | train loss: 0.084406 | valid loss: 0.067480\n","Epoch:  1809 | train loss: 0.051330 | valid loss: 0.067571\n","Epoch:  1810 | train loss: 0.067297 | valid loss: 0.067510\n","Epoch:  1811 | train loss: 0.090328 | valid loss: 0.067460\n","Epoch:  1812 | train loss: 0.079868 | valid loss: 0.067507\n","Epoch:  1813 | train loss: 0.076087 | valid loss: 0.067472\n","Epoch:  1814 | train loss: 0.066378 | valid loss: 0.067471\n","Epoch:  1815 | train loss: 0.062739 | valid loss: 0.067517\n","Epoch:  1816 | train loss: 0.076023 | valid loss: 0.067526\n","Epoch:  1817 | train loss: 0.057070 | valid loss: 0.067449\n","Epoch:  1818 | train loss: 0.077081 | valid loss: 0.067479\n","Epoch:  1819 | train loss: 0.067788 | valid loss: 0.067466\n","Epoch:  1820 | train loss: 0.074197 | valid loss: 0.067526\n","Epoch:  1821 | train loss: 0.082156 | valid loss: 0.067562\n","Epoch:  1822 | train loss: 0.075751 | valid loss: 0.067401\n","Epoch:  1823 | train loss: 0.091021 | valid loss: 0.067395\n","Epoch:  1824 | train loss: 0.102488 | valid loss: 0.067494\n","Epoch:  1825 | train loss: 0.088514 | valid loss: 0.067413\n","Epoch:  1826 | train loss: 0.075840 | valid loss: 0.067449\n","Epoch:  1827 | train loss: 0.063297 | valid loss: 0.067474\n","Epoch:  1828 | train loss: 0.086251 | valid loss: 0.067479\n","Epoch:  1829 | train loss: 0.072713 | valid loss: 0.067484\n","Epoch:  1830 | train loss: 0.095154 | valid loss: 0.067500\n","Epoch:  1831 | train loss: 0.069946 | valid loss: 0.067428\n","Epoch:  1832 | train loss: 0.074556 | valid loss: 0.067520\n","Epoch:  1833 | train loss: 0.078871 | valid loss: 0.067412\n","Epoch:  1834 | train loss: 0.089976 | valid loss: 0.067491\n","Epoch:  1835 | train loss: 0.052073 | valid loss: 0.067469\n","Epoch:  1836 | train loss: 0.050870 | valid loss: 0.067445\n","Epoch:  1837 | train loss: 0.120834 | valid loss: 0.067538\n","Epoch:  1838 | train loss: 0.066462 | valid loss: 0.067433\n","Epoch:  1839 | train loss: 0.083691 | valid loss: 0.067552\n","Epoch:  1840 | train loss: 0.061611 | valid loss: 0.067474\n","Epoch:  1841 | train loss: 0.051291 | valid loss: 0.067462\n","Epoch:  1842 | train loss: 0.087162 | valid loss: 0.067514\n","Epoch:  1843 | train loss: 0.063926 | valid loss: 0.067451\n","Epoch:  1844 | train loss: 0.066288 | valid loss: 0.067513\n","Epoch:  1845 | train loss: 0.071164 | valid loss: 0.067507\n","Epoch:  1846 | train loss: 0.102670 | valid loss: 0.067470\n","Epoch:  1847 | train loss: 0.071873 | valid loss: 0.067444\n","Epoch:  1848 | train loss: 0.086392 | valid loss: 0.067476\n","Epoch:  1849 | train loss: 0.085005 | valid loss: 0.067556\n","Epoch:  1850 | train loss: 0.068279 | valid loss: 0.067440\n","Epoch:  1851 | train loss: 0.070436 | valid loss: 0.067521\n","Epoch:  1852 | train loss: 0.078986 | valid loss: 0.067582\n","Epoch:  1853 | train loss: 0.054215 | valid loss: 0.067510\n","Epoch:  1854 | train loss: 0.069358 | valid loss: 0.067557\n","Epoch:  1855 | train loss: 0.061612 | valid loss: 0.067431\n","Epoch:  1856 | train loss: 0.061535 | valid loss: 0.067382\n","Epoch:  1857 | train loss: 0.072458 | valid loss: 0.067475\n","Epoch:  1858 | train loss: 0.058712 | valid loss: 0.067406\n","Epoch:  1859 | train loss: 0.071280 | valid loss: 0.067530\n","Epoch:  1860 | train loss: 0.051821 | valid loss: 0.067551\n","Epoch:  1861 | train loss: 0.088248 | valid loss: 0.067555\n","Epoch:  1862 | train loss: 0.060770 | valid loss: 0.067620\n","Epoch:  1863 | train loss: 0.069477 | valid loss: 0.067506\n","Epoch:  1864 | train loss: 0.072490 | valid loss: 0.067487\n","Epoch:  1865 | train loss: 0.057241 | valid loss: 0.067587\n","Epoch:  1866 | train loss: 0.057664 | valid loss: 0.067387\n","Epoch:  1867 | train loss: 0.067764 | valid loss: 0.067470\n","Epoch:  1868 | train loss: 0.101674 | valid loss: 0.067513\n","Epoch:  1869 | train loss: 0.084566 | valid loss: 0.067523\n","Epoch:  1870 | train loss: 0.059874 | valid loss: 0.067511\n","Epoch:  1871 | train loss: 0.062096 | valid loss: 0.067458\n","Epoch:  1872 | train loss: 0.065385 | valid loss: 0.067419\n","Epoch:  1873 | train loss: 0.073158 | valid loss: 0.067499\n","Epoch:  1874 | train loss: 0.071996 | valid loss: 0.067504\n","Epoch:  1875 | train loss: 0.049230 | valid loss: 0.067512\n","Epoch:  1876 | train loss: 0.076871 | valid loss: 0.067532\n","Epoch:  1877 | train loss: 0.051963 | valid loss: 0.067535\n","Epoch:  1878 | train loss: 0.058616 | valid loss: 0.067550\n","Epoch:  1879 | train loss: 0.075291 | valid loss: 0.067486\n","Epoch:  1880 | train loss: 0.075433 | valid loss: 0.067464\n","Epoch:  1881 | train loss: 0.054908 | valid loss: 0.067575\n","Epoch:  1882 | train loss: 0.058827 | valid loss: 0.067544\n","Epoch:  1883 | train loss: 0.076459 | valid loss: 0.067547\n","Epoch:  1884 | train loss: 0.075637 | valid loss: 0.067530\n","Epoch:  1885 | train loss: 0.058562 | valid loss: 0.067539\n","Epoch:  1886 | train loss: 0.069940 | valid loss: 0.067549\n","Epoch:  1887 | train loss: 0.060371 | valid loss: 0.067495\n","Epoch:  1888 | train loss: 0.063671 | valid loss: 0.067389\n","Epoch:  1889 | train loss: 0.056925 | valid loss: 0.067489\n","Epoch:  1890 | train loss: 0.059261 | valid loss: 0.067461\n","Epoch:  1891 | train loss: 0.067460 | valid loss: 0.067510\n","Epoch:  1892 | train loss: 0.057925 | valid loss: 0.067495\n","Epoch:  1893 | train loss: 0.074229 | valid loss: 0.067466\n","Epoch:  1894 | train loss: 0.079155 | valid loss: 0.067433\n","Epoch:  1895 | train loss: 0.075733 | valid loss: 0.067577\n","Epoch:  1896 | train loss: 0.063237 | valid loss: 0.067444\n","Epoch:  1897 | train loss: 0.060352 | valid loss: 0.067629\n","Epoch:  1898 | train loss: 0.048536 | valid loss: 0.067544\n","Epoch:  1899 | train loss: 0.082188 | valid loss: 0.067460\n","Epoch:  1900 | train loss: 0.054957 | valid loss: 0.067443\n","Epoch:  1901 | train loss: 0.084766 | valid loss: 0.067563\n","Epoch:  1902 | train loss: 0.052857 | valid loss: 0.067530\n","Epoch:  1903 | train loss: 0.091334 | valid loss: 0.067467\n","Epoch:  1904 | train loss: 0.064438 | valid loss: 0.067456\n","Epoch:  1905 | train loss: 0.075012 | valid loss: 0.067470\n","Epoch:  1906 | train loss: 0.049095 | valid loss: 0.067518\n","Epoch:  1907 | train loss: 0.102337 | valid loss: 0.067536\n","Epoch:  1908 | train loss: 0.060467 | valid loss: 0.067446\n","Epoch:  1909 | train loss: 0.078703 | valid loss: 0.067560\n","Epoch:  1910 | train loss: 0.050521 | valid loss: 0.067509\n","Epoch:  1911 | train loss: 0.068220 | valid loss: 0.067525\n","Epoch:  1912 | train loss: 0.070537 | valid loss: 0.067497\n","Epoch:  1913 | train loss: 0.072338 | valid loss: 0.067486\n","Epoch:  1914 | train loss: 0.056716 | valid loss: 0.067513\n","Epoch:  1915 | train loss: 0.063600 | valid loss: 0.067497\n","Epoch:  1916 | train loss: 0.061158 | valid loss: 0.067455\n","Epoch:  1917 | train loss: 0.080847 | valid loss: 0.067563\n","Epoch:  1918 | train loss: 0.058609 | valid loss: 0.067534\n","Epoch:  1919 | train loss: 0.055738 | valid loss: 0.067550\n","Epoch:  1920 | train loss: 0.070580 | valid loss: 0.067454\n","Epoch:  1921 | train loss: 0.062261 | valid loss: 0.067475\n","Epoch:  1922 | train loss: 0.081470 | valid loss: 0.067567\n","Epoch:  1923 | train loss: 0.076475 | valid loss: 0.067511\n","Epoch:  1924 | train loss: 0.073371 | valid loss: 0.067557\n","Epoch:  1925 | train loss: 0.099116 | valid loss: 0.067465\n","Epoch:  1926 | train loss: 0.059270 | valid loss: 0.067511\n","Epoch:  1927 | train loss: 0.074489 | valid loss: 0.067491\n","Epoch:  1928 | train loss: 0.089015 | valid loss: 0.067534\n","Epoch:  1929 | train loss: 0.073236 | valid loss: 0.067525\n","Epoch:  1930 | train loss: 0.053792 | valid loss: 0.067554\n","Epoch:  1931 | train loss: 0.081602 | valid loss: 0.067507\n","Epoch:  1932 | train loss: 0.067424 | valid loss: 0.067535\n","Epoch:  1933 | train loss: 0.078949 | valid loss: 0.067537\n","Epoch:  1934 | train loss: 0.064881 | valid loss: 0.067505\n","Epoch:  1935 | train loss: 0.066976 | valid loss: 0.067497\n","Epoch:  1936 | train loss: 0.046937 | valid loss: 0.067572\n","Epoch:  1937 | train loss: 0.097659 | valid loss: 0.067454\n","Epoch:  1938 | train loss: 0.075808 | valid loss: 0.067536\n","Epoch:  1939 | train loss: 0.090290 | valid loss: 0.067544\n","Epoch:  1940 | train loss: 0.056908 | valid loss: 0.067501\n","Epoch:  1941 | train loss: 0.073111 | valid loss: 0.067475\n","Epoch:  1942 | train loss: 0.045729 | valid loss: 0.067486\n","Epoch:  1943 | train loss: 0.076534 | valid loss: 0.067572\n","Epoch:  1944 | train loss: 0.080019 | valid loss: 0.067480\n","Epoch:  1945 | train loss: 0.068098 | valid loss: 0.067478\n","Epoch:  1946 | train loss: 0.089575 | valid loss: 0.067513\n","Epoch:  1947 | train loss: 0.078249 | valid loss: 0.067453\n","Epoch:  1948 | train loss: 0.065249 | valid loss: 0.067526\n","Epoch:  1949 | train loss: 0.078042 | valid loss: 0.067424\n","Epoch:  1950 | train loss: 0.083348 | valid loss: 0.067536\n","Epoch:  1951 | train loss: 0.073287 | valid loss: 0.067559\n","Epoch:  1952 | train loss: 0.058942 | valid loss: 0.067534\n","Epoch:  1953 | train loss: 0.051422 | valid loss: 0.067430\n","Epoch:  1954 | train loss: 0.074876 | valid loss: 0.067468\n","Epoch:  1955 | train loss: 0.055252 | valid loss: 0.067463\n","Epoch:  1956 | train loss: 0.064113 | valid loss: 0.067533\n","Epoch:  1957 | train loss: 0.062656 | valid loss: 0.067522\n","Epoch:  1958 | train loss: 0.062315 | valid loss: 0.067500\n","Epoch:  1959 | train loss: 0.068178 | valid loss: 0.067603\n","Epoch:  1960 | train loss: 0.049541 | valid loss: 0.067549\n","Epoch:  1961 | train loss: 0.055541 | valid loss: 0.067541\n","Epoch:  1962 | train loss: 0.059446 | valid loss: 0.067486\n","Epoch:  1963 | train loss: 0.072994 | valid loss: 0.067522\n","Epoch:  1964 | train loss: 0.071931 | valid loss: 0.067638\n","Epoch:  1965 | train loss: 0.083939 | valid loss: 0.067554\n","Epoch:  1966 | train loss: 0.061690 | valid loss: 0.067425\n","Epoch:  1967 | train loss: 0.050425 | valid loss: 0.067643\n","Epoch:  1968 | train loss: 0.059230 | valid loss: 0.067465\n","Epoch:  1969 | train loss: 0.074807 | valid loss: 0.067580\n","Epoch:  1970 | train loss: 0.053224 | valid loss: 0.067543\n","Epoch:  1971 | train loss: 0.061789 | valid loss: 0.067510\n","Epoch:  1972 | train loss: 0.055962 | valid loss: 0.067545\n","Epoch:  1973 | train loss: 0.061290 | valid loss: 0.067553\n","Epoch:  1974 | train loss: 0.070248 | valid loss: 0.067437\n","Epoch:  1975 | train loss: 0.074792 | valid loss: 0.067604\n","Epoch:  1976 | train loss: 0.083990 | valid loss: 0.067524\n","Epoch:  1977 | train loss: 0.081146 | valid loss: 0.067445\n","Epoch:  1978 | train loss: 0.088390 | valid loss: 0.067475\n","Epoch:  1979 | train loss: 0.096514 | valid loss: 0.067506\n","Epoch:  1980 | train loss: 0.083274 | valid loss: 0.067492\n","Epoch:  1981 | train loss: 0.069332 | valid loss: 0.067484\n","Epoch:  1982 | train loss: 0.062692 | valid loss: 0.067489\n","Epoch:  1983 | train loss: 0.095307 | valid loss: 0.067483\n","Epoch:  1984 | train loss: 0.076668 | valid loss: 0.067496\n","Epoch:  1985 | train loss: 0.050428 | valid loss: 0.067491\n","Epoch:  1986 | train loss: 0.066272 | valid loss: 0.067475\n","Epoch:  1987 | train loss: 0.066493 | valid loss: 0.067432\n","Epoch:  1988 | train loss: 0.071614 | valid loss: 0.067506\n","Epoch:  1989 | train loss: 0.058549 | valid loss: 0.067465\n","Epoch:  1990 | train loss: 0.058794 | valid loss: 0.067589\n","Epoch:  1991 | train loss: 0.053132 | valid loss: 0.067504\n","Epoch:  1992 | train loss: 0.069811 | valid loss: 0.067528\n","Epoch:  1993 | train loss: 0.056787 | valid loss: 0.067539\n","Epoch:  1994 | train loss: 0.070922 | valid loss: 0.067640\n","Epoch:  1995 | train loss: 0.061564 | valid loss: 0.067540\n","Epoch:  1996 | train loss: 0.066203 | valid loss: 0.067554\n","Epoch:  1997 | train loss: 0.056085 | valid loss: 0.067523\n","Epoch:  1998 | train loss: 0.059146 | valid loss: 0.067534\n","Epoch:  1999 | train loss: 0.076041 | valid loss: 0.067492\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"549MYgnadWWn","executionInfo":{"status":"ok","timestamp":1629653347520,"user_tz":-60,"elapsed":41,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"3209c0b8-6424-4fc7-cd8b-41f36a7ba043"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Train time: 301.9267563819885\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"8hekMFhIzIEW","executionInfo":{"status":"ok","timestamp":1629653347528,"user_tz":-60,"elapsed":29,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"e3332166-3fd7-4680-9cae-394c6c85c7e8"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":48},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klzcKoiqZ6ZL","executionInfo":{"status":"ok","timestamp":1629653357064,"user_tz":-60,"elapsed":9550,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"68f6f91c-17e6-4c20-ec45-4f6cdb5d3bcf"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":49,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 0.002650861132446212\n","MSE_err of valid data 0.002627653939337591\n","MSE_err of test data 0.002500614753612316\n","MSE_err of total data 0.0026335157752519598\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R2FzxvGRv14B"},"source":["#### 8 variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15s-FkiYzBsc","executionInfo":{"status":"ok","timestamp":1629651850580,"user_tz":-60,"elapsed":17,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"fb63c715-6c55-4453-a497-2b829a59b6b0"},"source":["print(\"compress to 8\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 2000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["compress to 8\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ezz2oAocfqdK","executionInfo":{"status":"ok","timestamp":1629652113779,"user_tz":-60,"elapsed":263212,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"d38e9727-8f9e-4038-8387-55a2a9226043"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(8).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 1.769436 | valid loss: 1.788029\n","Epoch:  1 | train loss: 1.666520 | valid loss: 1.563458\n","Epoch:  2 | train loss: 1.276657 | valid loss: 1.242736\n","Epoch:  3 | train loss: 0.868304 | valid loss: 0.882487\n","Epoch:  4 | train loss: 0.588733 | valid loss: 0.546339\n","Epoch:  5 | train loss: 0.303958 | valid loss: 0.308255\n","Epoch:  6 | train loss: 0.205188 | valid loss: 0.181429\n","Epoch:  7 | train loss: 0.128207 | valid loss: 0.128518\n","Epoch:  8 | train loss: 0.109216 | valid loss: 0.108485\n","Epoch:  9 | train loss: 0.098266 | valid loss: 0.099824\n","Epoch:  10 | train loss: 0.087486 | valid loss: 0.094698\n","Epoch:  11 | train loss: 0.106612 | valid loss: 0.091269\n","Epoch:  12 | train loss: 0.072668 | valid loss: 0.088267\n","Epoch:  13 | train loss: 0.086595 | valid loss: 0.085364\n","Epoch:  14 | train loss: 0.082336 | valid loss: 0.082417\n","Epoch:  15 | train loss: 0.070221 | valid loss: 0.079787\n","Epoch:  16 | train loss: 0.052654 | valid loss: 0.077258\n","Epoch:  17 | train loss: 0.060419 | valid loss: 0.074957\n","Epoch:  18 | train loss: 0.067511 | valid loss: 0.073251\n","Epoch:  19 | train loss: 0.082947 | valid loss: 0.071570\n","Epoch:  20 | train loss: 0.088679 | valid loss: 0.070118\n","Epoch:  21 | train loss: 0.067244 | valid loss: 0.068425\n","Epoch:  22 | train loss: 0.069191 | valid loss: 0.067285\n","Epoch:  23 | train loss: 0.072213 | valid loss: 0.065952\n","Epoch:  24 | train loss: 0.067360 | valid loss: 0.065020\n","Epoch:  25 | train loss: 0.061777 | valid loss: 0.063741\n","Epoch:  26 | train loss: 0.069852 | valid loss: 0.062681\n","Epoch:  27 | train loss: 0.038607 | valid loss: 0.061801\n","Epoch:  28 | train loss: 0.057698 | valid loss: 0.060527\n","Epoch:  29 | train loss: 0.080539 | valid loss: 0.059028\n","Epoch:  30 | train loss: 0.085607 | valid loss: 0.058035\n","Epoch:  31 | train loss: 0.042382 | valid loss: 0.056739\n","Epoch:  32 | train loss: 0.054918 | valid loss: 0.056185\n","Epoch:  33 | train loss: 0.043493 | valid loss: 0.055117\n","Epoch:  34 | train loss: 0.058900 | valid loss: 0.054376\n","Epoch:  35 | train loss: 0.044778 | valid loss: 0.053789\n","Epoch:  36 | train loss: 0.072195 | valid loss: 0.053095\n","Epoch:  37 | train loss: 0.051917 | valid loss: 0.052582\n","Epoch:  38 | train loss: 0.058735 | valid loss: 0.051899\n","Epoch:  39 | train loss: 0.048726 | valid loss: 0.051318\n","Epoch:  40 | train loss: 0.060648 | valid loss: 0.050722\n","Epoch:  41 | train loss: 0.068780 | valid loss: 0.049901\n","Epoch:  42 | train loss: 0.031074 | valid loss: 0.049499\n","Epoch:  43 | train loss: 0.061916 | valid loss: 0.049149\n","Epoch:  44 | train loss: 0.059807 | valid loss: 0.049139\n","Epoch:  45 | train loss: 0.058219 | valid loss: 0.048477\n","Epoch:  46 | train loss: 0.040524 | valid loss: 0.048051\n","Epoch:  47 | train loss: 0.033045 | valid loss: 0.047743\n","Epoch:  48 | train loss: 0.038236 | valid loss: 0.047282\n","Epoch:  49 | train loss: 0.053764 | valid loss: 0.047216\n","Epoch:  50 | train loss: 0.052477 | valid loss: 0.046834\n","Epoch:  51 | train loss: 0.055603 | valid loss: 0.046795\n","Epoch:  52 | train loss: 0.046999 | valid loss: 0.046313\n","Epoch:  53 | train loss: 0.037973 | valid loss: 0.046198\n","Epoch:  54 | train loss: 0.040189 | valid loss: 0.045840\n","Epoch:  55 | train loss: 0.042423 | valid loss: 0.045685\n","Epoch:  56 | train loss: 0.062377 | valid loss: 0.045629\n","Epoch:  57 | train loss: 0.038373 | valid loss: 0.045361\n","Epoch:  58 | train loss: 0.043266 | valid loss: 0.045107\n","Epoch:  59 | train loss: 0.053885 | valid loss: 0.044812\n","Epoch:  60 | train loss: 0.048541 | valid loss: 0.044796\n","Epoch:  61 | train loss: 0.041983 | valid loss: 0.044695\n","Epoch:  62 | train loss: 0.046504 | valid loss: 0.044760\n","Epoch:  63 | train loss: 0.040569 | valid loss: 0.044194\n","Epoch:  64 | train loss: 0.034413 | valid loss: 0.044176\n","Epoch:  65 | train loss: 0.033741 | valid loss: 0.044001\n","Epoch:  66 | train loss: 0.040495 | valid loss: 0.044055\n","Epoch:  67 | train loss: 0.077541 | valid loss: 0.043890\n","Epoch:  68 | train loss: 0.056670 | valid loss: 0.043918\n","Epoch:  69 | train loss: 0.045250 | valid loss: 0.043578\n","Epoch:  70 | train loss: 0.038412 | valid loss: 0.043545\n","Epoch:  71 | train loss: 0.061985 | valid loss: 0.043370\n","Epoch:  72 | train loss: 0.065577 | valid loss: 0.043372\n","Epoch:  73 | train loss: 0.036970 | valid loss: 0.043697\n","Epoch:  74 | train loss: 0.067675 | valid loss: 0.043207\n","Epoch:  75 | train loss: 0.056550 | valid loss: 0.043135\n","Epoch:  76 | train loss: 0.037759 | valid loss: 0.042929\n","Epoch:  77 | train loss: 0.041976 | valid loss: 0.042996\n","Epoch:  78 | train loss: 0.031409 | valid loss: 0.042773\n","Epoch:  79 | train loss: 0.060543 | valid loss: 0.042876\n","Epoch:  80 | train loss: 0.046384 | valid loss: 0.042508\n","Epoch:  81 | train loss: 0.050186 | valid loss: 0.042745\n","Epoch:  82 | train loss: 0.041135 | valid loss: 0.042518\n","Epoch:  83 | train loss: 0.037907 | valid loss: 0.042427\n","Epoch:  84 | train loss: 0.034170 | valid loss: 0.042358\n","Epoch:  85 | train loss: 0.028305 | valid loss: 0.042362\n","Epoch:  86 | train loss: 0.033820 | valid loss: 0.042185\n","Epoch:  87 | train loss: 0.039146 | valid loss: 0.042305\n","Epoch:  88 | train loss: 0.043358 | valid loss: 0.042146\n","Epoch:  89 | train loss: 0.045542 | valid loss: 0.042053\n","Epoch:  90 | train loss: 0.064938 | valid loss: 0.041983\n","Epoch:  91 | train loss: 0.035035 | valid loss: 0.041868\n","Epoch:  92 | train loss: 0.035172 | valid loss: 0.041816\n","Epoch:  93 | train loss: 0.051235 | valid loss: 0.041988\n","Epoch:  94 | train loss: 0.035043 | valid loss: 0.041929\n","Epoch:  95 | train loss: 0.040894 | valid loss: 0.041692\n","Epoch:  96 | train loss: 0.030835 | valid loss: 0.041702\n","Epoch:  97 | train loss: 0.040699 | valid loss: 0.041637\n","Epoch:  98 | train loss: 0.036511 | valid loss: 0.041566\n","Epoch:  99 | train loss: 0.048575 | valid loss: 0.041495\n","Epoch:  100 | train loss: 0.059196 | valid loss: 0.041560\n","Epoch:  101 | train loss: 0.022141 | valid loss: 0.041435\n","Epoch:  102 | train loss: 0.052540 | valid loss: 0.041353\n","Epoch:  103 | train loss: 0.047288 | valid loss: 0.041353\n","Epoch:  104 | train loss: 0.046600 | valid loss: 0.041274\n","Epoch:  105 | train loss: 0.045964 | valid loss: 0.041330\n","Epoch:  106 | train loss: 0.049696 | valid loss: 0.041338\n","Epoch:  107 | train loss: 0.026093 | valid loss: 0.041344\n","Epoch:  108 | train loss: 0.025136 | valid loss: 0.041145\n","Epoch:  109 | train loss: 0.041106 | valid loss: 0.041170\n","Epoch:  110 | train loss: 0.064338 | valid loss: 0.041107\n","Epoch:  111 | train loss: 0.047108 | valid loss: 0.041051\n","Epoch:  112 | train loss: 0.029687 | valid loss: 0.041090\n","Epoch:  113 | train loss: 0.052591 | valid loss: 0.040948\n","Epoch:  114 | train loss: 0.042295 | valid loss: 0.041065\n","Epoch:  115 | train loss: 0.039966 | valid loss: 0.041002\n","Epoch:  116 | train loss: 0.029646 | valid loss: 0.041050\n","Epoch:  117 | train loss: 0.037834 | valid loss: 0.040922\n","Epoch:  118 | train loss: 0.029503 | valid loss: 0.041013\n","Epoch:  119 | train loss: 0.047506 | valid loss: 0.040889\n","Epoch:  120 | train loss: 0.038861 | valid loss: 0.040879\n","Epoch:  121 | train loss: 0.039785 | valid loss: 0.040748\n","Epoch:  122 | train loss: 0.041003 | valid loss: 0.041112\n","Epoch:  123 | train loss: 0.037833 | valid loss: 0.040686\n","Epoch:  124 | train loss: 0.040481 | valid loss: 0.040713\n","Epoch:  125 | train loss: 0.039494 | valid loss: 0.040622\n","Epoch:  126 | train loss: 0.048424 | valid loss: 0.040811\n","Epoch:  127 | train loss: 0.038672 | valid loss: 0.040690\n","Epoch:  128 | train loss: 0.071820 | valid loss: 0.040858\n","Epoch:  129 | train loss: 0.048833 | valid loss: 0.040691\n","Epoch:  130 | train loss: 0.047007 | valid loss: 0.040658\n","Epoch:  131 | train loss: 0.036652 | valid loss: 0.040644\n","Epoch:  132 | train loss: 0.033009 | valid loss: 0.040775\n","Epoch:  133 | train loss: 0.035559 | valid loss: 0.040797\n","Epoch:  134 | train loss: 0.043797 | valid loss: 0.040583\n","Epoch:  135 | train loss: 0.035034 | valid loss: 0.040521\n","Epoch:  136 | train loss: 0.044269 | valid loss: 0.040759\n","Epoch:  137 | train loss: 0.045533 | valid loss: 0.040598\n","Epoch:  138 | train loss: 0.036194 | valid loss: 0.040521\n","Epoch:  139 | train loss: 0.030607 | valid loss: 0.040658\n","Epoch:  140 | train loss: 0.046023 | valid loss: 0.040500\n","Epoch:  141 | train loss: 0.035973 | valid loss: 0.040553\n","Epoch:  142 | train loss: 0.040596 | valid loss: 0.040458\n","Epoch:  143 | train loss: 0.038323 | valid loss: 0.040464\n","Epoch:  144 | train loss: 0.049385 | valid loss: 0.040480\n","Epoch:  145 | train loss: 0.024258 | valid loss: 0.040372\n","Epoch:  146 | train loss: 0.047704 | valid loss: 0.040551\n","Epoch:  147 | train loss: 0.031027 | valid loss: 0.040422\n","Epoch:  148 | train loss: 0.042175 | valid loss: 0.040486\n","Epoch:  149 | train loss: 0.027320 | valid loss: 0.040426\n","Epoch:  150 | train loss: 0.035971 | valid loss: 0.040431\n","Epoch:  151 | train loss: 0.031860 | valid loss: 0.040377\n","Epoch:  152 | train loss: 0.032302 | valid loss: 0.040339\n","Epoch:  153 | train loss: 0.036246 | valid loss: 0.040385\n","Epoch:  154 | train loss: 0.023620 | valid loss: 0.040260\n","Epoch:  155 | train loss: 0.025062 | valid loss: 0.040252\n","Epoch:  156 | train loss: 0.030512 | valid loss: 0.040230\n","Epoch:  157 | train loss: 0.038326 | valid loss: 0.040255\n","Epoch:  158 | train loss: 0.055612 | valid loss: 0.039512\n","Epoch:  159 | train loss: 0.022112 | valid loss: 0.038886\n","Epoch:  160 | train loss: 0.047662 | valid loss: 0.038583\n","Epoch:  161 | train loss: 0.063583 | valid loss: 0.038382\n","Epoch:  162 | train loss: 0.031837 | valid loss: 0.038339\n","Epoch:  163 | train loss: 0.055992 | valid loss: 0.038248\n","Epoch:  164 | train loss: 0.028667 | valid loss: 0.038182\n","Epoch:  165 | train loss: 0.047486 | valid loss: 0.038248\n","Epoch:  166 | train loss: 0.036299 | valid loss: 0.038086\n","Epoch:  167 | train loss: 0.038194 | valid loss: 0.038121\n","Epoch:  168 | train loss: 0.044351 | valid loss: 0.038034\n","Epoch:  169 | train loss: 0.030087 | valid loss: 0.038049\n","Epoch:  170 | train loss: 0.033414 | valid loss: 0.037927\n","Epoch:  171 | train loss: 0.060225 | valid loss: 0.037666\n","Epoch:  172 | train loss: 0.055862 | valid loss: 0.037740\n","Epoch:  173 | train loss: 0.031359 | valid loss: 0.037690\n","Epoch:  174 | train loss: 0.041045 | valid loss: 0.037727\n","Epoch:  175 | train loss: 0.036382 | valid loss: 0.037614\n","Epoch:  176 | train loss: 0.044924 | valid loss: 0.037640\n","Epoch:  177 | train loss: 0.041615 | valid loss: 0.037673\n","Epoch:  178 | train loss: 0.076951 | valid loss: 0.037650\n","Epoch:  179 | train loss: 0.031010 | valid loss: 0.037660\n","Epoch:  180 | train loss: 0.033693 | valid loss: 0.037634\n","Epoch:  181 | train loss: 0.058555 | valid loss: 0.037595\n","Epoch:  182 | train loss: 0.026501 | valid loss: 0.037571\n","Epoch:  183 | train loss: 0.030708 | valid loss: 0.037620\n","Epoch:  184 | train loss: 0.044629 | valid loss: 0.037573\n","Epoch:  185 | train loss: 0.053652 | valid loss: 0.037513\n","Epoch:  186 | train loss: 0.043555 | valid loss: 0.037487\n","Epoch:  187 | train loss: 0.049910 | valid loss: 0.037474\n","Epoch:  188 | train loss: 0.029056 | valid loss: 0.037581\n","Epoch:  189 | train loss: 0.048127 | valid loss: 0.037564\n","Epoch:  190 | train loss: 0.040600 | valid loss: 0.037631\n","Epoch:  191 | train loss: 0.048685 | valid loss: 0.037524\n","Epoch:  192 | train loss: 0.055323 | valid loss: 0.037587\n","Epoch:  193 | train loss: 0.035504 | valid loss: 0.037485\n","Epoch:  194 | train loss: 0.049673 | valid loss: 0.037467\n","Epoch:  195 | train loss: 0.042452 | valid loss: 0.037483\n","Epoch:  196 | train loss: 0.027199 | valid loss: 0.037428\n","Epoch:  197 | train loss: 0.042041 | valid loss: 0.037507\n","Epoch:  198 | train loss: 0.035318 | valid loss: 0.037349\n","Epoch:  199 | train loss: 0.029994 | valid loss: 0.037562\n","Epoch:  200 | train loss: 0.059148 | valid loss: 0.037376\n","Epoch:  201 | train loss: 0.029945 | valid loss: 0.037309\n","Epoch:  202 | train loss: 0.039941 | valid loss: 0.037399\n","Epoch:  203 | train loss: 0.033434 | valid loss: 0.037411\n","Epoch:  204 | train loss: 0.036803 | valid loss: 0.037398\n","Epoch:  205 | train loss: 0.041078 | valid loss: 0.037357\n","Epoch:  206 | train loss: 0.030494 | valid loss: 0.037557\n","Epoch:  207 | train loss: 0.035769 | valid loss: 0.037534\n","Epoch:  208 | train loss: 0.040472 | valid loss: 0.037380\n","Epoch:  209 | train loss: 0.038746 | valid loss: 0.037405\n","Epoch:  210 | train loss: 0.042013 | valid loss: 0.037418\n","Epoch:  211 | train loss: 0.039702 | valid loss: 0.037325\n","Epoch:  212 | train loss: 0.066803 | valid loss: 0.037463\n","Epoch:  213 | train loss: 0.039448 | valid loss: 0.037434\n","Epoch:  214 | train loss: 0.050990 | valid loss: 0.037507\n","Epoch:  215 | train loss: 0.051429 | valid loss: 0.037356\n","Epoch:  216 | train loss: 0.051148 | valid loss: 0.037402\n","Epoch:  217 | train loss: 0.037618 | valid loss: 0.037351\n","Epoch:  218 | train loss: 0.041848 | valid loss: 0.037336\n","Epoch:  219 | train loss: 0.057175 | valid loss: 0.037312\n","Epoch:  220 | train loss: 0.036563 | valid loss: 0.037279\n","Epoch:  221 | train loss: 0.035155 | valid loss: 0.037232\n","Epoch:  222 | train loss: 0.036761 | valid loss: 0.037268\n","Epoch:  223 | train loss: 0.064494 | valid loss: 0.037288\n","Epoch:  224 | train loss: 0.036095 | valid loss: 0.037348\n","Epoch:  225 | train loss: 0.041533 | valid loss: 0.037395\n","Epoch:  226 | train loss: 0.042228 | valid loss: 0.037371\n","Epoch:  227 | train loss: 0.061690 | valid loss: 0.037496\n","Epoch:  228 | train loss: 0.024380 | valid loss: 0.037347\n","Epoch:  229 | train loss: 0.031640 | valid loss: 0.037208\n","Epoch:  230 | train loss: 0.045827 | valid loss: 0.037395\n","Epoch:  231 | train loss: 0.035451 | valid loss: 0.037446\n","Epoch:  232 | train loss: 0.038663 | valid loss: 0.037302\n","Epoch:  233 | train loss: 0.022810 | valid loss: 0.037412\n","Epoch:  234 | train loss: 0.044421 | valid loss: 0.037297\n","Epoch:  235 | train loss: 0.025519 | valid loss: 0.037401\n","Epoch:  236 | train loss: 0.045391 | valid loss: 0.037257\n","Epoch:  237 | train loss: 0.052854 | valid loss: 0.037346\n","Epoch:  238 | train loss: 0.036414 | valid loss: 0.037328\n","Epoch:  239 | train loss: 0.057309 | valid loss: 0.037376\n","Epoch:  240 | train loss: 0.034183 | valid loss: 0.037281\n","Epoch:  241 | train loss: 0.054699 | valid loss: 0.037284\n","Epoch:  242 | train loss: 0.053239 | valid loss: 0.037372\n","Epoch:  243 | train loss: 0.026767 | valid loss: 0.037196\n","Epoch:  244 | train loss: 0.029452 | valid loss: 0.037216\n","Epoch:  245 | train loss: 0.039601 | valid loss: 0.037283\n","Epoch:  246 | train loss: 0.038378 | valid loss: 0.037241\n","Epoch:  247 | train loss: 0.056603 | valid loss: 0.037229\n","Epoch:  248 | train loss: 0.023615 | valid loss: 0.037211\n","Epoch:  249 | train loss: 0.043043 | valid loss: 0.037244\n","Epoch:  250 | train loss: 0.040790 | valid loss: 0.037283\n","Epoch:  251 | train loss: 0.032123 | valid loss: 0.037161\n","Epoch:  252 | train loss: 0.039185 | valid loss: 0.037241\n","Epoch:  253 | train loss: 0.035012 | valid loss: 0.037208\n","Epoch:  254 | train loss: 0.035527 | valid loss: 0.037237\n","Epoch:  255 | train loss: 0.030295 | valid loss: 0.037279\n","Epoch:  256 | train loss: 0.037267 | valid loss: 0.037177\n","Epoch:  257 | train loss: 0.030809 | valid loss: 0.037194\n","Epoch:  258 | train loss: 0.041584 | valid loss: 0.037263\n","Epoch:  259 | train loss: 0.051111 | valid loss: 0.037161\n","Epoch:  260 | train loss: 0.040149 | valid loss: 0.037152\n","Epoch:  261 | train loss: 0.027011 | valid loss: 0.037173\n","Epoch:  262 | train loss: 0.036110 | valid loss: 0.037195\n","Epoch:  263 | train loss: 0.043237 | valid loss: 0.037236\n","Epoch:  264 | train loss: 0.031905 | valid loss: 0.037253\n","Epoch:  265 | train loss: 0.034189 | valid loss: 0.037198\n","Epoch:  266 | train loss: 0.029706 | valid loss: 0.037188\n","Epoch:  267 | train loss: 0.035151 | valid loss: 0.037229\n","Epoch:  268 | train loss: 0.042739 | valid loss: 0.037310\n","Epoch:  269 | train loss: 0.026014 | valid loss: 0.037252\n","Epoch:  270 | train loss: 0.050204 | valid loss: 0.037101\n","Epoch:  271 | train loss: 0.034371 | valid loss: 0.037196\n","Epoch:  272 | train loss: 0.033333 | valid loss: 0.037247\n","Epoch:  273 | train loss: 0.049213 | valid loss: 0.037223\n","Epoch:  274 | train loss: 0.051922 | valid loss: 0.037223\n","Epoch:  275 | train loss: 0.042343 | valid loss: 0.037246\n","Epoch:  276 | train loss: 0.057200 | valid loss: 0.037204\n","Epoch:  277 | train loss: 0.047289 | valid loss: 0.037149\n","Epoch:  278 | train loss: 0.051789 | valid loss: 0.037251\n","Epoch:  279 | train loss: 0.043466 | valid loss: 0.037166\n","Epoch:  280 | train loss: 0.030583 | valid loss: 0.037227\n","Epoch:  281 | train loss: 0.024264 | valid loss: 0.037150\n","Epoch:  282 | train loss: 0.043276 | valid loss: 0.037189\n","Epoch:  283 | train loss: 0.047900 | valid loss: 0.037179\n","Epoch:  284 | train loss: 0.041423 | valid loss: 0.037327\n","Epoch:  285 | train loss: 0.049889 | valid loss: 0.037281\n","Epoch:  286 | train loss: 0.039313 | valid loss: 0.037245\n","Epoch:  287 | train loss: 0.036404 | valid loss: 0.037119\n","Epoch:  288 | train loss: 0.063574 | valid loss: 0.037148\n","Epoch:  289 | train loss: 0.034942 | valid loss: 0.037256\n","Epoch:  290 | train loss: 0.037566 | valid loss: 0.037232\n","Epoch:  291 | train loss: 0.042496 | valid loss: 0.037270\n","Epoch:  292 | train loss: 0.039269 | valid loss: 0.037236\n","Epoch:  293 | train loss: 0.028408 | valid loss: 0.037295\n","Epoch:  294 | train loss: 0.030929 | valid loss: 0.037188\n","Epoch:  295 | train loss: 0.043974 | valid loss: 0.037179\n","Epoch:  296 | train loss: 0.024812 | valid loss: 0.037238\n","Epoch:  297 | train loss: 0.041136 | valid loss: 0.037167\n","Epoch:  298 | train loss: 0.045748 | valid loss: 0.037184\n","Epoch:  299 | train loss: 0.023253 | valid loss: 0.037252\n","Epoch:  300 | train loss: 0.027383 | valid loss: 0.037263\n","Epoch:  301 | train loss: 0.037648 | valid loss: 0.037193\n","Epoch:  302 | train loss: 0.045814 | valid loss: 0.037309\n","Epoch:  303 | train loss: 0.027301 | valid loss: 0.037275\n","Epoch:  304 | train loss: 0.041366 | valid loss: 0.037368\n","Epoch:  305 | train loss: 0.049744 | valid loss: 0.037292\n","Epoch:  306 | train loss: 0.051897 | valid loss: 0.037070\n","Epoch:  307 | train loss: 0.026360 | valid loss: 0.037153\n","Epoch:  308 | train loss: 0.024860 | valid loss: 0.037185\n","Epoch:  309 | train loss: 0.031215 | valid loss: 0.037110\n","Epoch:  310 | train loss: 0.041110 | valid loss: 0.037213\n","Epoch:  311 | train loss: 0.021956 | valid loss: 0.037321\n","Epoch:  312 | train loss: 0.021242 | valid loss: 0.037119\n","Epoch:  313 | train loss: 0.045291 | valid loss: 0.037193\n","Epoch:  314 | train loss: 0.024463 | valid loss: 0.037315\n","Epoch:  315 | train loss: 0.055680 | valid loss: 0.037189\n","Epoch:  316 | train loss: 0.028784 | valid loss: 0.037108\n","Epoch:  317 | train loss: 0.026572 | valid loss: 0.037235\n","Epoch:  318 | train loss: 0.048329 | valid loss: 0.037122\n","Epoch:  319 | train loss: 0.040463 | valid loss: 0.037157\n","Epoch:  320 | train loss: 0.049651 | valid loss: 0.037201\n","Epoch:  321 | train loss: 0.044059 | valid loss: 0.037143\n","Epoch:  322 | train loss: 0.036712 | valid loss: 0.037116\n","Epoch:  323 | train loss: 0.031885 | valid loss: 0.037070\n","Epoch:  324 | train loss: 0.045249 | valid loss: 0.037140\n","Epoch:  325 | train loss: 0.045849 | valid loss: 0.037133\n","Epoch:  326 | train loss: 0.042835 | valid loss: 0.037162\n","Epoch:  327 | train loss: 0.032881 | valid loss: 0.037258\n","Epoch:  328 | train loss: 0.033801 | valid loss: 0.037150\n","Epoch:  329 | train loss: 0.032107 | valid loss: 0.037149\n","Epoch:  330 | train loss: 0.033248 | valid loss: 0.037154\n","Epoch:  331 | train loss: 0.054863 | valid loss: 0.037138\n","Epoch:  332 | train loss: 0.035420 | valid loss: 0.037195\n","Epoch:  333 | train loss: 0.036704 | valid loss: 0.037098\n","Epoch:  334 | train loss: 0.033379 | valid loss: 0.037135\n","Epoch:  335 | train loss: 0.043691 | valid loss: 0.037180\n","Epoch:  336 | train loss: 0.036562 | valid loss: 0.037103\n","Epoch:  337 | train loss: 0.035601 | valid loss: 0.037189\n","Epoch:  338 | train loss: 0.066455 | valid loss: 0.037097\n","Epoch:  339 | train loss: 0.031326 | valid loss: 0.037113\n","Epoch:  340 | train loss: 0.030532 | valid loss: 0.037061\n","Epoch:  341 | train loss: 0.042732 | valid loss: 0.037285\n","Epoch:  342 | train loss: 0.026245 | valid loss: 0.037151\n","Epoch:  343 | train loss: 0.056945 | valid loss: 0.037142\n","Epoch:  344 | train loss: 0.048955 | valid loss: 0.037114\n","Epoch:  345 | train loss: 0.050907 | valid loss: 0.037178\n","Epoch:  346 | train loss: 0.039631 | valid loss: 0.037060\n","Epoch:  347 | train loss: 0.034591 | valid loss: 0.037246\n","Epoch:  348 | train loss: 0.049524 | valid loss: 0.037191\n","Epoch:  349 | train loss: 0.035021 | valid loss: 0.037205\n","Epoch:  350 | train loss: 0.048697 | valid loss: 0.037193\n","Epoch:  351 | train loss: 0.054598 | valid loss: 0.037222\n","Epoch:  352 | train loss: 0.056001 | valid loss: 0.037152\n","Epoch:  353 | train loss: 0.036228 | valid loss: 0.037078\n","Epoch:  354 | train loss: 0.052366 | valid loss: 0.037264\n","Epoch:  355 | train loss: 0.025857 | valid loss: 0.037067\n","Epoch:  356 | train loss: 0.031106 | valid loss: 0.037148\n","Epoch:  357 | train loss: 0.034681 | valid loss: 0.037111\n","Epoch:  358 | train loss: 0.046793 | valid loss: 0.037186\n","Epoch:  359 | train loss: 0.031393 | valid loss: 0.037226\n","Epoch:  360 | train loss: 0.049079 | valid loss: 0.037107\n","Epoch:  361 | train loss: 0.039210 | valid loss: 0.037131\n","Epoch:  362 | train loss: 0.028134 | valid loss: 0.037073\n","Epoch:  363 | train loss: 0.048821 | valid loss: 0.037176\n","Epoch:  364 | train loss: 0.039043 | valid loss: 0.037150\n","Epoch:  365 | train loss: 0.027788 | valid loss: 0.037114\n","Epoch:  366 | train loss: 0.033755 | valid loss: 0.037203\n","Epoch:  367 | train loss: 0.041500 | valid loss: 0.037119\n","Epoch:  368 | train loss: 0.046968 | valid loss: 0.037248\n","Epoch:  369 | train loss: 0.038249 | valid loss: 0.037155\n","Epoch:  370 | train loss: 0.044753 | valid loss: 0.037119\n","Epoch:  371 | train loss: 0.053456 | valid loss: 0.037132\n","Epoch:  372 | train loss: 0.069338 | valid loss: 0.037292\n","Epoch:  373 | train loss: 0.052132 | valid loss: 0.037143\n","Epoch:  374 | train loss: 0.034371 | valid loss: 0.037059\n","Epoch:  375 | train loss: 0.027891 | valid loss: 0.037147\n","Epoch:  376 | train loss: 0.042767 | valid loss: 0.037280\n","Epoch:  377 | train loss: 0.029175 | valid loss: 0.037137\n","Epoch:  378 | train loss: 0.027453 | valid loss: 0.037045\n","Epoch:  379 | train loss: 0.035294 | valid loss: 0.037139\n","Epoch:  380 | train loss: 0.041075 | valid loss: 0.037210\n","Epoch:  381 | train loss: 0.036916 | valid loss: 0.037124\n","Epoch:  382 | train loss: 0.044658 | valid loss: 0.037233\n","Epoch:  383 | train loss: 0.025922 | valid loss: 0.037195\n","Epoch:  384 | train loss: 0.038025 | valid loss: 0.037111\n","Epoch:  385 | train loss: 0.037946 | valid loss: 0.037171\n","Epoch:  386 | train loss: 0.038116 | valid loss: 0.037217\n","Epoch:  387 | train loss: 0.036298 | valid loss: 0.037166\n","Epoch:  388 | train loss: 0.029406 | valid loss: 0.037092\n","Epoch:  389 | train loss: 0.043083 | valid loss: 0.037246\n","Epoch:  390 | train loss: 0.040288 | valid loss: 0.037152\n","Epoch:  391 | train loss: 0.022170 | valid loss: 0.037139\n","Epoch:  392 | train loss: 0.035047 | valid loss: 0.037182\n","Epoch:  393 | train loss: 0.023509 | valid loss: 0.037186\n","Epoch:  394 | train loss: 0.027802 | valid loss: 0.037119\n","Epoch:  395 | train loss: 0.047122 | valid loss: 0.037140\n","Epoch:  396 | train loss: 0.038286 | valid loss: 0.037164\n","Epoch:  397 | train loss: 0.034095 | valid loss: 0.037141\n","Epoch:  398 | train loss: 0.035526 | valid loss: 0.037162\n","Epoch:  399 | train loss: 0.045658 | valid loss: 0.037245\n","Epoch:  400 | train loss: 0.029738 | valid loss: 0.037207\n","Epoch:  401 | train loss: 0.036157 | valid loss: 0.037150\n","Epoch:  402 | train loss: 0.028518 | valid loss: 0.037181\n","Epoch:  403 | train loss: 0.032040 | valid loss: 0.037180\n","Epoch:  404 | train loss: 0.032778 | valid loss: 0.037097\n","Epoch:  405 | train loss: 0.050973 | valid loss: 0.037158\n","Epoch:  406 | train loss: 0.064545 | valid loss: 0.037070\n","Epoch:  407 | train loss: 0.039237 | valid loss: 0.037148\n","Epoch:  408 | train loss: 0.037694 | valid loss: 0.037108\n","Epoch:  409 | train loss: 0.034102 | valid loss: 0.037197\n","Epoch:  410 | train loss: 0.041760 | valid loss: 0.037194\n","Epoch:  411 | train loss: 0.034168 | valid loss: 0.037202\n","Epoch:  412 | train loss: 0.039584 | valid loss: 0.037078\n","Epoch:  413 | train loss: 0.055535 | valid loss: 0.037145\n","Epoch:  414 | train loss: 0.024667 | valid loss: 0.037127\n","Epoch:  415 | train loss: 0.041692 | valid loss: 0.037161\n","Epoch:  416 | train loss: 0.024632 | valid loss: 0.037102\n","Epoch:  417 | train loss: 0.062065 | valid loss: 0.037212\n","Epoch:  418 | train loss: 0.033709 | valid loss: 0.037255\n","Epoch:  419 | train loss: 0.055400 | valid loss: 0.037164\n","Epoch:  420 | train loss: 0.052187 | valid loss: 0.037183\n","Epoch:  421 | train loss: 0.044557 | valid loss: 0.037197\n","Epoch:  422 | train loss: 0.029616 | valid loss: 0.037078\n","Epoch:  423 | train loss: 0.028678 | valid loss: 0.037220\n","Epoch:  424 | train loss: 0.033343 | valid loss: 0.037087\n","Epoch:  425 | train loss: 0.025214 | valid loss: 0.037172\n","Epoch:  426 | train loss: 0.024778 | valid loss: 0.037210\n","Epoch:  427 | train loss: 0.032516 | valid loss: 0.037157\n","Epoch:  428 | train loss: 0.046627 | valid loss: 0.037201\n","Epoch:  429 | train loss: 0.024478 | valid loss: 0.037086\n","Epoch:  430 | train loss: 0.045054 | valid loss: 0.037188\n","Epoch:  431 | train loss: 0.039683 | valid loss: 0.037158\n","Epoch:  432 | train loss: 0.028361 | valid loss: 0.037088\n","Epoch:  433 | train loss: 0.043850 | valid loss: 0.037213\n","Epoch:  434 | train loss: 0.030269 | valid loss: 0.037038\n","Epoch:  435 | train loss: 0.042610 | valid loss: 0.037117\n","Epoch:  436 | train loss: 0.046895 | valid loss: 0.037093\n","Epoch:  437 | train loss: 0.029311 | valid loss: 0.037198\n","Epoch:  438 | train loss: 0.024496 | valid loss: 0.037146\n","Epoch:  439 | train loss: 0.023916 | valid loss: 0.037107\n","Epoch:  440 | train loss: 0.054121 | valid loss: 0.037139\n","Epoch:  441 | train loss: 0.031744 | valid loss: 0.037157\n","Epoch:  442 | train loss: 0.031651 | valid loss: 0.037130\n","Epoch:  443 | train loss: 0.032588 | valid loss: 0.037164\n","Epoch:  444 | train loss: 0.047111 | valid loss: 0.037196\n","Epoch:  445 | train loss: 0.030848 | valid loss: 0.037278\n","Epoch:  446 | train loss: 0.054724 | valid loss: 0.037258\n","Epoch:  447 | train loss: 0.035216 | valid loss: 0.037146\n","Epoch:  448 | train loss: 0.053920 | valid loss: 0.037139\n","Epoch:  449 | train loss: 0.033401 | valid loss: 0.037182\n","Epoch:  450 | train loss: 0.023600 | valid loss: 0.037171\n","Epoch:  451 | train loss: 0.038338 | valid loss: 0.037051\n","Epoch:  452 | train loss: 0.024235 | valid loss: 0.037248\n","Epoch:  453 | train loss: 0.040299 | valid loss: 0.037158\n","Epoch:  454 | train loss: 0.030892 | valid loss: 0.037299\n","Epoch:  455 | train loss: 0.050486 | valid loss: 0.037210\n","Epoch:  456 | train loss: 0.024791 | valid loss: 0.037159\n","Epoch:  457 | train loss: 0.049291 | valid loss: 0.037203\n","Epoch:  458 | train loss: 0.038198 | valid loss: 0.037199\n","Epoch:  459 | train loss: 0.049823 | valid loss: 0.037155\n","Epoch:  460 | train loss: 0.041048 | valid loss: 0.037135\n","Epoch:  461 | train loss: 0.031083 | valid loss: 0.037142\n","Epoch:  462 | train loss: 0.030758 | valid loss: 0.037183\n","Epoch:  463 | train loss: 0.040018 | valid loss: 0.037181\n","Epoch:  464 | train loss: 0.067543 | valid loss: 0.037154\n","Epoch:  465 | train loss: 0.046543 | valid loss: 0.037160\n","Epoch:  466 | train loss: 0.039059 | valid loss: 0.037192\n","Epoch:  467 | train loss: 0.039633 | valid loss: 0.037192\n","Epoch:  468 | train loss: 0.028436 | valid loss: 0.037153\n","Epoch:  469 | train loss: 0.038422 | valid loss: 0.037236\n","Epoch:  470 | train loss: 0.045761 | valid loss: 0.037151\n","Epoch:  471 | train loss: 0.038014 | valid loss: 0.037229\n","Epoch:  472 | train loss: 0.054300 | valid loss: 0.037265\n","Epoch:  473 | train loss: 0.026655 | valid loss: 0.037133\n","Epoch:  474 | train loss: 0.035088 | valid loss: 0.037223\n","Epoch:  475 | train loss: 0.052924 | valid loss: 0.037218\n","Epoch:  476 | train loss: 0.041446 | valid loss: 0.037128\n","Epoch:  477 | train loss: 0.036146 | valid loss: 0.037207\n","Epoch:  478 | train loss: 0.046389 | valid loss: 0.037138\n","Epoch:  479 | train loss: 0.032885 | valid loss: 0.037116\n","Epoch:  480 | train loss: 0.041856 | valid loss: 0.037138\n","Epoch:  481 | train loss: 0.043205 | valid loss: 0.037097\n","Epoch:  482 | train loss: 0.035890 | valid loss: 0.037249\n","Epoch:  483 | train loss: 0.022279 | valid loss: 0.037261\n","Epoch:  484 | train loss: 0.049150 | valid loss: 0.037105\n","Epoch:  485 | train loss: 0.027736 | valid loss: 0.037159\n","Epoch:  486 | train loss: 0.056148 | valid loss: 0.037330\n","Epoch:  487 | train loss: 0.035804 | valid loss: 0.037172\n","Epoch:  488 | train loss: 0.026377 | valid loss: 0.037066\n","Epoch:  489 | train loss: 0.038600 | valid loss: 0.037203\n","Epoch:  490 | train loss: 0.045741 | valid loss: 0.037164\n","Epoch:  491 | train loss: 0.032678 | valid loss: 0.037197\n","Epoch:  492 | train loss: 0.050764 | valid loss: 0.037231\n","Epoch:  493 | train loss: 0.034117 | valid loss: 0.037120\n","Epoch:  494 | train loss: 0.036579 | valid loss: 0.037224\n","Epoch:  495 | train loss: 0.024338 | valid loss: 0.037132\n","Epoch:  496 | train loss: 0.025600 | valid loss: 0.037225\n","Epoch:  497 | train loss: 0.065962 | valid loss: 0.037203\n","Epoch:  498 | train loss: 0.028936 | valid loss: 0.037131\n","Epoch:  499 | train loss: 0.038475 | valid loss: 0.037185\n","Epoch:  500 | train loss: 0.033891 | valid loss: 0.037181\n","Epoch:  501 | train loss: 0.029548 | valid loss: 0.037166\n","Epoch:  502 | train loss: 0.039534 | valid loss: 0.037204\n","Epoch:  503 | train loss: 0.035788 | valid loss: 0.037159\n","Epoch:  504 | train loss: 0.029709 | valid loss: 0.037192\n","Epoch:  505 | train loss: 0.032631 | valid loss: 0.037246\n","Epoch:  506 | train loss: 0.044605 | valid loss: 0.037187\n","Epoch:  507 | train loss: 0.041568 | valid loss: 0.037159\n","Epoch:  508 | train loss: 0.027081 | valid loss: 0.037072\n","Epoch:  509 | train loss: 0.043968 | valid loss: 0.037287\n","Epoch:  510 | train loss: 0.049550 | valid loss: 0.037191\n","Epoch:  511 | train loss: 0.044885 | valid loss: 0.037150\n","Epoch:  512 | train loss: 0.043171 | valid loss: 0.037225\n","Epoch:  513 | train loss: 0.028523 | valid loss: 0.037184\n","Epoch:  514 | train loss: 0.068674 | valid loss: 0.037177\n","Epoch:  515 | train loss: 0.039577 | valid loss: 0.037111\n","Epoch:  516 | train loss: 0.043069 | valid loss: 0.037133\n","Epoch:  517 | train loss: 0.044862 | valid loss: 0.037135\n","Epoch:  518 | train loss: 0.028817 | valid loss: 0.037146\n","Epoch:  519 | train loss: 0.038103 | valid loss: 0.037179\n","Epoch:  520 | train loss: 0.040570 | valid loss: 0.037117\n","Epoch:  521 | train loss: 0.023021 | valid loss: 0.037141\n","Epoch:  522 | train loss: 0.035703 | valid loss: 0.037275\n","Epoch:  523 | train loss: 0.027740 | valid loss: 0.037221\n","Epoch:  524 | train loss: 0.029672 | valid loss: 0.037224\n","Epoch:  525 | train loss: 0.038769 | valid loss: 0.037248\n","Epoch:  526 | train loss: 0.056720 | valid loss: 0.037228\n","Epoch:  527 | train loss: 0.033033 | valid loss: 0.037178\n","Epoch:  528 | train loss: 0.042736 | valid loss: 0.037255\n","Epoch:  529 | train loss: 0.036710 | valid loss: 0.037102\n","Epoch:  530 | train loss: 0.038274 | valid loss: 0.037131\n","Epoch:  531 | train loss: 0.034440 | valid loss: 0.037154\n","Epoch:  532 | train loss: 0.054872 | valid loss: 0.037184\n","Epoch:  533 | train loss: 0.030704 | valid loss: 0.037136\n","Epoch:  534 | train loss: 0.039539 | valid loss: 0.037262\n","Epoch:  535 | train loss: 0.046367 | valid loss: 0.037184\n","Epoch:  536 | train loss: 0.028388 | valid loss: 0.037181\n","Epoch:  537 | train loss: 0.054970 | valid loss: 0.037140\n","Epoch:  538 | train loss: 0.037049 | valid loss: 0.037174\n","Epoch:  539 | train loss: 0.060999 | valid loss: 0.037175\n","Epoch:  540 | train loss: 0.035086 | valid loss: 0.037238\n","Epoch:  541 | train loss: 0.041001 | valid loss: 0.037152\n","Epoch:  542 | train loss: 0.063578 | valid loss: 0.037219\n","Epoch:  543 | train loss: 0.056799 | valid loss: 0.037111\n","Epoch:  544 | train loss: 0.045205 | valid loss: 0.037130\n","Epoch:  545 | train loss: 0.039118 | valid loss: 0.037173\n","Epoch:  546 | train loss: 0.036043 | valid loss: 0.037219\n","Epoch:  547 | train loss: 0.023099 | valid loss: 0.037237\n","Epoch:  548 | train loss: 0.038571 | valid loss: 0.037175\n","Epoch:  549 | train loss: 0.033145 | valid loss: 0.037215\n","Epoch:  550 | train loss: 0.050381 | valid loss: 0.037172\n","Epoch:  551 | train loss: 0.044036 | valid loss: 0.037215\n","Epoch:  552 | train loss: 0.049052 | valid loss: 0.037141\n","Epoch:  553 | train loss: 0.036962 | valid loss: 0.037173\n","Epoch:  554 | train loss: 0.030555 | valid loss: 0.037217\n","Epoch:  555 | train loss: 0.038832 | valid loss: 0.037208\n","Epoch:  556 | train loss: 0.037212 | valid loss: 0.037211\n","Epoch:  557 | train loss: 0.067371 | valid loss: 0.037159\n","Epoch:  558 | train loss: 0.040816 | valid loss: 0.037155\n","Epoch:  559 | train loss: 0.044793 | valid loss: 0.037201\n","Epoch:  560 | train loss: 0.032727 | valid loss: 0.037182\n","Epoch:  561 | train loss: 0.030728 | valid loss: 0.037178\n","Epoch:  562 | train loss: 0.037728 | valid loss: 0.037215\n","Epoch:  563 | train loss: 0.067109 | valid loss: 0.037149\n","Epoch:  564 | train loss: 0.038309 | valid loss: 0.037214\n","Epoch:  565 | train loss: 0.043169 | valid loss: 0.037213\n","Epoch:  566 | train loss: 0.058938 | valid loss: 0.037182\n","Epoch:  567 | train loss: 0.040970 | valid loss: 0.037231\n","Epoch:  568 | train loss: 0.053199 | valid loss: 0.037191\n","Epoch:  569 | train loss: 0.038983 | valid loss: 0.037161\n","Epoch:  570 | train loss: 0.029503 | valid loss: 0.037298\n","Epoch:  571 | train loss: 0.036846 | valid loss: 0.037135\n","Epoch:  572 | train loss: 0.030182 | valid loss: 0.037283\n","Epoch:  573 | train loss: 0.052396 | valid loss: 0.037209\n","Epoch:  574 | train loss: 0.034960 | valid loss: 0.037203\n","Epoch:  575 | train loss: 0.053510 | valid loss: 0.037223\n","Epoch:  576 | train loss: 0.031136 | valid loss: 0.037192\n","Epoch:  577 | train loss: 0.050650 | valid loss: 0.037171\n","Epoch:  578 | train loss: 0.037732 | valid loss: 0.037195\n","Epoch:  579 | train loss: 0.031294 | valid loss: 0.037233\n","Epoch:  580 | train loss: 0.041868 | valid loss: 0.037257\n","Epoch:  581 | train loss: 0.037265 | valid loss: 0.037197\n","Epoch:  582 | train loss: 0.039616 | valid loss: 0.037193\n","Epoch:  583 | train loss: 0.026776 | valid loss: 0.037123\n","Epoch:  584 | train loss: 0.035451 | valid loss: 0.037121\n","Epoch:  585 | train loss: 0.041979 | valid loss: 0.037187\n","Epoch:  586 | train loss: 0.034348 | valid loss: 0.037241\n","Epoch:  587 | train loss: 0.047514 | valid loss: 0.037223\n","Epoch:  588 | train loss: 0.040379 | valid loss: 0.037225\n","Epoch:  589 | train loss: 0.054174 | valid loss: 0.037204\n","Epoch:  590 | train loss: 0.032747 | valid loss: 0.037071\n","Epoch:  591 | train loss: 0.035790 | valid loss: 0.037181\n","Epoch:  592 | train loss: 0.037159 | valid loss: 0.037111\n","Epoch:  593 | train loss: 0.032753 | valid loss: 0.037147\n","Epoch:  594 | train loss: 0.039133 | valid loss: 0.037190\n","Epoch:  595 | train loss: 0.030459 | valid loss: 0.037220\n","Epoch:  596 | train loss: 0.046898 | valid loss: 0.037198\n","Epoch:  597 | train loss: 0.040555 | valid loss: 0.037218\n","Epoch:  598 | train loss: 0.037074 | valid loss: 0.037124\n","Epoch:  599 | train loss: 0.035502 | valid loss: 0.037232\n","Epoch:  600 | train loss: 0.036860 | valid loss: 0.037261\n","Epoch:  601 | train loss: 0.034596 | valid loss: 0.037250\n","Epoch:  602 | train loss: 0.056940 | valid loss: 0.037242\n","Epoch:  603 | train loss: 0.030727 | valid loss: 0.037336\n","Epoch:  604 | train loss: 0.056054 | valid loss: 0.037215\n","Epoch:  605 | train loss: 0.045480 | valid loss: 0.037174\n","Epoch:  606 | train loss: 0.045887 | valid loss: 0.037219\n","Epoch:  607 | train loss: 0.049291 | valid loss: 0.037174\n","Epoch:  608 | train loss: 0.060967 | valid loss: 0.037180\n","Epoch:  609 | train loss: 0.031156 | valid loss: 0.037253\n","Epoch:  610 | train loss: 0.063124 | valid loss: 0.037253\n","Epoch:  611 | train loss: 0.030482 | valid loss: 0.037255\n","Epoch:  612 | train loss: 0.053113 | valid loss: 0.037190\n","Epoch:  613 | train loss: 0.045188 | valid loss: 0.037252\n","Epoch:  614 | train loss: 0.027239 | valid loss: 0.037226\n","Epoch:  615 | train loss: 0.029781 | valid loss: 0.037225\n","Epoch:  616 | train loss: 0.025523 | valid loss: 0.037165\n","Epoch:  617 | train loss: 0.052565 | valid loss: 0.037317\n","Epoch:  618 | train loss: 0.021794 | valid loss: 0.037206\n","Epoch:  619 | train loss: 0.060612 | valid loss: 0.037262\n","Epoch:  620 | train loss: 0.041850 | valid loss: 0.037218\n","Epoch:  621 | train loss: 0.042977 | valid loss: 0.037249\n","Epoch:  622 | train loss: 0.037108 | valid loss: 0.037180\n","Epoch:  623 | train loss: 0.028932 | valid loss: 0.037203\n","Epoch:  624 | train loss: 0.043121 | valid loss: 0.037178\n","Epoch:  625 | train loss: 0.032629 | valid loss: 0.037215\n","Epoch:  626 | train loss: 0.034658 | valid loss: 0.037236\n","Epoch:  627 | train loss: 0.034436 | valid loss: 0.037136\n","Epoch:  628 | train loss: 0.025789 | valid loss: 0.037293\n","Epoch:  629 | train loss: 0.052470 | valid loss: 0.037278\n","Epoch:  630 | train loss: 0.032096 | valid loss: 0.037207\n","Epoch:  631 | train loss: 0.056816 | valid loss: 0.037175\n","Epoch:  632 | train loss: 0.033193 | valid loss: 0.037175\n","Epoch:  633 | train loss: 0.052421 | valid loss: 0.037230\n","Epoch:  634 | train loss: 0.062684 | valid loss: 0.037237\n","Epoch:  635 | train loss: 0.027920 | valid loss: 0.037213\n","Epoch:  636 | train loss: 0.030325 | valid loss: 0.037224\n","Epoch:  637 | train loss: 0.029318 | valid loss: 0.037224\n","Epoch:  638 | train loss: 0.036409 | valid loss: 0.037231\n","Epoch:  639 | train loss: 0.021780 | valid loss: 0.037267\n","Epoch:  640 | train loss: 0.023465 | valid loss: 0.037366\n","Epoch:  641 | train loss: 0.047824 | valid loss: 0.037326\n","Epoch:  642 | train loss: 0.039332 | valid loss: 0.037253\n","Epoch:  643 | train loss: 0.023773 | valid loss: 0.037188\n","Epoch:  644 | train loss: 0.041339 | valid loss: 0.037264\n","Epoch:  645 | train loss: 0.032975 | valid loss: 0.037230\n","Epoch:  646 | train loss: 0.035224 | valid loss: 0.037232\n","Epoch:  647 | train loss: 0.040159 | valid loss: 0.037202\n","Epoch:  648 | train loss: 0.062118 | valid loss: 0.037272\n","Epoch:  649 | train loss: 0.033232 | valid loss: 0.037156\n","Epoch:  650 | train loss: 0.025556 | valid loss: 0.037217\n","Epoch:  651 | train loss: 0.033095 | valid loss: 0.037239\n","Epoch:  652 | train loss: 0.022112 | valid loss: 0.037127\n","Epoch:  653 | train loss: 0.025651 | valid loss: 0.037254\n","Epoch:  654 | train loss: 0.036422 | valid loss: 0.037165\n","Epoch:  655 | train loss: 0.038173 | valid loss: 0.037328\n","Epoch:  656 | train loss: 0.061727 | valid loss: 0.037185\n","Epoch:  657 | train loss: 0.032208 | valid loss: 0.037298\n","Epoch:  658 | train loss: 0.047627 | valid loss: 0.037306\n","Epoch:  659 | train loss: 0.043406 | valid loss: 0.037277\n","Epoch:  660 | train loss: 0.030653 | valid loss: 0.037237\n","Epoch:  661 | train loss: 0.044475 | valid loss: 0.037129\n","Epoch:  662 | train loss: 0.030653 | valid loss: 0.037223\n","Epoch:  663 | train loss: 0.028408 | valid loss: 0.037332\n","Epoch:  664 | train loss: 0.032794 | valid loss: 0.037243\n","Epoch:  665 | train loss: 0.032414 | valid loss: 0.037259\n","Epoch:  666 | train loss: 0.050746 | valid loss: 0.037170\n","Epoch:  667 | train loss: 0.024812 | valid loss: 0.037259\n","Epoch:  668 | train loss: 0.046356 | valid loss: 0.037214\n","Epoch:  669 | train loss: 0.043819 | valid loss: 0.037238\n","Epoch:  670 | train loss: 0.055330 | valid loss: 0.037200\n","Epoch:  671 | train loss: 0.042761 | valid loss: 0.037239\n","Epoch:  672 | train loss: 0.033329 | valid loss: 0.037315\n","Epoch:  673 | train loss: 0.041075 | valid loss: 0.037200\n","Epoch:  674 | train loss: 0.049270 | valid loss: 0.037308\n","Epoch:  675 | train loss: 0.031307 | valid loss: 0.037148\n","Epoch:  676 | train loss: 0.033238 | valid loss: 0.037219\n","Epoch:  677 | train loss: 0.024899 | valid loss: 0.037238\n","Epoch:  678 | train loss: 0.052572 | valid loss: 0.037219\n","Epoch:  679 | train loss: 0.045460 | valid loss: 0.037211\n","Epoch:  680 | train loss: 0.023354 | valid loss: 0.037179\n","Epoch:  681 | train loss: 0.057309 | valid loss: 0.037216\n","Epoch:  682 | train loss: 0.048933 | valid loss: 0.037232\n","Epoch:  683 | train loss: 0.034891 | valid loss: 0.037220\n","Epoch:  684 | train loss: 0.044465 | valid loss: 0.037178\n","Epoch:  685 | train loss: 0.043581 | valid loss: 0.037162\n","Epoch:  686 | train loss: 0.035395 | valid loss: 0.037189\n","Epoch:  687 | train loss: 0.036852 | valid loss: 0.037274\n","Epoch:  688 | train loss: 0.027973 | valid loss: 0.037265\n","Epoch:  689 | train loss: 0.047084 | valid loss: 0.037241\n","Epoch:  690 | train loss: 0.033217 | valid loss: 0.037256\n","Epoch:  691 | train loss: 0.036783 | valid loss: 0.037213\n","Epoch:  692 | train loss: 0.027985 | valid loss: 0.037250\n","Epoch:  693 | train loss: 0.032571 | valid loss: 0.037203\n","Epoch:  694 | train loss: 0.051653 | valid loss: 0.037293\n","Epoch:  695 | train loss: 0.024688 | valid loss: 0.037277\n","Epoch:  696 | train loss: 0.045794 | valid loss: 0.037218\n","Epoch:  697 | train loss: 0.032666 | valid loss: 0.037211\n","Epoch:  698 | train loss: 0.034288 | valid loss: 0.037196\n","Epoch:  699 | train loss: 0.037294 | valid loss: 0.037238\n","Epoch:  700 | train loss: 0.022712 | valid loss: 0.037206\n","Epoch:  701 | train loss: 0.027178 | valid loss: 0.037285\n","Epoch:  702 | train loss: 0.048584 | valid loss: 0.037229\n","Epoch:  703 | train loss: 0.033154 | valid loss: 0.037300\n","Epoch:  704 | train loss: 0.030004 | valid loss: 0.037205\n","Epoch:  705 | train loss: 0.034654 | valid loss: 0.037203\n","Epoch:  706 | train loss: 0.026657 | valid loss: 0.037243\n","Epoch:  707 | train loss: 0.033330 | valid loss: 0.037293\n","Epoch:  708 | train loss: 0.047570 | valid loss: 0.037201\n","Epoch:  709 | train loss: 0.028427 | valid loss: 0.037218\n","Epoch:  710 | train loss: 0.061375 | valid loss: 0.037349\n","Epoch:  711 | train loss: 0.036788 | valid loss: 0.037345\n","Epoch:  712 | train loss: 0.046856 | valid loss: 0.037142\n","Epoch:  713 | train loss: 0.036247 | valid loss: 0.037283\n","Epoch:  714 | train loss: 0.033138 | valid loss: 0.037265\n","Epoch:  715 | train loss: 0.033872 | valid loss: 0.037274\n","Epoch:  716 | train loss: 0.039403 | valid loss: 0.037235\n","Epoch:  717 | train loss: 0.052286 | valid loss: 0.037243\n","Epoch:  718 | train loss: 0.047291 | valid loss: 0.037285\n","Epoch:  719 | train loss: 0.023544 | valid loss: 0.037253\n","Epoch:  720 | train loss: 0.042124 | valid loss: 0.037351\n","Epoch:  721 | train loss: 0.038665 | valid loss: 0.037343\n","Epoch:  722 | train loss: 0.028887 | valid loss: 0.037342\n","Epoch:  723 | train loss: 0.041689 | valid loss: 0.037280\n","Epoch:  724 | train loss: 0.040455 | valid loss: 0.037247\n","Epoch:  725 | train loss: 0.024343 | valid loss: 0.037293\n","Epoch:  726 | train loss: 0.038321 | valid loss: 0.037316\n","Epoch:  727 | train loss: 0.028880 | valid loss: 0.037270\n","Epoch:  728 | train loss: 0.033096 | valid loss: 0.037252\n","Epoch:  729 | train loss: 0.047195 | valid loss: 0.037297\n","Epoch:  730 | train loss: 0.030494 | valid loss: 0.037297\n","Epoch:  731 | train loss: 0.044569 | valid loss: 0.037331\n","Epoch:  732 | train loss: 0.045960 | valid loss: 0.037283\n","Epoch:  733 | train loss: 0.043677 | valid loss: 0.037305\n","Epoch:  734 | train loss: 0.049522 | valid loss: 0.037268\n","Epoch:  735 | train loss: 0.051459 | valid loss: 0.037216\n","Epoch:  736 | train loss: 0.047737 | valid loss: 0.037227\n","Epoch:  737 | train loss: 0.035921 | valid loss: 0.037298\n","Epoch:  738 | train loss: 0.050714 | valid loss: 0.037268\n","Epoch:  739 | train loss: 0.048894 | valid loss: 0.037262\n","Epoch:  740 | train loss: 0.037759 | valid loss: 0.037184\n","Epoch:  741 | train loss: 0.040452 | valid loss: 0.037230\n","Epoch:  742 | train loss: 0.048086 | valid loss: 0.037303\n","Epoch:  743 | train loss: 0.038119 | valid loss: 0.037263\n","Epoch:  744 | train loss: 0.050369 | valid loss: 0.037294\n","Epoch:  745 | train loss: 0.046807 | valid loss: 0.037305\n","Epoch:  746 | train loss: 0.025229 | valid loss: 0.037286\n","Epoch:  747 | train loss: 0.044732 | valid loss: 0.037235\n","Epoch:  748 | train loss: 0.031958 | valid loss: 0.037291\n","Epoch:  749 | train loss: 0.042947 | valid loss: 0.037259\n","Epoch:  750 | train loss: 0.027724 | valid loss: 0.037263\n","Epoch:  751 | train loss: 0.033465 | valid loss: 0.037236\n","Epoch:  752 | train loss: 0.052641 | valid loss: 0.037235\n","Epoch:  753 | train loss: 0.037276 | valid loss: 0.037349\n","Epoch:  754 | train loss: 0.057174 | valid loss: 0.037306\n","Epoch:  755 | train loss: 0.067006 | valid loss: 0.037187\n","Epoch:  756 | train loss: 0.029126 | valid loss: 0.037286\n","Epoch:  757 | train loss: 0.052648 | valid loss: 0.037195\n","Epoch:  758 | train loss: 0.044168 | valid loss: 0.037278\n","Epoch:  759 | train loss: 0.040591 | valid loss: 0.037162\n","Epoch:  760 | train loss: 0.044762 | valid loss: 0.037296\n","Epoch:  761 | train loss: 0.036454 | valid loss: 0.037206\n","Epoch:  762 | train loss: 0.057474 | valid loss: 0.037368\n","Epoch:  763 | train loss: 0.036039 | valid loss: 0.037369\n","Epoch:  764 | train loss: 0.034067 | valid loss: 0.037302\n","Epoch:  765 | train loss: 0.040618 | valid loss: 0.037309\n","Epoch:  766 | train loss: 0.033131 | valid loss: 0.037201\n","Epoch:  767 | train loss: 0.047992 | valid loss: 0.037243\n","Epoch:  768 | train loss: 0.053691 | valid loss: 0.037238\n","Epoch:  769 | train loss: 0.053679 | valid loss: 0.037257\n","Epoch:  770 | train loss: 0.021315 | valid loss: 0.037238\n","Epoch:  771 | train loss: 0.042566 | valid loss: 0.037271\n","Epoch:  772 | train loss: 0.024023 | valid loss: 0.037226\n","Epoch:  773 | train loss: 0.034142 | valid loss: 0.037290\n","Epoch:  774 | train loss: 0.028146 | valid loss: 0.037251\n","Epoch:  775 | train loss: 0.021824 | valid loss: 0.037298\n","Epoch:  776 | train loss: 0.027371 | valid loss: 0.037241\n","Epoch:  777 | train loss: 0.026630 | valid loss: 0.037205\n","Epoch:  778 | train loss: 0.045870 | valid loss: 0.037266\n","Epoch:  779 | train loss: 0.033799 | valid loss: 0.037354\n","Epoch:  780 | train loss: 0.044046 | valid loss: 0.037275\n","Epoch:  781 | train loss: 0.033179 | valid loss: 0.037277\n","Epoch:  782 | train loss: 0.039201 | valid loss: 0.037245\n","Epoch:  783 | train loss: 0.043530 | valid loss: 0.037215\n","Epoch:  784 | train loss: 0.048470 | valid loss: 0.037316\n","Epoch:  785 | train loss: 0.034232 | valid loss: 0.037224\n","Epoch:  786 | train loss: 0.032557 | valid loss: 0.037343\n","Epoch:  787 | train loss: 0.040855 | valid loss: 0.037316\n","Epoch:  788 | train loss: 0.035633 | valid loss: 0.037268\n","Epoch:  789 | train loss: 0.034320 | valid loss: 0.037263\n","Epoch:  790 | train loss: 0.035152 | valid loss: 0.037227\n","Epoch:  791 | train loss: 0.028244 | valid loss: 0.037290\n","Epoch:  792 | train loss: 0.040101 | valid loss: 0.037266\n","Epoch:  793 | train loss: 0.036412 | valid loss: 0.037391\n","Epoch:  794 | train loss: 0.044818 | valid loss: 0.037272\n","Epoch:  795 | train loss: 0.035546 | valid loss: 0.037304\n","Epoch:  796 | train loss: 0.044242 | valid loss: 0.037361\n","Epoch:  797 | train loss: 0.039033 | valid loss: 0.037279\n","Epoch:  798 | train loss: 0.032518 | valid loss: 0.037208\n","Epoch:  799 | train loss: 0.023917 | valid loss: 0.037232\n","Epoch:  800 | train loss: 0.051234 | valid loss: 0.037210\n","Epoch:  801 | train loss: 0.033323 | valid loss: 0.037246\n","Epoch:  802 | train loss: 0.036845 | valid loss: 0.037254\n","Epoch:  803 | train loss: 0.021961 | valid loss: 0.037192\n","Epoch:  804 | train loss: 0.035498 | valid loss: 0.037241\n","Epoch:  805 | train loss: 0.032876 | valid loss: 0.037258\n","Epoch:  806 | train loss: 0.047886 | valid loss: 0.037255\n","Epoch:  807 | train loss: 0.030499 | valid loss: 0.037230\n","Epoch:  808 | train loss: 0.040007 | valid loss: 0.037323\n","Epoch:  809 | train loss: 0.040291 | valid loss: 0.037292\n","Epoch:  810 | train loss: 0.034109 | valid loss: 0.037288\n","Epoch:  811 | train loss: 0.033740 | valid loss: 0.037285\n","Epoch:  812 | train loss: 0.027190 | valid loss: 0.037299\n","Epoch:  813 | train loss: 0.045177 | valid loss: 0.037256\n","Epoch:  814 | train loss: 0.024347 | valid loss: 0.037228\n","Epoch:  815 | train loss: 0.023778 | valid loss: 0.037232\n","Epoch:  816 | train loss: 0.039998 | valid loss: 0.037359\n","Epoch:  817 | train loss: 0.033887 | valid loss: 0.037288\n","Epoch:  818 | train loss: 0.044851 | valid loss: 0.037343\n","Epoch:  819 | train loss: 0.039769 | valid loss: 0.037223\n","Epoch:  820 | train loss: 0.040395 | valid loss: 0.037275\n","Epoch:  821 | train loss: 0.037683 | valid loss: 0.037316\n","Epoch:  822 | train loss: 0.041597 | valid loss: 0.037279\n","Epoch:  823 | train loss: 0.045896 | valid loss: 0.037366\n","Epoch:  824 | train loss: 0.027981 | valid loss: 0.037350\n","Epoch:  825 | train loss: 0.031783 | valid loss: 0.037274\n","Epoch:  826 | train loss: 0.028650 | valid loss: 0.037298\n","Epoch:  827 | train loss: 0.034739 | valid loss: 0.037311\n","Epoch:  828 | train loss: 0.043489 | valid loss: 0.037243\n","Epoch:  829 | train loss: 0.024908 | valid loss: 0.037225\n","Epoch:  830 | train loss: 0.023125 | valid loss: 0.037259\n","Epoch:  831 | train loss: 0.030142 | valid loss: 0.037293\n","Epoch:  832 | train loss: 0.053031 | valid loss: 0.037256\n","Epoch:  833 | train loss: 0.024787 | valid loss: 0.037253\n","Epoch:  834 | train loss: 0.061064 | valid loss: 0.037228\n","Epoch:  835 | train loss: 0.044126 | valid loss: 0.037226\n","Epoch:  836 | train loss: 0.048578 | valid loss: 0.037359\n","Epoch:  837 | train loss: 0.034371 | valid loss: 0.037246\n","Epoch:  838 | train loss: 0.037921 | valid loss: 0.037309\n","Epoch:  839 | train loss: 0.051296 | valid loss: 0.037329\n","Epoch:  840 | train loss: 0.060526 | valid loss: 0.037335\n","Epoch:  841 | train loss: 0.049344 | valid loss: 0.037289\n","Epoch:  842 | train loss: 0.028528 | valid loss: 0.037318\n","Epoch:  843 | train loss: 0.023879 | valid loss: 0.037309\n","Epoch:  844 | train loss: 0.065176 | valid loss: 0.037280\n","Epoch:  845 | train loss: 0.034764 | valid loss: 0.037303\n","Epoch:  846 | train loss: 0.035828 | valid loss: 0.037250\n","Epoch:  847 | train loss: 0.027917 | valid loss: 0.037268\n","Epoch:  848 | train loss: 0.045467 | valid loss: 0.037337\n","Epoch:  849 | train loss: 0.038390 | valid loss: 0.037257\n","Epoch:  850 | train loss: 0.048098 | valid loss: 0.037298\n","Epoch:  851 | train loss: 0.041070 | valid loss: 0.037207\n","Epoch:  852 | train loss: 0.039315 | valid loss: 0.037311\n","Epoch:  853 | train loss: 0.034632 | valid loss: 0.037338\n","Epoch:  854 | train loss: 0.033166 | valid loss: 0.037300\n","Epoch:  855 | train loss: 0.047715 | valid loss: 0.037374\n","Epoch:  856 | train loss: 0.041416 | valid loss: 0.037348\n","Epoch:  857 | train loss: 0.031370 | valid loss: 0.037349\n","Epoch:  858 | train loss: 0.021155 | valid loss: 0.037310\n","Epoch:  859 | train loss: 0.038919 | valid loss: 0.037319\n","Epoch:  860 | train loss: 0.051045 | valid loss: 0.037304\n","Epoch:  861 | train loss: 0.054291 | valid loss: 0.037312\n","Epoch:  862 | train loss: 0.041672 | valid loss: 0.037364\n","Epoch:  863 | train loss: 0.037934 | valid loss: 0.037304\n","Epoch:  864 | train loss: 0.044685 | valid loss: 0.037257\n","Epoch:  865 | train loss: 0.041776 | valid loss: 0.037261\n","Epoch:  866 | train loss: 0.029801 | valid loss: 0.037273\n","Epoch:  867 | train loss: 0.038622 | valid loss: 0.037222\n","Epoch:  868 | train loss: 0.036515 | valid loss: 0.037235\n","Epoch:  869 | train loss: 0.036020 | valid loss: 0.037245\n","Epoch:  870 | train loss: 0.029039 | valid loss: 0.037216\n","Epoch:  871 | train loss: 0.030640 | valid loss: 0.037245\n","Epoch:  872 | train loss: 0.024983 | valid loss: 0.037229\n","Epoch:  873 | train loss: 0.034124 | valid loss: 0.037278\n","Epoch:  874 | train loss: 0.029284 | valid loss: 0.037275\n","Epoch:  875 | train loss: 0.027472 | valid loss: 0.037263\n","Epoch:  876 | train loss: 0.037047 | valid loss: 0.037216\n","Epoch:  877 | train loss: 0.047090 | valid loss: 0.037252\n","Epoch:  878 | train loss: 0.032687 | valid loss: 0.037329\n","Epoch:  879 | train loss: 0.026575 | valid loss: 0.037234\n","Epoch:  880 | train loss: 0.049509 | valid loss: 0.037292\n","Epoch:  881 | train loss: 0.038394 | valid loss: 0.037309\n","Epoch:  882 | train loss: 0.037947 | valid loss: 0.037279\n","Epoch:  883 | train loss: 0.045025 | valid loss: 0.037348\n","Epoch:  884 | train loss: 0.028777 | valid loss: 0.037245\n","Epoch:  885 | train loss: 0.039553 | valid loss: 0.037269\n","Epoch:  886 | train loss: 0.056294 | valid loss: 0.037333\n","Epoch:  887 | train loss: 0.050708 | valid loss: 0.037302\n","Epoch:  888 | train loss: 0.043555 | valid loss: 0.037310\n","Epoch:  889 | train loss: 0.046301 | valid loss: 0.037338\n","Epoch:  890 | train loss: 0.039879 | valid loss: 0.037351\n","Epoch:  891 | train loss: 0.041808 | valid loss: 0.037233\n","Epoch:  892 | train loss: 0.049838 | valid loss: 0.037346\n","Epoch:  893 | train loss: 0.039216 | valid loss: 0.037306\n","Epoch:  894 | train loss: 0.041954 | valid loss: 0.037282\n","Epoch:  895 | train loss: 0.049888 | valid loss: 0.037425\n","Epoch:  896 | train loss: 0.032248 | valid loss: 0.037311\n","Epoch:  897 | train loss: 0.043454 | valid loss: 0.037294\n","Epoch:  898 | train loss: 0.030246 | valid loss: 0.037314\n","Epoch:  899 | train loss: 0.041312 | valid loss: 0.037372\n","Epoch:  900 | train loss: 0.033858 | valid loss: 0.037363\n","Epoch:  901 | train loss: 0.048052 | valid loss: 0.037274\n","Epoch:  902 | train loss: 0.051135 | valid loss: 0.037350\n","Epoch:  903 | train loss: 0.022845 | valid loss: 0.037287\n","Epoch:  904 | train loss: 0.045369 | valid loss: 0.037272\n","Epoch:  905 | train loss: 0.028094 | valid loss: 0.037253\n","Epoch:  906 | train loss: 0.058879 | valid loss: 0.037317\n","Epoch:  907 | train loss: 0.032683 | valid loss: 0.037282\n","Epoch:  908 | train loss: 0.050943 | valid loss: 0.037397\n","Epoch:  909 | train loss: 0.031516 | valid loss: 0.037281\n","Epoch:  910 | train loss: 0.047727 | valid loss: 0.037331\n","Epoch:  911 | train loss: 0.031143 | valid loss: 0.037278\n","Epoch:  912 | train loss: 0.049800 | valid loss: 0.037334\n","Epoch:  913 | train loss: 0.032480 | valid loss: 0.037318\n","Epoch:  914 | train loss: 0.038065 | valid loss: 0.037325\n","Epoch:  915 | train loss: 0.031395 | valid loss: 0.037300\n","Epoch:  916 | train loss: 0.054850 | valid loss: 0.037313\n","Epoch:  917 | train loss: 0.026157 | valid loss: 0.037241\n","Epoch:  918 | train loss: 0.030603 | valid loss: 0.037358\n","Epoch:  919 | train loss: 0.038107 | valid loss: 0.037322\n","Epoch:  920 | train loss: 0.036172 | valid loss: 0.037330\n","Epoch:  921 | train loss: 0.047615 | valid loss: 0.037274\n","Epoch:  922 | train loss: 0.032387 | valid loss: 0.037279\n","Epoch:  923 | train loss: 0.035398 | valid loss: 0.037387\n","Epoch:  924 | train loss: 0.044082 | valid loss: 0.037290\n","Epoch:  925 | train loss: 0.064388 | valid loss: 0.037372\n","Epoch:  926 | train loss: 0.035286 | valid loss: 0.037410\n","Epoch:  927 | train loss: 0.026955 | valid loss: 0.037288\n","Epoch:  928 | train loss: 0.024650 | valid loss: 0.037229\n","Epoch:  929 | train loss: 0.036878 | valid loss: 0.037298\n","Epoch:  930 | train loss: 0.023828 | valid loss: 0.037328\n","Epoch:  931 | train loss: 0.023285 | valid loss: 0.037313\n","Epoch:  932 | train loss: 0.023845 | valid loss: 0.037345\n","Epoch:  933 | train loss: 0.030107 | valid loss: 0.037242\n","Epoch:  934 | train loss: 0.025199 | valid loss: 0.037394\n","Epoch:  935 | train loss: 0.031262 | valid loss: 0.037320\n","Epoch:  936 | train loss: 0.047962 | valid loss: 0.037340\n","Epoch:  937 | train loss: 0.046839 | valid loss: 0.037258\n","Epoch:  938 | train loss: 0.044255 | valid loss: 0.037334\n","Epoch:  939 | train loss: 0.045093 | valid loss: 0.037259\n","Epoch:  940 | train loss: 0.029759 | valid loss: 0.037312\n","Epoch:  941 | train loss: 0.050155 | valid loss: 0.037294\n","Epoch:  942 | train loss: 0.041099 | valid loss: 0.037276\n","Epoch:  943 | train loss: 0.021862 | valid loss: 0.037301\n","Epoch:  944 | train loss: 0.051727 | valid loss: 0.037317\n","Epoch:  945 | train loss: 0.024001 | valid loss: 0.037302\n","Epoch:  946 | train loss: 0.044899 | valid loss: 0.037301\n","Epoch:  947 | train loss: 0.036108 | valid loss: 0.037317\n","Epoch:  948 | train loss: 0.040350 | valid loss: 0.037222\n","Epoch:  949 | train loss: 0.048770 | valid loss: 0.037288\n","Epoch:  950 | train loss: 0.041931 | valid loss: 0.037324\n","Epoch:  951 | train loss: 0.038593 | valid loss: 0.037299\n","Epoch:  952 | train loss: 0.050255 | valid loss: 0.037297\n","Epoch:  953 | train loss: 0.043495 | valid loss: 0.037258\n","Epoch:  954 | train loss: 0.024179 | valid loss: 0.037307\n","Epoch:  955 | train loss: 0.030300 | valid loss: 0.037287\n","Epoch:  956 | train loss: 0.035774 | valid loss: 0.037323\n","Epoch:  957 | train loss: 0.028799 | valid loss: 0.037353\n","Epoch:  958 | train loss: 0.047858 | valid loss: 0.037379\n","Epoch:  959 | train loss: 0.029089 | valid loss: 0.037303\n","Epoch:  960 | train loss: 0.046703 | valid loss: 0.037250\n","Epoch:  961 | train loss: 0.047216 | valid loss: 0.037289\n","Epoch:  962 | train loss: 0.048466 | valid loss: 0.037334\n","Epoch:  963 | train loss: 0.025191 | valid loss: 0.037341\n","Epoch:  964 | train loss: 0.023011 | valid loss: 0.037288\n","Epoch:  965 | train loss: 0.043201 | valid loss: 0.037362\n","Epoch:  966 | train loss: 0.024319 | valid loss: 0.037436\n","Epoch:  967 | train loss: 0.022418 | valid loss: 0.037325\n","Epoch:  968 | train loss: 0.039092 | valid loss: 0.037304\n","Epoch:  969 | train loss: 0.059799 | valid loss: 0.037293\n","Epoch:  970 | train loss: 0.028500 | valid loss: 0.037340\n","Epoch:  971 | train loss: 0.039926 | valid loss: 0.037278\n","Epoch:  972 | train loss: 0.023207 | valid loss: 0.037311\n","Epoch:  973 | train loss: 0.042463 | valid loss: 0.037331\n","Epoch:  974 | train loss: 0.039164 | valid loss: 0.037430\n","Epoch:  975 | train loss: 0.054076 | valid loss: 0.037354\n","Epoch:  976 | train loss: 0.026322 | valid loss: 0.037384\n","Epoch:  977 | train loss: 0.047577 | valid loss: 0.037341\n","Epoch:  978 | train loss: 0.025377 | valid loss: 0.037344\n","Epoch:  979 | train loss: 0.035264 | valid loss: 0.037341\n","Epoch:  980 | train loss: 0.065689 | valid loss: 0.037382\n","Epoch:  981 | train loss: 0.042820 | valid loss: 0.037324\n","Epoch:  982 | train loss: 0.048893 | valid loss: 0.037374\n","Epoch:  983 | train loss: 0.033405 | valid loss: 0.037319\n","Epoch:  984 | train loss: 0.056697 | valid loss: 0.037374\n","Epoch:  985 | train loss: 0.042942 | valid loss: 0.037325\n","Epoch:  986 | train loss: 0.043656 | valid loss: 0.037347\n","Epoch:  987 | train loss: 0.033680 | valid loss: 0.037276\n","Epoch:  988 | train loss: 0.036057 | valid loss: 0.037326\n","Epoch:  989 | train loss: 0.051955 | valid loss: 0.037361\n","Epoch:  990 | train loss: 0.034663 | valid loss: 0.037322\n","Epoch:  991 | train loss: 0.039550 | valid loss: 0.037329\n","Epoch:  992 | train loss: 0.030295 | valid loss: 0.037292\n","Epoch:  993 | train loss: 0.049784 | valid loss: 0.037322\n","Epoch:  994 | train loss: 0.053703 | valid loss: 0.037316\n","Epoch:  995 | train loss: 0.037457 | valid loss: 0.037300\n","Epoch:  996 | train loss: 0.056952 | valid loss: 0.037395\n","Epoch:  997 | train loss: 0.062471 | valid loss: 0.037382\n","Epoch:  998 | train loss: 0.027045 | valid loss: 0.037384\n","Epoch:  999 | train loss: 0.031898 | valid loss: 0.037345\n","Epoch:  1000 | train loss: 0.035930 | valid loss: 0.037345\n","Epoch:  1001 | train loss: 0.039517 | valid loss: 0.037304\n","Epoch:  1002 | train loss: 0.024204 | valid loss: 0.037363\n","Epoch:  1003 | train loss: 0.037300 | valid loss: 0.037393\n","Epoch:  1004 | train loss: 0.039188 | valid loss: 0.037364\n","Epoch:  1005 | train loss: 0.055918 | valid loss: 0.037390\n","Epoch:  1006 | train loss: 0.033656 | valid loss: 0.037336\n","Epoch:  1007 | train loss: 0.030547 | valid loss: 0.037284\n","Epoch:  1008 | train loss: 0.037237 | valid loss: 0.037316\n","Epoch:  1009 | train loss: 0.046440 | valid loss: 0.037377\n","Epoch:  1010 | train loss: 0.030859 | valid loss: 0.037398\n","Epoch:  1011 | train loss: 0.027668 | valid loss: 0.037427\n","Epoch:  1012 | train loss: 0.030089 | valid loss: 0.037345\n","Epoch:  1013 | train loss: 0.042881 | valid loss: 0.037357\n","Epoch:  1014 | train loss: 0.033951 | valid loss: 0.037323\n","Epoch:  1015 | train loss: 0.026661 | valid loss: 0.037288\n","Epoch:  1016 | train loss: 0.030334 | valid loss: 0.037352\n","Epoch:  1017 | train loss: 0.044516 | valid loss: 0.037405\n","Epoch:  1018 | train loss: 0.026362 | valid loss: 0.037410\n","Epoch:  1019 | train loss: 0.041561 | valid loss: 0.037468\n","Epoch:  1020 | train loss: 0.052377 | valid loss: 0.037362\n","Epoch:  1021 | train loss: 0.047408 | valid loss: 0.037313\n","Epoch:  1022 | train loss: 0.035580 | valid loss: 0.037374\n","Epoch:  1023 | train loss: 0.031101 | valid loss: 0.037366\n","Epoch:  1024 | train loss: 0.047409 | valid loss: 0.037359\n","Epoch:  1025 | train loss: 0.039443 | valid loss: 0.037336\n","Epoch:  1026 | train loss: 0.043976 | valid loss: 0.037304\n","Epoch:  1027 | train loss: 0.043297 | valid loss: 0.037413\n","Epoch:  1028 | train loss: 0.038658 | valid loss: 0.037409\n","Epoch:  1029 | train loss: 0.021465 | valid loss: 0.037347\n","Epoch:  1030 | train loss: 0.029465 | valid loss: 0.037378\n","Epoch:  1031 | train loss: 0.041679 | valid loss: 0.037332\n","Epoch:  1032 | train loss: 0.038977 | valid loss: 0.037401\n","Epoch:  1033 | train loss: 0.044681 | valid loss: 0.037448\n","Epoch:  1034 | train loss: 0.054581 | valid loss: 0.037283\n","Epoch:  1035 | train loss: 0.033353 | valid loss: 0.037377\n","Epoch:  1036 | train loss: 0.034927 | valid loss: 0.037341\n","Epoch:  1037 | train loss: 0.039823 | valid loss: 0.037322\n","Epoch:  1038 | train loss: 0.021102 | valid loss: 0.037324\n","Epoch:  1039 | train loss: 0.041804 | valid loss: 0.037308\n","Epoch:  1040 | train loss: 0.035152 | valid loss: 0.037399\n","Epoch:  1041 | train loss: 0.062013 | valid loss: 0.037374\n","Epoch:  1042 | train loss: 0.028168 | valid loss: 0.037407\n","Epoch:  1043 | train loss: 0.025754 | valid loss: 0.037385\n","Epoch:  1044 | train loss: 0.029722 | valid loss: 0.037344\n","Epoch:  1045 | train loss: 0.022996 | valid loss: 0.037358\n","Epoch:  1046 | train loss: 0.056913 | valid loss: 0.037359\n","Epoch:  1047 | train loss: 0.029888 | valid loss: 0.037416\n","Epoch:  1048 | train loss: 0.041755 | valid loss: 0.037490\n","Epoch:  1049 | train loss: 0.026110 | valid loss: 0.037375\n","Epoch:  1050 | train loss: 0.044791 | valid loss: 0.037392\n","Epoch:  1051 | train loss: 0.036455 | valid loss: 0.037356\n","Epoch:  1052 | train loss: 0.049759 | valid loss: 0.037354\n","Epoch:  1053 | train loss: 0.050855 | valid loss: 0.037420\n","Epoch:  1054 | train loss: 0.056549 | valid loss: 0.037359\n","Epoch:  1055 | train loss: 0.034114 | valid loss: 0.037383\n","Epoch:  1056 | train loss: 0.026859 | valid loss: 0.037350\n","Epoch:  1057 | train loss: 0.030173 | valid loss: 0.037389\n","Epoch:  1058 | train loss: 0.038484 | valid loss: 0.037366\n","Epoch:  1059 | train loss: 0.044995 | valid loss: 0.037499\n","Epoch:  1060 | train loss: 0.042252 | valid loss: 0.037360\n","Epoch:  1061 | train loss: 0.031313 | valid loss: 0.037373\n","Epoch:  1062 | train loss: 0.029529 | valid loss: 0.037390\n","Epoch:  1063 | train loss: 0.047852 | valid loss: 0.037336\n","Epoch:  1064 | train loss: 0.047812 | valid loss: 0.037381\n","Epoch:  1065 | train loss: 0.035349 | valid loss: 0.037353\n","Epoch:  1066 | train loss: 0.024566 | valid loss: 0.037309\n","Epoch:  1067 | train loss: 0.035192 | valid loss: 0.037432\n","Epoch:  1068 | train loss: 0.036751 | valid loss: 0.037480\n","Epoch:  1069 | train loss: 0.027781 | valid loss: 0.037416\n","Epoch:  1070 | train loss: 0.040774 | valid loss: 0.037421\n","Epoch:  1071 | train loss: 0.044855 | valid loss: 0.037390\n","Epoch:  1072 | train loss: 0.045521 | valid loss: 0.037315\n","Epoch:  1073 | train loss: 0.023603 | valid loss: 0.037394\n","Epoch:  1074 | train loss: 0.048854 | valid loss: 0.037316\n","Epoch:  1075 | train loss: 0.024956 | valid loss: 0.037348\n","Epoch:  1076 | train loss: 0.033707 | valid loss: 0.037368\n","Epoch:  1077 | train loss: 0.032257 | valid loss: 0.037386\n","Epoch:  1078 | train loss: 0.057999 | valid loss: 0.037469\n","Epoch:  1079 | train loss: 0.028906 | valid loss: 0.037440\n","Epoch:  1080 | train loss: 0.045117 | valid loss: 0.037470\n","Epoch:  1081 | train loss: 0.048065 | valid loss: 0.037377\n","Epoch:  1082 | train loss: 0.050006 | valid loss: 0.037413\n","Epoch:  1083 | train loss: 0.043518 | valid loss: 0.037386\n","Epoch:  1084 | train loss: 0.049571 | valid loss: 0.037447\n","Epoch:  1085 | train loss: 0.049469 | valid loss: 0.037374\n","Epoch:  1086 | train loss: 0.034624 | valid loss: 0.037383\n","Epoch:  1087 | train loss: 0.038809 | valid loss: 0.037387\n","Epoch:  1088 | train loss: 0.030841 | valid loss: 0.037423\n","Epoch:  1089 | train loss: 0.036660 | valid loss: 0.037352\n","Epoch:  1090 | train loss: 0.023316 | valid loss: 0.037400\n","Epoch:  1091 | train loss: 0.040289 | valid loss: 0.037360\n","Epoch:  1092 | train loss: 0.030732 | valid loss: 0.037375\n","Epoch:  1093 | train loss: 0.034479 | valid loss: 0.037408\n","Epoch:  1094 | train loss: 0.037805 | valid loss: 0.037337\n","Epoch:  1095 | train loss: 0.048173 | valid loss: 0.037366\n","Epoch:  1096 | train loss: 0.065396 | valid loss: 0.037381\n","Epoch:  1097 | train loss: 0.038184 | valid loss: 0.037419\n","Epoch:  1098 | train loss: 0.026768 | valid loss: 0.037370\n","Epoch:  1099 | train loss: 0.038845 | valid loss: 0.037413\n","Epoch:  1100 | train loss: 0.034073 | valid loss: 0.037486\n","Epoch:  1101 | train loss: 0.038307 | valid loss: 0.037391\n","Epoch:  1102 | train loss: 0.065863 | valid loss: 0.037425\n","Epoch:  1103 | train loss: 0.049124 | valid loss: 0.037386\n","Epoch:  1104 | train loss: 0.051098 | valid loss: 0.037406\n","Epoch:  1105 | train loss: 0.030339 | valid loss: 0.037404\n","Epoch:  1106 | train loss: 0.035685 | valid loss: 0.037395\n","Epoch:  1107 | train loss: 0.027189 | valid loss: 0.037382\n","Epoch:  1108 | train loss: 0.039154 | valid loss: 0.037343\n","Epoch:  1109 | train loss: 0.037519 | valid loss: 0.037390\n","Epoch:  1110 | train loss: 0.050190 | valid loss: 0.037420\n","Epoch:  1111 | train loss: 0.031327 | valid loss: 0.037380\n","Epoch:  1112 | train loss: 0.044501 | valid loss: 0.037355\n","Epoch:  1113 | train loss: 0.041044 | valid loss: 0.037410\n","Epoch:  1114 | train loss: 0.054639 | valid loss: 0.037354\n","Epoch:  1115 | train loss: 0.024945 | valid loss: 0.037395\n","Epoch:  1116 | train loss: 0.044874 | valid loss: 0.037410\n","Epoch:  1117 | train loss: 0.039053 | valid loss: 0.037374\n","Epoch:  1118 | train loss: 0.036366 | valid loss: 0.037400\n","Epoch:  1119 | train loss: 0.032841 | valid loss: 0.037425\n","Epoch:  1120 | train loss: 0.043445 | valid loss: 0.037418\n","Epoch:  1121 | train loss: 0.040402 | valid loss: 0.037418\n","Epoch:  1122 | train loss: 0.045600 | valid loss: 0.037399\n","Epoch:  1123 | train loss: 0.044544 | valid loss: 0.037379\n","Epoch:  1124 | train loss: 0.033781 | valid loss: 0.037410\n","Epoch:  1125 | train loss: 0.055513 | valid loss: 0.037433\n","Epoch:  1126 | train loss: 0.021494 | valid loss: 0.037460\n","Epoch:  1127 | train loss: 0.022988 | valid loss: 0.037352\n","Epoch:  1128 | train loss: 0.046445 | valid loss: 0.037353\n","Epoch:  1129 | train loss: 0.030669 | valid loss: 0.037398\n","Epoch:  1130 | train loss: 0.025066 | valid loss: 0.037321\n","Epoch:  1131 | train loss: 0.049622 | valid loss: 0.037355\n","Epoch:  1132 | train loss: 0.040371 | valid loss: 0.037451\n","Epoch:  1133 | train loss: 0.045745 | valid loss: 0.037538\n","Epoch:  1134 | train loss: 0.039319 | valid loss: 0.037377\n","Epoch:  1135 | train loss: 0.027494 | valid loss: 0.037378\n","Epoch:  1136 | train loss: 0.032874 | valid loss: 0.037450\n","Epoch:  1137 | train loss: 0.042094 | valid loss: 0.037350\n","Epoch:  1138 | train loss: 0.043045 | valid loss: 0.037388\n","Epoch:  1139 | train loss: 0.036772 | valid loss: 0.037401\n","Epoch:  1140 | train loss: 0.034061 | valid loss: 0.037385\n","Epoch:  1141 | train loss: 0.039763 | valid loss: 0.037473\n","Epoch:  1142 | train loss: 0.033178 | valid loss: 0.037500\n","Epoch:  1143 | train loss: 0.038616 | valid loss: 0.037385\n","Epoch:  1144 | train loss: 0.033708 | valid loss: 0.037404\n","Epoch:  1145 | train loss: 0.047168 | valid loss: 0.037414\n","Epoch:  1146 | train loss: 0.040916 | valid loss: 0.037413\n","Epoch:  1147 | train loss: 0.044899 | valid loss: 0.037318\n","Epoch:  1148 | train loss: 0.025120 | valid loss: 0.037471\n","Epoch:  1149 | train loss: 0.042066 | valid loss: 0.037372\n","Epoch:  1150 | train loss: 0.070286 | valid loss: 0.037372\n","Epoch:  1151 | train loss: 0.033319 | valid loss: 0.037390\n","Epoch:  1152 | train loss: 0.041528 | valid loss: 0.037380\n","Epoch:  1153 | train loss: 0.020949 | valid loss: 0.037410\n","Epoch:  1154 | train loss: 0.030283 | valid loss: 0.037449\n","Epoch:  1155 | train loss: 0.042170 | valid loss: 0.037436\n","Epoch:  1156 | train loss: 0.051428 | valid loss: 0.037365\n","Epoch:  1157 | train loss: 0.045011 | valid loss: 0.037423\n","Epoch:  1158 | train loss: 0.042791 | valid loss: 0.037347\n","Epoch:  1159 | train loss: 0.027595 | valid loss: 0.037375\n","Epoch:  1160 | train loss: 0.053780 | valid loss: 0.037315\n","Epoch:  1161 | train loss: 0.047620 | valid loss: 0.037369\n","Epoch:  1162 | train loss: 0.042180 | valid loss: 0.037430\n","Epoch:  1163 | train loss: 0.029786 | valid loss: 0.037523\n","Epoch:  1164 | train loss: 0.041014 | valid loss: 0.037474\n","Epoch:  1165 | train loss: 0.024536 | valid loss: 0.037407\n","Epoch:  1166 | train loss: 0.036594 | valid loss: 0.037456\n","Epoch:  1167 | train loss: 0.041662 | valid loss: 0.037395\n","Epoch:  1168 | train loss: 0.039705 | valid loss: 0.037352\n","Epoch:  1169 | train loss: 0.064127 | valid loss: 0.037421\n","Epoch:  1170 | train loss: 0.055844 | valid loss: 0.037379\n","Epoch:  1171 | train loss: 0.033977 | valid loss: 0.037384\n","Epoch:  1172 | train loss: 0.025689 | valid loss: 0.037397\n","Epoch:  1173 | train loss: 0.039859 | valid loss: 0.037344\n","Epoch:  1174 | train loss: 0.043744 | valid loss: 0.037398\n","Epoch:  1175 | train loss: 0.024741 | valid loss: 0.037482\n","Epoch:  1176 | train loss: 0.070741 | valid loss: 0.037459\n","Epoch:  1177 | train loss: 0.045257 | valid loss: 0.037355\n","Epoch:  1178 | train loss: 0.060228 | valid loss: 0.037410\n","Epoch:  1179 | train loss: 0.029565 | valid loss: 0.037452\n","Epoch:  1180 | train loss: 0.063923 | valid loss: 0.037477\n","Epoch:  1181 | train loss: 0.031669 | valid loss: 0.037385\n","Epoch:  1182 | train loss: 0.033251 | valid loss: 0.037406\n","Epoch:  1183 | train loss: 0.026047 | valid loss: 0.037401\n","Epoch:  1184 | train loss: 0.029984 | valid loss: 0.037391\n","Epoch:  1185 | train loss: 0.043223 | valid loss: 0.037505\n","Epoch:  1186 | train loss: 0.048600 | valid loss: 0.037389\n","Epoch:  1187 | train loss: 0.048700 | valid loss: 0.037497\n","Epoch:  1188 | train loss: 0.028749 | valid loss: 0.037451\n","Epoch:  1189 | train loss: 0.053659 | valid loss: 0.037462\n","Epoch:  1190 | train loss: 0.035620 | valid loss: 0.037451\n","Epoch:  1191 | train loss: 0.026638 | valid loss: 0.037439\n","Epoch:  1192 | train loss: 0.048009 | valid loss: 0.037430\n","Epoch:  1193 | train loss: 0.043160 | valid loss: 0.037412\n","Epoch:  1194 | train loss: 0.046603 | valid loss: 0.037389\n","Epoch:  1195 | train loss: 0.027596 | valid loss: 0.037326\n","Epoch:  1196 | train loss: 0.032827 | valid loss: 0.037437\n","Epoch:  1197 | train loss: 0.040038 | valid loss: 0.037457\n","Epoch:  1198 | train loss: 0.049290 | valid loss: 0.037516\n","Epoch:  1199 | train loss: 0.043379 | valid loss: 0.037359\n","Epoch:  1200 | train loss: 0.034708 | valid loss: 0.037431\n","Epoch:  1201 | train loss: 0.038563 | valid loss: 0.037399\n","Epoch:  1202 | train loss: 0.031519 | valid loss: 0.037319\n","Epoch:  1203 | train loss: 0.021445 | valid loss: 0.037427\n","Epoch:  1204 | train loss: 0.051327 | valid loss: 0.037483\n","Epoch:  1205 | train loss: 0.038528 | valid loss: 0.037468\n","Epoch:  1206 | train loss: 0.057139 | valid loss: 0.037459\n","Epoch:  1207 | train loss: 0.035934 | valid loss: 0.037438\n","Epoch:  1208 | train loss: 0.028050 | valid loss: 0.037412\n","Epoch:  1209 | train loss: 0.025159 | valid loss: 0.037437\n","Epoch:  1210 | train loss: 0.039228 | valid loss: 0.037445\n","Epoch:  1211 | train loss: 0.047423 | valid loss: 0.037359\n","Epoch:  1212 | train loss: 0.052298 | valid loss: 0.037388\n","Epoch:  1213 | train loss: 0.031084 | valid loss: 0.037331\n","Epoch:  1214 | train loss: 0.045607 | valid loss: 0.037462\n","Epoch:  1215 | train loss: 0.046908 | valid loss: 0.037455\n","Epoch:  1216 | train loss: 0.049418 | valid loss: 0.037398\n","Epoch:  1217 | train loss: 0.050587 | valid loss: 0.037448\n","Epoch:  1218 | train loss: 0.032450 | valid loss: 0.037403\n","Epoch:  1219 | train loss: 0.033777 | valid loss: 0.037359\n","Epoch:  1220 | train loss: 0.049790 | valid loss: 0.037420\n","Epoch:  1221 | train loss: 0.027125 | valid loss: 0.037400\n","Epoch:  1222 | train loss: 0.038131 | valid loss: 0.037366\n","Epoch:  1223 | train loss: 0.027952 | valid loss: 0.037430\n","Epoch:  1224 | train loss: 0.055813 | valid loss: 0.037390\n","Epoch:  1225 | train loss: 0.045676 | valid loss: 0.037427\n","Epoch:  1226 | train loss: 0.047875 | valid loss: 0.037439\n","Epoch:  1227 | train loss: 0.049937 | valid loss: 0.037466\n","Epoch:  1228 | train loss: 0.029678 | valid loss: 0.037380\n","Epoch:  1229 | train loss: 0.045588 | valid loss: 0.037525\n","Epoch:  1230 | train loss: 0.032380 | valid loss: 0.037439\n","Epoch:  1231 | train loss: 0.039398 | valid loss: 0.037521\n","Epoch:  1232 | train loss: 0.033548 | valid loss: 0.037471\n","Epoch:  1233 | train loss: 0.037911 | valid loss: 0.037425\n","Epoch:  1234 | train loss: 0.044685 | valid loss: 0.037389\n","Epoch:  1235 | train loss: 0.025547 | valid loss: 0.037395\n","Epoch:  1236 | train loss: 0.041863 | valid loss: 0.037423\n","Epoch:  1237 | train loss: 0.033750 | valid loss: 0.037383\n","Epoch:  1238 | train loss: 0.035357 | valid loss: 0.037378\n","Epoch:  1239 | train loss: 0.033849 | valid loss: 0.037369\n","Epoch:  1240 | train loss: 0.041470 | valid loss: 0.037424\n","Epoch:  1241 | train loss: 0.042148 | valid loss: 0.037387\n","Epoch:  1242 | train loss: 0.059211 | valid loss: 0.037509\n","Epoch:  1243 | train loss: 0.042755 | valid loss: 0.037399\n","Epoch:  1244 | train loss: 0.026710 | valid loss: 0.037418\n","Epoch:  1245 | train loss: 0.033521 | valid loss: 0.037385\n","Epoch:  1246 | train loss: 0.027289 | valid loss: 0.037424\n","Epoch:  1247 | train loss: 0.029145 | valid loss: 0.037341\n","Epoch:  1248 | train loss: 0.040571 | valid loss: 0.037387\n","Epoch:  1249 | train loss: 0.056354 | valid loss: 0.037394\n","Epoch:  1250 | train loss: 0.021919 | valid loss: 0.037390\n","Epoch:  1251 | train loss: 0.040802 | valid loss: 0.037403\n","Epoch:  1252 | train loss: 0.044074 | valid loss: 0.037430\n","Epoch:  1253 | train loss: 0.048744 | valid loss: 0.037427\n","Epoch:  1254 | train loss: 0.043560 | valid loss: 0.037470\n","Epoch:  1255 | train loss: 0.023666 | valid loss: 0.037422\n","Epoch:  1256 | train loss: 0.035079 | valid loss: 0.037460\n","Epoch:  1257 | train loss: 0.032937 | valid loss: 0.037375\n","Epoch:  1258 | train loss: 0.054521 | valid loss: 0.037415\n","Epoch:  1259 | train loss: 0.039742 | valid loss: 0.037523\n","Epoch:  1260 | train loss: 0.036598 | valid loss: 0.037404\n","Epoch:  1261 | train loss: 0.049277 | valid loss: 0.037464\n","Epoch:  1262 | train loss: 0.030193 | valid loss: 0.037404\n","Epoch:  1263 | train loss: 0.034704 | valid loss: 0.037375\n","Epoch:  1264 | train loss: 0.043023 | valid loss: 0.037365\n","Epoch:  1265 | train loss: 0.042759 | valid loss: 0.037435\n","Epoch:  1266 | train loss: 0.052858 | valid loss: 0.037408\n","Epoch:  1267 | train loss: 0.047428 | valid loss: 0.037444\n","Epoch:  1268 | train loss: 0.025628 | valid loss: 0.037406\n","Epoch:  1269 | train loss: 0.041205 | valid loss: 0.037450\n","Epoch:  1270 | train loss: 0.039494 | valid loss: 0.037379\n","Epoch:  1271 | train loss: 0.029939 | valid loss: 0.037404\n","Epoch:  1272 | train loss: 0.046994 | valid loss: 0.037414\n","Epoch:  1273 | train loss: 0.059088 | valid loss: 0.037471\n","Epoch:  1274 | train loss: 0.029018 | valid loss: 0.037364\n","Epoch:  1275 | train loss: 0.038885 | valid loss: 0.037430\n","Epoch:  1276 | train loss: 0.035567 | valid loss: 0.037385\n","Epoch:  1277 | train loss: 0.033721 | valid loss: 0.037508\n","Epoch:  1278 | train loss: 0.032849 | valid loss: 0.037394\n","Epoch:  1279 | train loss: 0.047221 | valid loss: 0.037458\n","Epoch:  1280 | train loss: 0.033203 | valid loss: 0.037543\n","Epoch:  1281 | train loss: 0.051338 | valid loss: 0.037397\n","Epoch:  1282 | train loss: 0.031351 | valid loss: 0.037451\n","Epoch:  1283 | train loss: 0.024866 | valid loss: 0.037440\n","Epoch:  1284 | train loss: 0.047917 | valid loss: 0.037458\n","Epoch:  1285 | train loss: 0.023884 | valid loss: 0.037409\n","Epoch:  1286 | train loss: 0.036277 | valid loss: 0.037469\n","Epoch:  1287 | train loss: 0.026462 | valid loss: 0.037455\n","Epoch:  1288 | train loss: 0.025938 | valid loss: 0.037482\n","Epoch:  1289 | train loss: 0.039004 | valid loss: 0.037507\n","Epoch:  1290 | train loss: 0.025519 | valid loss: 0.037460\n","Epoch:  1291 | train loss: 0.040810 | valid loss: 0.037516\n","Epoch:  1292 | train loss: 0.032520 | valid loss: 0.037496\n","Epoch:  1293 | train loss: 0.036352 | valid loss: 0.037495\n","Epoch:  1294 | train loss: 0.036404 | valid loss: 0.037520\n","Epoch:  1295 | train loss: 0.047371 | valid loss: 0.037416\n","Epoch:  1296 | train loss: 0.049710 | valid loss: 0.037423\n","Epoch:  1297 | train loss: 0.022210 | valid loss: 0.037406\n","Epoch:  1298 | train loss: 0.046399 | valid loss: 0.037391\n","Epoch:  1299 | train loss: 0.023441 | valid loss: 0.037422\n","Epoch:  1300 | train loss: 0.032600 | valid loss: 0.037493\n","Epoch:  1301 | train loss: 0.025992 | valid loss: 0.037457\n","Epoch:  1302 | train loss: 0.057528 | valid loss: 0.037441\n","Epoch:  1303 | train loss: 0.036143 | valid loss: 0.037418\n","Epoch:  1304 | train loss: 0.021838 | valid loss: 0.037352\n","Epoch:  1305 | train loss: 0.040515 | valid loss: 0.037449\n","Epoch:  1306 | train loss: 0.041651 | valid loss: 0.037420\n","Epoch:  1307 | train loss: 0.035572 | valid loss: 0.037537\n","Epoch:  1308 | train loss: 0.027834 | valid loss: 0.037536\n","Epoch:  1309 | train loss: 0.034167 | valid loss: 0.037471\n","Epoch:  1310 | train loss: 0.030088 | valid loss: 0.037474\n","Epoch:  1311 | train loss: 0.037939 | valid loss: 0.037423\n","Epoch:  1312 | train loss: 0.037192 | valid loss: 0.037402\n","Epoch:  1313 | train loss: 0.026064 | valid loss: 0.037439\n","Epoch:  1314 | train loss: 0.034253 | valid loss: 0.037423\n","Epoch:  1315 | train loss: 0.025300 | valid loss: 0.037467\n","Epoch:  1316 | train loss: 0.035884 | valid loss: 0.037484\n","Epoch:  1317 | train loss: 0.026950 | valid loss: 0.037477\n","Epoch:  1318 | train loss: 0.042247 | valid loss: 0.037427\n","Epoch:  1319 | train loss: 0.039459 | valid loss: 0.037440\n","Epoch:  1320 | train loss: 0.033760 | valid loss: 0.037390\n","Epoch:  1321 | train loss: 0.030981 | valid loss: 0.037379\n","Epoch:  1322 | train loss: 0.030878 | valid loss: 0.037414\n","Epoch:  1323 | train loss: 0.042003 | valid loss: 0.037403\n","Epoch:  1324 | train loss: 0.045290 | valid loss: 0.037428\n","Epoch:  1325 | train loss: 0.026790 | valid loss: 0.037491\n","Epoch:  1326 | train loss: 0.046140 | valid loss: 0.037478\n","Epoch:  1327 | train loss: 0.038530 | valid loss: 0.037500\n","Epoch:  1328 | train loss: 0.041005 | valid loss: 0.037436\n","Epoch:  1329 | train loss: 0.035129 | valid loss: 0.037377\n","Epoch:  1330 | train loss: 0.043572 | valid loss: 0.037425\n","Epoch:  1331 | train loss: 0.036762 | valid loss: 0.037385\n","Epoch:  1332 | train loss: 0.050722 | valid loss: 0.037527\n","Epoch:  1333 | train loss: 0.034327 | valid loss: 0.037578\n","Epoch:  1334 | train loss: 0.058238 | valid loss: 0.037420\n","Epoch:  1335 | train loss: 0.028832 | valid loss: 0.037442\n","Epoch:  1336 | train loss: 0.032702 | valid loss: 0.037426\n","Epoch:  1337 | train loss: 0.039997 | valid loss: 0.037460\n","Epoch:  1338 | train loss: 0.054995 | valid loss: 0.037403\n","Epoch:  1339 | train loss: 0.030179 | valid loss: 0.037427\n","Epoch:  1340 | train loss: 0.027384 | valid loss: 0.037423\n","Epoch:  1341 | train loss: 0.031576 | valid loss: 0.037400\n","Epoch:  1342 | train loss: 0.058650 | valid loss: 0.037476\n","Epoch:  1343 | train loss: 0.044695 | valid loss: 0.037459\n","Epoch:  1344 | train loss: 0.035521 | valid loss: 0.037401\n","Epoch:  1345 | train loss: 0.054675 | valid loss: 0.037417\n","Epoch:  1346 | train loss: 0.026552 | valid loss: 0.037473\n","Epoch:  1347 | train loss: 0.054392 | valid loss: 0.037507\n","Epoch:  1348 | train loss: 0.034471 | valid loss: 0.037486\n","Epoch:  1349 | train loss: 0.032576 | valid loss: 0.037437\n","Epoch:  1350 | train loss: 0.023580 | valid loss: 0.037376\n","Epoch:  1351 | train loss: 0.045664 | valid loss: 0.037480\n","Epoch:  1352 | train loss: 0.030367 | valid loss: 0.037509\n","Epoch:  1353 | train loss: 0.042412 | valid loss: 0.037459\n","Epoch:  1354 | train loss: 0.029448 | valid loss: 0.037439\n","Epoch:  1355 | train loss: 0.045220 | valid loss: 0.037545\n","Epoch:  1356 | train loss: 0.034172 | valid loss: 0.037519\n","Epoch:  1357 | train loss: 0.027734 | valid loss: 0.037445\n","Epoch:  1358 | train loss: 0.031846 | valid loss: 0.037419\n","Epoch:  1359 | train loss: 0.042285 | valid loss: 0.037457\n","Epoch:  1360 | train loss: 0.026757 | valid loss: 0.037478\n","Epoch:  1361 | train loss: 0.037497 | valid loss: 0.037402\n","Epoch:  1362 | train loss: 0.029429 | valid loss: 0.037554\n","Epoch:  1363 | train loss: 0.029051 | valid loss: 0.037479\n","Epoch:  1364 | train loss: 0.025366 | valid loss: 0.037500\n","Epoch:  1365 | train loss: 0.028289 | valid loss: 0.037534\n","Epoch:  1366 | train loss: 0.033274 | valid loss: 0.037558\n","Epoch:  1367 | train loss: 0.050624 | valid loss: 0.037453\n","Epoch:  1368 | train loss: 0.032671 | valid loss: 0.037407\n","Epoch:  1369 | train loss: 0.025816 | valid loss: 0.037440\n","Epoch:  1370 | train loss: 0.032565 | valid loss: 0.037478\n","Epoch:  1371 | train loss: 0.042598 | valid loss: 0.037478\n","Epoch:  1372 | train loss: 0.034793 | valid loss: 0.037520\n","Epoch:  1373 | train loss: 0.049080 | valid loss: 0.037467\n","Epoch:  1374 | train loss: 0.043583 | valid loss: 0.037479\n","Epoch:  1375 | train loss: 0.035131 | valid loss: 0.037643\n","Epoch:  1376 | train loss: 0.030184 | valid loss: 0.037525\n","Epoch:  1377 | train loss: 0.038250 | valid loss: 0.037489\n","Epoch:  1378 | train loss: 0.041697 | valid loss: 0.037492\n","Epoch:  1379 | train loss: 0.022435 | valid loss: 0.037420\n","Epoch:  1380 | train loss: 0.023667 | valid loss: 0.037436\n","Epoch:  1381 | train loss: 0.036202 | valid loss: 0.037515\n","Epoch:  1382 | train loss: 0.031523 | valid loss: 0.037423\n","Epoch:  1383 | train loss: 0.043042 | valid loss: 0.037439\n","Epoch:  1384 | train loss: 0.027798 | valid loss: 0.037401\n","Epoch:  1385 | train loss: 0.029328 | valid loss: 0.037539\n","Epoch:  1386 | train loss: 0.041482 | valid loss: 0.037492\n","Epoch:  1387 | train loss: 0.038556 | valid loss: 0.037461\n","Epoch:  1388 | train loss: 0.035166 | valid loss: 0.037440\n","Epoch:  1389 | train loss: 0.029924 | valid loss: 0.037463\n","Epoch:  1390 | train loss: 0.038923 | valid loss: 0.037497\n","Epoch:  1391 | train loss: 0.030935 | valid loss: 0.037477\n","Epoch:  1392 | train loss: 0.033010 | valid loss: 0.037499\n","Epoch:  1393 | train loss: 0.033743 | valid loss: 0.037454\n","Epoch:  1394 | train loss: 0.031664 | valid loss: 0.037451\n","Epoch:  1395 | train loss: 0.041592 | valid loss: 0.037477\n","Epoch:  1396 | train loss: 0.048441 | valid loss: 0.037476\n","Epoch:  1397 | train loss: 0.027075 | valid loss: 0.037436\n","Epoch:  1398 | train loss: 0.032627 | valid loss: 0.037484\n","Epoch:  1399 | train loss: 0.038889 | valid loss: 0.037493\n","Epoch:  1400 | train loss: 0.050420 | valid loss: 0.037484\n","Epoch:  1401 | train loss: 0.028765 | valid loss: 0.037415\n","Epoch:  1402 | train loss: 0.036172 | valid loss: 0.037534\n","Epoch:  1403 | train loss: 0.049602 | valid loss: 0.037509\n","Epoch:  1404 | train loss: 0.041696 | valid loss: 0.037486\n","Epoch:  1405 | train loss: 0.035723 | valid loss: 0.037397\n","Epoch:  1406 | train loss: 0.026526 | valid loss: 0.037435\n","Epoch:  1407 | train loss: 0.029615 | valid loss: 0.037413\n","Epoch:  1408 | train loss: 0.056855 | valid loss: 0.037489\n","Epoch:  1409 | train loss: 0.036132 | valid loss: 0.037420\n","Epoch:  1410 | train loss: 0.029691 | valid loss: 0.037432\n","Epoch:  1411 | train loss: 0.040951 | valid loss: 0.037467\n","Epoch:  1412 | train loss: 0.028818 | valid loss: 0.037454\n","Epoch:  1413 | train loss: 0.056370 | valid loss: 0.037514\n","Epoch:  1414 | train loss: 0.035133 | valid loss: 0.037462\n","Epoch:  1415 | train loss: 0.043939 | valid loss: 0.037464\n","Epoch:  1416 | train loss: 0.046383 | valid loss: 0.037544\n","Epoch:  1417 | train loss: 0.035891 | valid loss: 0.037513\n","Epoch:  1418 | train loss: 0.048573 | valid loss: 0.037544\n","Epoch:  1419 | train loss: 0.050869 | valid loss: 0.037473\n","Epoch:  1420 | train loss: 0.041276 | valid loss: 0.037457\n","Epoch:  1421 | train loss: 0.036070 | valid loss: 0.037452\n","Epoch:  1422 | train loss: 0.042562 | valid loss: 0.037477\n","Epoch:  1423 | train loss: 0.042921 | valid loss: 0.037483\n","Epoch:  1424 | train loss: 0.029741 | valid loss: 0.037399\n","Epoch:  1425 | train loss: 0.021682 | valid loss: 0.037498\n","Epoch:  1426 | train loss: 0.034282 | valid loss: 0.037461\n","Epoch:  1427 | train loss: 0.046070 | valid loss: 0.037430\n","Epoch:  1428 | train loss: 0.032966 | valid loss: 0.037567\n","Epoch:  1429 | train loss: 0.039862 | valid loss: 0.037525\n","Epoch:  1430 | train loss: 0.046589 | valid loss: 0.037430\n","Epoch:  1431 | train loss: 0.030149 | valid loss: 0.037427\n","Epoch:  1432 | train loss: 0.041913 | valid loss: 0.037475\n","Epoch:  1433 | train loss: 0.063585 | valid loss: 0.037490\n","Epoch:  1434 | train loss: 0.045256 | valid loss: 0.037481\n","Epoch:  1435 | train loss: 0.042975 | valid loss: 0.037468\n","Epoch:  1436 | train loss: 0.036707 | valid loss: 0.037500\n","Epoch:  1437 | train loss: 0.060146 | valid loss: 0.037502\n","Epoch:  1438 | train loss: 0.035965 | valid loss: 0.037424\n","Epoch:  1439 | train loss: 0.039385 | valid loss: 0.037476\n","Epoch:  1440 | train loss: 0.032765 | valid loss: 0.037453\n","Epoch:  1441 | train loss: 0.045561 | valid loss: 0.037490\n","Epoch:  1442 | train loss: 0.049161 | valid loss: 0.037477\n","Epoch:  1443 | train loss: 0.043591 | valid loss: 0.037533\n","Epoch:  1444 | train loss: 0.026783 | valid loss: 0.037501\n","Epoch:  1445 | train loss: 0.030120 | valid loss: 0.037516\n","Epoch:  1446 | train loss: 0.044196 | valid loss: 0.037551\n","Epoch:  1447 | train loss: 0.044912 | valid loss: 0.037676\n","Epoch:  1448 | train loss: 0.046097 | valid loss: 0.037469\n","Epoch:  1449 | train loss: 0.035090 | valid loss: 0.037481\n","Epoch:  1450 | train loss: 0.027331 | valid loss: 0.037584\n","Epoch:  1451 | train loss: 0.055409 | valid loss: 0.037622\n","Epoch:  1452 | train loss: 0.027070 | valid loss: 0.037514\n","Epoch:  1453 | train loss: 0.029850 | valid loss: 0.037493\n","Epoch:  1454 | train loss: 0.060394 | valid loss: 0.037451\n","Epoch:  1455 | train loss: 0.065721 | valid loss: 0.037500\n","Epoch:  1456 | train loss: 0.034909 | valid loss: 0.037494\n","Epoch:  1457 | train loss: 0.028856 | valid loss: 0.037464\n","Epoch:  1458 | train loss: 0.034955 | valid loss: 0.037459\n","Epoch:  1459 | train loss: 0.056863 | valid loss: 0.037520\n","Epoch:  1460 | train loss: 0.034139 | valid loss: 0.037442\n","Epoch:  1461 | train loss: 0.048893 | valid loss: 0.037465\n","Epoch:  1462 | train loss: 0.033686 | valid loss: 0.037536\n","Epoch:  1463 | train loss: 0.036917 | valid loss: 0.037561\n","Epoch:  1464 | train loss: 0.032852 | valid loss: 0.037470\n","Epoch:  1465 | train loss: 0.042782 | valid loss: 0.037530\n","Epoch:  1466 | train loss: 0.043558 | valid loss: 0.037480\n","Epoch:  1467 | train loss: 0.052056 | valid loss: 0.037496\n","Epoch:  1468 | train loss: 0.031429 | valid loss: 0.037577\n","Epoch:  1469 | train loss: 0.034612 | valid loss: 0.037454\n","Epoch:  1470 | train loss: 0.023199 | valid loss: 0.037602\n","Epoch:  1471 | train loss: 0.042044 | valid loss: 0.037549\n","Epoch:  1472 | train loss: 0.059102 | valid loss: 0.037512\n","Epoch:  1473 | train loss: 0.042871 | valid loss: 0.037575\n","Epoch:  1474 | train loss: 0.046386 | valid loss: 0.037521\n","Epoch:  1475 | train loss: 0.062539 | valid loss: 0.037484\n","Epoch:  1476 | train loss: 0.031906 | valid loss: 0.037491\n","Epoch:  1477 | train loss: 0.030434 | valid loss: 0.037499\n","Epoch:  1478 | train loss: 0.034025 | valid loss: 0.037480\n","Epoch:  1479 | train loss: 0.044604 | valid loss: 0.037499\n","Epoch:  1480 | train loss: 0.022669 | valid loss: 0.037485\n","Epoch:  1481 | train loss: 0.046296 | valid loss: 0.037465\n","Epoch:  1482 | train loss: 0.046949 | valid loss: 0.037512\n","Epoch:  1483 | train loss: 0.052358 | valid loss: 0.037558\n","Epoch:  1484 | train loss: 0.038104 | valid loss: 0.037382\n","Epoch:  1485 | train loss: 0.048214 | valid loss: 0.037493\n","Epoch:  1486 | train loss: 0.039568 | valid loss: 0.037507\n","Epoch:  1487 | train loss: 0.050385 | valid loss: 0.037527\n","Epoch:  1488 | train loss: 0.052274 | valid loss: 0.037460\n","Epoch:  1489 | train loss: 0.050330 | valid loss: 0.037467\n","Epoch:  1490 | train loss: 0.036484 | valid loss: 0.037465\n","Epoch:  1491 | train loss: 0.038273 | valid loss: 0.037617\n","Epoch:  1492 | train loss: 0.044424 | valid loss: 0.037482\n","Epoch:  1493 | train loss: 0.032687 | valid loss: 0.037452\n","Epoch:  1494 | train loss: 0.029752 | valid loss: 0.037545\n","Epoch:  1495 | train loss: 0.055972 | valid loss: 0.037543\n","Epoch:  1496 | train loss: 0.037196 | valid loss: 0.037471\n","Epoch:  1497 | train loss: 0.054238 | valid loss: 0.037620\n","Epoch:  1498 | train loss: 0.029866 | valid loss: 0.037501\n","Epoch:  1499 | train loss: 0.034718 | valid loss: 0.037504\n","Epoch:  1500 | train loss: 0.027327 | valid loss: 0.037517\n","Epoch:  1501 | train loss: 0.047772 | valid loss: 0.037475\n","Epoch:  1502 | train loss: 0.049862 | valid loss: 0.037525\n","Epoch:  1503 | train loss: 0.060415 | valid loss: 0.037549\n","Epoch:  1504 | train loss: 0.026531 | valid loss: 0.037541\n","Epoch:  1505 | train loss: 0.028166 | valid loss: 0.037602\n","Epoch:  1506 | train loss: 0.029286 | valid loss: 0.037584\n","Epoch:  1507 | train loss: 0.060778 | valid loss: 0.037553\n","Epoch:  1508 | train loss: 0.040523 | valid loss: 0.037524\n","Epoch:  1509 | train loss: 0.025517 | valid loss: 0.037586\n","Epoch:  1510 | train loss: 0.037701 | valid loss: 0.037495\n","Epoch:  1511 | train loss: 0.029224 | valid loss: 0.037496\n","Epoch:  1512 | train loss: 0.050661 | valid loss: 0.037462\n","Epoch:  1513 | train loss: 0.034002 | valid loss: 0.037536\n","Epoch:  1514 | train loss: 0.039718 | valid loss: 0.037497\n","Epoch:  1515 | train loss: 0.046040 | valid loss: 0.037547\n","Epoch:  1516 | train loss: 0.039862 | valid loss: 0.037525\n","Epoch:  1517 | train loss: 0.023251 | valid loss: 0.037452\n","Epoch:  1518 | train loss: 0.048442 | valid loss: 0.037568\n","Epoch:  1519 | train loss: 0.026015 | valid loss: 0.037510\n","Epoch:  1520 | train loss: 0.040116 | valid loss: 0.037539\n","Epoch:  1521 | train loss: 0.024456 | valid loss: 0.037494\n","Epoch:  1522 | train loss: 0.035612 | valid loss: 0.037475\n","Epoch:  1523 | train loss: 0.039218 | valid loss: 0.037502\n","Epoch:  1524 | train loss: 0.031957 | valid loss: 0.037425\n","Epoch:  1525 | train loss: 0.042972 | valid loss: 0.037716\n","Epoch:  1526 | train loss: 0.057401 | valid loss: 0.037493\n","Epoch:  1527 | train loss: 0.037411 | valid loss: 0.037524\n","Epoch:  1528 | train loss: 0.032413 | valid loss: 0.037573\n","Epoch:  1529 | train loss: 0.043228 | valid loss: 0.037513\n","Epoch:  1530 | train loss: 0.039909 | valid loss: 0.037567\n","Epoch:  1531 | train loss: 0.022317 | valid loss: 0.037495\n","Epoch:  1532 | train loss: 0.052663 | valid loss: 0.037488\n","Epoch:  1533 | train loss: 0.026294 | valid loss: 0.037478\n","Epoch:  1534 | train loss: 0.040755 | valid loss: 0.037559\n","Epoch:  1535 | train loss: 0.033050 | valid loss: 0.037556\n","Epoch:  1536 | train loss: 0.036250 | valid loss: 0.037497\n","Epoch:  1537 | train loss: 0.050561 | valid loss: 0.037428\n","Epoch:  1538 | train loss: 0.049703 | valid loss: 0.037517\n","Epoch:  1539 | train loss: 0.031973 | valid loss: 0.037576\n","Epoch:  1540 | train loss: 0.035667 | valid loss: 0.037512\n","Epoch:  1541 | train loss: 0.052733 | valid loss: 0.037503\n","Epoch:  1542 | train loss: 0.030722 | valid loss: 0.037533\n","Epoch:  1543 | train loss: 0.027170 | valid loss: 0.037524\n","Epoch:  1544 | train loss: 0.025235 | valid loss: 0.037497\n","Epoch:  1545 | train loss: 0.061064 | valid loss: 0.037478\n","Epoch:  1546 | train loss: 0.062680 | valid loss: 0.037489\n","Epoch:  1547 | train loss: 0.033357 | valid loss: 0.037485\n","Epoch:  1548 | train loss: 0.060049 | valid loss: 0.037456\n","Epoch:  1549 | train loss: 0.048016 | valid loss: 0.037480\n","Epoch:  1550 | train loss: 0.045418 | valid loss: 0.037457\n","Epoch:  1551 | train loss: 0.030930 | valid loss: 0.037560\n","Epoch:  1552 | train loss: 0.022306 | valid loss: 0.037488\n","Epoch:  1553 | train loss: 0.025332 | valid loss: 0.037525\n","Epoch:  1554 | train loss: 0.039026 | valid loss: 0.037510\n","Epoch:  1555 | train loss: 0.030880 | valid loss: 0.037565\n","Epoch:  1556 | train loss: 0.033618 | valid loss: 0.037536\n","Epoch:  1557 | train loss: 0.036735 | valid loss: 0.037549\n","Epoch:  1558 | train loss: 0.038059 | valid loss: 0.037527\n","Epoch:  1559 | train loss: 0.042544 | valid loss: 0.037555\n","Epoch:  1560 | train loss: 0.038562 | valid loss: 0.037493\n","Epoch:  1561 | train loss: 0.046922 | valid loss: 0.037515\n","Epoch:  1562 | train loss: 0.054275 | valid loss: 0.037517\n","Epoch:  1563 | train loss: 0.035048 | valid loss: 0.037523\n","Epoch:  1564 | train loss: 0.046141 | valid loss: 0.037526\n","Epoch:  1565 | train loss: 0.046513 | valid loss: 0.037499\n","Epoch:  1566 | train loss: 0.024065 | valid loss: 0.037544\n","Epoch:  1567 | train loss: 0.033082 | valid loss: 0.037504\n","Epoch:  1568 | train loss: 0.052896 | valid loss: 0.037516\n","Epoch:  1569 | train loss: 0.038991 | valid loss: 0.037569\n","Epoch:  1570 | train loss: 0.037486 | valid loss: 0.037566\n","Epoch:  1571 | train loss: 0.029934 | valid loss: 0.037469\n","Epoch:  1572 | train loss: 0.038052 | valid loss: 0.037466\n","Epoch:  1573 | train loss: 0.050541 | valid loss: 0.037571\n","Epoch:  1574 | train loss: 0.038013 | valid loss: 0.037573\n","Epoch:  1575 | train loss: 0.039013 | valid loss: 0.037631\n","Epoch:  1576 | train loss: 0.033155 | valid loss: 0.037606\n","Epoch:  1577 | train loss: 0.028876 | valid loss: 0.037517\n","Epoch:  1578 | train loss: 0.036850 | valid loss: 0.037517\n","Epoch:  1579 | train loss: 0.044365 | valid loss: 0.037605\n","Epoch:  1580 | train loss: 0.044139 | valid loss: 0.037507\n","Epoch:  1581 | train loss: 0.050939 | valid loss: 0.037528\n","Epoch:  1582 | train loss: 0.036235 | valid loss: 0.037528\n","Epoch:  1583 | train loss: 0.033901 | valid loss: 0.037518\n","Epoch:  1584 | train loss: 0.039123 | valid loss: 0.037476\n","Epoch:  1585 | train loss: 0.026424 | valid loss: 0.037596\n","Epoch:  1586 | train loss: 0.035540 | valid loss: 0.037467\n","Epoch:  1587 | train loss: 0.034133 | valid loss: 0.037568\n","Epoch:  1588 | train loss: 0.034621 | valid loss: 0.037540\n","Epoch:  1589 | train loss: 0.023156 | valid loss: 0.037594\n","Epoch:  1590 | train loss: 0.033891 | valid loss: 0.037559\n","Epoch:  1591 | train loss: 0.025580 | valid loss: 0.037551\n","Epoch:  1592 | train loss: 0.034594 | valid loss: 0.037471\n","Epoch:  1593 | train loss: 0.023646 | valid loss: 0.037545\n","Epoch:  1594 | train loss: 0.028487 | valid loss: 0.037528\n","Epoch:  1595 | train loss: 0.044558 | valid loss: 0.037516\n","Epoch:  1596 | train loss: 0.027098 | valid loss: 0.037506\n","Epoch:  1597 | train loss: 0.035958 | valid loss: 0.037539\n","Epoch:  1598 | train loss: 0.022027 | valid loss: 0.037506\n","Epoch:  1599 | train loss: 0.046148 | valid loss: 0.037596\n","Epoch:  1600 | train loss: 0.028994 | valid loss: 0.037513\n","Epoch:  1601 | train loss: 0.050021 | valid loss: 0.037600\n","Epoch:  1602 | train loss: 0.036811 | valid loss: 0.037494\n","Epoch:  1603 | train loss: 0.047234 | valid loss: 0.037538\n","Epoch:  1604 | train loss: 0.045981 | valid loss: 0.037496\n","Epoch:  1605 | train loss: 0.049056 | valid loss: 0.037619\n","Epoch:  1606 | train loss: 0.068850 | valid loss: 0.037543\n","Epoch:  1607 | train loss: 0.029054 | valid loss: 0.037586\n","Epoch:  1608 | train loss: 0.039698 | valid loss: 0.037541\n","Epoch:  1609 | train loss: 0.033693 | valid loss: 0.037503\n","Epoch:  1610 | train loss: 0.028496 | valid loss: 0.037591\n","Epoch:  1611 | train loss: 0.043955 | valid loss: 0.037578\n","Epoch:  1612 | train loss: 0.038005 | valid loss: 0.037533\n","Epoch:  1613 | train loss: 0.037793 | valid loss: 0.037574\n","Epoch:  1614 | train loss: 0.031928 | valid loss: 0.037550\n","Epoch:  1615 | train loss: 0.026698 | valid loss: 0.037551\n","Epoch:  1616 | train loss: 0.030698 | valid loss: 0.037515\n","Epoch:  1617 | train loss: 0.026078 | valid loss: 0.037594\n","Epoch:  1618 | train loss: 0.033702 | valid loss: 0.037532\n","Epoch:  1619 | train loss: 0.041987 | valid loss: 0.037555\n","Epoch:  1620 | train loss: 0.054509 | valid loss: 0.037521\n","Epoch:  1621 | train loss: 0.026276 | valid loss: 0.037559\n","Epoch:  1622 | train loss: 0.038386 | valid loss: 0.037470\n","Epoch:  1623 | train loss: 0.027173 | valid loss: 0.037475\n","Epoch:  1624 | train loss: 0.033899 | valid loss: 0.037496\n","Epoch:  1625 | train loss: 0.043917 | valid loss: 0.037590\n","Epoch:  1626 | train loss: 0.029702 | valid loss: 0.037509\n","Epoch:  1627 | train loss: 0.042365 | valid loss: 0.037473\n","Epoch:  1628 | train loss: 0.023402 | valid loss: 0.037545\n","Epoch:  1629 | train loss: 0.046204 | valid loss: 0.037562\n","Epoch:  1630 | train loss: 0.029235 | valid loss: 0.037481\n","Epoch:  1631 | train loss: 0.049640 | valid loss: 0.037603\n","Epoch:  1632 | train loss: 0.046285 | valid loss: 0.037631\n","Epoch:  1633 | train loss: 0.047645 | valid loss: 0.037514\n","Epoch:  1634 | train loss: 0.037098 | valid loss: 0.037622\n","Epoch:  1635 | train loss: 0.027385 | valid loss: 0.037550\n","Epoch:  1636 | train loss: 0.047524 | valid loss: 0.037577\n","Epoch:  1637 | train loss: 0.023441 | valid loss: 0.037537\n","Epoch:  1638 | train loss: 0.032276 | valid loss: 0.037505\n","Epoch:  1639 | train loss: 0.044349 | valid loss: 0.037619\n","Epoch:  1640 | train loss: 0.049646 | valid loss: 0.037544\n","Epoch:  1641 | train loss: 0.026388 | valid loss: 0.037616\n","Epoch:  1642 | train loss: 0.034770 | valid loss: 0.037622\n","Epoch:  1643 | train loss: 0.025679 | valid loss: 0.037586\n","Epoch:  1644 | train loss: 0.038209 | valid loss: 0.037542\n","Epoch:  1645 | train loss: 0.072364 | valid loss: 0.037523\n","Epoch:  1646 | train loss: 0.045399 | valid loss: 0.037534\n","Epoch:  1647 | train loss: 0.031018 | valid loss: 0.037494\n","Epoch:  1648 | train loss: 0.046777 | valid loss: 0.037534\n","Epoch:  1649 | train loss: 0.040721 | valid loss: 0.037533\n","Epoch:  1650 | train loss: 0.051568 | valid loss: 0.037551\n","Epoch:  1651 | train loss: 0.036960 | valid loss: 0.037553\n","Epoch:  1652 | train loss: 0.055422 | valid loss: 0.037577\n","Epoch:  1653 | train loss: 0.033965 | valid loss: 0.037533\n","Epoch:  1654 | train loss: 0.047826 | valid loss: 0.037516\n","Epoch:  1655 | train loss: 0.041077 | valid loss: 0.037570\n","Epoch:  1656 | train loss: 0.030560 | valid loss: 0.037539\n","Epoch:  1657 | train loss: 0.028459 | valid loss: 0.037556\n","Epoch:  1658 | train loss: 0.033160 | valid loss: 0.037512\n","Epoch:  1659 | train loss: 0.038296 | valid loss: 0.037529\n","Epoch:  1660 | train loss: 0.064221 | valid loss: 0.037526\n","Epoch:  1661 | train loss: 0.047774 | valid loss: 0.037565\n","Epoch:  1662 | train loss: 0.045087 | valid loss: 0.037603\n","Epoch:  1663 | train loss: 0.060090 | valid loss: 0.037548\n","Epoch:  1664 | train loss: 0.033246 | valid loss: 0.037599\n","Epoch:  1665 | train loss: 0.032968 | valid loss: 0.037657\n","Epoch:  1666 | train loss: 0.024420 | valid loss: 0.037559\n","Epoch:  1667 | train loss: 0.058031 | valid loss: 0.037573\n","Epoch:  1668 | train loss: 0.040559 | valid loss: 0.037647\n","Epoch:  1669 | train loss: 0.058753 | valid loss: 0.037700\n","Epoch:  1670 | train loss: 0.022010 | valid loss: 0.037563\n","Epoch:  1671 | train loss: 0.025990 | valid loss: 0.037472\n","Epoch:  1672 | train loss: 0.027923 | valid loss: 0.037625\n","Epoch:  1673 | train loss: 0.038531 | valid loss: 0.037559\n","Epoch:  1674 | train loss: 0.041506 | valid loss: 0.037577\n","Epoch:  1675 | train loss: 0.043891 | valid loss: 0.037549\n","Epoch:  1676 | train loss: 0.031744 | valid loss: 0.037643\n","Epoch:  1677 | train loss: 0.034189 | valid loss: 0.037549\n","Epoch:  1678 | train loss: 0.036981 | valid loss: 0.037526\n","Epoch:  1679 | train loss: 0.054407 | valid loss: 0.037610\n","Epoch:  1680 | train loss: 0.037380 | valid loss: 0.037507\n","Epoch:  1681 | train loss: 0.034213 | valid loss: 0.037546\n","Epoch:  1682 | train loss: 0.047622 | valid loss: 0.037617\n","Epoch:  1683 | train loss: 0.025055 | valid loss: 0.037552\n","Epoch:  1684 | train loss: 0.033555 | valid loss: 0.037592\n","Epoch:  1685 | train loss: 0.035660 | valid loss: 0.037564\n","Epoch:  1686 | train loss: 0.054621 | valid loss: 0.037500\n","Epoch:  1687 | train loss: 0.038390 | valid loss: 0.037625\n","Epoch:  1688 | train loss: 0.049005 | valid loss: 0.037676\n","Epoch:  1689 | train loss: 0.037698 | valid loss: 0.037525\n","Epoch:  1690 | train loss: 0.032055 | valid loss: 0.037648\n","Epoch:  1691 | train loss: 0.030128 | valid loss: 0.037528\n","Epoch:  1692 | train loss: 0.033585 | valid loss: 0.037568\n","Epoch:  1693 | train loss: 0.038909 | valid loss: 0.037538\n","Epoch:  1694 | train loss: 0.028465 | valid loss: 0.037514\n","Epoch:  1695 | train loss: 0.041135 | valid loss: 0.037618\n","Epoch:  1696 | train loss: 0.063603 | valid loss: 0.037557\n","Epoch:  1697 | train loss: 0.036581 | valid loss: 0.037588\n","Epoch:  1698 | train loss: 0.028374 | valid loss: 0.037587\n","Epoch:  1699 | train loss: 0.032200 | valid loss: 0.037516\n","Epoch:  1700 | train loss: 0.048441 | valid loss: 0.037640\n","Epoch:  1701 | train loss: 0.045337 | valid loss: 0.037624\n","Epoch:  1702 | train loss: 0.048878 | valid loss: 0.037691\n","Epoch:  1703 | train loss: 0.049203 | valid loss: 0.037569\n","Epoch:  1704 | train loss: 0.043371 | valid loss: 0.037478\n","Epoch:  1705 | train loss: 0.030246 | valid loss: 0.037569\n","Epoch:  1706 | train loss: 0.040028 | valid loss: 0.037561\n","Epoch:  1707 | train loss: 0.043958 | valid loss: 0.037601\n","Epoch:  1708 | train loss: 0.046457 | valid loss: 0.037540\n","Epoch:  1709 | train loss: 0.048222 | valid loss: 0.037558\n","Epoch:  1710 | train loss: 0.038506 | valid loss: 0.037563\n","Epoch:  1711 | train loss: 0.039156 | valid loss: 0.037546\n","Epoch:  1712 | train loss: 0.047753 | valid loss: 0.037608\n","Epoch:  1713 | train loss: 0.039931 | valid loss: 0.037544\n","Epoch:  1714 | train loss: 0.031568 | valid loss: 0.037542\n","Epoch:  1715 | train loss: 0.024139 | valid loss: 0.037525\n","Epoch:  1716 | train loss: 0.056045 | valid loss: 0.037656\n","Epoch:  1717 | train loss: 0.046559 | valid loss: 0.037679\n","Epoch:  1718 | train loss: 0.049676 | valid loss: 0.037641\n","Epoch:  1719 | train loss: 0.038555 | valid loss: 0.037573\n","Epoch:  1720 | train loss: 0.039972 | valid loss: 0.037569\n","Epoch:  1721 | train loss: 0.030524 | valid loss: 0.037631\n","Epoch:  1722 | train loss: 0.033304 | valid loss: 0.037545\n","Epoch:  1723 | train loss: 0.024981 | valid loss: 0.037524\n","Epoch:  1724 | train loss: 0.051490 | valid loss: 0.037547\n","Epoch:  1725 | train loss: 0.025870 | valid loss: 0.037599\n","Epoch:  1726 | train loss: 0.043773 | valid loss: 0.037553\n","Epoch:  1727 | train loss: 0.036846 | valid loss: 0.037516\n","Epoch:  1728 | train loss: 0.037600 | valid loss: 0.037538\n","Epoch:  1729 | train loss: 0.033709 | valid loss: 0.037629\n","Epoch:  1730 | train loss: 0.039206 | valid loss: 0.037573\n","Epoch:  1731 | train loss: 0.029491 | valid loss: 0.037588\n","Epoch:  1732 | train loss: 0.052044 | valid loss: 0.037586\n","Epoch:  1733 | train loss: 0.029915 | valid loss: 0.037559\n","Epoch:  1734 | train loss: 0.042604 | valid loss: 0.037554\n","Epoch:  1735 | train loss: 0.031695 | valid loss: 0.037567\n","Epoch:  1736 | train loss: 0.027576 | valid loss: 0.037565\n","Epoch:  1737 | train loss: 0.050662 | valid loss: 0.037602\n","Epoch:  1738 | train loss: 0.037195 | valid loss: 0.037566\n","Epoch:  1739 | train loss: 0.063745 | valid loss: 0.037542\n","Epoch:  1740 | train loss: 0.039012 | valid loss: 0.037598\n","Epoch:  1741 | train loss: 0.069774 | valid loss: 0.037551\n","Epoch:  1742 | train loss: 0.043234 | valid loss: 0.037604\n","Epoch:  1743 | train loss: 0.029449 | valid loss: 0.037678\n","Epoch:  1744 | train loss: 0.028429 | valid loss: 0.037574\n","Epoch:  1745 | train loss: 0.037479 | valid loss: 0.037599\n","Epoch:  1746 | train loss: 0.042818 | valid loss: 0.037535\n","Epoch:  1747 | train loss: 0.047151 | valid loss: 0.037541\n","Epoch:  1748 | train loss: 0.044893 | valid loss: 0.037604\n","Epoch:  1749 | train loss: 0.042376 | valid loss: 0.037674\n","Epoch:  1750 | train loss: 0.043239 | valid loss: 0.037620\n","Epoch:  1751 | train loss: 0.025971 | valid loss: 0.037616\n","Epoch:  1752 | train loss: 0.034049 | valid loss: 0.037583\n","Epoch:  1753 | train loss: 0.024814 | valid loss: 0.037552\n","Epoch:  1754 | train loss: 0.048131 | valid loss: 0.037637\n","Epoch:  1755 | train loss: 0.031686 | valid loss: 0.037600\n","Epoch:  1756 | train loss: 0.044660 | valid loss: 0.037592\n","Epoch:  1757 | train loss: 0.029672 | valid loss: 0.037587\n","Epoch:  1758 | train loss: 0.040520 | valid loss: 0.037582\n","Epoch:  1759 | train loss: 0.035109 | valid loss: 0.037567\n","Epoch:  1760 | train loss: 0.050730 | valid loss: 0.037591\n","Epoch:  1761 | train loss: 0.032173 | valid loss: 0.037555\n","Epoch:  1762 | train loss: 0.037013 | valid loss: 0.037683\n","Epoch:  1763 | train loss: 0.024899 | valid loss: 0.037542\n","Epoch:  1764 | train loss: 0.044409 | valid loss: 0.037583\n","Epoch:  1765 | train loss: 0.030070 | valid loss: 0.037645\n","Epoch:  1766 | train loss: 0.029205 | valid loss: 0.037666\n","Epoch:  1767 | train loss: 0.027049 | valid loss: 0.037600\n","Epoch:  1768 | train loss: 0.044602 | valid loss: 0.037577\n","Epoch:  1769 | train loss: 0.029177 | valid loss: 0.037558\n","Epoch:  1770 | train loss: 0.050943 | valid loss: 0.037551\n","Epoch:  1771 | train loss: 0.044759 | valid loss: 0.037673\n","Epoch:  1772 | train loss: 0.024600 | valid loss: 0.037630\n","Epoch:  1773 | train loss: 0.025473 | valid loss: 0.037587\n","Epoch:  1774 | train loss: 0.030230 | valid loss: 0.037610\n","Epoch:  1775 | train loss: 0.044421 | valid loss: 0.037615\n","Epoch:  1776 | train loss: 0.046280 | valid loss: 0.037611\n","Epoch:  1777 | train loss: 0.031187 | valid loss: 0.037594\n","Epoch:  1778 | train loss: 0.053430 | valid loss: 0.037606\n","Epoch:  1779 | train loss: 0.033331 | valid loss: 0.037586\n","Epoch:  1780 | train loss: 0.025198 | valid loss: 0.037628\n","Epoch:  1781 | train loss: 0.056730 | valid loss: 0.037643\n","Epoch:  1782 | train loss: 0.027127 | valid loss: 0.037556\n","Epoch:  1783 | train loss: 0.046447 | valid loss: 0.037588\n","Epoch:  1784 | train loss: 0.036044 | valid loss: 0.037586\n","Epoch:  1785 | train loss: 0.024058 | valid loss: 0.037506\n","Epoch:  1786 | train loss: 0.050881 | valid loss: 0.037629\n","Epoch:  1787 | train loss: 0.036109 | valid loss: 0.037634\n","Epoch:  1788 | train loss: 0.031089 | valid loss: 0.037599\n","Epoch:  1789 | train loss: 0.038029 | valid loss: 0.037574\n","Epoch:  1790 | train loss: 0.057047 | valid loss: 0.037645\n","Epoch:  1791 | train loss: 0.022326 | valid loss: 0.037631\n","Epoch:  1792 | train loss: 0.038643 | valid loss: 0.037631\n","Epoch:  1793 | train loss: 0.038271 | valid loss: 0.037534\n","Epoch:  1794 | train loss: 0.041918 | valid loss: 0.037618\n","Epoch:  1795 | train loss: 0.036245 | valid loss: 0.037667\n","Epoch:  1796 | train loss: 0.037723 | valid loss: 0.037631\n","Epoch:  1797 | train loss: 0.046846 | valid loss: 0.037609\n","Epoch:  1798 | train loss: 0.045759 | valid loss: 0.037604\n","Epoch:  1799 | train loss: 0.045687 | valid loss: 0.037606\n","Epoch:  1800 | train loss: 0.035134 | valid loss: 0.037573\n","Epoch:  1801 | train loss: 0.024926 | valid loss: 0.037605\n","Epoch:  1802 | train loss: 0.034178 | valid loss: 0.037536\n","Epoch:  1803 | train loss: 0.034089 | valid loss: 0.037616\n","Epoch:  1804 | train loss: 0.046353 | valid loss: 0.037562\n","Epoch:  1805 | train loss: 0.037733 | valid loss: 0.037581\n","Epoch:  1806 | train loss: 0.024023 | valid loss: 0.037582\n","Epoch:  1807 | train loss: 0.032418 | valid loss: 0.037540\n","Epoch:  1808 | train loss: 0.023458 | valid loss: 0.037694\n","Epoch:  1809 | train loss: 0.048181 | valid loss: 0.037644\n","Epoch:  1810 | train loss: 0.031360 | valid loss: 0.037622\n","Epoch:  1811 | train loss: 0.038904 | valid loss: 0.037598\n","Epoch:  1812 | train loss: 0.035322 | valid loss: 0.037642\n","Epoch:  1813 | train loss: 0.020698 | valid loss: 0.037634\n","Epoch:  1814 | train loss: 0.043136 | valid loss: 0.037648\n","Epoch:  1815 | train loss: 0.041866 | valid loss: 0.037593\n","Epoch:  1816 | train loss: 0.029914 | valid loss: 0.037623\n","Epoch:  1817 | train loss: 0.049202 | valid loss: 0.037646\n","Epoch:  1818 | train loss: 0.028008 | valid loss: 0.037683\n","Epoch:  1819 | train loss: 0.034238 | valid loss: 0.037608\n","Epoch:  1820 | train loss: 0.052098 | valid loss: 0.037620\n","Epoch:  1821 | train loss: 0.029419 | valid loss: 0.037583\n","Epoch:  1822 | train loss: 0.029642 | valid loss: 0.037602\n","Epoch:  1823 | train loss: 0.037900 | valid loss: 0.037647\n","Epoch:  1824 | train loss: 0.036418 | valid loss: 0.037589\n","Epoch:  1825 | train loss: 0.032702 | valid loss: 0.037563\n","Epoch:  1826 | train loss: 0.043253 | valid loss: 0.037651\n","Epoch:  1827 | train loss: 0.027177 | valid loss: 0.037590\n","Epoch:  1828 | train loss: 0.022111 | valid loss: 0.037621\n","Epoch:  1829 | train loss: 0.031183 | valid loss: 0.037603\n","Epoch:  1830 | train loss: 0.031448 | valid loss: 0.037538\n","Epoch:  1831 | train loss: 0.036282 | valid loss: 0.037615\n","Epoch:  1832 | train loss: 0.055133 | valid loss: 0.037671\n","Epoch:  1833 | train loss: 0.026582 | valid loss: 0.037627\n","Epoch:  1834 | train loss: 0.033241 | valid loss: 0.037651\n","Epoch:  1835 | train loss: 0.038835 | valid loss: 0.037652\n","Epoch:  1836 | train loss: 0.043090 | valid loss: 0.037623\n","Epoch:  1837 | train loss: 0.046432 | valid loss: 0.037601\n","Epoch:  1838 | train loss: 0.048684 | valid loss: 0.037530\n","Epoch:  1839 | train loss: 0.023542 | valid loss: 0.037615\n","Epoch:  1840 | train loss: 0.044178 | valid loss: 0.037559\n","Epoch:  1841 | train loss: 0.029164 | valid loss: 0.037559\n","Epoch:  1842 | train loss: 0.033187 | valid loss: 0.037663\n","Epoch:  1843 | train loss: 0.033425 | valid loss: 0.037685\n","Epoch:  1844 | train loss: 0.042373 | valid loss: 0.037619\n","Epoch:  1845 | train loss: 0.045121 | valid loss: 0.037599\n","Epoch:  1846 | train loss: 0.041265 | valid loss: 0.037630\n","Epoch:  1847 | train loss: 0.032359 | valid loss: 0.037590\n","Epoch:  1848 | train loss: 0.036705 | valid loss: 0.037566\n","Epoch:  1849 | train loss: 0.042292 | valid loss: 0.037603\n","Epoch:  1850 | train loss: 0.027941 | valid loss: 0.037598\n","Epoch:  1851 | train loss: 0.044131 | valid loss: 0.037596\n","Epoch:  1852 | train loss: 0.029920 | valid loss: 0.037726\n","Epoch:  1853 | train loss: 0.036079 | valid loss: 0.037585\n","Epoch:  1854 | train loss: 0.021094 | valid loss: 0.037608\n","Epoch:  1855 | train loss: 0.038953 | valid loss: 0.037594\n","Epoch:  1856 | train loss: 0.060793 | valid loss: 0.037617\n","Epoch:  1857 | train loss: 0.032234 | valid loss: 0.037573\n","Epoch:  1858 | train loss: 0.025400 | valid loss: 0.037638\n","Epoch:  1859 | train loss: 0.024373 | valid loss: 0.037592\n","Epoch:  1860 | train loss: 0.039436 | valid loss: 0.037609\n","Epoch:  1861 | train loss: 0.044608 | valid loss: 0.037628\n","Epoch:  1862 | train loss: 0.075238 | valid loss: 0.037616\n","Epoch:  1863 | train loss: 0.043542 | valid loss: 0.037596\n","Epoch:  1864 | train loss: 0.022188 | valid loss: 0.037674\n","Epoch:  1865 | train loss: 0.030997 | valid loss: 0.037647\n","Epoch:  1866 | train loss: 0.037812 | valid loss: 0.037584\n","Epoch:  1867 | train loss: 0.038737 | valid loss: 0.037585\n","Epoch:  1868 | train loss: 0.057591 | valid loss: 0.037678\n","Epoch:  1869 | train loss: 0.037874 | valid loss: 0.037694\n","Epoch:  1870 | train loss: 0.052010 | valid loss: 0.037600\n","Epoch:  1871 | train loss: 0.045179 | valid loss: 0.037690\n","Epoch:  1872 | train loss: 0.034501 | valid loss: 0.037670\n","Epoch:  1873 | train loss: 0.025836 | valid loss: 0.037573\n","Epoch:  1874 | train loss: 0.035304 | valid loss: 0.037618\n","Epoch:  1875 | train loss: 0.038103 | valid loss: 0.037616\n","Epoch:  1876 | train loss: 0.036022 | valid loss: 0.037609\n","Epoch:  1877 | train loss: 0.028034 | valid loss: 0.037673\n","Epoch:  1878 | train loss: 0.034277 | valid loss: 0.037621\n","Epoch:  1879 | train loss: 0.037151 | valid loss: 0.037622\n","Epoch:  1880 | train loss: 0.043529 | valid loss: 0.037618\n","Epoch:  1881 | train loss: 0.041890 | valid loss: 0.037696\n","Epoch:  1882 | train loss: 0.047964 | valid loss: 0.037566\n","Epoch:  1883 | train loss: 0.057851 | valid loss: 0.037644\n","Epoch:  1884 | train loss: 0.044356 | valid loss: 0.037561\n","Epoch:  1885 | train loss: 0.039241 | valid loss: 0.037627\n","Epoch:  1886 | train loss: 0.030664 | valid loss: 0.037603\n","Epoch:  1887 | train loss: 0.029344 | valid loss: 0.037608\n","Epoch:  1888 | train loss: 0.029405 | valid loss: 0.037688\n","Epoch:  1889 | train loss: 0.030450 | valid loss: 0.037574\n","Epoch:  1890 | train loss: 0.061177 | valid loss: 0.037727\n","Epoch:  1891 | train loss: 0.032433 | valid loss: 0.037616\n","Epoch:  1892 | train loss: 0.029078 | valid loss: 0.037615\n","Epoch:  1893 | train loss: 0.024712 | valid loss: 0.037732\n","Epoch:  1894 | train loss: 0.022567 | valid loss: 0.037660\n","Epoch:  1895 | train loss: 0.048185 | valid loss: 0.037596\n","Epoch:  1896 | train loss: 0.034828 | valid loss: 0.037631\n","Epoch:  1897 | train loss: 0.036742 | valid loss: 0.037753\n","Epoch:  1898 | train loss: 0.047495 | valid loss: 0.037680\n","Epoch:  1899 | train loss: 0.047596 | valid loss: 0.037696\n","Epoch:  1900 | train loss: 0.035532 | valid loss: 0.037677\n","Epoch:  1901 | train loss: 0.040344 | valid loss: 0.037713\n","Epoch:  1902 | train loss: 0.027106 | valid loss: 0.037693\n","Epoch:  1903 | train loss: 0.033668 | valid loss: 0.037634\n","Epoch:  1904 | train loss: 0.036243 | valid loss: 0.037613\n","Epoch:  1905 | train loss: 0.025320 | valid loss: 0.037679\n","Epoch:  1906 | train loss: 0.035358 | valid loss: 0.037606\n","Epoch:  1907 | train loss: 0.022630 | valid loss: 0.037667\n","Epoch:  1908 | train loss: 0.041265 | valid loss: 0.037596\n","Epoch:  1909 | train loss: 0.039324 | valid loss: 0.037620\n","Epoch:  1910 | train loss: 0.045718 | valid loss: 0.037708\n","Epoch:  1911 | train loss: 0.038907 | valid loss: 0.037661\n","Epoch:  1912 | train loss: 0.050565 | valid loss: 0.037644\n","Epoch:  1913 | train loss: 0.046239 | valid loss: 0.037617\n","Epoch:  1914 | train loss: 0.046795 | valid loss: 0.037636\n","Epoch:  1915 | train loss: 0.033874 | valid loss: 0.037603\n","Epoch:  1916 | train loss: 0.030606 | valid loss: 0.037596\n","Epoch:  1917 | train loss: 0.021223 | valid loss: 0.037617\n","Epoch:  1918 | train loss: 0.030961 | valid loss: 0.037755\n","Epoch:  1919 | train loss: 0.030648 | valid loss: 0.037679\n","Epoch:  1920 | train loss: 0.026308 | valid loss: 0.037605\n","Epoch:  1921 | train loss: 0.047851 | valid loss: 0.037624\n","Epoch:  1922 | train loss: 0.044377 | valid loss: 0.037737\n","Epoch:  1923 | train loss: 0.039060 | valid loss: 0.037723\n","Epoch:  1924 | train loss: 0.025213 | valid loss: 0.037603\n","Epoch:  1925 | train loss: 0.065480 | valid loss: 0.037586\n","Epoch:  1926 | train loss: 0.047634 | valid loss: 0.037618\n","Epoch:  1927 | train loss: 0.023615 | valid loss: 0.037584\n","Epoch:  1928 | train loss: 0.029256 | valid loss: 0.037563\n","Epoch:  1929 | train loss: 0.032980 | valid loss: 0.037648\n","Epoch:  1930 | train loss: 0.058813 | valid loss: 0.037616\n","Epoch:  1931 | train loss: 0.049414 | valid loss: 0.037652\n","Epoch:  1932 | train loss: 0.036301 | valid loss: 0.037660\n","Epoch:  1933 | train loss: 0.033052 | valid loss: 0.037709\n","Epoch:  1934 | train loss: 0.050374 | valid loss: 0.037628\n","Epoch:  1935 | train loss: 0.049620 | valid loss: 0.037695\n","Epoch:  1936 | train loss: 0.035869 | valid loss: 0.037626\n","Epoch:  1937 | train loss: 0.047403 | valid loss: 0.037706\n","Epoch:  1938 | train loss: 0.027431 | valid loss: 0.037727\n","Epoch:  1939 | train loss: 0.026928 | valid loss: 0.037666\n","Epoch:  1940 | train loss: 0.039388 | valid loss: 0.037695\n","Epoch:  1941 | train loss: 0.030883 | valid loss: 0.037572\n","Epoch:  1942 | train loss: 0.033248 | valid loss: 0.037656\n","Epoch:  1943 | train loss: 0.045792 | valid loss: 0.037694\n","Epoch:  1944 | train loss: 0.029617 | valid loss: 0.037662\n","Epoch:  1945 | train loss: 0.029606 | valid loss: 0.037662\n","Epoch:  1946 | train loss: 0.023530 | valid loss: 0.037676\n","Epoch:  1947 | train loss: 0.043608 | valid loss: 0.037622\n","Epoch:  1948 | train loss: 0.054832 | valid loss: 0.037642\n","Epoch:  1949 | train loss: 0.038158 | valid loss: 0.037620\n","Epoch:  1950 | train loss: 0.034904 | valid loss: 0.037663\n","Epoch:  1951 | train loss: 0.031422 | valid loss: 0.037622\n","Epoch:  1952 | train loss: 0.041745 | valid loss: 0.037572\n","Epoch:  1953 | train loss: 0.043781 | valid loss: 0.037630\n","Epoch:  1954 | train loss: 0.047392 | valid loss: 0.037705\n","Epoch:  1955 | train loss: 0.052374 | valid loss: 0.037722\n","Epoch:  1956 | train loss: 0.030841 | valid loss: 0.037653\n","Epoch:  1957 | train loss: 0.046626 | valid loss: 0.037647\n","Epoch:  1958 | train loss: 0.027640 | valid loss: 0.037627\n","Epoch:  1959 | train loss: 0.043854 | valid loss: 0.037568\n","Epoch:  1960 | train loss: 0.024876 | valid loss: 0.037670\n","Epoch:  1961 | train loss: 0.034229 | valid loss: 0.037639\n","Epoch:  1962 | train loss: 0.039033 | valid loss: 0.037636\n","Epoch:  1963 | train loss: 0.037313 | valid loss: 0.037619\n","Epoch:  1964 | train loss: 0.038468 | valid loss: 0.037614\n","Epoch:  1965 | train loss: 0.035103 | valid loss: 0.037632\n","Epoch:  1966 | train loss: 0.031596 | valid loss: 0.037691\n","Epoch:  1967 | train loss: 0.033729 | valid loss: 0.037649\n","Epoch:  1968 | train loss: 0.052931 | valid loss: 0.037612\n","Epoch:  1969 | train loss: 0.040438 | valid loss: 0.037623\n","Epoch:  1970 | train loss: 0.045233 | valid loss: 0.037610\n","Epoch:  1971 | train loss: 0.038584 | valid loss: 0.037588\n","Epoch:  1972 | train loss: 0.032584 | valid loss: 0.037563\n","Epoch:  1973 | train loss: 0.031494 | valid loss: 0.037625\n","Epoch:  1974 | train loss: 0.034394 | valid loss: 0.037731\n","Epoch:  1975 | train loss: 0.047462 | valid loss: 0.037653\n","Epoch:  1976 | train loss: 0.047599 | valid loss: 0.037671\n","Epoch:  1977 | train loss: 0.028270 | valid loss: 0.037644\n","Epoch:  1978 | train loss: 0.043495 | valid loss: 0.037687\n","Epoch:  1979 | train loss: 0.055453 | valid loss: 0.037697\n","Epoch:  1980 | train loss: 0.029991 | valid loss: 0.037697\n","Epoch:  1981 | train loss: 0.029338 | valid loss: 0.037693\n","Epoch:  1982 | train loss: 0.033394 | valid loss: 0.037647\n","Epoch:  1983 | train loss: 0.051120 | valid loss: 0.037701\n","Epoch:  1984 | train loss: 0.034728 | valid loss: 0.037652\n","Epoch:  1985 | train loss: 0.066194 | valid loss: 0.037640\n","Epoch:  1986 | train loss: 0.039562 | valid loss: 0.037678\n","Epoch:  1987 | train loss: 0.033001 | valid loss: 0.037679\n","Epoch:  1988 | train loss: 0.059719 | valid loss: 0.037687\n","Epoch:  1989 | train loss: 0.054743 | valid loss: 0.037603\n","Epoch:  1990 | train loss: 0.053293 | valid loss: 0.037630\n","Epoch:  1991 | train loss: 0.045844 | valid loss: 0.037619\n","Epoch:  1992 | train loss: 0.054847 | valid loss: 0.037657\n","Epoch:  1993 | train loss: 0.022780 | valid loss: 0.037664\n","Epoch:  1994 | train loss: 0.040264 | valid loss: 0.037714\n","Epoch:  1995 | train loss: 0.037214 | valid loss: 0.037600\n","Epoch:  1996 | train loss: 0.023581 | valid loss: 0.037681\n","Epoch:  1997 | train loss: 0.046705 | valid loss: 0.037693\n","Epoch:  1998 | train loss: 0.028286 | valid loss: 0.037628\n","Epoch:  1999 | train loss: 0.035446 | valid loss: 0.037616\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtGatxx4dX-N","executionInfo":{"status":"ok","timestamp":1629652113780,"user_tz":-60,"elapsed":29,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"cd0f57a5-eb37-4ac6-a085-ab1f7b082f1b"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Train time: 328.1714162826538\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"lTRydB8607Rb","executionInfo":{"status":"ok","timestamp":1629652114828,"user_tz":-60,"elapsed":1058,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"6069da0b-66c9-49e5-f791-ab086d6a8105"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":25},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAyTKOBLM8kW","executionInfo":{"status":"ok","timestamp":1629652123811,"user_tz":-60,"elapsed":8992,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"b7010f1e-e67d-4655-e519-82fc460d80c0"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":26,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 0.0015069425405558837\n","MSE_err of valid data 0.0014646045553159508\n","MSE_err of test data 0.001421297401950374\n","MSE_err of total data 0.0014941442287083602\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t7tRIGIuv1_t"},"source":["#### 16 variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXxkLoDFAK_k","executionInfo":{"status":"ok","timestamp":1629653357065,"user_tz":-60,"elapsed":14,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"755200aa-22ae-4cfb-f4cf-cbd8d71ba88d"},"source":["print(\"compress to 16\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 2000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["compress to 16\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9mrlRVrAdsK","executionInfo":{"status":"ok","timestamp":1629653595086,"user_tz":-60,"elapsed":238029,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"7ad92bb2-b4cd-437a-9b78-499848ec9f59"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(16).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 1.740698 | valid loss: 1.716596\n","Epoch:  1 | train loss: 1.312787 | valid loss: 1.321009\n","Epoch:  2 | train loss: 0.796693 | valid loss: 0.825048\n","Epoch:  3 | train loss: 0.413768 | valid loss: 0.400695\n","Epoch:  4 | train loss: 0.206235 | valid loss: 0.188371\n","Epoch:  5 | train loss: 0.121416 | valid loss: 0.123315\n","Epoch:  6 | train loss: 0.108093 | valid loss: 0.104557\n","Epoch:  7 | train loss: 0.103340 | valid loss: 0.093579\n","Epoch:  8 | train loss: 0.081997 | valid loss: 0.088213\n","Epoch:  9 | train loss: 0.067801 | valid loss: 0.083573\n","Epoch:  10 | train loss: 0.072757 | valid loss: 0.079294\n","Epoch:  11 | train loss: 0.074437 | valid loss: 0.075497\n","Epoch:  12 | train loss: 0.086570 | valid loss: 0.072722\n","Epoch:  13 | train loss: 0.073724 | valid loss: 0.069309\n","Epoch:  14 | train loss: 0.088571 | valid loss: 0.066658\n","Epoch:  15 | train loss: 0.061518 | valid loss: 0.063774\n","Epoch:  16 | train loss: 0.064113 | valid loss: 0.062542\n","Epoch:  17 | train loss: 0.074775 | valid loss: 0.060293\n","Epoch:  18 | train loss: 0.082134 | valid loss: 0.058725\n","Epoch:  19 | train loss: 0.071110 | valid loss: 0.057224\n","Epoch:  20 | train loss: 0.050312 | valid loss: 0.055425\n","Epoch:  21 | train loss: 0.067576 | valid loss: 0.053786\n","Epoch:  22 | train loss: 0.034247 | valid loss: 0.052392\n","Epoch:  23 | train loss: 0.036573 | valid loss: 0.050820\n","Epoch:  24 | train loss: 0.041883 | valid loss: 0.049203\n","Epoch:  25 | train loss: 0.054545 | valid loss: 0.047949\n","Epoch:  26 | train loss: 0.050592 | valid loss: 0.046308\n","Epoch:  27 | train loss: 0.048231 | valid loss: 0.045330\n","Epoch:  28 | train loss: 0.034575 | valid loss: 0.044075\n","Epoch:  29 | train loss: 0.036900 | valid loss: 0.042919\n","Epoch:  30 | train loss: 0.026779 | valid loss: 0.041743\n","Epoch:  31 | train loss: 0.054066 | valid loss: 0.040525\n","Epoch:  32 | train loss: 0.041829 | valid loss: 0.039214\n","Epoch:  33 | train loss: 0.030778 | valid loss: 0.038208\n","Epoch:  34 | train loss: 0.039499 | valid loss: 0.035875\n","Epoch:  35 | train loss: 0.047109 | valid loss: 0.034649\n","Epoch:  36 | train loss: 0.034081 | valid loss: 0.033664\n","Epoch:  37 | train loss: 0.025809 | valid loss: 0.032743\n","Epoch:  38 | train loss: 0.053887 | valid loss: 0.031898\n","Epoch:  39 | train loss: 0.043462 | valid loss: 0.031679\n","Epoch:  40 | train loss: 0.023452 | valid loss: 0.030963\n","Epoch:  41 | train loss: 0.030502 | valid loss: 0.030530\n","Epoch:  42 | train loss: 0.037644 | valid loss: 0.029783\n","Epoch:  43 | train loss: 0.031973 | valid loss: 0.029228\n","Epoch:  44 | train loss: 0.045009 | valid loss: 0.028911\n","Epoch:  45 | train loss: 0.032196 | valid loss: 0.028460\n","Epoch:  46 | train loss: 0.027221 | valid loss: 0.027969\n","Epoch:  47 | train loss: 0.017352 | valid loss: 0.027159\n","Epoch:  48 | train loss: 0.019535 | valid loss: 0.027405\n","Epoch:  49 | train loss: 0.030116 | valid loss: 0.026556\n","Epoch:  50 | train loss: 0.024553 | valid loss: 0.026349\n","Epoch:  51 | train loss: 0.019349 | valid loss: 0.025895\n","Epoch:  52 | train loss: 0.022807 | valid loss: 0.025391\n","Epoch:  53 | train loss: 0.027048 | valid loss: 0.025012\n","Epoch:  54 | train loss: 0.020078 | valid loss: 0.024769\n","Epoch:  55 | train loss: 0.025911 | valid loss: 0.024246\n","Epoch:  56 | train loss: 0.026768 | valid loss: 0.023971\n","Epoch:  57 | train loss: 0.029768 | valid loss: 0.023895\n","Epoch:  58 | train loss: 0.022445 | valid loss: 0.023464\n","Epoch:  59 | train loss: 0.028710 | valid loss: 0.023325\n","Epoch:  60 | train loss: 0.019817 | valid loss: 0.022933\n","Epoch:  61 | train loss: 0.022685 | valid loss: 0.022651\n","Epoch:  62 | train loss: 0.022022 | valid loss: 0.022515\n","Epoch:  63 | train loss: 0.020885 | valid loss: 0.022260\n","Epoch:  64 | train loss: 0.042936 | valid loss: 0.022103\n","Epoch:  65 | train loss: 0.024348 | valid loss: 0.021739\n","Epoch:  66 | train loss: 0.019720 | valid loss: 0.021786\n","Epoch:  67 | train loss: 0.014504 | valid loss: 0.021319\n","Epoch:  68 | train loss: 0.025278 | valid loss: 0.021295\n","Epoch:  69 | train loss: 0.037093 | valid loss: 0.021010\n","Epoch:  70 | train loss: 0.016795 | valid loss: 0.020725\n","Epoch:  71 | train loss: 0.017169 | valid loss: 0.020840\n","Epoch:  72 | train loss: 0.021358 | valid loss: 0.020421\n","Epoch:  73 | train loss: 0.013642 | valid loss: 0.020202\n","Epoch:  74 | train loss: 0.042102 | valid loss: 0.020376\n","Epoch:  75 | train loss: 0.019096 | valid loss: 0.020424\n","Epoch:  76 | train loss: 0.021306 | valid loss: 0.020156\n","Epoch:  77 | train loss: 0.031110 | valid loss: 0.019994\n","Epoch:  78 | train loss: 0.012433 | valid loss: 0.019915\n","Epoch:  79 | train loss: 0.019046 | valid loss: 0.019805\n","Epoch:  80 | train loss: 0.017411 | valid loss: 0.019747\n","Epoch:  81 | train loss: 0.020086 | valid loss: 0.019465\n","Epoch:  82 | train loss: 0.016417 | valid loss: 0.019391\n","Epoch:  83 | train loss: 0.020000 | valid loss: 0.019352\n","Epoch:  84 | train loss: 0.018226 | valid loss: 0.019172\n","Epoch:  85 | train loss: 0.013221 | valid loss: 0.019282\n","Epoch:  86 | train loss: 0.034948 | valid loss: 0.019216\n","Epoch:  87 | train loss: 0.018601 | valid loss: 0.019169\n","Epoch:  88 | train loss: 0.020598 | valid loss: 0.019127\n","Epoch:  89 | train loss: 0.020522 | valid loss: 0.019008\n","Epoch:  90 | train loss: 0.020043 | valid loss: 0.018929\n","Epoch:  91 | train loss: 0.026798 | valid loss: 0.018905\n","Epoch:  92 | train loss: 0.018045 | valid loss: 0.018829\n","Epoch:  93 | train loss: 0.024671 | valid loss: 0.018829\n","Epoch:  94 | train loss: 0.016201 | valid loss: 0.018748\n","Epoch:  95 | train loss: 0.014017 | valid loss: 0.018888\n","Epoch:  96 | train loss: 0.020202 | valid loss: 0.018494\n","Epoch:  97 | train loss: 0.020853 | valid loss: 0.018555\n","Epoch:  98 | train loss: 0.016906 | valid loss: 0.018498\n","Epoch:  99 | train loss: 0.013695 | valid loss: 0.018290\n","Epoch:  100 | train loss: 0.035873 | valid loss: 0.018470\n","Epoch:  101 | train loss: 0.025273 | valid loss: 0.018310\n","Epoch:  102 | train loss: 0.031345 | valid loss: 0.018497\n","Epoch:  103 | train loss: 0.018726 | valid loss: 0.018245\n","Epoch:  104 | train loss: 0.021448 | valid loss: 0.018183\n","Epoch:  105 | train loss: 0.021728 | valid loss: 0.018047\n","Epoch:  106 | train loss: 0.016583 | valid loss: 0.018238\n","Epoch:  107 | train loss: 0.013429 | valid loss: 0.018081\n","Epoch:  108 | train loss: 0.015390 | valid loss: 0.018022\n","Epoch:  109 | train loss: 0.013050 | valid loss: 0.018104\n","Epoch:  110 | train loss: 0.034373 | valid loss: 0.018050\n","Epoch:  111 | train loss: 0.023531 | valid loss: 0.018101\n","Epoch:  112 | train loss: 0.014873 | valid loss: 0.017969\n","Epoch:  113 | train loss: 0.016315 | valid loss: 0.018096\n","Epoch:  114 | train loss: 0.024381 | valid loss: 0.018065\n","Epoch:  115 | train loss: 0.009603 | valid loss: 0.017860\n","Epoch:  116 | train loss: 0.018669 | valid loss: 0.018016\n","Epoch:  117 | train loss: 0.012109 | valid loss: 0.017814\n","Epoch:  118 | train loss: 0.018505 | valid loss: 0.017803\n","Epoch:  119 | train loss: 0.025252 | valid loss: 0.017949\n","Epoch:  120 | train loss: 0.014647 | valid loss: 0.017864\n","Epoch:  121 | train loss: 0.016930 | valid loss: 0.017759\n","Epoch:  122 | train loss: 0.021851 | valid loss: 0.017791\n","Epoch:  123 | train loss: 0.020751 | valid loss: 0.017769\n","Epoch:  124 | train loss: 0.015528 | valid loss: 0.017669\n","Epoch:  125 | train loss: 0.019826 | valid loss: 0.017615\n","Epoch:  126 | train loss: 0.028464 | valid loss: 0.017806\n","Epoch:  127 | train loss: 0.017666 | valid loss: 0.017760\n","Epoch:  128 | train loss: 0.028596 | valid loss: 0.017701\n","Epoch:  129 | train loss: 0.022080 | valid loss: 0.017661\n","Epoch:  130 | train loss: 0.023786 | valid loss: 0.017753\n","Epoch:  131 | train loss: 0.011018 | valid loss: 0.017669\n","Epoch:  132 | train loss: 0.023802 | valid loss: 0.017675\n","Epoch:  133 | train loss: 0.016663 | valid loss: 0.017637\n","Epoch:  134 | train loss: 0.010230 | valid loss: 0.017726\n","Epoch:  135 | train loss: 0.019767 | valid loss: 0.017645\n","Epoch:  136 | train loss: 0.018757 | valid loss: 0.017508\n","Epoch:  137 | train loss: 0.016825 | valid loss: 0.017663\n","Epoch:  138 | train loss: 0.016964 | valid loss: 0.017569\n","Epoch:  139 | train loss: 0.022540 | valid loss: 0.017446\n","Epoch:  140 | train loss: 0.020032 | valid loss: 0.017543\n","Epoch:  141 | train loss: 0.020234 | valid loss: 0.017554\n","Epoch:  142 | train loss: 0.010579 | valid loss: 0.017393\n","Epoch:  143 | train loss: 0.023721 | valid loss: 0.017518\n","Epoch:  144 | train loss: 0.022704 | valid loss: 0.017594\n","Epoch:  145 | train loss: 0.023445 | valid loss: 0.017517\n","Epoch:  146 | train loss: 0.016665 | valid loss: 0.017438\n","Epoch:  147 | train loss: 0.021597 | valid loss: 0.017631\n","Epoch:  148 | train loss: 0.019617 | valid loss: 0.017571\n","Epoch:  149 | train loss: 0.008426 | valid loss: 0.017490\n","Epoch:  150 | train loss: 0.021775 | valid loss: 0.017509\n","Epoch:  151 | train loss: 0.023516 | valid loss: 0.017488\n","Epoch:  152 | train loss: 0.017814 | valid loss: 0.017434\n","Epoch:  153 | train loss: 0.030363 | valid loss: 0.017567\n","Epoch:  154 | train loss: 0.024916 | valid loss: 0.017526\n","Epoch:  155 | train loss: 0.020377 | valid loss: 0.017529\n","Epoch:  156 | train loss: 0.012425 | valid loss: 0.017461\n","Epoch:  157 | train loss: 0.008828 | valid loss: 0.017630\n","Epoch:  158 | train loss: 0.019954 | valid loss: 0.017510\n","Epoch:  159 | train loss: 0.015220 | valid loss: 0.017441\n","Epoch:  160 | train loss: 0.024026 | valid loss: 0.017444\n","Epoch:  161 | train loss: 0.012597 | valid loss: 0.017328\n","Epoch:  162 | train loss: 0.017148 | valid loss: 0.017309\n","Epoch:  163 | train loss: 0.019396 | valid loss: 0.017516\n","Epoch:  164 | train loss: 0.018077 | valid loss: 0.017339\n","Epoch:  165 | train loss: 0.015720 | valid loss: 0.017431\n","Epoch:  166 | train loss: 0.016237 | valid loss: 0.017433\n","Epoch:  167 | train loss: 0.017665 | valid loss: 0.017541\n","Epoch:  168 | train loss: 0.020822 | valid loss: 0.017459\n","Epoch:  169 | train loss: 0.023297 | valid loss: 0.017394\n","Epoch:  170 | train loss: 0.013441 | valid loss: 0.017493\n","Epoch:  171 | train loss: 0.023267 | valid loss: 0.017374\n","Epoch:  172 | train loss: 0.021968 | valid loss: 0.017374\n","Epoch:  173 | train loss: 0.013368 | valid loss: 0.017296\n","Epoch:  174 | train loss: 0.020774 | valid loss: 0.017270\n","Epoch:  175 | train loss: 0.011308 | valid loss: 0.017359\n","Epoch:  176 | train loss: 0.010343 | valid loss: 0.017258\n","Epoch:  177 | train loss: 0.008625 | valid loss: 0.017194\n","Epoch:  178 | train loss: 0.016431 | valid loss: 0.017297\n","Epoch:  179 | train loss: 0.022505 | valid loss: 0.017332\n","Epoch:  180 | train loss: 0.020736 | valid loss: 0.017420\n","Epoch:  181 | train loss: 0.016691 | valid loss: 0.017339\n","Epoch:  182 | train loss: 0.014932 | valid loss: 0.017371\n","Epoch:  183 | train loss: 0.018018 | valid loss: 0.017259\n","Epoch:  184 | train loss: 0.021749 | valid loss: 0.017306\n","Epoch:  185 | train loss: 0.008371 | valid loss: 0.017244\n","Epoch:  186 | train loss: 0.017616 | valid loss: 0.017375\n","Epoch:  187 | train loss: 0.012609 | valid loss: 0.017426\n","Epoch:  188 | train loss: 0.017839 | valid loss: 0.017273\n","Epoch:  189 | train loss: 0.021168 | valid loss: 0.017311\n","Epoch:  190 | train loss: 0.021405 | valid loss: 0.017212\n","Epoch:  191 | train loss: 0.018754 | valid loss: 0.017207\n","Epoch:  192 | train loss: 0.019259 | valid loss: 0.017261\n","Epoch:  193 | train loss: 0.016654 | valid loss: 0.017209\n","Epoch:  194 | train loss: 0.013732 | valid loss: 0.017205\n","Epoch:  195 | train loss: 0.018573 | valid loss: 0.017283\n","Epoch:  196 | train loss: 0.025395 | valid loss: 0.017293\n","Epoch:  197 | train loss: 0.020121 | valid loss: 0.017245\n","Epoch:  198 | train loss: 0.016881 | valid loss: 0.017195\n","Epoch:  199 | train loss: 0.032288 | valid loss: 0.017309\n","Epoch:  200 | train loss: 0.015724 | valid loss: 0.017242\n","Epoch:  201 | train loss: 0.013223 | valid loss: 0.017240\n","Epoch:  202 | train loss: 0.020217 | valid loss: 0.017253\n","Epoch:  203 | train loss: 0.019619 | valid loss: 0.017327\n","Epoch:  204 | train loss: 0.026999 | valid loss: 0.017263\n","Epoch:  205 | train loss: 0.018753 | valid loss: 0.017166\n","Epoch:  206 | train loss: 0.016708 | valid loss: 0.017228\n","Epoch:  207 | train loss: 0.017228 | valid loss: 0.017251\n","Epoch:  208 | train loss: 0.018025 | valid loss: 0.017071\n","Epoch:  209 | train loss: 0.015536 | valid loss: 0.017290\n","Epoch:  210 | train loss: 0.019842 | valid loss: 0.017161\n","Epoch:  211 | train loss: 0.022145 | valid loss: 0.017194\n","Epoch:  212 | train loss: 0.014568 | valid loss: 0.017236\n","Epoch:  213 | train loss: 0.022488 | valid loss: 0.017255\n","Epoch:  214 | train loss: 0.022170 | valid loss: 0.017259\n","Epoch:  215 | train loss: 0.009207 | valid loss: 0.017230\n","Epoch:  216 | train loss: 0.025420 | valid loss: 0.017298\n","Epoch:  217 | train loss: 0.021412 | valid loss: 0.017229\n","Epoch:  218 | train loss: 0.019077 | valid loss: 0.017078\n","Epoch:  219 | train loss: 0.014807 | valid loss: 0.017080\n","Epoch:  220 | train loss: 0.021619 | valid loss: 0.017230\n","Epoch:  221 | train loss: 0.024944 | valid loss: 0.017032\n","Epoch:  222 | train loss: 0.025552 | valid loss: 0.017200\n","Epoch:  223 | train loss: 0.023716 | valid loss: 0.017142\n","Epoch:  224 | train loss: 0.019428 | valid loss: 0.017141\n","Epoch:  225 | train loss: 0.014106 | valid loss: 0.017079\n","Epoch:  226 | train loss: 0.009017 | valid loss: 0.017198\n","Epoch:  227 | train loss: 0.017018 | valid loss: 0.017144\n","Epoch:  228 | train loss: 0.007563 | valid loss: 0.017203\n","Epoch:  229 | train loss: 0.016875 | valid loss: 0.017146\n","Epoch:  230 | train loss: 0.021391 | valid loss: 0.017125\n","Epoch:  231 | train loss: 0.011949 | valid loss: 0.017224\n","Epoch:  232 | train loss: 0.012881 | valid loss: 0.017324\n","Epoch:  233 | train loss: 0.015656 | valid loss: 0.017241\n","Epoch:  234 | train loss: 0.014544 | valid loss: 0.017247\n","Epoch:  235 | train loss: 0.019600 | valid loss: 0.017230\n","Epoch:  236 | train loss: 0.017469 | valid loss: 0.017101\n","Epoch:  237 | train loss: 0.010586 | valid loss: 0.017114\n","Epoch:  238 | train loss: 0.016442 | valid loss: 0.017075\n","Epoch:  239 | train loss: 0.036948 | valid loss: 0.017145\n","Epoch:  240 | train loss: 0.013149 | valid loss: 0.017161\n","Epoch:  241 | train loss: 0.017522 | valid loss: 0.017176\n","Epoch:  242 | train loss: 0.021656 | valid loss: 0.017296\n","Epoch:  243 | train loss: 0.013204 | valid loss: 0.017214\n","Epoch:  244 | train loss: 0.019264 | valid loss: 0.017094\n","Epoch:  245 | train loss: 0.016267 | valid loss: 0.017298\n","Epoch:  246 | train loss: 0.020794 | valid loss: 0.017080\n","Epoch:  247 | train loss: 0.012521 | valid loss: 0.017156\n","Epoch:  248 | train loss: 0.022382 | valid loss: 0.017094\n","Epoch:  249 | train loss: 0.010316 | valid loss: 0.017089\n","Epoch:  250 | train loss: 0.023853 | valid loss: 0.017117\n","Epoch:  251 | train loss: 0.009260 | valid loss: 0.017089\n","Epoch:  252 | train loss: 0.020284 | valid loss: 0.017047\n","Epoch:  253 | train loss: 0.022598 | valid loss: 0.017156\n","Epoch:  254 | train loss: 0.017824 | valid loss: 0.017065\n","Epoch:  255 | train loss: 0.012953 | valid loss: 0.017018\n","Epoch:  256 | train loss: 0.023667 | valid loss: 0.017112\n","Epoch:  257 | train loss: 0.019059 | valid loss: 0.017133\n","Epoch:  258 | train loss: 0.017681 | valid loss: 0.017206\n","Epoch:  259 | train loss: 0.012500 | valid loss: 0.017199\n","Epoch:  260 | train loss: 0.020244 | valid loss: 0.017273\n","Epoch:  261 | train loss: 0.016861 | valid loss: 0.017122\n","Epoch:  262 | train loss: 0.013421 | valid loss: 0.017072\n","Epoch:  263 | train loss: 0.015948 | valid loss: 0.017127\n","Epoch:  264 | train loss: 0.016459 | valid loss: 0.017173\n","Epoch:  265 | train loss: 0.014854 | valid loss: 0.017079\n","Epoch:  266 | train loss: 0.008289 | valid loss: 0.017082\n","Epoch:  267 | train loss: 0.023253 | valid loss: 0.017089\n","Epoch:  268 | train loss: 0.014890 | valid loss: 0.016992\n","Epoch:  269 | train loss: 0.012328 | valid loss: 0.017018\n","Epoch:  270 | train loss: 0.018198 | valid loss: 0.017154\n","Epoch:  271 | train loss: 0.015785 | valid loss: 0.017042\n","Epoch:  272 | train loss: 0.021901 | valid loss: 0.017090\n","Epoch:  273 | train loss: 0.022147 | valid loss: 0.017045\n","Epoch:  274 | train loss: 0.017901 | valid loss: 0.017082\n","Epoch:  275 | train loss: 0.019311 | valid loss: 0.017101\n","Epoch:  276 | train loss: 0.022260 | valid loss: 0.017062\n","Epoch:  277 | train loss: 0.021116 | valid loss: 0.017020\n","Epoch:  278 | train loss: 0.015320 | valid loss: 0.017083\n","Epoch:  279 | train loss: 0.012666 | valid loss: 0.016981\n","Epoch:  280 | train loss: 0.028791 | valid loss: 0.017061\n","Epoch:  281 | train loss: 0.018918 | valid loss: 0.017016\n","Epoch:  282 | train loss: 0.020931 | valid loss: 0.017030\n","Epoch:  283 | train loss: 0.013733 | valid loss: 0.016956\n","Epoch:  284 | train loss: 0.015262 | valid loss: 0.017045\n","Epoch:  285 | train loss: 0.008261 | valid loss: 0.017114\n","Epoch:  286 | train loss: 0.021548 | valid loss: 0.017096\n","Epoch:  287 | train loss: 0.018197 | valid loss: 0.016983\n","Epoch:  288 | train loss: 0.014704 | valid loss: 0.016957\n","Epoch:  289 | train loss: 0.013331 | valid loss: 0.017080\n","Epoch:  290 | train loss: 0.012972 | valid loss: 0.017053\n","Epoch:  291 | train loss: 0.024840 | valid loss: 0.017006\n","Epoch:  292 | train loss: 0.009616 | valid loss: 0.017111\n","Epoch:  293 | train loss: 0.012765 | valid loss: 0.017001\n","Epoch:  294 | train loss: 0.034439 | valid loss: 0.016970\n","Epoch:  295 | train loss: 0.011047 | valid loss: 0.017053\n","Epoch:  296 | train loss: 0.030455 | valid loss: 0.017120\n","Epoch:  297 | train loss: 0.017459 | valid loss: 0.016956\n","Epoch:  298 | train loss: 0.011652 | valid loss: 0.017050\n","Epoch:  299 | train loss: 0.016069 | valid loss: 0.017024\n","Epoch:  300 | train loss: 0.015804 | valid loss: 0.017131\n","Epoch:  301 | train loss: 0.012678 | valid loss: 0.017077\n","Epoch:  302 | train loss: 0.016879 | valid loss: 0.017006\n","Epoch:  303 | train loss: 0.008651 | valid loss: 0.017046\n","Epoch:  304 | train loss: 0.014567 | valid loss: 0.017163\n","Epoch:  305 | train loss: 0.017938 | valid loss: 0.017018\n","Epoch:  306 | train loss: 0.010468 | valid loss: 0.017020\n","Epoch:  307 | train loss: 0.017667 | valid loss: 0.016940\n","Epoch:  308 | train loss: 0.026745 | valid loss: 0.017103\n","Epoch:  309 | train loss: 0.017655 | valid loss: 0.017012\n","Epoch:  310 | train loss: 0.014894 | valid loss: 0.016944\n","Epoch:  311 | train loss: 0.029001 | valid loss: 0.017025\n","Epoch:  312 | train loss: 0.022950 | valid loss: 0.016957\n","Epoch:  313 | train loss: 0.014633 | valid loss: 0.016957\n","Epoch:  314 | train loss: 0.012478 | valid loss: 0.017009\n","Epoch:  315 | train loss: 0.023925 | valid loss: 0.016988\n","Epoch:  316 | train loss: 0.016245 | valid loss: 0.016999\n","Epoch:  317 | train loss: 0.012293 | valid loss: 0.016928\n","Epoch:  318 | train loss: 0.029873 | valid loss: 0.017082\n","Epoch:  319 | train loss: 0.020440 | valid loss: 0.016972\n","Epoch:  320 | train loss: 0.019237 | valid loss: 0.016984\n","Epoch:  321 | train loss: 0.011422 | valid loss: 0.016962\n","Epoch:  322 | train loss: 0.016872 | valid loss: 0.016904\n","Epoch:  323 | train loss: 0.015320 | valid loss: 0.016952\n","Epoch:  324 | train loss: 0.020442 | valid loss: 0.016995\n","Epoch:  325 | train loss: 0.023399 | valid loss: 0.017060\n","Epoch:  326 | train loss: 0.017257 | valid loss: 0.017082\n","Epoch:  327 | train loss: 0.014401 | valid loss: 0.016996\n","Epoch:  328 | train loss: 0.021827 | valid loss: 0.016950\n","Epoch:  329 | train loss: 0.018167 | valid loss: 0.017016\n","Epoch:  330 | train loss: 0.018473 | valid loss: 0.016985\n","Epoch:  331 | train loss: 0.013010 | valid loss: 0.016993\n","Epoch:  332 | train loss: 0.021068 | valid loss: 0.016976\n","Epoch:  333 | train loss: 0.007296 | valid loss: 0.017052\n","Epoch:  334 | train loss: 0.013270 | valid loss: 0.016961\n","Epoch:  335 | train loss: 0.017943 | valid loss: 0.016941\n","Epoch:  336 | train loss: 0.018239 | valid loss: 0.017009\n","Epoch:  337 | train loss: 0.025770 | valid loss: 0.016950\n","Epoch:  338 | train loss: 0.008979 | valid loss: 0.016996\n","Epoch:  339 | train loss: 0.016493 | valid loss: 0.016953\n","Epoch:  340 | train loss: 0.012796 | valid loss: 0.016944\n","Epoch:  341 | train loss: 0.012469 | valid loss: 0.016984\n","Epoch:  342 | train loss: 0.016851 | valid loss: 0.016989\n","Epoch:  343 | train loss: 0.025582 | valid loss: 0.016965\n","Epoch:  344 | train loss: 0.021492 | valid loss: 0.017009\n","Epoch:  345 | train loss: 0.013475 | valid loss: 0.016938\n","Epoch:  346 | train loss: 0.011971 | valid loss: 0.016899\n","Epoch:  347 | train loss: 0.019075 | valid loss: 0.017038\n","Epoch:  348 | train loss: 0.008841 | valid loss: 0.017019\n","Epoch:  349 | train loss: 0.011432 | valid loss: 0.016997\n","Epoch:  350 | train loss: 0.017360 | valid loss: 0.016948\n","Epoch:  351 | train loss: 0.008829 | valid loss: 0.017072\n","Epoch:  352 | train loss: 0.019024 | valid loss: 0.016993\n","Epoch:  353 | train loss: 0.008562 | valid loss: 0.016989\n","Epoch:  354 | train loss: 0.018286 | valid loss: 0.016950\n","Epoch:  355 | train loss: 0.010011 | valid loss: 0.016943\n","Epoch:  356 | train loss: 0.019333 | valid loss: 0.016979\n","Epoch:  357 | train loss: 0.014188 | valid loss: 0.016970\n","Epoch:  358 | train loss: 0.019817 | valid loss: 0.016907\n","Epoch:  359 | train loss: 0.017731 | valid loss: 0.016965\n","Epoch:  360 | train loss: 0.015677 | valid loss: 0.016905\n","Epoch:  361 | train loss: 0.022581 | valid loss: 0.016995\n","Epoch:  362 | train loss: 0.012422 | valid loss: 0.016992\n","Epoch:  363 | train loss: 0.015879 | valid loss: 0.016989\n","Epoch:  364 | train loss: 0.014758 | valid loss: 0.016968\n","Epoch:  365 | train loss: 0.019672 | valid loss: 0.016969\n","Epoch:  366 | train loss: 0.015461 | valid loss: 0.017009\n","Epoch:  367 | train loss: 0.015984 | valid loss: 0.016935\n","Epoch:  368 | train loss: 0.015958 | valid loss: 0.016961\n","Epoch:  369 | train loss: 0.009226 | valid loss: 0.017093\n","Epoch:  370 | train loss: 0.012939 | valid loss: 0.017017\n","Epoch:  371 | train loss: 0.026547 | valid loss: 0.016995\n","Epoch:  372 | train loss: 0.012793 | valid loss: 0.017064\n","Epoch:  373 | train loss: 0.026344 | valid loss: 0.016951\n","Epoch:  374 | train loss: 0.019918 | valid loss: 0.016931\n","Epoch:  375 | train loss: 0.022073 | valid loss: 0.016990\n","Epoch:  376 | train loss: 0.029524 | valid loss: 0.017000\n","Epoch:  377 | train loss: 0.013040 | valid loss: 0.016971\n","Epoch:  378 | train loss: 0.011518 | valid loss: 0.017021\n","Epoch:  379 | train loss: 0.026581 | valid loss: 0.017106\n","Epoch:  380 | train loss: 0.017409 | valid loss: 0.016981\n","Epoch:  381 | train loss: 0.008697 | valid loss: 0.017034\n","Epoch:  382 | train loss: 0.017924 | valid loss: 0.016980\n","Epoch:  383 | train loss: 0.021553 | valid loss: 0.017015\n","Epoch:  384 | train loss: 0.016675 | valid loss: 0.016922\n","Epoch:  385 | train loss: 0.021206 | valid loss: 0.016901\n","Epoch:  386 | train loss: 0.022018 | valid loss: 0.016942\n","Epoch:  387 | train loss: 0.019191 | valid loss: 0.016973\n","Epoch:  388 | train loss: 0.011315 | valid loss: 0.017063\n","Epoch:  389 | train loss: 0.027332 | valid loss: 0.016918\n","Epoch:  390 | train loss: 0.013678 | valid loss: 0.017022\n","Epoch:  391 | train loss: 0.020154 | valid loss: 0.016923\n","Epoch:  392 | train loss: 0.016994 | valid loss: 0.017013\n","Epoch:  393 | train loss: 0.027223 | valid loss: 0.017113\n","Epoch:  394 | train loss: 0.019466 | valid loss: 0.017046\n","Epoch:  395 | train loss: 0.022076 | valid loss: 0.016973\n","Epoch:  396 | train loss: 0.024138 | valid loss: 0.016981\n","Epoch:  397 | train loss: 0.013789 | valid loss: 0.016983\n","Epoch:  398 | train loss: 0.026262 | valid loss: 0.017002\n","Epoch:  399 | train loss: 0.016004 | valid loss: 0.016881\n","Epoch:  400 | train loss: 0.010710 | valid loss: 0.016994\n","Epoch:  401 | train loss: 0.024447 | valid loss: 0.016921\n","Epoch:  402 | train loss: 0.017167 | valid loss: 0.017028\n","Epoch:  403 | train loss: 0.024072 | valid loss: 0.016979\n","Epoch:  404 | train loss: 0.022665 | valid loss: 0.016998\n","Epoch:  405 | train loss: 0.016974 | valid loss: 0.017049\n","Epoch:  406 | train loss: 0.011129 | valid loss: 0.017000\n","Epoch:  407 | train loss: 0.022279 | valid loss: 0.016948\n","Epoch:  408 | train loss: 0.020765 | valid loss: 0.016987\n","Epoch:  409 | train loss: 0.021796 | valid loss: 0.017030\n","Epoch:  410 | train loss: 0.018536 | valid loss: 0.016976\n","Epoch:  411 | train loss: 0.022562 | valid loss: 0.016981\n","Epoch:  412 | train loss: 0.023681 | valid loss: 0.017021\n","Epoch:  413 | train loss: 0.018847 | valid loss: 0.016968\n","Epoch:  414 | train loss: 0.025498 | valid loss: 0.016975\n","Epoch:  415 | train loss: 0.016936 | valid loss: 0.017040\n","Epoch:  416 | train loss: 0.010427 | valid loss: 0.016959\n","Epoch:  417 | train loss: 0.009305 | valid loss: 0.016945\n","Epoch:  418 | train loss: 0.014229 | valid loss: 0.016969\n","Epoch:  419 | train loss: 0.011742 | valid loss: 0.017047\n","Epoch:  420 | train loss: 0.012897 | valid loss: 0.017065\n","Epoch:  421 | train loss: 0.023428 | valid loss: 0.017049\n","Epoch:  422 | train loss: 0.015037 | valid loss: 0.017105\n","Epoch:  423 | train loss: 0.032624 | valid loss: 0.016942\n","Epoch:  424 | train loss: 0.016829 | valid loss: 0.017002\n","Epoch:  425 | train loss: 0.023028 | valid loss: 0.017021\n","Epoch:  426 | train loss: 0.022290 | valid loss: 0.016996\n","Epoch:  427 | train loss: 0.023646 | valid loss: 0.016993\n","Epoch:  428 | train loss: 0.013626 | valid loss: 0.016954\n","Epoch:  429 | train loss: 0.018895 | valid loss: 0.017063\n","Epoch:  430 | train loss: 0.037503 | valid loss: 0.017044\n","Epoch:  431 | train loss: 0.009515 | valid loss: 0.016950\n","Epoch:  432 | train loss: 0.010279 | valid loss: 0.016940\n","Epoch:  433 | train loss: 0.021341 | valid loss: 0.017008\n","Epoch:  434 | train loss: 0.016191 | valid loss: 0.016987\n","Epoch:  435 | train loss: 0.010246 | valid loss: 0.016992\n","Epoch:  436 | train loss: 0.014567 | valid loss: 0.016980\n","Epoch:  437 | train loss: 0.020773 | valid loss: 0.017026\n","Epoch:  438 | train loss: 0.025269 | valid loss: 0.016996\n","Epoch:  439 | train loss: 0.023931 | valid loss: 0.016941\n","Epoch:  440 | train loss: 0.023241 | valid loss: 0.016978\n","Epoch:  441 | train loss: 0.010824 | valid loss: 0.017063\n","Epoch:  442 | train loss: 0.009903 | valid loss: 0.017053\n","Epoch:  443 | train loss: 0.020002 | valid loss: 0.016986\n","Epoch:  444 | train loss: 0.011054 | valid loss: 0.017018\n","Epoch:  445 | train loss: 0.009635 | valid loss: 0.016980\n","Epoch:  446 | train loss: 0.017755 | valid loss: 0.017076\n","Epoch:  447 | train loss: 0.014810 | valid loss: 0.017139\n","Epoch:  448 | train loss: 0.018153 | valid loss: 0.016961\n","Epoch:  449 | train loss: 0.027619 | valid loss: 0.017053\n","Epoch:  450 | train loss: 0.015097 | valid loss: 0.017004\n","Epoch:  451 | train loss: 0.014899 | valid loss: 0.016998\n","Epoch:  452 | train loss: 0.009469 | valid loss: 0.016966\n","Epoch:  453 | train loss: 0.020113 | valid loss: 0.017017\n","Epoch:  454 | train loss: 0.019739 | valid loss: 0.017061\n","Epoch:  455 | train loss: 0.015781 | valid loss: 0.017065\n","Epoch:  456 | train loss: 0.015691 | valid loss: 0.017030\n","Epoch:  457 | train loss: 0.013747 | valid loss: 0.016953\n","Epoch:  458 | train loss: 0.013822 | valid loss: 0.017007\n","Epoch:  459 | train loss: 0.016850 | valid loss: 0.016970\n","Epoch:  460 | train loss: 0.009307 | valid loss: 0.017000\n","Epoch:  461 | train loss: 0.014803 | valid loss: 0.016981\n","Epoch:  462 | train loss: 0.019204 | valid loss: 0.017020\n","Epoch:  463 | train loss: 0.021246 | valid loss: 0.017049\n","Epoch:  464 | train loss: 0.017313 | valid loss: 0.016938\n","Epoch:  465 | train loss: 0.021092 | valid loss: 0.016928\n","Epoch:  466 | train loss: 0.019643 | valid loss: 0.016992\n","Epoch:  467 | train loss: 0.019262 | valid loss: 0.017049\n","Epoch:  468 | train loss: 0.011570 | valid loss: 0.016997\n","Epoch:  469 | train loss: 0.010542 | valid loss: 0.016923\n","Epoch:  470 | train loss: 0.025746 | valid loss: 0.017064\n","Epoch:  471 | train loss: 0.016086 | valid loss: 0.017011\n","Epoch:  472 | train loss: 0.023990 | valid loss: 0.016968\n","Epoch:  473 | train loss: 0.017262 | valid loss: 0.016997\n","Epoch:  474 | train loss: 0.022778 | valid loss: 0.016934\n","Epoch:  475 | train loss: 0.016332 | valid loss: 0.016961\n","Epoch:  476 | train loss: 0.013945 | valid loss: 0.016941\n","Epoch:  477 | train loss: 0.016614 | valid loss: 0.017085\n","Epoch:  478 | train loss: 0.018853 | valid loss: 0.017000\n","Epoch:  479 | train loss: 0.028558 | valid loss: 0.017000\n","Epoch:  480 | train loss: 0.028208 | valid loss: 0.016949\n","Epoch:  481 | train loss: 0.013834 | valid loss: 0.016979\n","Epoch:  482 | train loss: 0.014249 | valid loss: 0.016944\n","Epoch:  483 | train loss: 0.021289 | valid loss: 0.016969\n","Epoch:  484 | train loss: 0.025075 | valid loss: 0.016972\n","Epoch:  485 | train loss: 0.017032 | valid loss: 0.016937\n","Epoch:  486 | train loss: 0.022340 | valid loss: 0.016992\n","Epoch:  487 | train loss: 0.014729 | valid loss: 0.016985\n","Epoch:  488 | train loss: 0.011764 | valid loss: 0.017070\n","Epoch:  489 | train loss: 0.019804 | valid loss: 0.017002\n","Epoch:  490 | train loss: 0.021184 | valid loss: 0.016933\n","Epoch:  491 | train loss: 0.017850 | valid loss: 0.016957\n","Epoch:  492 | train loss: 0.019276 | valid loss: 0.017073\n","Epoch:  493 | train loss: 0.013257 | valid loss: 0.016970\n","Epoch:  494 | train loss: 0.017215 | valid loss: 0.017025\n","Epoch:  495 | train loss: 0.013858 | valid loss: 0.017014\n","Epoch:  496 | train loss: 0.016366 | valid loss: 0.017043\n","Epoch:  497 | train loss: 0.023075 | valid loss: 0.016984\n","Epoch:  498 | train loss: 0.021193 | valid loss: 0.017100\n","Epoch:  499 | train loss: 0.016952 | valid loss: 0.016935\n","Epoch:  500 | train loss: 0.019290 | valid loss: 0.016957\n","Epoch:  501 | train loss: 0.022457 | valid loss: 0.016974\n","Epoch:  502 | train loss: 0.019290 | valid loss: 0.016962\n","Epoch:  503 | train loss: 0.020932 | valid loss: 0.016997\n","Epoch:  504 | train loss: 0.033041 | valid loss: 0.017143\n","Epoch:  505 | train loss: 0.019993 | valid loss: 0.017045\n","Epoch:  506 | train loss: 0.016088 | valid loss: 0.016946\n","Epoch:  507 | train loss: 0.012641 | valid loss: 0.017023\n","Epoch:  508 | train loss: 0.014994 | valid loss: 0.016993\n","Epoch:  509 | train loss: 0.009981 | valid loss: 0.017001\n","Epoch:  510 | train loss: 0.015781 | valid loss: 0.016958\n","Epoch:  511 | train loss: 0.018189 | valid loss: 0.017117\n","Epoch:  512 | train loss: 0.023245 | valid loss: 0.017015\n","Epoch:  513 | train loss: 0.019354 | valid loss: 0.016970\n","Epoch:  514 | train loss: 0.014444 | valid loss: 0.016907\n","Epoch:  515 | train loss: 0.015677 | valid loss: 0.017003\n","Epoch:  516 | train loss: 0.019610 | valid loss: 0.016976\n","Epoch:  517 | train loss: 0.008012 | valid loss: 0.017031\n","Epoch:  518 | train loss: 0.012548 | valid loss: 0.017035\n","Epoch:  519 | train loss: 0.015674 | valid loss: 0.016991\n","Epoch:  520 | train loss: 0.008388 | valid loss: 0.017038\n","Epoch:  521 | train loss: 0.017886 | valid loss: 0.017039\n","Epoch:  522 | train loss: 0.016115 | valid loss: 0.017194\n","Epoch:  523 | train loss: 0.025546 | valid loss: 0.017003\n","Epoch:  524 | train loss: 0.025330 | valid loss: 0.017056\n","Epoch:  525 | train loss: 0.011795 | valid loss: 0.017065\n","Epoch:  526 | train loss: 0.013999 | valid loss: 0.017012\n","Epoch:  527 | train loss: 0.017952 | valid loss: 0.017048\n","Epoch:  528 | train loss: 0.010965 | valid loss: 0.016992\n","Epoch:  529 | train loss: 0.017975 | valid loss: 0.016962\n","Epoch:  530 | train loss: 0.009534 | valid loss: 0.016979\n","Epoch:  531 | train loss: 0.013006 | valid loss: 0.016930\n","Epoch:  532 | train loss: 0.010160 | valid loss: 0.016956\n","Epoch:  533 | train loss: 0.018832 | valid loss: 0.016989\n","Epoch:  534 | train loss: 0.014485 | valid loss: 0.016987\n","Epoch:  535 | train loss: 0.014485 | valid loss: 0.016998\n","Epoch:  536 | train loss: 0.018249 | valid loss: 0.016974\n","Epoch:  537 | train loss: 0.011086 | valid loss: 0.017009\n","Epoch:  538 | train loss: 0.011729 | valid loss: 0.016983\n","Epoch:  539 | train loss: 0.015850 | valid loss: 0.016960\n","Epoch:  540 | train loss: 0.016801 | valid loss: 0.017088\n","Epoch:  541 | train loss: 0.015609 | valid loss: 0.017068\n","Epoch:  542 | train loss: 0.016176 | valid loss: 0.017004\n","Epoch:  543 | train loss: 0.017231 | valid loss: 0.017016\n","Epoch:  544 | train loss: 0.017947 | valid loss: 0.017079\n","Epoch:  545 | train loss: 0.033735 | valid loss: 0.017052\n","Epoch:  546 | train loss: 0.014439 | valid loss: 0.017065\n","Epoch:  547 | train loss: 0.013388 | valid loss: 0.016928\n","Epoch:  548 | train loss: 0.016941 | valid loss: 0.017091\n","Epoch:  549 | train loss: 0.022844 | valid loss: 0.017006\n","Epoch:  550 | train loss: 0.010265 | valid loss: 0.016991\n","Epoch:  551 | train loss: 0.012635 | valid loss: 0.016982\n","Epoch:  552 | train loss: 0.007562 | valid loss: 0.017032\n","Epoch:  553 | train loss: 0.016207 | valid loss: 0.017080\n","Epoch:  554 | train loss: 0.009828 | valid loss: 0.017085\n","Epoch:  555 | train loss: 0.022520 | valid loss: 0.016970\n","Epoch:  556 | train loss: 0.011853 | valid loss: 0.017109\n","Epoch:  557 | train loss: 0.019271 | valid loss: 0.017071\n","Epoch:  558 | train loss: 0.020726 | valid loss: 0.017028\n","Epoch:  559 | train loss: 0.017940 | valid loss: 0.016999\n","Epoch:  560 | train loss: 0.012214 | valid loss: 0.017015\n","Epoch:  561 | train loss: 0.018584 | valid loss: 0.016979\n","Epoch:  562 | train loss: 0.024498 | valid loss: 0.017058\n","Epoch:  563 | train loss: 0.008829 | valid loss: 0.017017\n","Epoch:  564 | train loss: 0.027311 | valid loss: 0.017021\n","Epoch:  565 | train loss: 0.023657 | valid loss: 0.017013\n","Epoch:  566 | train loss: 0.009498 | valid loss: 0.017051\n","Epoch:  567 | train loss: 0.013396 | valid loss: 0.017082\n","Epoch:  568 | train loss: 0.012318 | valid loss: 0.017070\n","Epoch:  569 | train loss: 0.009688 | valid loss: 0.017055\n","Epoch:  570 | train loss: 0.015392 | valid loss: 0.016944\n","Epoch:  571 | train loss: 0.011595 | valid loss: 0.016994\n","Epoch:  572 | train loss: 0.011787 | valid loss: 0.017073\n","Epoch:  573 | train loss: 0.008212 | valid loss: 0.017031\n","Epoch:  574 | train loss: 0.013155 | valid loss: 0.017103\n","Epoch:  575 | train loss: 0.016532 | valid loss: 0.017051\n","Epoch:  576 | train loss: 0.010882 | valid loss: 0.017071\n","Epoch:  577 | train loss: 0.013275 | valid loss: 0.016952\n","Epoch:  578 | train loss: 0.020307 | valid loss: 0.017059\n","Epoch:  579 | train loss: 0.015865 | valid loss: 0.017052\n","Epoch:  580 | train loss: 0.018099 | valid loss: 0.017081\n","Epoch:  581 | train loss: 0.016939 | valid loss: 0.017058\n","Epoch:  582 | train loss: 0.019312 | valid loss: 0.017130\n","Epoch:  583 | train loss: 0.026201 | valid loss: 0.017179\n","Epoch:  584 | train loss: 0.014752 | valid loss: 0.016952\n","Epoch:  585 | train loss: 0.017859 | valid loss: 0.017058\n","Epoch:  586 | train loss: 0.022287 | valid loss: 0.016926\n","Epoch:  587 | train loss: 0.011509 | valid loss: 0.016964\n","Epoch:  588 | train loss: 0.017651 | valid loss: 0.017040\n","Epoch:  589 | train loss: 0.013483 | valid loss: 0.017020\n","Epoch:  590 | train loss: 0.016501 | valid loss: 0.016995\n","Epoch:  591 | train loss: 0.025865 | valid loss: 0.017013\n","Epoch:  592 | train loss: 0.011043 | valid loss: 0.017022\n","Epoch:  593 | train loss: 0.020802 | valid loss: 0.017012\n","Epoch:  594 | train loss: 0.015731 | valid loss: 0.017031\n","Epoch:  595 | train loss: 0.016051 | valid loss: 0.017014\n","Epoch:  596 | train loss: 0.007479 | valid loss: 0.017023\n","Epoch:  597 | train loss: 0.019502 | valid loss: 0.017113\n","Epoch:  598 | train loss: 0.026079 | valid loss: 0.017015\n","Epoch:  599 | train loss: 0.013553 | valid loss: 0.017061\n","Epoch:  600 | train loss: 0.015473 | valid loss: 0.017028\n","Epoch:  601 | train loss: 0.014773 | valid loss: 0.016964\n","Epoch:  602 | train loss: 0.012035 | valid loss: 0.016974\n","Epoch:  603 | train loss: 0.018585 | valid loss: 0.016998\n","Epoch:  604 | train loss: 0.024559 | valid loss: 0.017024\n","Epoch:  605 | train loss: 0.015003 | valid loss: 0.016935\n","Epoch:  606 | train loss: 0.015473 | valid loss: 0.017029\n","Epoch:  607 | train loss: 0.013323 | valid loss: 0.017140\n","Epoch:  608 | train loss: 0.014285 | valid loss: 0.017120\n","Epoch:  609 | train loss: 0.014721 | valid loss: 0.017159\n","Epoch:  610 | train loss: 0.014059 | valid loss: 0.017022\n","Epoch:  611 | train loss: 0.011349 | valid loss: 0.017074\n","Epoch:  612 | train loss: 0.010325 | valid loss: 0.017032\n","Epoch:  613 | train loss: 0.018032 | valid loss: 0.017051\n","Epoch:  614 | train loss: 0.030962 | valid loss: 0.017026\n","Epoch:  615 | train loss: 0.012451 | valid loss: 0.017078\n","Epoch:  616 | train loss: 0.020627 | valid loss: 0.016950\n","Epoch:  617 | train loss: 0.024041 | valid loss: 0.017028\n","Epoch:  618 | train loss: 0.021029 | valid loss: 0.017130\n","Epoch:  619 | train loss: 0.025637 | valid loss: 0.017055\n","Epoch:  620 | train loss: 0.010771 | valid loss: 0.017024\n","Epoch:  621 | train loss: 0.032045 | valid loss: 0.017063\n","Epoch:  622 | train loss: 0.008791 | valid loss: 0.017040\n","Epoch:  623 | train loss: 0.026086 | valid loss: 0.017138\n","Epoch:  624 | train loss: 0.013714 | valid loss: 0.017059\n","Epoch:  625 | train loss: 0.016311 | valid loss: 0.017023\n","Epoch:  626 | train loss: 0.010242 | valid loss: 0.017091\n","Epoch:  627 | train loss: 0.023538 | valid loss: 0.017112\n","Epoch:  628 | train loss: 0.015020 | valid loss: 0.017037\n","Epoch:  629 | train loss: 0.010809 | valid loss: 0.017063\n","Epoch:  630 | train loss: 0.011122 | valid loss: 0.017198\n","Epoch:  631 | train loss: 0.013932 | valid loss: 0.017255\n","Epoch:  632 | train loss: 0.017824 | valid loss: 0.017132\n","Epoch:  633 | train loss: 0.011699 | valid loss: 0.017062\n","Epoch:  634 | train loss: 0.011926 | valid loss: 0.017115\n","Epoch:  635 | train loss: 0.021700 | valid loss: 0.017052\n","Epoch:  636 | train loss: 0.016946 | valid loss: 0.017052\n","Epoch:  637 | train loss: 0.010693 | valid loss: 0.017045\n","Epoch:  638 | train loss: 0.009295 | valid loss: 0.017024\n","Epoch:  639 | train loss: 0.015360 | valid loss: 0.017011\n","Epoch:  640 | train loss: 0.010585 | valid loss: 0.017089\n","Epoch:  641 | train loss: 0.010876 | valid loss: 0.017057\n","Epoch:  642 | train loss: 0.011817 | valid loss: 0.016969\n","Epoch:  643 | train loss: 0.013276 | valid loss: 0.017069\n","Epoch:  644 | train loss: 0.016272 | valid loss: 0.017138\n","Epoch:  645 | train loss: 0.017298 | valid loss: 0.017057\n","Epoch:  646 | train loss: 0.022043 | valid loss: 0.017014\n","Epoch:  647 | train loss: 0.011739 | valid loss: 0.016986\n","Epoch:  648 | train loss: 0.019086 | valid loss: 0.017054\n","Epoch:  649 | train loss: 0.023716 | valid loss: 0.017021\n","Epoch:  650 | train loss: 0.016220 | valid loss: 0.017149\n","Epoch:  651 | train loss: 0.017832 | valid loss: 0.017012\n","Epoch:  652 | train loss: 0.023299 | valid loss: 0.017045\n","Epoch:  653 | train loss: 0.021494 | valid loss: 0.017007\n","Epoch:  654 | train loss: 0.017827 | valid loss: 0.017059\n","Epoch:  655 | train loss: 0.020565 | valid loss: 0.016969\n","Epoch:  656 | train loss: 0.014294 | valid loss: 0.017075\n","Epoch:  657 | train loss: 0.012736 | valid loss: 0.017102\n","Epoch:  658 | train loss: 0.014564 | valid loss: 0.017059\n","Epoch:  659 | train loss: 0.014002 | valid loss: 0.017216\n","Epoch:  660 | train loss: 0.018122 | valid loss: 0.017151\n","Epoch:  661 | train loss: 0.015713 | valid loss: 0.017210\n","Epoch:  662 | train loss: 0.012973 | valid loss: 0.017123\n","Epoch:  663 | train loss: 0.018326 | valid loss: 0.017093\n","Epoch:  664 | train loss: 0.016516 | valid loss: 0.017085\n","Epoch:  665 | train loss: 0.017493 | valid loss: 0.017113\n","Epoch:  666 | train loss: 0.026464 | valid loss: 0.017102\n","Epoch:  667 | train loss: 0.018415 | valid loss: 0.017133\n","Epoch:  668 | train loss: 0.011004 | valid loss: 0.017063\n","Epoch:  669 | train loss: 0.021596 | valid loss: 0.017035\n","Epoch:  670 | train loss: 0.017792 | valid loss: 0.017051\n","Epoch:  671 | train loss: 0.014050 | valid loss: 0.016947\n","Epoch:  672 | train loss: 0.016639 | valid loss: 0.017037\n","Epoch:  673 | train loss: 0.029232 | valid loss: 0.017104\n","Epoch:  674 | train loss: 0.014985 | valid loss: 0.017088\n","Epoch:  675 | train loss: 0.013297 | valid loss: 0.017092\n","Epoch:  676 | train loss: 0.016770 | valid loss: 0.017110\n","Epoch:  677 | train loss: 0.021808 | valid loss: 0.017138\n","Epoch:  678 | train loss: 0.011980 | valid loss: 0.017181\n","Epoch:  679 | train loss: 0.007701 | valid loss: 0.017055\n","Epoch:  680 | train loss: 0.019215 | valid loss: 0.017057\n","Epoch:  681 | train loss: 0.015300 | valid loss: 0.017035\n","Epoch:  682 | train loss: 0.012182 | valid loss: 0.017043\n","Epoch:  683 | train loss: 0.020971 | valid loss: 0.017135\n","Epoch:  684 | train loss: 0.012615 | valid loss: 0.017160\n","Epoch:  685 | train loss: 0.019458 | valid loss: 0.017166\n","Epoch:  686 | train loss: 0.023913 | valid loss: 0.017088\n","Epoch:  687 | train loss: 0.016945 | valid loss: 0.017120\n","Epoch:  688 | train loss: 0.013873 | valid loss: 0.017200\n","Epoch:  689 | train loss: 0.011575 | valid loss: 0.017123\n","Epoch:  690 | train loss: 0.015707 | valid loss: 0.017122\n","Epoch:  691 | train loss: 0.017797 | valid loss: 0.017068\n","Epoch:  692 | train loss: 0.020588 | valid loss: 0.017099\n","Epoch:  693 | train loss: 0.006243 | valid loss: 0.017103\n","Epoch:  694 | train loss: 0.013323 | valid loss: 0.017023\n","Epoch:  695 | train loss: 0.015345 | valid loss: 0.016995\n","Epoch:  696 | train loss: 0.021886 | valid loss: 0.017112\n","Epoch:  697 | train loss: 0.019095 | valid loss: 0.017103\n","Epoch:  698 | train loss: 0.024750 | valid loss: 0.017071\n","Epoch:  699 | train loss: 0.014650 | valid loss: 0.017176\n","Epoch:  700 | train loss: 0.016902 | valid loss: 0.017205\n","Epoch:  701 | train loss: 0.030957 | valid loss: 0.017122\n","Epoch:  702 | train loss: 0.010278 | valid loss: 0.017139\n","Epoch:  703 | train loss: 0.014209 | valid loss: 0.017116\n","Epoch:  704 | train loss: 0.022853 | valid loss: 0.017207\n","Epoch:  705 | train loss: 0.016414 | valid loss: 0.017114\n","Epoch:  706 | train loss: 0.009481 | valid loss: 0.017117\n","Epoch:  707 | train loss: 0.014648 | valid loss: 0.017146\n","Epoch:  708 | train loss: 0.011425 | valid loss: 0.017171\n","Epoch:  709 | train loss: 0.020593 | valid loss: 0.017129\n","Epoch:  710 | train loss: 0.018137 | valid loss: 0.017113\n","Epoch:  711 | train loss: 0.013731 | valid loss: 0.017105\n","Epoch:  712 | train loss: 0.016313 | valid loss: 0.017104\n","Epoch:  713 | train loss: 0.010048 | valid loss: 0.017115\n","Epoch:  714 | train loss: 0.016450 | valid loss: 0.017105\n","Epoch:  715 | train loss: 0.018046 | valid loss: 0.017163\n","Epoch:  716 | train loss: 0.030218 | valid loss: 0.017096\n","Epoch:  717 | train loss: 0.015791 | valid loss: 0.017107\n","Epoch:  718 | train loss: 0.009059 | valid loss: 0.017104\n","Epoch:  719 | train loss: 0.019457 | valid loss: 0.017090\n","Epoch:  720 | train loss: 0.020600 | valid loss: 0.017099\n","Epoch:  721 | train loss: 0.012823 | valid loss: 0.017105\n","Epoch:  722 | train loss: 0.020595 | valid loss: 0.017138\n","Epoch:  723 | train loss: 0.026257 | valid loss: 0.017060\n","Epoch:  724 | train loss: 0.016953 | valid loss: 0.017047\n","Epoch:  725 | train loss: 0.014392 | valid loss: 0.017125\n","Epoch:  726 | train loss: 0.015780 | valid loss: 0.017010\n","Epoch:  727 | train loss: 0.020854 | valid loss: 0.017071\n","Epoch:  728 | train loss: 0.011310 | valid loss: 0.017108\n","Epoch:  729 | train loss: 0.014450 | valid loss: 0.017112\n","Epoch:  730 | train loss: 0.013472 | valid loss: 0.017022\n","Epoch:  731 | train loss: 0.020490 | valid loss: 0.017154\n","Epoch:  732 | train loss: 0.021811 | valid loss: 0.017145\n","Epoch:  733 | train loss: 0.026394 | valid loss: 0.017201\n","Epoch:  734 | train loss: 0.013167 | valid loss: 0.017052\n","Epoch:  735 | train loss: 0.012506 | valid loss: 0.017145\n","Epoch:  736 | train loss: 0.009236 | valid loss: 0.017092\n","Epoch:  737 | train loss: 0.010152 | valid loss: 0.017088\n","Epoch:  738 | train loss: 0.011809 | valid loss: 0.017143\n","Epoch:  739 | train loss: 0.019383 | valid loss: 0.017063\n","Epoch:  740 | train loss: 0.020763 | valid loss: 0.017121\n","Epoch:  741 | train loss: 0.014816 | valid loss: 0.017113\n","Epoch:  742 | train loss: 0.013337 | valid loss: 0.017038\n","Epoch:  743 | train loss: 0.019469 | valid loss: 0.017099\n","Epoch:  744 | train loss: 0.024563 | valid loss: 0.017100\n","Epoch:  745 | train loss: 0.016281 | valid loss: 0.017177\n","Epoch:  746 | train loss: 0.015332 | valid loss: 0.017145\n","Epoch:  747 | train loss: 0.021077 | valid loss: 0.017123\n","Epoch:  748 | train loss: 0.013219 | valid loss: 0.017067\n","Epoch:  749 | train loss: 0.016331 | valid loss: 0.017080\n","Epoch:  750 | train loss: 0.020807 | valid loss: 0.017182\n","Epoch:  751 | train loss: 0.011953 | valid loss: 0.017075\n","Epoch:  752 | train loss: 0.013532 | valid loss: 0.017098\n","Epoch:  753 | train loss: 0.016265 | valid loss: 0.017189\n","Epoch:  754 | train loss: 0.020376 | valid loss: 0.017172\n","Epoch:  755 | train loss: 0.021528 | valid loss: 0.017207\n","Epoch:  756 | train loss: 0.011860 | valid loss: 0.017209\n","Epoch:  757 | train loss: 0.020582 | valid loss: 0.017108\n","Epoch:  758 | train loss: 0.011535 | valid loss: 0.017236\n","Epoch:  759 | train loss: 0.014333 | valid loss: 0.017137\n","Epoch:  760 | train loss: 0.016042 | valid loss: 0.017087\n","Epoch:  761 | train loss: 0.017741 | valid loss: 0.017078\n","Epoch:  762 | train loss: 0.010269 | valid loss: 0.017127\n","Epoch:  763 | train loss: 0.016423 | valid loss: 0.017208\n","Epoch:  764 | train loss: 0.024874 | valid loss: 0.017115\n","Epoch:  765 | train loss: 0.026421 | valid loss: 0.017168\n","Epoch:  766 | train loss: 0.024866 | valid loss: 0.017108\n","Epoch:  767 | train loss: 0.013168 | valid loss: 0.017210\n","Epoch:  768 | train loss: 0.016412 | valid loss: 0.017292\n","Epoch:  769 | train loss: 0.025474 | valid loss: 0.017190\n","Epoch:  770 | train loss: 0.021099 | valid loss: 0.017129\n","Epoch:  771 | train loss: 0.012188 | valid loss: 0.017118\n","Epoch:  772 | train loss: 0.019828 | valid loss: 0.017140\n","Epoch:  773 | train loss: 0.018784 | valid loss: 0.017106\n","Epoch:  774 | train loss: 0.019674 | valid loss: 0.017155\n","Epoch:  775 | train loss: 0.028303 | valid loss: 0.017151\n","Epoch:  776 | train loss: 0.011261 | valid loss: 0.017060\n","Epoch:  777 | train loss: 0.021797 | valid loss: 0.017162\n","Epoch:  778 | train loss: 0.019767 | valid loss: 0.017135\n","Epoch:  779 | train loss: 0.015445 | valid loss: 0.017119\n","Epoch:  780 | train loss: 0.011418 | valid loss: 0.017081\n","Epoch:  781 | train loss: 0.011356 | valid loss: 0.017253\n","Epoch:  782 | train loss: 0.013519 | valid loss: 0.017140\n","Epoch:  783 | train loss: 0.014368 | valid loss: 0.017171\n","Epoch:  784 | train loss: 0.010710 | valid loss: 0.017149\n","Epoch:  785 | train loss: 0.020874 | valid loss: 0.017245\n","Epoch:  786 | train loss: 0.020015 | valid loss: 0.017152\n","Epoch:  787 | train loss: 0.016004 | valid loss: 0.017189\n","Epoch:  788 | train loss: 0.016183 | valid loss: 0.017215\n","Epoch:  789 | train loss: 0.017417 | valid loss: 0.017262\n","Epoch:  790 | train loss: 0.013660 | valid loss: 0.017176\n","Epoch:  791 | train loss: 0.012597 | valid loss: 0.017171\n","Epoch:  792 | train loss: 0.014999 | valid loss: 0.017142\n","Epoch:  793 | train loss: 0.015739 | valid loss: 0.017183\n","Epoch:  794 | train loss: 0.018647 | valid loss: 0.017293\n","Epoch:  795 | train loss: 0.019222 | valid loss: 0.017222\n","Epoch:  796 | train loss: 0.017947 | valid loss: 0.017208\n","Epoch:  797 | train loss: 0.020760 | valid loss: 0.017138\n","Epoch:  798 | train loss: 0.008911 | valid loss: 0.017191\n","Epoch:  799 | train loss: 0.012747 | valid loss: 0.017078\n","Epoch:  800 | train loss: 0.015179 | valid loss: 0.017158\n","Epoch:  801 | train loss: 0.026583 | valid loss: 0.017197\n","Epoch:  802 | train loss: 0.017145 | valid loss: 0.017161\n","Epoch:  803 | train loss: 0.009314 | valid loss: 0.017094\n","Epoch:  804 | train loss: 0.015161 | valid loss: 0.017165\n","Epoch:  805 | train loss: 0.011333 | valid loss: 0.017135\n","Epoch:  806 | train loss: 0.017672 | valid loss: 0.017106\n","Epoch:  807 | train loss: 0.022706 | valid loss: 0.017140\n","Epoch:  808 | train loss: 0.019852 | valid loss: 0.017129\n","Epoch:  809 | train loss: 0.022577 | valid loss: 0.017136\n","Epoch:  810 | train loss: 0.018115 | valid loss: 0.017179\n","Epoch:  811 | train loss: 0.015494 | valid loss: 0.017221\n","Epoch:  812 | train loss: 0.016520 | valid loss: 0.017187\n","Epoch:  813 | train loss: 0.017567 | valid loss: 0.017180\n","Epoch:  814 | train loss: 0.019792 | valid loss: 0.017167\n","Epoch:  815 | train loss: 0.019176 | valid loss: 0.017188\n","Epoch:  816 | train loss: 0.011561 | valid loss: 0.017103\n","Epoch:  817 | train loss: 0.019889 | valid loss: 0.017122\n","Epoch:  818 | train loss: 0.021041 | valid loss: 0.017271\n","Epoch:  819 | train loss: 0.017653 | valid loss: 0.017239\n","Epoch:  820 | train loss: 0.010575 | valid loss: 0.017186\n","Epoch:  821 | train loss: 0.015101 | valid loss: 0.017213\n","Epoch:  822 | train loss: 0.020082 | valid loss: 0.017227\n","Epoch:  823 | train loss: 0.017242 | valid loss: 0.017135\n","Epoch:  824 | train loss: 0.015791 | valid loss: 0.017238\n","Epoch:  825 | train loss: 0.022341 | valid loss: 0.017144\n","Epoch:  826 | train loss: 0.021190 | valid loss: 0.017156\n","Epoch:  827 | train loss: 0.012025 | valid loss: 0.017181\n","Epoch:  828 | train loss: 0.021349 | valid loss: 0.017202\n","Epoch:  829 | train loss: 0.020958 | valid loss: 0.017197\n","Epoch:  830 | train loss: 0.019101 | valid loss: 0.017231\n","Epoch:  831 | train loss: 0.015503 | valid loss: 0.017275\n","Epoch:  832 | train loss: 0.009433 | valid loss: 0.017147\n","Epoch:  833 | train loss: 0.012030 | valid loss: 0.017213\n","Epoch:  834 | train loss: 0.018140 | valid loss: 0.017079\n","Epoch:  835 | train loss: 0.020948 | valid loss: 0.017165\n","Epoch:  836 | train loss: 0.015395 | valid loss: 0.017172\n","Epoch:  837 | train loss: 0.018669 | valid loss: 0.017155\n","Epoch:  838 | train loss: 0.022166 | valid loss: 0.017185\n","Epoch:  839 | train loss: 0.016292 | valid loss: 0.017169\n","Epoch:  840 | train loss: 0.016505 | valid loss: 0.017175\n","Epoch:  841 | train loss: 0.017709 | valid loss: 0.017195\n","Epoch:  842 | train loss: 0.012014 | valid loss: 0.017189\n","Epoch:  843 | train loss: 0.022240 | valid loss: 0.017314\n","Epoch:  844 | train loss: 0.026140 | valid loss: 0.017205\n","Epoch:  845 | train loss: 0.017028 | valid loss: 0.017161\n","Epoch:  846 | train loss: 0.022988 | valid loss: 0.017279\n","Epoch:  847 | train loss: 0.018405 | valid loss: 0.017191\n","Epoch:  848 | train loss: 0.010029 | valid loss: 0.017166\n","Epoch:  849 | train loss: 0.013754 | valid loss: 0.017283\n","Epoch:  850 | train loss: 0.026585 | valid loss: 0.017242\n","Epoch:  851 | train loss: 0.015616 | valid loss: 0.017166\n","Epoch:  852 | train loss: 0.015488 | valid loss: 0.017172\n","Epoch:  853 | train loss: 0.021121 | valid loss: 0.017249\n","Epoch:  854 | train loss: 0.015949 | valid loss: 0.017202\n","Epoch:  855 | train loss: 0.024426 | valid loss: 0.017248\n","Epoch:  856 | train loss: 0.013931 | valid loss: 0.017214\n","Epoch:  857 | train loss: 0.010438 | valid loss: 0.017150\n","Epoch:  858 | train loss: 0.012365 | valid loss: 0.017240\n","Epoch:  859 | train loss: 0.019276 | valid loss: 0.017086\n","Epoch:  860 | train loss: 0.018641 | valid loss: 0.017189\n","Epoch:  861 | train loss: 0.026491 | valid loss: 0.017337\n","Epoch:  862 | train loss: 0.012087 | valid loss: 0.017181\n","Epoch:  863 | train loss: 0.018327 | valid loss: 0.017193\n","Epoch:  864 | train loss: 0.007953 | valid loss: 0.017138\n","Epoch:  865 | train loss: 0.017026 | valid loss: 0.017221\n","Epoch:  866 | train loss: 0.018238 | valid loss: 0.017264\n","Epoch:  867 | train loss: 0.016394 | valid loss: 0.017228\n","Epoch:  868 | train loss: 0.015301 | valid loss: 0.017182\n","Epoch:  869 | train loss: 0.015564 | valid loss: 0.017159\n","Epoch:  870 | train loss: 0.014146 | valid loss: 0.017227\n","Epoch:  871 | train loss: 0.018334 | valid loss: 0.017307\n","Epoch:  872 | train loss: 0.018653 | valid loss: 0.017249\n","Epoch:  873 | train loss: 0.021177 | valid loss: 0.017181\n","Epoch:  874 | train loss: 0.013427 | valid loss: 0.017263\n","Epoch:  875 | train loss: 0.018632 | valid loss: 0.017238\n","Epoch:  876 | train loss: 0.013262 | valid loss: 0.017207\n","Epoch:  877 | train loss: 0.021094 | valid loss: 0.017255\n","Epoch:  878 | train loss: 0.009686 | valid loss: 0.017228\n","Epoch:  879 | train loss: 0.020147 | valid loss: 0.017197\n","Epoch:  880 | train loss: 0.015510 | valid loss: 0.017220\n","Epoch:  881 | train loss: 0.026477 | valid loss: 0.017192\n","Epoch:  882 | train loss: 0.020554 | valid loss: 0.017383\n","Epoch:  883 | train loss: 0.024851 | valid loss: 0.017275\n","Epoch:  884 | train loss: 0.027438 | valid loss: 0.017270\n","Epoch:  885 | train loss: 0.011838 | valid loss: 0.017295\n","Epoch:  886 | train loss: 0.017313 | valid loss: 0.017256\n","Epoch:  887 | train loss: 0.019156 | valid loss: 0.017221\n","Epoch:  888 | train loss: 0.020485 | valid loss: 0.017212\n","Epoch:  889 | train loss: 0.016802 | valid loss: 0.017180\n","Epoch:  890 | train loss: 0.012263 | valid loss: 0.017307\n","Epoch:  891 | train loss: 0.021744 | valid loss: 0.017236\n","Epoch:  892 | train loss: 0.016580 | valid loss: 0.017340\n","Epoch:  893 | train loss: 0.025360 | valid loss: 0.017205\n","Epoch:  894 | train loss: 0.010022 | valid loss: 0.017223\n","Epoch:  895 | train loss: 0.018036 | valid loss: 0.017225\n","Epoch:  896 | train loss: 0.007881 | valid loss: 0.017235\n","Epoch:  897 | train loss: 0.012070 | valid loss: 0.017235\n","Epoch:  898 | train loss: 0.013752 | valid loss: 0.017244\n","Epoch:  899 | train loss: 0.016028 | valid loss: 0.017277\n","Epoch:  900 | train loss: 0.018690 | valid loss: 0.017382\n","Epoch:  901 | train loss: 0.021958 | valid loss: 0.017374\n","Epoch:  902 | train loss: 0.019848 | valid loss: 0.017212\n","Epoch:  903 | train loss: 0.034106 | valid loss: 0.017191\n","Epoch:  904 | train loss: 0.032488 | valid loss: 0.017207\n","Epoch:  905 | train loss: 0.013326 | valid loss: 0.017350\n","Epoch:  906 | train loss: 0.016911 | valid loss: 0.017221\n","Epoch:  907 | train loss: 0.010771 | valid loss: 0.017253\n","Epoch:  908 | train loss: 0.012707 | valid loss: 0.017361\n","Epoch:  909 | train loss: 0.017729 | valid loss: 0.017298\n","Epoch:  910 | train loss: 0.011235 | valid loss: 0.017278\n","Epoch:  911 | train loss: 0.016665 | valid loss: 0.017352\n","Epoch:  912 | train loss: 0.017065 | valid loss: 0.017280\n","Epoch:  913 | train loss: 0.013213 | valid loss: 0.017343\n","Epoch:  914 | train loss: 0.011215 | valid loss: 0.017265\n","Epoch:  915 | train loss: 0.021774 | valid loss: 0.017205\n","Epoch:  916 | train loss: 0.009417 | valid loss: 0.017182\n","Epoch:  917 | train loss: 0.011297 | valid loss: 0.017221\n","Epoch:  918 | train loss: 0.009708 | valid loss: 0.017241\n","Epoch:  919 | train loss: 0.016546 | valid loss: 0.017278\n","Epoch:  920 | train loss: 0.017687 | valid loss: 0.017207\n","Epoch:  921 | train loss: 0.018868 | valid loss: 0.017205\n","Epoch:  922 | train loss: 0.016109 | valid loss: 0.017329\n","Epoch:  923 | train loss: 0.016319 | valid loss: 0.017254\n","Epoch:  924 | train loss: 0.011307 | valid loss: 0.017388\n","Epoch:  925 | train loss: 0.016271 | valid loss: 0.017210\n","Epoch:  926 | train loss: 0.016425 | valid loss: 0.017315\n","Epoch:  927 | train loss: 0.018349 | valid loss: 0.017264\n","Epoch:  928 | train loss: 0.018289 | valid loss: 0.017270\n","Epoch:  929 | train loss: 0.011445 | valid loss: 0.017217\n","Epoch:  930 | train loss: 0.011714 | valid loss: 0.017220\n","Epoch:  931 | train loss: 0.018538 | valid loss: 0.017282\n","Epoch:  932 | train loss: 0.008004 | valid loss: 0.017322\n","Epoch:  933 | train loss: 0.021237 | valid loss: 0.017301\n","Epoch:  934 | train loss: 0.018983 | valid loss: 0.017263\n","Epoch:  935 | train loss: 0.009188 | valid loss: 0.017287\n","Epoch:  936 | train loss: 0.009319 | valid loss: 0.017246\n","Epoch:  937 | train loss: 0.022769 | valid loss: 0.017220\n","Epoch:  938 | train loss: 0.018364 | valid loss: 0.017304\n","Epoch:  939 | train loss: 0.014087 | valid loss: 0.017278\n","Epoch:  940 | train loss: 0.019143 | valid loss: 0.017307\n","Epoch:  941 | train loss: 0.010673 | valid loss: 0.017337\n","Epoch:  942 | train loss: 0.010757 | valid loss: 0.017230\n","Epoch:  943 | train loss: 0.012732 | valid loss: 0.017291\n","Epoch:  944 | train loss: 0.014121 | valid loss: 0.017309\n","Epoch:  945 | train loss: 0.008973 | valid loss: 0.017299\n","Epoch:  946 | train loss: 0.010912 | valid loss: 0.017351\n","Epoch:  947 | train loss: 0.017895 | valid loss: 0.017274\n","Epoch:  948 | train loss: 0.010475 | valid loss: 0.017306\n","Epoch:  949 | train loss: 0.009373 | valid loss: 0.017241\n","Epoch:  950 | train loss: 0.024051 | valid loss: 0.017288\n","Epoch:  951 | train loss: 0.010896 | valid loss: 0.017356\n","Epoch:  952 | train loss: 0.024538 | valid loss: 0.017219\n","Epoch:  953 | train loss: 0.008773 | valid loss: 0.017333\n","Epoch:  954 | train loss: 0.018721 | valid loss: 0.017317\n","Epoch:  955 | train loss: 0.013973 | valid loss: 0.017332\n","Epoch:  956 | train loss: 0.024182 | valid loss: 0.017311\n","Epoch:  957 | train loss: 0.024965 | valid loss: 0.017337\n","Epoch:  958 | train loss: 0.030901 | valid loss: 0.017331\n","Epoch:  959 | train loss: 0.022292 | valid loss: 0.017294\n","Epoch:  960 | train loss: 0.015472 | valid loss: 0.017263\n","Epoch:  961 | train loss: 0.021254 | valid loss: 0.017329\n","Epoch:  962 | train loss: 0.013629 | valid loss: 0.017327\n","Epoch:  963 | train loss: 0.018345 | valid loss: 0.017203\n","Epoch:  964 | train loss: 0.026448 | valid loss: 0.017332\n","Epoch:  965 | train loss: 0.015430 | valid loss: 0.017260\n","Epoch:  966 | train loss: 0.019721 | valid loss: 0.017332\n","Epoch:  967 | train loss: 0.015629 | valid loss: 0.017336\n","Epoch:  968 | train loss: 0.017681 | valid loss: 0.017273\n","Epoch:  969 | train loss: 0.018093 | valid loss: 0.017292\n","Epoch:  970 | train loss: 0.017080 | valid loss: 0.017263\n","Epoch:  971 | train loss: 0.018970 | valid loss: 0.017382\n","Epoch:  972 | train loss: 0.021894 | valid loss: 0.017389\n","Epoch:  973 | train loss: 0.024125 | valid loss: 0.017309\n","Epoch:  974 | train loss: 0.020670 | valid loss: 0.017314\n","Epoch:  975 | train loss: 0.009981 | valid loss: 0.017353\n","Epoch:  976 | train loss: 0.013646 | valid loss: 0.017308\n","Epoch:  977 | train loss: 0.013151 | valid loss: 0.017265\n","Epoch:  978 | train loss: 0.022854 | valid loss: 0.017398\n","Epoch:  979 | train loss: 0.021040 | valid loss: 0.017433\n","Epoch:  980 | train loss: 0.020117 | valid loss: 0.017256\n","Epoch:  981 | train loss: 0.018422 | valid loss: 0.017366\n","Epoch:  982 | train loss: 0.013976 | valid loss: 0.017596\n","Epoch:  983 | train loss: 0.010423 | valid loss: 0.017305\n","Epoch:  984 | train loss: 0.015820 | valid loss: 0.017305\n","Epoch:  985 | train loss: 0.011392 | valid loss: 0.017224\n","Epoch:  986 | train loss: 0.019374 | valid loss: 0.017230\n","Epoch:  987 | train loss: 0.007722 | valid loss: 0.017299\n","Epoch:  988 | train loss: 0.015263 | valid loss: 0.017283\n","Epoch:  989 | train loss: 0.019960 | valid loss: 0.017223\n","Epoch:  990 | train loss: 0.013458 | valid loss: 0.017282\n","Epoch:  991 | train loss: 0.016218 | valid loss: 0.017218\n","Epoch:  992 | train loss: 0.014434 | valid loss: 0.017248\n","Epoch:  993 | train loss: 0.019490 | valid loss: 0.017275\n","Epoch:  994 | train loss: 0.011862 | valid loss: 0.017338\n","Epoch:  995 | train loss: 0.019275 | valid loss: 0.017205\n","Epoch:  996 | train loss: 0.011472 | valid loss: 0.017249\n","Epoch:  997 | train loss: 0.012350 | valid loss: 0.017293\n","Epoch:  998 | train loss: 0.013461 | valid loss: 0.017352\n","Epoch:  999 | train loss: 0.018697 | valid loss: 0.017390\n","Epoch:  1000 | train loss: 0.009780 | valid loss: 0.017230\n","Epoch:  1001 | train loss: 0.016378 | valid loss: 0.017295\n","Epoch:  1002 | train loss: 0.018345 | valid loss: 0.017288\n","Epoch:  1003 | train loss: 0.017569 | valid loss: 0.017294\n","Epoch:  1004 | train loss: 0.013071 | valid loss: 0.017304\n","Epoch:  1005 | train loss: 0.010445 | valid loss: 0.017264\n","Epoch:  1006 | train loss: 0.023018 | valid loss: 0.017277\n","Epoch:  1007 | train loss: 0.017285 | valid loss: 0.017275\n","Epoch:  1008 | train loss: 0.021527 | valid loss: 0.017342\n","Epoch:  1009 | train loss: 0.013196 | valid loss: 0.017244\n","Epoch:  1010 | train loss: 0.014566 | valid loss: 0.017327\n","Epoch:  1011 | train loss: 0.011616 | valid loss: 0.017258\n","Epoch:  1012 | train loss: 0.023727 | valid loss: 0.017297\n","Epoch:  1013 | train loss: 0.007008 | valid loss: 0.017364\n","Epoch:  1014 | train loss: 0.014636 | valid loss: 0.017423\n","Epoch:  1015 | train loss: 0.014789 | valid loss: 0.017278\n","Epoch:  1016 | train loss: 0.021936 | valid loss: 0.017344\n","Epoch:  1017 | train loss: 0.012421 | valid loss: 0.017362\n","Epoch:  1018 | train loss: 0.024917 | valid loss: 0.017291\n","Epoch:  1019 | train loss: 0.016450 | valid loss: 0.017304\n","Epoch:  1020 | train loss: 0.016732 | valid loss: 0.017355\n","Epoch:  1021 | train loss: 0.018059 | valid loss: 0.017255\n","Epoch:  1022 | train loss: 0.012033 | valid loss: 0.017298\n","Epoch:  1023 | train loss: 0.017273 | valid loss: 0.017312\n","Epoch:  1024 | train loss: 0.013478 | valid loss: 0.017285\n","Epoch:  1025 | train loss: 0.012381 | valid loss: 0.017437\n","Epoch:  1026 | train loss: 0.022484 | valid loss: 0.017308\n","Epoch:  1027 | train loss: 0.011102 | valid loss: 0.017392\n","Epoch:  1028 | train loss: 0.012125 | valid loss: 0.017305\n","Epoch:  1029 | train loss: 0.011029 | valid loss: 0.017330\n","Epoch:  1030 | train loss: 0.018471 | valid loss: 0.017271\n","Epoch:  1031 | train loss: 0.023513 | valid loss: 0.017306\n","Epoch:  1032 | train loss: 0.016551 | valid loss: 0.017264\n","Epoch:  1033 | train loss: 0.020661 | valid loss: 0.017362\n","Epoch:  1034 | train loss: 0.009508 | valid loss: 0.017449\n","Epoch:  1035 | train loss: 0.016430 | valid loss: 0.017532\n","Epoch:  1036 | train loss: 0.010255 | valid loss: 0.017322\n","Epoch:  1037 | train loss: 0.018237 | valid loss: 0.017348\n","Epoch:  1038 | train loss: 0.014158 | valid loss: 0.017390\n","Epoch:  1039 | train loss: 0.024375 | valid loss: 0.017345\n","Epoch:  1040 | train loss: 0.010716 | valid loss: 0.017296\n","Epoch:  1041 | train loss: 0.008341 | valid loss: 0.017338\n","Epoch:  1042 | train loss: 0.015613 | valid loss: 0.017355\n","Epoch:  1043 | train loss: 0.014542 | valid loss: 0.017287\n","Epoch:  1044 | train loss: 0.011229 | valid loss: 0.017348\n","Epoch:  1045 | train loss: 0.015576 | valid loss: 0.017396\n","Epoch:  1046 | train loss: 0.008820 | valid loss: 0.017305\n","Epoch:  1047 | train loss: 0.015838 | valid loss: 0.017324\n","Epoch:  1048 | train loss: 0.016050 | valid loss: 0.017302\n","Epoch:  1049 | train loss: 0.015139 | valid loss: 0.017454\n","Epoch:  1050 | train loss: 0.022718 | valid loss: 0.017318\n","Epoch:  1051 | train loss: 0.007717 | valid loss: 0.017267\n","Epoch:  1052 | train loss: 0.018869 | valid loss: 0.017372\n","Epoch:  1053 | train loss: 0.016665 | valid loss: 0.017413\n","Epoch:  1054 | train loss: 0.015659 | valid loss: 0.017381\n","Epoch:  1055 | train loss: 0.026177 | valid loss: 0.017344\n","Epoch:  1056 | train loss: 0.023271 | valid loss: 0.017277\n","Epoch:  1057 | train loss: 0.012698 | valid loss: 0.017300\n","Epoch:  1058 | train loss: 0.020842 | valid loss: 0.017336\n","Epoch:  1059 | train loss: 0.027986 | valid loss: 0.017324\n","Epoch:  1060 | train loss: 0.016026 | valid loss: 0.017341\n","Epoch:  1061 | train loss: 0.018737 | valid loss: 0.017322\n","Epoch:  1062 | train loss: 0.017035 | valid loss: 0.017335\n","Epoch:  1063 | train loss: 0.013984 | valid loss: 0.017356\n","Epoch:  1064 | train loss: 0.017366 | valid loss: 0.017415\n","Epoch:  1065 | train loss: 0.022116 | valid loss: 0.017373\n","Epoch:  1066 | train loss: 0.030355 | valid loss: 0.017374\n","Epoch:  1067 | train loss: 0.021339 | valid loss: 0.017331\n","Epoch:  1068 | train loss: 0.017659 | valid loss: 0.017279\n","Epoch:  1069 | train loss: 0.014219 | valid loss: 0.017327\n","Epoch:  1070 | train loss: 0.019714 | valid loss: 0.017334\n","Epoch:  1071 | train loss: 0.023553 | valid loss: 0.017330\n","Epoch:  1072 | train loss: 0.019494 | valid loss: 0.017379\n","Epoch:  1073 | train loss: 0.013570 | valid loss: 0.017320\n","Epoch:  1074 | train loss: 0.022797 | valid loss: 0.017339\n","Epoch:  1075 | train loss: 0.012974 | valid loss: 0.017510\n","Epoch:  1076 | train loss: 0.019726 | valid loss: 0.017330\n","Epoch:  1077 | train loss: 0.020849 | valid loss: 0.017316\n","Epoch:  1078 | train loss: 0.030918 | valid loss: 0.017314\n","Epoch:  1079 | train loss: 0.011341 | valid loss: 0.017366\n","Epoch:  1080 | train loss: 0.027398 | valid loss: 0.017357\n","Epoch:  1081 | train loss: 0.016208 | valid loss: 0.017368\n","Epoch:  1082 | train loss: 0.019918 | valid loss: 0.017363\n","Epoch:  1083 | train loss: 0.021573 | valid loss: 0.017449\n","Epoch:  1084 | train loss: 0.009397 | valid loss: 0.017414\n","Epoch:  1085 | train loss: 0.015861 | valid loss: 0.017389\n","Epoch:  1086 | train loss: 0.017673 | valid loss: 0.017362\n","Epoch:  1087 | train loss: 0.018864 | valid loss: 0.017403\n","Epoch:  1088 | train loss: 0.009930 | valid loss: 0.017402\n","Epoch:  1089 | train loss: 0.016075 | valid loss: 0.017318\n","Epoch:  1090 | train loss: 0.010833 | valid loss: 0.017298\n","Epoch:  1091 | train loss: 0.017376 | valid loss: 0.017319\n","Epoch:  1092 | train loss: 0.016725 | valid loss: 0.017571\n","Epoch:  1093 | train loss: 0.019238 | valid loss: 0.017321\n","Epoch:  1094 | train loss: 0.017873 | valid loss: 0.017355\n","Epoch:  1095 | train loss: 0.015734 | valid loss: 0.017319\n","Epoch:  1096 | train loss: 0.012253 | valid loss: 0.017330\n","Epoch:  1097 | train loss: 0.013385 | valid loss: 0.017327\n","Epoch:  1098 | train loss: 0.015046 | valid loss: 0.017475\n","Epoch:  1099 | train loss: 0.017873 | valid loss: 0.017436\n","Epoch:  1100 | train loss: 0.024577 | valid loss: 0.017378\n","Epoch:  1101 | train loss: 0.019305 | valid loss: 0.017295\n","Epoch:  1102 | train loss: 0.023658 | valid loss: 0.017393\n","Epoch:  1103 | train loss: 0.023429 | valid loss: 0.017373\n","Epoch:  1104 | train loss: 0.012515 | valid loss: 0.017301\n","Epoch:  1105 | train loss: 0.013527 | valid loss: 0.017377\n","Epoch:  1106 | train loss: 0.008993 | valid loss: 0.017392\n","Epoch:  1107 | train loss: 0.026034 | valid loss: 0.017412\n","Epoch:  1108 | train loss: 0.016264 | valid loss: 0.017580\n","Epoch:  1109 | train loss: 0.015238 | valid loss: 0.017377\n","Epoch:  1110 | train loss: 0.016211 | valid loss: 0.017319\n","Epoch:  1111 | train loss: 0.019410 | valid loss: 0.017425\n","Epoch:  1112 | train loss: 0.017816 | valid loss: 0.017368\n","Epoch:  1113 | train loss: 0.019102 | valid loss: 0.017422\n","Epoch:  1114 | train loss: 0.018618 | valid loss: 0.017475\n","Epoch:  1115 | train loss: 0.012591 | valid loss: 0.017323\n","Epoch:  1116 | train loss: 0.017547 | valid loss: 0.017370\n","Epoch:  1117 | train loss: 0.014770 | valid loss: 0.017409\n","Epoch:  1118 | train loss: 0.025377 | valid loss: 0.017349\n","Epoch:  1119 | train loss: 0.011594 | valid loss: 0.017370\n","Epoch:  1120 | train loss: 0.010489 | valid loss: 0.017322\n","Epoch:  1121 | train loss: 0.011352 | valid loss: 0.017347\n","Epoch:  1122 | train loss: 0.016934 | valid loss: 0.017337\n","Epoch:  1123 | train loss: 0.024147 | valid loss: 0.017455\n","Epoch:  1124 | train loss: 0.017716 | valid loss: 0.017395\n","Epoch:  1125 | train loss: 0.011634 | valid loss: 0.017354\n","Epoch:  1126 | train loss: 0.023800 | valid loss: 0.017417\n","Epoch:  1127 | train loss: 0.012096 | valid loss: 0.017420\n","Epoch:  1128 | train loss: 0.013610 | valid loss: 0.017382\n","Epoch:  1129 | train loss: 0.018750 | valid loss: 0.017407\n","Epoch:  1130 | train loss: 0.022513 | valid loss: 0.017457\n","Epoch:  1131 | train loss: 0.020564 | valid loss: 0.017390\n","Epoch:  1132 | train loss: 0.008400 | valid loss: 0.017395\n","Epoch:  1133 | train loss: 0.016685 | valid loss: 0.017442\n","Epoch:  1134 | train loss: 0.015280 | valid loss: 0.017436\n","Epoch:  1135 | train loss: 0.018670 | valid loss: 0.017342\n","Epoch:  1136 | train loss: 0.014063 | valid loss: 0.017348\n","Epoch:  1137 | train loss: 0.014919 | valid loss: 0.017406\n","Epoch:  1138 | train loss: 0.012174 | valid loss: 0.017355\n","Epoch:  1139 | train loss: 0.018717 | valid loss: 0.017415\n","Epoch:  1140 | train loss: 0.030461 | valid loss: 0.017420\n","Epoch:  1141 | train loss: 0.019177 | valid loss: 0.017528\n","Epoch:  1142 | train loss: 0.015767 | valid loss: 0.017436\n","Epoch:  1143 | train loss: 0.013018 | valid loss: 0.017408\n","Epoch:  1144 | train loss: 0.011923 | valid loss: 0.017438\n","Epoch:  1145 | train loss: 0.013820 | valid loss: 0.017373\n","Epoch:  1146 | train loss: 0.017975 | valid loss: 0.017420\n","Epoch:  1147 | train loss: 0.017140 | valid loss: 0.017456\n","Epoch:  1148 | train loss: 0.018945 | valid loss: 0.017433\n","Epoch:  1149 | train loss: 0.026377 | valid loss: 0.017473\n","Epoch:  1150 | train loss: 0.012630 | valid loss: 0.017324\n","Epoch:  1151 | train loss: 0.010615 | valid loss: 0.017388\n","Epoch:  1152 | train loss: 0.022405 | valid loss: 0.017392\n","Epoch:  1153 | train loss: 0.012718 | valid loss: 0.017359\n","Epoch:  1154 | train loss: 0.031719 | valid loss: 0.017402\n","Epoch:  1155 | train loss: 0.020759 | valid loss: 0.017355\n","Epoch:  1156 | train loss: 0.012526 | valid loss: 0.017373\n","Epoch:  1157 | train loss: 0.024358 | valid loss: 0.017467\n","Epoch:  1158 | train loss: 0.021277 | valid loss: 0.017499\n","Epoch:  1159 | train loss: 0.011033 | valid loss: 0.017373\n","Epoch:  1160 | train loss: 0.022710 | valid loss: 0.017435\n","Epoch:  1161 | train loss: 0.013986 | valid loss: 0.017397\n","Epoch:  1162 | train loss: 0.017352 | valid loss: 0.017332\n","Epoch:  1163 | train loss: 0.010684 | valid loss: 0.017384\n","Epoch:  1164 | train loss: 0.029937 | valid loss: 0.017344\n","Epoch:  1165 | train loss: 0.014302 | valid loss: 0.017369\n","Epoch:  1166 | train loss: 0.012870 | valid loss: 0.017437\n","Epoch:  1167 | train loss: 0.019472 | valid loss: 0.017336\n","Epoch:  1168 | train loss: 0.009709 | valid loss: 0.017387\n","Epoch:  1169 | train loss: 0.012065 | valid loss: 0.017425\n","Epoch:  1170 | train loss: 0.013180 | valid loss: 0.017369\n","Epoch:  1171 | train loss: 0.017047 | valid loss: 0.017475\n","Epoch:  1172 | train loss: 0.018317 | valid loss: 0.017442\n","Epoch:  1173 | train loss: 0.016879 | valid loss: 0.017366\n","Epoch:  1174 | train loss: 0.020130 | valid loss: 0.017286\n","Epoch:  1175 | train loss: 0.017634 | valid loss: 0.017358\n","Epoch:  1176 | train loss: 0.013584 | valid loss: 0.017436\n","Epoch:  1177 | train loss: 0.008754 | valid loss: 0.017435\n","Epoch:  1178 | train loss: 0.010972 | valid loss: 0.017438\n","Epoch:  1179 | train loss: 0.020338 | valid loss: 0.017512\n","Epoch:  1180 | train loss: 0.020812 | valid loss: 0.017445\n","Epoch:  1181 | train loss: 0.016209 | valid loss: 0.017542\n","Epoch:  1182 | train loss: 0.013523 | valid loss: 0.017352\n","Epoch:  1183 | train loss: 0.015083 | valid loss: 0.017474\n","Epoch:  1184 | train loss: 0.021336 | valid loss: 0.017387\n","Epoch:  1185 | train loss: 0.024792 | valid loss: 0.017390\n","Epoch:  1186 | train loss: 0.016754 | valid loss: 0.017421\n","Epoch:  1187 | train loss: 0.017268 | valid loss: 0.017415\n","Epoch:  1188 | train loss: 0.023153 | valid loss: 0.017433\n","Epoch:  1189 | train loss: 0.023863 | valid loss: 0.017405\n","Epoch:  1190 | train loss: 0.021372 | valid loss: 0.017437\n","Epoch:  1191 | train loss: 0.009127 | valid loss: 0.017477\n","Epoch:  1192 | train loss: 0.014380 | valid loss: 0.017423\n","Epoch:  1193 | train loss: 0.011399 | valid loss: 0.017383\n","Epoch:  1194 | train loss: 0.030698 | valid loss: 0.017551\n","Epoch:  1195 | train loss: 0.020614 | valid loss: 0.017364\n","Epoch:  1196 | train loss: 0.015546 | valid loss: 0.017476\n","Epoch:  1197 | train loss: 0.007559 | valid loss: 0.017354\n","Epoch:  1198 | train loss: 0.020213 | valid loss: 0.017506\n","Epoch:  1199 | train loss: 0.007298 | valid loss: 0.017428\n","Epoch:  1200 | train loss: 0.011747 | valid loss: 0.017396\n","Epoch:  1201 | train loss: 0.011216 | valid loss: 0.017460\n","Epoch:  1202 | train loss: 0.019372 | valid loss: 0.017387\n","Epoch:  1203 | train loss: 0.021597 | valid loss: 0.017424\n","Epoch:  1204 | train loss: 0.007316 | valid loss: 0.017371\n","Epoch:  1205 | train loss: 0.012349 | valid loss: 0.017354\n","Epoch:  1206 | train loss: 0.012745 | valid loss: 0.017383\n","Epoch:  1207 | train loss: 0.011386 | valid loss: 0.017367\n","Epoch:  1208 | train loss: 0.010799 | valid loss: 0.017385\n","Epoch:  1209 | train loss: 0.018590 | valid loss: 0.017480\n","Epoch:  1210 | train loss: 0.018297 | valid loss: 0.017394\n","Epoch:  1211 | train loss: 0.027021 | valid loss: 0.017312\n","Epoch:  1212 | train loss: 0.009341 | valid loss: 0.017424\n","Epoch:  1213 | train loss: 0.015303 | valid loss: 0.017410\n","Epoch:  1214 | train loss: 0.016341 | valid loss: 0.017506\n","Epoch:  1215 | train loss: 0.014394 | valid loss: 0.017417\n","Epoch:  1216 | train loss: 0.021320 | valid loss: 0.017502\n","Epoch:  1217 | train loss: 0.017173 | valid loss: 0.017343\n","Epoch:  1218 | train loss: 0.012138 | valid loss: 0.017492\n","Epoch:  1219 | train loss: 0.013334 | valid loss: 0.017449\n","Epoch:  1220 | train loss: 0.015110 | valid loss: 0.017498\n","Epoch:  1221 | train loss: 0.011341 | valid loss: 0.017488\n","Epoch:  1222 | train loss: 0.016454 | valid loss: 0.017428\n","Epoch:  1223 | train loss: 0.015086 | valid loss: 0.017434\n","Epoch:  1224 | train loss: 0.013799 | valid loss: 0.017431\n","Epoch:  1225 | train loss: 0.011543 | valid loss: 0.017398\n","Epoch:  1226 | train loss: 0.014959 | valid loss: 0.017455\n","Epoch:  1227 | train loss: 0.021021 | valid loss: 0.017469\n","Epoch:  1228 | train loss: 0.019551 | valid loss: 0.017420\n","Epoch:  1229 | train loss: 0.018186 | valid loss: 0.017484\n","Epoch:  1230 | train loss: 0.023765 | valid loss: 0.017454\n","Epoch:  1231 | train loss: 0.011328 | valid loss: 0.017501\n","Epoch:  1232 | train loss: 0.019085 | valid loss: 0.017466\n","Epoch:  1233 | train loss: 0.012374 | valid loss: 0.017386\n","Epoch:  1234 | train loss: 0.029798 | valid loss: 0.017405\n","Epoch:  1235 | train loss: 0.021937 | valid loss: 0.017546\n","Epoch:  1236 | train loss: 0.013338 | valid loss: 0.017382\n","Epoch:  1237 | train loss: 0.013599 | valid loss: 0.017390\n","Epoch:  1238 | train loss: 0.022340 | valid loss: 0.017471\n","Epoch:  1239 | train loss: 0.017720 | valid loss: 0.017622\n","Epoch:  1240 | train loss: 0.019962 | valid loss: 0.017445\n","Epoch:  1241 | train loss: 0.023301 | valid loss: 0.017481\n","Epoch:  1242 | train loss: 0.018984 | valid loss: 0.017408\n","Epoch:  1243 | train loss: 0.015372 | valid loss: 0.017509\n","Epoch:  1244 | train loss: 0.012620 | valid loss: 0.017419\n","Epoch:  1245 | train loss: 0.015201 | valid loss: 0.017488\n","Epoch:  1246 | train loss: 0.011939 | valid loss: 0.017446\n","Epoch:  1247 | train loss: 0.015710 | valid loss: 0.017464\n","Epoch:  1248 | train loss: 0.012189 | valid loss: 0.017374\n","Epoch:  1249 | train loss: 0.016382 | valid loss: 0.017409\n","Epoch:  1250 | train loss: 0.017452 | valid loss: 0.017409\n","Epoch:  1251 | train loss: 0.013214 | valid loss: 0.017383\n","Epoch:  1252 | train loss: 0.020563 | valid loss: 0.017475\n","Epoch:  1253 | train loss: 0.020436 | valid loss: 0.017344\n","Epoch:  1254 | train loss: 0.019248 | valid loss: 0.017440\n","Epoch:  1255 | train loss: 0.013468 | valid loss: 0.017444\n","Epoch:  1256 | train loss: 0.008763 | valid loss: 0.017453\n","Epoch:  1257 | train loss: 0.017866 | valid loss: 0.017482\n","Epoch:  1258 | train loss: 0.023034 | valid loss: 0.017470\n","Epoch:  1259 | train loss: 0.020351 | valid loss: 0.017649\n","Epoch:  1260 | train loss: 0.019028 | valid loss: 0.017561\n","Epoch:  1261 | train loss: 0.014368 | valid loss: 0.017470\n","Epoch:  1262 | train loss: 0.017246 | valid loss: 0.017495\n","Epoch:  1263 | train loss: 0.012644 | valid loss: 0.017432\n","Epoch:  1264 | train loss: 0.019840 | valid loss: 0.017389\n","Epoch:  1265 | train loss: 0.022171 | valid loss: 0.017432\n","Epoch:  1266 | train loss: 0.022987 | valid loss: 0.017397\n","Epoch:  1267 | train loss: 0.011299 | valid loss: 0.017445\n","Epoch:  1268 | train loss: 0.025830 | valid loss: 0.017372\n","Epoch:  1269 | train loss: 0.018024 | valid loss: 0.017416\n","Epoch:  1270 | train loss: 0.018151 | valid loss: 0.017450\n","Epoch:  1271 | train loss: 0.014588 | valid loss: 0.017440\n","Epoch:  1272 | train loss: 0.010405 | valid loss: 0.017528\n","Epoch:  1273 | train loss: 0.022785 | valid loss: 0.017501\n","Epoch:  1274 | train loss: 0.013839 | valid loss: 0.017418\n","Epoch:  1275 | train loss: 0.032407 | valid loss: 0.017574\n","Epoch:  1276 | train loss: 0.021611 | valid loss: 0.017457\n","Epoch:  1277 | train loss: 0.022164 | valid loss: 0.017430\n","Epoch:  1278 | train loss: 0.014644 | valid loss: 0.017416\n","Epoch:  1279 | train loss: 0.018917 | valid loss: 0.017450\n","Epoch:  1280 | train loss: 0.019935 | valid loss: 0.017455\n","Epoch:  1281 | train loss: 0.013152 | valid loss: 0.017481\n","Epoch:  1282 | train loss: 0.025011 | valid loss: 0.017491\n","Epoch:  1283 | train loss: 0.017816 | valid loss: 0.017520\n","Epoch:  1284 | train loss: 0.017909 | valid loss: 0.017438\n","Epoch:  1285 | train loss: 0.013136 | valid loss: 0.017408\n","Epoch:  1286 | train loss: 0.012905 | valid loss: 0.017531\n","Epoch:  1287 | train loss: 0.014397 | valid loss: 0.017449\n","Epoch:  1288 | train loss: 0.019436 | valid loss: 0.017395\n","Epoch:  1289 | train loss: 0.016668 | valid loss: 0.017445\n","Epoch:  1290 | train loss: 0.018229 | valid loss: 0.017521\n","Epoch:  1291 | train loss: 0.016204 | valid loss: 0.017424\n","Epoch:  1292 | train loss: 0.011682 | valid loss: 0.017422\n","Epoch:  1293 | train loss: 0.015118 | valid loss: 0.017465\n","Epoch:  1294 | train loss: 0.017826 | valid loss: 0.017475\n","Epoch:  1295 | train loss: 0.015584 | valid loss: 0.017459\n","Epoch:  1296 | train loss: 0.012753 | valid loss: 0.017396\n","Epoch:  1297 | train loss: 0.016636 | valid loss: 0.017473\n","Epoch:  1298 | train loss: 0.024209 | valid loss: 0.017423\n","Epoch:  1299 | train loss: 0.015585 | valid loss: 0.017525\n","Epoch:  1300 | train loss: 0.017889 | valid loss: 0.017403\n","Epoch:  1301 | train loss: 0.018514 | valid loss: 0.017503\n","Epoch:  1302 | train loss: 0.010936 | valid loss: 0.017494\n","Epoch:  1303 | train loss: 0.013141 | valid loss: 0.017549\n","Epoch:  1304 | train loss: 0.011075 | valid loss: 0.017626\n","Epoch:  1305 | train loss: 0.018944 | valid loss: 0.017399\n","Epoch:  1306 | train loss: 0.010399 | valid loss: 0.017401\n","Epoch:  1307 | train loss: 0.012061 | valid loss: 0.017461\n","Epoch:  1308 | train loss: 0.024722 | valid loss: 0.017435\n","Epoch:  1309 | train loss: 0.013319 | valid loss: 0.017482\n","Epoch:  1310 | train loss: 0.010080 | valid loss: 0.017437\n","Epoch:  1311 | train loss: 0.018986 | valid loss: 0.017412\n","Epoch:  1312 | train loss: 0.020414 | valid loss: 0.017518\n","Epoch:  1313 | train loss: 0.016515 | valid loss: 0.017610\n","Epoch:  1314 | train loss: 0.018502 | valid loss: 0.017514\n","Epoch:  1315 | train loss: 0.022029 | valid loss: 0.017427\n","Epoch:  1316 | train loss: 0.024055 | valid loss: 0.017492\n","Epoch:  1317 | train loss: 0.014490 | valid loss: 0.017474\n","Epoch:  1318 | train loss: 0.016519 | valid loss: 0.017421\n","Epoch:  1319 | train loss: 0.014149 | valid loss: 0.017439\n","Epoch:  1320 | train loss: 0.017569 | valid loss: 0.017446\n","Epoch:  1321 | train loss: 0.022909 | valid loss: 0.017521\n","Epoch:  1322 | train loss: 0.010822 | valid loss: 0.017383\n","Epoch:  1323 | train loss: 0.011520 | valid loss: 0.017490\n","Epoch:  1324 | train loss: 0.012631 | valid loss: 0.017460\n","Epoch:  1325 | train loss: 0.012727 | valid loss: 0.017529\n","Epoch:  1326 | train loss: 0.023967 | valid loss: 0.017476\n","Epoch:  1327 | train loss: 0.008811 | valid loss: 0.017594\n","Epoch:  1328 | train loss: 0.007739 | valid loss: 0.017510\n","Epoch:  1329 | train loss: 0.009665 | valid loss: 0.017513\n","Epoch:  1330 | train loss: 0.013085 | valid loss: 0.017523\n","Epoch:  1331 | train loss: 0.014359 | valid loss: 0.017548\n","Epoch:  1332 | train loss: 0.014410 | valid loss: 0.017638\n","Epoch:  1333 | train loss: 0.019723 | valid loss: 0.017433\n","Epoch:  1334 | train loss: 0.022441 | valid loss: 0.017536\n","Epoch:  1335 | train loss: 0.014290 | valid loss: 0.017453\n","Epoch:  1336 | train loss: 0.012442 | valid loss: 0.017506\n","Epoch:  1337 | train loss: 0.012131 | valid loss: 0.017479\n","Epoch:  1338 | train loss: 0.015644 | valid loss: 0.017453\n","Epoch:  1339 | train loss: 0.024221 | valid loss: 0.017419\n","Epoch:  1340 | train loss: 0.013107 | valid loss: 0.017470\n","Epoch:  1341 | train loss: 0.010574 | valid loss: 0.017452\n","Epoch:  1342 | train loss: 0.015816 | valid loss: 0.017510\n","Epoch:  1343 | train loss: 0.015211 | valid loss: 0.017453\n","Epoch:  1344 | train loss: 0.013044 | valid loss: 0.017426\n","Epoch:  1345 | train loss: 0.017544 | valid loss: 0.017568\n","Epoch:  1346 | train loss: 0.012245 | valid loss: 0.017518\n","Epoch:  1347 | train loss: 0.015834 | valid loss: 0.017445\n","Epoch:  1348 | train loss: 0.021106 | valid loss: 0.017464\n","Epoch:  1349 | train loss: 0.010447 | valid loss: 0.017489\n","Epoch:  1350 | train loss: 0.015401 | valid loss: 0.017543\n","Epoch:  1351 | train loss: 0.011720 | valid loss: 0.017422\n","Epoch:  1352 | train loss: 0.011379 | valid loss: 0.017481\n","Epoch:  1353 | train loss: 0.020649 | valid loss: 0.017632\n","Epoch:  1354 | train loss: 0.015170 | valid loss: 0.017576\n","Epoch:  1355 | train loss: 0.017986 | valid loss: 0.017547\n","Epoch:  1356 | train loss: 0.014286 | valid loss: 0.017566\n","Epoch:  1357 | train loss: 0.009754 | valid loss: 0.017492\n","Epoch:  1358 | train loss: 0.021574 | valid loss: 0.017531\n","Epoch:  1359 | train loss: 0.020290 | valid loss: 0.017476\n","Epoch:  1360 | train loss: 0.022593 | valid loss: 0.017465\n","Epoch:  1361 | train loss: 0.029494 | valid loss: 0.017550\n","Epoch:  1362 | train loss: 0.008471 | valid loss: 0.017500\n","Epoch:  1363 | train loss: 0.016653 | valid loss: 0.017519\n","Epoch:  1364 | train loss: 0.018534 | valid loss: 0.017533\n","Epoch:  1365 | train loss: 0.013297 | valid loss: 0.017564\n","Epoch:  1366 | train loss: 0.008762 | valid loss: 0.017558\n","Epoch:  1367 | train loss: 0.019632 | valid loss: 0.017533\n","Epoch:  1368 | train loss: 0.014200 | valid loss: 0.017554\n","Epoch:  1369 | train loss: 0.018085 | valid loss: 0.017549\n","Epoch:  1370 | train loss: 0.019120 | valid loss: 0.017556\n","Epoch:  1371 | train loss: 0.028403 | valid loss: 0.017610\n","Epoch:  1372 | train loss: 0.014710 | valid loss: 0.017530\n","Epoch:  1373 | train loss: 0.016986 | valid loss: 0.017452\n","Epoch:  1374 | train loss: 0.007519 | valid loss: 0.017483\n","Epoch:  1375 | train loss: 0.011567 | valid loss: 0.017456\n","Epoch:  1376 | train loss: 0.018105 | valid loss: 0.017465\n","Epoch:  1377 | train loss: 0.024590 | valid loss: 0.017489\n","Epoch:  1378 | train loss: 0.014732 | valid loss: 0.017617\n","Epoch:  1379 | train loss: 0.021803 | valid loss: 0.017537\n","Epoch:  1380 | train loss: 0.019209 | valid loss: 0.017538\n","Epoch:  1381 | train loss: 0.013340 | valid loss: 0.017552\n","Epoch:  1382 | train loss: 0.012584 | valid loss: 0.017511\n","Epoch:  1383 | train loss: 0.017512 | valid loss: 0.017566\n","Epoch:  1384 | train loss: 0.019928 | valid loss: 0.017542\n","Epoch:  1385 | train loss: 0.017260 | valid loss: 0.017528\n","Epoch:  1386 | train loss: 0.021868 | valid loss: 0.017517\n","Epoch:  1387 | train loss: 0.016249 | valid loss: 0.017483\n","Epoch:  1388 | train loss: 0.013299 | valid loss: 0.017544\n","Epoch:  1389 | train loss: 0.017316 | valid loss: 0.017516\n","Epoch:  1390 | train loss: 0.012420 | valid loss: 0.017614\n","Epoch:  1391 | train loss: 0.021025 | valid loss: 0.017476\n","Epoch:  1392 | train loss: 0.026410 | valid loss: 0.017485\n","Epoch:  1393 | train loss: 0.017964 | valid loss: 0.017497\n","Epoch:  1394 | train loss: 0.013985 | valid loss: 0.017651\n","Epoch:  1395 | train loss: 0.021889 | valid loss: 0.017605\n","Epoch:  1396 | train loss: 0.013856 | valid loss: 0.017539\n","Epoch:  1397 | train loss: 0.009148 | valid loss: 0.017490\n","Epoch:  1398 | train loss: 0.015401 | valid loss: 0.017496\n","Epoch:  1399 | train loss: 0.029606 | valid loss: 0.017460\n","Epoch:  1400 | train loss: 0.018632 | valid loss: 0.017495\n","Epoch:  1401 | train loss: 0.012689 | valid loss: 0.017484\n","Epoch:  1402 | train loss: 0.009229 | valid loss: 0.017666\n","Epoch:  1403 | train loss: 0.024751 | valid loss: 0.017478\n","Epoch:  1404 | train loss: 0.021731 | valid loss: 0.017582\n","Epoch:  1405 | train loss: 0.009999 | valid loss: 0.017468\n","Epoch:  1406 | train loss: 0.027031 | valid loss: 0.017611\n","Epoch:  1407 | train loss: 0.019621 | valid loss: 0.017486\n","Epoch:  1408 | train loss: 0.018600 | valid loss: 0.017514\n","Epoch:  1409 | train loss: 0.014192 | valid loss: 0.017616\n","Epoch:  1410 | train loss: 0.022283 | valid loss: 0.017562\n","Epoch:  1411 | train loss: 0.028889 | valid loss: 0.017595\n","Epoch:  1412 | train loss: 0.015930 | valid loss: 0.017538\n","Epoch:  1413 | train loss: 0.020959 | valid loss: 0.017487\n","Epoch:  1414 | train loss: 0.014220 | valid loss: 0.017511\n","Epoch:  1415 | train loss: 0.014492 | valid loss: 0.017478\n","Epoch:  1416 | train loss: 0.011437 | valid loss: 0.017526\n","Epoch:  1417 | train loss: 0.016415 | valid loss: 0.017540\n","Epoch:  1418 | train loss: 0.023438 | valid loss: 0.017549\n","Epoch:  1419 | train loss: 0.017167 | valid loss: 0.017453\n","Epoch:  1420 | train loss: 0.014652 | valid loss: 0.017509\n","Epoch:  1421 | train loss: 0.012011 | valid loss: 0.017489\n","Epoch:  1422 | train loss: 0.018787 | valid loss: 0.017542\n","Epoch:  1423 | train loss: 0.011836 | valid loss: 0.017555\n","Epoch:  1424 | train loss: 0.021896 | valid loss: 0.017541\n","Epoch:  1425 | train loss: 0.013099 | valid loss: 0.017622\n","Epoch:  1426 | train loss: 0.013794 | valid loss: 0.017583\n","Epoch:  1427 | train loss: 0.010804 | valid loss: 0.017499\n","Epoch:  1428 | train loss: 0.019641 | valid loss: 0.017628\n","Epoch:  1429 | train loss: 0.021698 | valid loss: 0.017496\n","Epoch:  1430 | train loss: 0.018340 | valid loss: 0.017592\n","Epoch:  1431 | train loss: 0.018839 | valid loss: 0.017887\n","Epoch:  1432 | train loss: 0.016038 | valid loss: 0.017526\n","Epoch:  1433 | train loss: 0.020751 | valid loss: 0.017550\n","Epoch:  1434 | train loss: 0.018469 | valid loss: 0.017496\n","Epoch:  1435 | train loss: 0.022378 | valid loss: 0.017504\n","Epoch:  1436 | train loss: 0.022715 | valid loss: 0.017551\n","Epoch:  1437 | train loss: 0.015524 | valid loss: 0.017495\n","Epoch:  1438 | train loss: 0.019859 | valid loss: 0.017499\n","Epoch:  1439 | train loss: 0.012110 | valid loss: 0.017489\n","Epoch:  1440 | train loss: 0.026738 | valid loss: 0.017600\n","Epoch:  1441 | train loss: 0.022750 | valid loss: 0.017614\n","Epoch:  1442 | train loss: 0.012938 | valid loss: 0.017563\n","Epoch:  1443 | train loss: 0.017835 | valid loss: 0.017547\n","Epoch:  1444 | train loss: 0.008194 | valid loss: 0.017640\n","Epoch:  1445 | train loss: 0.016657 | valid loss: 0.017568\n","Epoch:  1446 | train loss: 0.013925 | valid loss: 0.017481\n","Epoch:  1447 | train loss: 0.018653 | valid loss: 0.017610\n","Epoch:  1448 | train loss: 0.025137 | valid loss: 0.017538\n","Epoch:  1449 | train loss: 0.013389 | valid loss: 0.017607\n","Epoch:  1450 | train loss: 0.014140 | valid loss: 0.017511\n","Epoch:  1451 | train loss: 0.011302 | valid loss: 0.017562\n","Epoch:  1452 | train loss: 0.016471 | valid loss: 0.017505\n","Epoch:  1453 | train loss: 0.015182 | valid loss: 0.017580\n","Epoch:  1454 | train loss: 0.010495 | valid loss: 0.017578\n","Epoch:  1455 | train loss: 0.024551 | valid loss: 0.017541\n","Epoch:  1456 | train loss: 0.016974 | valid loss: 0.017555\n","Epoch:  1457 | train loss: 0.027608 | valid loss: 0.017658\n","Epoch:  1458 | train loss: 0.014791 | valid loss: 0.017667\n","Epoch:  1459 | train loss: 0.014368 | valid loss: 0.017604\n","Epoch:  1460 | train loss: 0.012510 | valid loss: 0.017528\n","Epoch:  1461 | train loss: 0.011787 | valid loss: 0.017543\n","Epoch:  1462 | train loss: 0.032644 | valid loss: 0.017558\n","Epoch:  1463 | train loss: 0.012332 | valid loss: 0.017605\n","Epoch:  1464 | train loss: 0.016038 | valid loss: 0.017545\n","Epoch:  1465 | train loss: 0.020814 | valid loss: 0.017550\n","Epoch:  1466 | train loss: 0.012896 | valid loss: 0.017502\n","Epoch:  1467 | train loss: 0.010420 | valid loss: 0.017682\n","Epoch:  1468 | train loss: 0.023930 | valid loss: 0.017607\n","Epoch:  1469 | train loss: 0.023060 | valid loss: 0.017576\n","Epoch:  1470 | train loss: 0.026256 | valid loss: 0.017486\n","Epoch:  1471 | train loss: 0.015232 | valid loss: 0.017557\n","Epoch:  1472 | train loss: 0.015887 | valid loss: 0.017484\n","Epoch:  1473 | train loss: 0.011235 | valid loss: 0.017586\n","Epoch:  1474 | train loss: 0.012156 | valid loss: 0.017694\n","Epoch:  1475 | train loss: 0.016469 | valid loss: 0.017577\n","Epoch:  1476 | train loss: 0.019204 | valid loss: 0.017587\n","Epoch:  1477 | train loss: 0.016815 | valid loss: 0.017574\n","Epoch:  1478 | train loss: 0.018383 | valid loss: 0.017576\n","Epoch:  1479 | train loss: 0.012121 | valid loss: 0.017543\n","Epoch:  1480 | train loss: 0.017460 | valid loss: 0.017531\n","Epoch:  1481 | train loss: 0.014013 | valid loss: 0.017532\n","Epoch:  1482 | train loss: 0.017030 | valid loss: 0.017518\n","Epoch:  1483 | train loss: 0.019189 | valid loss: 0.017642\n","Epoch:  1484 | train loss: 0.018990 | valid loss: 0.017559\n","Epoch:  1485 | train loss: 0.016450 | valid loss: 0.017684\n","Epoch:  1486 | train loss: 0.014008 | valid loss: 0.017789\n","Epoch:  1487 | train loss: 0.014591 | valid loss: 0.017596\n","Epoch:  1488 | train loss: 0.018964 | valid loss: 0.017518\n","Epoch:  1489 | train loss: 0.019407 | valid loss: 0.017560\n","Epoch:  1490 | train loss: 0.017260 | valid loss: 0.017542\n","Epoch:  1491 | train loss: 0.015307 | valid loss: 0.017585\n","Epoch:  1492 | train loss: 0.027879 | valid loss: 0.017578\n","Epoch:  1493 | train loss: 0.021669 | valid loss: 0.017534\n","Epoch:  1494 | train loss: 0.012243 | valid loss: 0.017588\n","Epoch:  1495 | train loss: 0.017447 | valid loss: 0.017602\n","Epoch:  1496 | train loss: 0.013504 | valid loss: 0.017514\n","Epoch:  1497 | train loss: 0.020697 | valid loss: 0.017650\n","Epoch:  1498 | train loss: 0.023547 | valid loss: 0.017530\n","Epoch:  1499 | train loss: 0.013374 | valid loss: 0.017529\n","Epoch:  1500 | train loss: 0.018405 | valid loss: 0.017558\n","Epoch:  1501 | train loss: 0.016323 | valid loss: 0.017521\n","Epoch:  1502 | train loss: 0.018820 | valid loss: 0.017632\n","Epoch:  1503 | train loss: 0.015836 | valid loss: 0.017569\n","Epoch:  1504 | train loss: 0.012995 | valid loss: 0.017642\n","Epoch:  1505 | train loss: 0.018922 | valid loss: 0.017574\n","Epoch:  1506 | train loss: 0.016944 | valid loss: 0.017669\n","Epoch:  1507 | train loss: 0.018718 | valid loss: 0.017601\n","Epoch:  1508 | train loss: 0.019560 | valid loss: 0.017632\n","Epoch:  1509 | train loss: 0.015189 | valid loss: 0.017619\n","Epoch:  1510 | train loss: 0.020701 | valid loss: 0.017569\n","Epoch:  1511 | train loss: 0.007523 | valid loss: 0.017588\n","Epoch:  1512 | train loss: 0.022433 | valid loss: 0.017798\n","Epoch:  1513 | train loss: 0.021556 | valid loss: 0.017700\n","Epoch:  1514 | train loss: 0.013664 | valid loss: 0.017663\n","Epoch:  1515 | train loss: 0.014507 | valid loss: 0.017562\n","Epoch:  1516 | train loss: 0.019452 | valid loss: 0.017573\n","Epoch:  1517 | train loss: 0.016805 | valid loss: 0.017548\n","Epoch:  1518 | train loss: 0.013360 | valid loss: 0.017489\n","Epoch:  1519 | train loss: 0.019139 | valid loss: 0.017520\n","Epoch:  1520 | train loss: 0.025386 | valid loss: 0.017558\n","Epoch:  1521 | train loss: 0.007160 | valid loss: 0.017489\n","Epoch:  1522 | train loss: 0.010204 | valid loss: 0.017552\n","Epoch:  1523 | train loss: 0.026758 | valid loss: 0.017579\n","Epoch:  1524 | train loss: 0.011067 | valid loss: 0.017590\n","Epoch:  1525 | train loss: 0.016055 | valid loss: 0.017550\n","Epoch:  1526 | train loss: 0.018800 | valid loss: 0.017586\n","Epoch:  1527 | train loss: 0.015624 | valid loss: 0.017633\n","Epoch:  1528 | train loss: 0.013187 | valid loss: 0.017589\n","Epoch:  1529 | train loss: 0.018137 | valid loss: 0.017677\n","Epoch:  1530 | train loss: 0.023957 | valid loss: 0.017689\n","Epoch:  1531 | train loss: 0.016463 | valid loss: 0.017708\n","Epoch:  1532 | train loss: 0.013844 | valid loss: 0.017540\n","Epoch:  1533 | train loss: 0.010416 | valid loss: 0.017599\n","Epoch:  1534 | train loss: 0.019471 | valid loss: 0.017543\n","Epoch:  1535 | train loss: 0.006924 | valid loss: 0.017516\n","Epoch:  1536 | train loss: 0.020918 | valid loss: 0.017552\n","Epoch:  1537 | train loss: 0.017107 | valid loss: 0.017592\n","Epoch:  1538 | train loss: 0.015408 | valid loss: 0.017663\n","Epoch:  1539 | train loss: 0.019980 | valid loss: 0.017666\n","Epoch:  1540 | train loss: 0.015626 | valid loss: 0.017548\n","Epoch:  1541 | train loss: 0.011570 | valid loss: 0.017604\n","Epoch:  1542 | train loss: 0.016744 | valid loss: 0.017563\n","Epoch:  1543 | train loss: 0.008092 | valid loss: 0.017567\n","Epoch:  1544 | train loss: 0.031312 | valid loss: 0.017599\n","Epoch:  1545 | train loss: 0.011583 | valid loss: 0.017637\n","Epoch:  1546 | train loss: 0.012128 | valid loss: 0.017770\n","Epoch:  1547 | train loss: 0.025750 | valid loss: 0.017625\n","Epoch:  1548 | train loss: 0.024016 | valid loss: 0.017553\n","Epoch:  1549 | train loss: 0.014236 | valid loss: 0.017613\n","Epoch:  1550 | train loss: 0.018167 | valid loss: 0.017547\n","Epoch:  1551 | train loss: 0.016430 | valid loss: 0.017587\n","Epoch:  1552 | train loss: 0.022078 | valid loss: 0.017607\n","Epoch:  1553 | train loss: 0.016877 | valid loss: 0.017752\n","Epoch:  1554 | train loss: 0.015192 | valid loss: 0.017627\n","Epoch:  1555 | train loss: 0.015786 | valid loss: 0.017507\n","Epoch:  1556 | train loss: 0.016109 | valid loss: 0.017711\n","Epoch:  1557 | train loss: 0.014970 | valid loss: 0.017716\n","Epoch:  1558 | train loss: 0.017972 | valid loss: 0.017595\n","Epoch:  1559 | train loss: 0.010405 | valid loss: 0.017580\n","Epoch:  1560 | train loss: 0.011329 | valid loss: 0.017700\n","Epoch:  1561 | train loss: 0.019892 | valid loss: 0.017599\n","Epoch:  1562 | train loss: 0.019742 | valid loss: 0.017505\n","Epoch:  1563 | train loss: 0.011598 | valid loss: 0.017574\n","Epoch:  1564 | train loss: 0.020177 | valid loss: 0.017570\n","Epoch:  1565 | train loss: 0.010128 | valid loss: 0.017593\n","Epoch:  1566 | train loss: 0.020377 | valid loss: 0.017870\n","Epoch:  1567 | train loss: 0.014230 | valid loss: 0.017688\n","Epoch:  1568 | train loss: 0.009675 | valid loss: 0.017631\n","Epoch:  1569 | train loss: 0.016548 | valid loss: 0.017545\n","Epoch:  1570 | train loss: 0.025241 | valid loss: 0.017621\n","Epoch:  1571 | train loss: 0.018088 | valid loss: 0.017610\n","Epoch:  1572 | train loss: 0.016903 | valid loss: 0.017657\n","Epoch:  1573 | train loss: 0.020506 | valid loss: 0.017700\n","Epoch:  1574 | train loss: 0.014832 | valid loss: 0.017573\n","Epoch:  1575 | train loss: 0.027726 | valid loss: 0.017669\n","Epoch:  1576 | train loss: 0.032859 | valid loss: 0.017634\n","Epoch:  1577 | train loss: 0.013942 | valid loss: 0.017699\n","Epoch:  1578 | train loss: 0.011806 | valid loss: 0.017699\n","Epoch:  1579 | train loss: 0.014164 | valid loss: 0.017575\n","Epoch:  1580 | train loss: 0.018837 | valid loss: 0.017686\n","Epoch:  1581 | train loss: 0.007071 | valid loss: 0.017578\n","Epoch:  1582 | train loss: 0.017764 | valid loss: 0.017813\n","Epoch:  1583 | train loss: 0.018798 | valid loss: 0.017584\n","Epoch:  1584 | train loss: 0.027676 | valid loss: 0.017681\n","Epoch:  1585 | train loss: 0.017841 | valid loss: 0.017815\n","Epoch:  1586 | train loss: 0.021703 | valid loss: 0.017832\n","Epoch:  1587 | train loss: 0.014958 | valid loss: 0.017686\n","Epoch:  1588 | train loss: 0.015129 | valid loss: 0.017620\n","Epoch:  1589 | train loss: 0.016157 | valid loss: 0.017706\n","Epoch:  1590 | train loss: 0.011538 | valid loss: 0.017590\n","Epoch:  1591 | train loss: 0.020404 | valid loss: 0.017616\n","Epoch:  1592 | train loss: 0.025180 | valid loss: 0.017710\n","Epoch:  1593 | train loss: 0.018651 | valid loss: 0.017663\n","Epoch:  1594 | train loss: 0.017418 | valid loss: 0.017657\n","Epoch:  1595 | train loss: 0.014383 | valid loss: 0.017738\n","Epoch:  1596 | train loss: 0.012921 | valid loss: 0.017677\n","Epoch:  1597 | train loss: 0.006966 | valid loss: 0.017649\n","Epoch:  1598 | train loss: 0.018154 | valid loss: 0.017630\n","Epoch:  1599 | train loss: 0.011906 | valid loss: 0.017645\n","Epoch:  1600 | train loss: 0.025676 | valid loss: 0.017604\n","Epoch:  1601 | train loss: 0.011229 | valid loss: 0.017664\n","Epoch:  1602 | train loss: 0.014736 | valid loss: 0.017625\n","Epoch:  1603 | train loss: 0.018536 | valid loss: 0.017697\n","Epoch:  1604 | train loss: 0.013588 | valid loss: 0.017713\n","Epoch:  1605 | train loss: 0.017869 | valid loss: 0.017623\n","Epoch:  1606 | train loss: 0.009717 | valid loss: 0.017704\n","Epoch:  1607 | train loss: 0.011486 | valid loss: 0.017678\n","Epoch:  1608 | train loss: 0.014785 | valid loss: 0.017737\n","Epoch:  1609 | train loss: 0.023664 | valid loss: 0.017814\n","Epoch:  1610 | train loss: 0.020559 | valid loss: 0.017804\n","Epoch:  1611 | train loss: 0.026749 | valid loss: 0.017614\n","Epoch:  1612 | train loss: 0.014518 | valid loss: 0.017644\n","Epoch:  1613 | train loss: 0.026738 | valid loss: 0.017630\n","Epoch:  1614 | train loss: 0.009254 | valid loss: 0.017617\n","Epoch:  1615 | train loss: 0.022155 | valid loss: 0.017599\n","Epoch:  1616 | train loss: 0.014641 | valid loss: 0.017605\n","Epoch:  1617 | train loss: 0.016116 | valid loss: 0.017631\n","Epoch:  1618 | train loss: 0.016351 | valid loss: 0.017564\n","Epoch:  1619 | train loss: 0.009903 | valid loss: 0.017672\n","Epoch:  1620 | train loss: 0.012525 | valid loss: 0.017592\n","Epoch:  1621 | train loss: 0.013019 | valid loss: 0.017609\n","Epoch:  1622 | train loss: 0.009517 | valid loss: 0.017741\n","Epoch:  1623 | train loss: 0.021463 | valid loss: 0.017622\n","Epoch:  1624 | train loss: 0.022302 | valid loss: 0.017517\n","Epoch:  1625 | train loss: 0.016182 | valid loss: 0.017688\n","Epoch:  1626 | train loss: 0.013288 | valid loss: 0.017554\n","Epoch:  1627 | train loss: 0.011754 | valid loss: 0.017642\n","Epoch:  1628 | train loss: 0.013270 | valid loss: 0.017608\n","Epoch:  1629 | train loss: 0.017919 | valid loss: 0.017758\n","Epoch:  1630 | train loss: 0.026080 | valid loss: 0.017553\n","Epoch:  1631 | train loss: 0.020095 | valid loss: 0.017621\n","Epoch:  1632 | train loss: 0.017686 | valid loss: 0.017640\n","Epoch:  1633 | train loss: 0.014989 | valid loss: 0.017708\n","Epoch:  1634 | train loss: 0.013269 | valid loss: 0.017732\n","Epoch:  1635 | train loss: 0.018984 | valid loss: 0.017684\n","Epoch:  1636 | train loss: 0.010319 | valid loss: 0.017609\n","Epoch:  1637 | train loss: 0.016726 | valid loss: 0.017630\n","Epoch:  1638 | train loss: 0.019264 | valid loss: 0.017690\n","Epoch:  1639 | train loss: 0.008126 | valid loss: 0.017584\n","Epoch:  1640 | train loss: 0.011073 | valid loss: 0.017641\n","Epoch:  1641 | train loss: 0.015777 | valid loss: 0.017678\n","Epoch:  1642 | train loss: 0.016338 | valid loss: 0.017814\n","Epoch:  1643 | train loss: 0.014220 | valid loss: 0.017719\n","Epoch:  1644 | train loss: 0.021514 | valid loss: 0.017728\n","Epoch:  1645 | train loss: 0.027326 | valid loss: 0.017722\n","Epoch:  1646 | train loss: 0.015553 | valid loss: 0.017606\n","Epoch:  1647 | train loss: 0.011135 | valid loss: 0.017714\n","Epoch:  1648 | train loss: 0.010981 | valid loss: 0.017729\n","Epoch:  1649 | train loss: 0.018432 | valid loss: 0.017689\n","Epoch:  1650 | train loss: 0.014970 | valid loss: 0.017744\n","Epoch:  1651 | train loss: 0.023692 | valid loss: 0.017656\n","Epoch:  1652 | train loss: 0.012165 | valid loss: 0.017738\n","Epoch:  1653 | train loss: 0.011600 | valid loss: 0.017738\n","Epoch:  1654 | train loss: 0.009675 | valid loss: 0.017666\n","Epoch:  1655 | train loss: 0.022881 | valid loss: 0.017694\n","Epoch:  1656 | train loss: 0.015951 | valid loss: 0.017594\n","Epoch:  1657 | train loss: 0.014261 | valid loss: 0.017633\n","Epoch:  1658 | train loss: 0.013908 | valid loss: 0.017637\n","Epoch:  1659 | train loss: 0.017658 | valid loss: 0.017631\n","Epoch:  1660 | train loss: 0.014585 | valid loss: 0.017654\n","Epoch:  1661 | train loss: 0.025171 | valid loss: 0.017748\n","Epoch:  1662 | train loss: 0.008054 | valid loss: 0.017873\n","Epoch:  1663 | train loss: 0.019618 | valid loss: 0.017685\n","Epoch:  1664 | train loss: 0.016917 | valid loss: 0.017818\n","Epoch:  1665 | train loss: 0.014866 | valid loss: 0.017612\n","Epoch:  1666 | train loss: 0.008461 | valid loss: 0.017711\n","Epoch:  1667 | train loss: 0.017903 | valid loss: 0.017727\n","Epoch:  1668 | train loss: 0.021067 | valid loss: 0.017689\n","Epoch:  1669 | train loss: 0.011911 | valid loss: 0.017760\n","Epoch:  1670 | train loss: 0.015594 | valid loss: 0.017672\n","Epoch:  1671 | train loss: 0.022141 | valid loss: 0.017651\n","Epoch:  1672 | train loss: 0.012860 | valid loss: 0.017724\n","Epoch:  1673 | train loss: 0.024020 | valid loss: 0.017769\n","Epoch:  1674 | train loss: 0.013748 | valid loss: 0.017654\n","Epoch:  1675 | train loss: 0.011162 | valid loss: 0.017598\n","Epoch:  1676 | train loss: 0.019347 | valid loss: 0.017674\n","Epoch:  1677 | train loss: 0.018932 | valid loss: 0.017639\n","Epoch:  1678 | train loss: 0.018831 | valid loss: 0.017654\n","Epoch:  1679 | train loss: 0.012998 | valid loss: 0.017695\n","Epoch:  1680 | train loss: 0.016281 | valid loss: 0.017713\n","Epoch:  1681 | train loss: 0.014053 | valid loss: 0.017767\n","Epoch:  1682 | train loss: 0.026868 | valid loss: 0.017758\n","Epoch:  1683 | train loss: 0.010895 | valid loss: 0.017811\n","Epoch:  1684 | train loss: 0.011946 | valid loss: 0.017668\n","Epoch:  1685 | train loss: 0.010498 | valid loss: 0.017859\n","Epoch:  1686 | train loss: 0.016187 | valid loss: 0.017710\n","Epoch:  1687 | train loss: 0.008895 | valid loss: 0.017670\n","Epoch:  1688 | train loss: 0.009427 | valid loss: 0.017785\n","Epoch:  1689 | train loss: 0.012635 | valid loss: 0.017681\n","Epoch:  1690 | train loss: 0.011495 | valid loss: 0.017709\n","Epoch:  1691 | train loss: 0.019094 | valid loss: 0.017628\n","Epoch:  1692 | train loss: 0.026766 | valid loss: 0.017868\n","Epoch:  1693 | train loss: 0.016787 | valid loss: 0.017748\n","Epoch:  1694 | train loss: 0.017842 | valid loss: 0.017749\n","Epoch:  1695 | train loss: 0.021266 | valid loss: 0.017634\n","Epoch:  1696 | train loss: 0.015576 | valid loss: 0.017724\n","Epoch:  1697 | train loss: 0.010908 | valid loss: 0.017743\n","Epoch:  1698 | train loss: 0.023640 | valid loss: 0.017639\n","Epoch:  1699 | train loss: 0.022016 | valid loss: 0.017710\n","Epoch:  1700 | train loss: 0.013976 | valid loss: 0.017664\n","Epoch:  1701 | train loss: 0.016524 | valid loss: 0.017717\n","Epoch:  1702 | train loss: 0.013332 | valid loss: 0.017740\n","Epoch:  1703 | train loss: 0.018771 | valid loss: 0.017720\n","Epoch:  1704 | train loss: 0.027929 | valid loss: 0.017700\n","Epoch:  1705 | train loss: 0.017199 | valid loss: 0.017706\n","Epoch:  1706 | train loss: 0.018809 | valid loss: 0.017725\n","Epoch:  1707 | train loss: 0.016483 | valid loss: 0.017717\n","Epoch:  1708 | train loss: 0.018335 | valid loss: 0.017772\n","Epoch:  1709 | train loss: 0.017277 | valid loss: 0.017702\n","Epoch:  1710 | train loss: 0.016763 | valid loss: 0.017945\n","Epoch:  1711 | train loss: 0.022407 | valid loss: 0.017784\n","Epoch:  1712 | train loss: 0.029755 | valid loss: 0.017753\n","Epoch:  1713 | train loss: 0.020174 | valid loss: 0.017729\n","Epoch:  1714 | train loss: 0.029885 | valid loss: 0.017737\n","Epoch:  1715 | train loss: 0.022416 | valid loss: 0.017629\n","Epoch:  1716 | train loss: 0.015684 | valid loss: 0.017782\n","Epoch:  1717 | train loss: 0.016941 | valid loss: 0.017698\n","Epoch:  1718 | train loss: 0.020955 | valid loss: 0.017765\n","Epoch:  1719 | train loss: 0.021552 | valid loss: 0.017764\n","Epoch:  1720 | train loss: 0.018558 | valid loss: 0.017685\n","Epoch:  1721 | train loss: 0.017742 | valid loss: 0.017704\n","Epoch:  1722 | train loss: 0.012209 | valid loss: 0.017719\n","Epoch:  1723 | train loss: 0.023187 | valid loss: 0.017774\n","Epoch:  1724 | train loss: 0.012937 | valid loss: 0.017741\n","Epoch:  1725 | train loss: 0.015140 | valid loss: 0.017735\n","Epoch:  1726 | train loss: 0.021390 | valid loss: 0.017793\n","Epoch:  1727 | train loss: 0.030489 | valid loss: 0.017736\n","Epoch:  1728 | train loss: 0.020814 | valid loss: 0.017629\n","Epoch:  1729 | train loss: 0.018203 | valid loss: 0.017826\n","Epoch:  1730 | train loss: 0.030082 | valid loss: 0.017728\n","Epoch:  1731 | train loss: 0.021937 | valid loss: 0.017730\n","Epoch:  1732 | train loss: 0.015102 | valid loss: 0.017763\n","Epoch:  1733 | train loss: 0.029759 | valid loss: 0.017847\n","Epoch:  1734 | train loss: 0.018126 | valid loss: 0.017779\n","Epoch:  1735 | train loss: 0.007339 | valid loss: 0.017765\n","Epoch:  1736 | train loss: 0.012774 | valid loss: 0.017723\n","Epoch:  1737 | train loss: 0.015379 | valid loss: 0.017659\n","Epoch:  1738 | train loss: 0.016231 | valid loss: 0.017679\n","Epoch:  1739 | train loss: 0.012508 | valid loss: 0.017740\n","Epoch:  1740 | train loss: 0.017649 | valid loss: 0.017734\n","Epoch:  1741 | train loss: 0.016076 | valid loss: 0.017712\n","Epoch:  1742 | train loss: 0.023022 | valid loss: 0.017787\n","Epoch:  1743 | train loss: 0.018963 | valid loss: 0.017694\n","Epoch:  1744 | train loss: 0.018067 | valid loss: 0.017784\n","Epoch:  1745 | train loss: 0.019332 | valid loss: 0.017710\n","Epoch:  1746 | train loss: 0.018856 | valid loss: 0.017649\n","Epoch:  1747 | train loss: 0.014608 | valid loss: 0.017644\n","Epoch:  1748 | train loss: 0.013445 | valid loss: 0.017809\n","Epoch:  1749 | train loss: 0.022926 | valid loss: 0.017722\n","Epoch:  1750 | train loss: 0.010065 | valid loss: 0.017627\n","Epoch:  1751 | train loss: 0.023200 | valid loss: 0.017761\n","Epoch:  1752 | train loss: 0.018237 | valid loss: 0.017653\n","Epoch:  1753 | train loss: 0.013222 | valid loss: 0.017707\n","Epoch:  1754 | train loss: 0.013967 | valid loss: 0.017675\n","Epoch:  1755 | train loss: 0.017481 | valid loss: 0.017720\n","Epoch:  1756 | train loss: 0.013354 | valid loss: 0.017664\n","Epoch:  1757 | train loss: 0.012458 | valid loss: 0.017709\n","Epoch:  1758 | train loss: 0.016934 | valid loss: 0.017687\n","Epoch:  1759 | train loss: 0.015330 | valid loss: 0.017759\n","Epoch:  1760 | train loss: 0.013552 | valid loss: 0.017741\n","Epoch:  1761 | train loss: 0.014907 | valid loss: 0.017837\n","Epoch:  1762 | train loss: 0.022560 | valid loss: 0.017806\n","Epoch:  1763 | train loss: 0.023838 | valid loss: 0.017678\n","Epoch:  1764 | train loss: 0.019180 | valid loss: 0.017837\n","Epoch:  1765 | train loss: 0.013717 | valid loss: 0.017689\n","Epoch:  1766 | train loss: 0.011151 | valid loss: 0.017691\n","Epoch:  1767 | train loss: 0.013226 | valid loss: 0.017678\n","Epoch:  1768 | train loss: 0.010929 | valid loss: 0.017704\n","Epoch:  1769 | train loss: 0.008401 | valid loss: 0.017629\n","Epoch:  1770 | train loss: 0.008026 | valid loss: 0.017814\n","Epoch:  1771 | train loss: 0.020576 | valid loss: 0.017679\n","Epoch:  1772 | train loss: 0.027324 | valid loss: 0.017692\n","Epoch:  1773 | train loss: 0.013437 | valid loss: 0.017715\n","Epoch:  1774 | train loss: 0.011281 | valid loss: 0.017679\n","Epoch:  1775 | train loss: 0.019102 | valid loss: 0.017790\n","Epoch:  1776 | train loss: 0.016358 | valid loss: 0.017736\n","Epoch:  1777 | train loss: 0.009210 | valid loss: 0.017723\n","Epoch:  1778 | train loss: 0.021084 | valid loss: 0.017809\n","Epoch:  1779 | train loss: 0.017421 | valid loss: 0.017730\n","Epoch:  1780 | train loss: 0.011826 | valid loss: 0.017760\n","Epoch:  1781 | train loss: 0.016591 | valid loss: 0.017715\n","Epoch:  1782 | train loss: 0.017879 | valid loss: 0.017679\n","Epoch:  1783 | train loss: 0.026363 | valid loss: 0.017716\n","Epoch:  1784 | train loss: 0.024895 | valid loss: 0.017697\n","Epoch:  1785 | train loss: 0.016995 | valid loss: 0.017729\n","Epoch:  1786 | train loss: 0.024931 | valid loss: 0.017830\n","Epoch:  1787 | train loss: 0.030761 | valid loss: 0.017700\n","Epoch:  1788 | train loss: 0.015728 | valid loss: 0.017797\n","Epoch:  1789 | train loss: 0.019076 | valid loss: 0.017756\n","Epoch:  1790 | train loss: 0.017777 | valid loss: 0.017721\n","Epoch:  1791 | train loss: 0.018352 | valid loss: 0.017773\n","Epoch:  1792 | train loss: 0.021042 | valid loss: 0.017769\n","Epoch:  1793 | train loss: 0.022180 | valid loss: 0.017730\n","Epoch:  1794 | train loss: 0.009929 | valid loss: 0.017777\n","Epoch:  1795 | train loss: 0.011703 | valid loss: 0.017780\n","Epoch:  1796 | train loss: 0.024660 | valid loss: 0.017729\n","Epoch:  1797 | train loss: 0.017439 | valid loss: 0.017755\n","Epoch:  1798 | train loss: 0.013241 | valid loss: 0.017766\n","Epoch:  1799 | train loss: 0.016172 | valid loss: 0.017668\n","Epoch:  1800 | train loss: 0.014987 | valid loss: 0.017706\n","Epoch:  1801 | train loss: 0.017092 | valid loss: 0.017695\n","Epoch:  1802 | train loss: 0.025664 | valid loss: 0.017703\n","Epoch:  1803 | train loss: 0.016510 | valid loss: 0.017719\n","Epoch:  1804 | train loss: 0.016968 | valid loss: 0.017728\n","Epoch:  1805 | train loss: 0.018919 | valid loss: 0.017849\n","Epoch:  1806 | train loss: 0.017710 | valid loss: 0.017874\n","Epoch:  1807 | train loss: 0.024916 | valid loss: 0.017834\n","Epoch:  1808 | train loss: 0.016370 | valid loss: 0.017743\n","Epoch:  1809 | train loss: 0.015460 | valid loss: 0.017747\n","Epoch:  1810 | train loss: 0.012804 | valid loss: 0.017720\n","Epoch:  1811 | train loss: 0.011315 | valid loss: 0.017825\n","Epoch:  1812 | train loss: 0.009155 | valid loss: 0.017794\n","Epoch:  1813 | train loss: 0.017298 | valid loss: 0.017798\n","Epoch:  1814 | train loss: 0.012154 | valid loss: 0.017717\n","Epoch:  1815 | train loss: 0.022853 | valid loss: 0.017696\n","Epoch:  1816 | train loss: 0.019076 | valid loss: 0.017644\n","Epoch:  1817 | train loss: 0.015723 | valid loss: 0.017759\n","Epoch:  1818 | train loss: 0.029394 | valid loss: 0.017749\n","Epoch:  1819 | train loss: 0.017004 | valid loss: 0.017824\n","Epoch:  1820 | train loss: 0.022471 | valid loss: 0.017702\n","Epoch:  1821 | train loss: 0.012025 | valid loss: 0.017735\n","Epoch:  1822 | train loss: 0.010501 | valid loss: 0.017667\n","Epoch:  1823 | train loss: 0.009553 | valid loss: 0.017703\n","Epoch:  1824 | train loss: 0.025913 | valid loss: 0.017921\n","Epoch:  1825 | train loss: 0.008523 | valid loss: 0.017892\n","Epoch:  1826 | train loss: 0.014038 | valid loss: 0.017710\n","Epoch:  1827 | train loss: 0.014170 | valid loss: 0.017671\n","Epoch:  1828 | train loss: 0.029826 | valid loss: 0.017804\n","Epoch:  1829 | train loss: 0.016229 | valid loss: 0.017709\n","Epoch:  1830 | train loss: 0.008237 | valid loss: 0.017660\n","Epoch:  1831 | train loss: 0.020454 | valid loss: 0.017795\n","Epoch:  1832 | train loss: 0.012825 | valid loss: 0.017714\n","Epoch:  1833 | train loss: 0.016790 | valid loss: 0.017778\n","Epoch:  1834 | train loss: 0.013386 | valid loss: 0.017689\n","Epoch:  1835 | train loss: 0.022832 | valid loss: 0.017663\n","Epoch:  1836 | train loss: 0.015451 | valid loss: 0.017713\n","Epoch:  1837 | train loss: 0.015112 | valid loss: 0.017761\n","Epoch:  1838 | train loss: 0.020036 | valid loss: 0.017754\n","Epoch:  1839 | train loss: 0.020725 | valid loss: 0.017786\n","Epoch:  1840 | train loss: 0.022058 | valid loss: 0.017734\n","Epoch:  1841 | train loss: 0.018874 | valid loss: 0.017737\n","Epoch:  1842 | train loss: 0.017618 | valid loss: 0.017794\n","Epoch:  1843 | train loss: 0.021639 | valid loss: 0.017707\n","Epoch:  1844 | train loss: 0.024073 | valid loss: 0.017754\n","Epoch:  1845 | train loss: 0.015611 | valid loss: 0.017756\n","Epoch:  1846 | train loss: 0.016071 | valid loss: 0.017711\n","Epoch:  1847 | train loss: 0.014571 | valid loss: 0.017816\n","Epoch:  1848 | train loss: 0.022978 | valid loss: 0.017780\n","Epoch:  1849 | train loss: 0.019279 | valid loss: 0.017774\n","Epoch:  1850 | train loss: 0.018382 | valid loss: 0.017773\n","Epoch:  1851 | train loss: 0.016942 | valid loss: 0.017734\n","Epoch:  1852 | train loss: 0.011792 | valid loss: 0.017686\n","Epoch:  1853 | train loss: 0.017929 | valid loss: 0.017818\n","Epoch:  1854 | train loss: 0.015147 | valid loss: 0.017753\n","Epoch:  1855 | train loss: 0.015215 | valid loss: 0.017807\n","Epoch:  1856 | train loss: 0.017931 | valid loss: 0.017780\n","Epoch:  1857 | train loss: 0.011229 | valid loss: 0.017830\n","Epoch:  1858 | train loss: 0.017664 | valid loss: 0.017727\n","Epoch:  1859 | train loss: 0.012314 | valid loss: 0.017871\n","Epoch:  1860 | train loss: 0.023823 | valid loss: 0.017740\n","Epoch:  1861 | train loss: 0.008203 | valid loss: 0.017806\n","Epoch:  1862 | train loss: 0.017321 | valid loss: 0.017821\n","Epoch:  1863 | train loss: 0.016853 | valid loss: 0.017771\n","Epoch:  1864 | train loss: 0.015366 | valid loss: 0.017867\n","Epoch:  1865 | train loss: 0.014840 | valid loss: 0.017747\n","Epoch:  1866 | train loss: 0.012217 | valid loss: 0.017733\n","Epoch:  1867 | train loss: 0.014409 | valid loss: 0.017784\n","Epoch:  1868 | train loss: 0.019233 | valid loss: 0.017764\n","Epoch:  1869 | train loss: 0.017180 | valid loss: 0.017772\n","Epoch:  1870 | train loss: 0.013917 | valid loss: 0.017759\n","Epoch:  1871 | train loss: 0.009687 | valid loss: 0.017906\n","Epoch:  1872 | train loss: 0.020741 | valid loss: 0.017795\n","Epoch:  1873 | train loss: 0.014558 | valid loss: 0.017816\n","Epoch:  1874 | train loss: 0.019266 | valid loss: 0.017733\n","Epoch:  1875 | train loss: 0.028253 | valid loss: 0.017871\n","Epoch:  1876 | train loss: 0.026381 | valid loss: 0.017781\n","Epoch:  1877 | train loss: 0.023057 | valid loss: 0.017721\n","Epoch:  1878 | train loss: 0.017276 | valid loss: 0.017747\n","Epoch:  1879 | train loss: 0.017088 | valid loss: 0.017817\n","Epoch:  1880 | train loss: 0.020311 | valid loss: 0.017771\n","Epoch:  1881 | train loss: 0.015468 | valid loss: 0.017764\n","Epoch:  1882 | train loss: 0.016439 | valid loss: 0.017801\n","Epoch:  1883 | train loss: 0.014020 | valid loss: 0.017721\n","Epoch:  1884 | train loss: 0.015112 | valid loss: 0.017813\n","Epoch:  1885 | train loss: 0.017719 | valid loss: 0.017685\n","Epoch:  1886 | train loss: 0.019455 | valid loss: 0.017889\n","Epoch:  1887 | train loss: 0.014681 | valid loss: 0.017808\n","Epoch:  1888 | train loss: 0.027533 | valid loss: 0.017842\n","Epoch:  1889 | train loss: 0.022052 | valid loss: 0.017849\n","Epoch:  1890 | train loss: 0.013554 | valid loss: 0.017780\n","Epoch:  1891 | train loss: 0.012356 | valid loss: 0.017844\n","Epoch:  1892 | train loss: 0.011310 | valid loss: 0.017822\n","Epoch:  1893 | train loss: 0.010644 | valid loss: 0.017728\n","Epoch:  1894 | train loss: 0.021138 | valid loss: 0.017737\n","Epoch:  1895 | train loss: 0.013277 | valid loss: 0.017778\n","Epoch:  1896 | train loss: 0.016845 | valid loss: 0.017827\n","Epoch:  1897 | train loss: 0.019175 | valid loss: 0.017764\n","Epoch:  1898 | train loss: 0.008794 | valid loss: 0.017787\n","Epoch:  1899 | train loss: 0.011942 | valid loss: 0.017738\n","Epoch:  1900 | train loss: 0.012235 | valid loss: 0.017721\n","Epoch:  1901 | train loss: 0.010185 | valid loss: 0.017719\n","Epoch:  1902 | train loss: 0.018567 | valid loss: 0.017746\n","Epoch:  1903 | train loss: 0.021835 | valid loss: 0.017815\n","Epoch:  1904 | train loss: 0.019898 | valid loss: 0.017891\n","Epoch:  1905 | train loss: 0.021502 | valid loss: 0.017881\n","Epoch:  1906 | train loss: 0.013109 | valid loss: 0.017933\n","Epoch:  1907 | train loss: 0.020113 | valid loss: 0.017863\n","Epoch:  1908 | train loss: 0.017063 | valid loss: 0.017779\n","Epoch:  1909 | train loss: 0.015587 | valid loss: 0.018052\n","Epoch:  1910 | train loss: 0.014266 | valid loss: 0.017899\n","Epoch:  1911 | train loss: 0.017462 | valid loss: 0.017793\n","Epoch:  1912 | train loss: 0.012153 | valid loss: 0.017776\n","Epoch:  1913 | train loss: 0.024300 | valid loss: 0.017768\n","Epoch:  1914 | train loss: 0.020862 | valid loss: 0.017831\n","Epoch:  1915 | train loss: 0.017783 | valid loss: 0.017810\n","Epoch:  1916 | train loss: 0.019317 | valid loss: 0.017735\n","Epoch:  1917 | train loss: 0.016911 | valid loss: 0.017789\n","Epoch:  1918 | train loss: 0.026034 | valid loss: 0.017813\n","Epoch:  1919 | train loss: 0.014022 | valid loss: 0.017907\n","Epoch:  1920 | train loss: 0.011946 | valid loss: 0.017778\n","Epoch:  1921 | train loss: 0.017433 | valid loss: 0.017890\n","Epoch:  1922 | train loss: 0.008018 | valid loss: 0.017757\n","Epoch:  1923 | train loss: 0.023532 | valid loss: 0.017815\n","Epoch:  1924 | train loss: 0.021313 | valid loss: 0.017822\n","Epoch:  1925 | train loss: 0.015204 | valid loss: 0.017817\n","Epoch:  1926 | train loss: 0.018166 | valid loss: 0.017804\n","Epoch:  1927 | train loss: 0.020437 | valid loss: 0.017781\n","Epoch:  1928 | train loss: 0.023643 | valid loss: 0.017782\n","Epoch:  1929 | train loss: 0.018263 | valid loss: 0.017763\n","Epoch:  1930 | train loss: 0.016538 | valid loss: 0.017888\n","Epoch:  1931 | train loss: 0.012128 | valid loss: 0.017812\n","Epoch:  1932 | train loss: 0.011160 | valid loss: 0.017755\n","Epoch:  1933 | train loss: 0.018037 | valid loss: 0.017824\n","Epoch:  1934 | train loss: 0.012172 | valid loss: 0.017785\n","Epoch:  1935 | train loss: 0.020463 | valid loss: 0.017747\n","Epoch:  1936 | train loss: 0.016066 | valid loss: 0.017788\n","Epoch:  1937 | train loss: 0.020990 | valid loss: 0.017799\n","Epoch:  1938 | train loss: 0.021944 | valid loss: 0.017778\n","Epoch:  1939 | train loss: 0.018363 | valid loss: 0.017851\n","Epoch:  1940 | train loss: 0.020443 | valid loss: 0.017790\n","Epoch:  1941 | train loss: 0.015798 | valid loss: 0.017859\n","Epoch:  1942 | train loss: 0.021135 | valid loss: 0.017818\n","Epoch:  1943 | train loss: 0.022909 | valid loss: 0.017835\n","Epoch:  1944 | train loss: 0.018652 | valid loss: 0.017801\n","Epoch:  1945 | train loss: 0.013345 | valid loss: 0.017839\n","Epoch:  1946 | train loss: 0.015882 | valid loss: 0.017794\n","Epoch:  1947 | train loss: 0.030462 | valid loss: 0.017852\n","Epoch:  1948 | train loss: 0.014346 | valid loss: 0.017887\n","Epoch:  1949 | train loss: 0.018162 | valid loss: 0.017814\n","Epoch:  1950 | train loss: 0.019125 | valid loss: 0.017792\n","Epoch:  1951 | train loss: 0.013561 | valid loss: 0.017741\n","Epoch:  1952 | train loss: 0.022846 | valid loss: 0.017782\n","Epoch:  1953 | train loss: 0.012814 | valid loss: 0.017732\n","Epoch:  1954 | train loss: 0.013447 | valid loss: 0.017776\n","Epoch:  1955 | train loss: 0.011227 | valid loss: 0.017780\n","Epoch:  1956 | train loss: 0.013867 | valid loss: 0.017784\n","Epoch:  1957 | train loss: 0.016112 | valid loss: 0.017804\n","Epoch:  1958 | train loss: 0.014124 | valid loss: 0.017772\n","Epoch:  1959 | train loss: 0.012040 | valid loss: 0.017837\n","Epoch:  1960 | train loss: 0.012365 | valid loss: 0.017833\n","Epoch:  1961 | train loss: 0.013168 | valid loss: 0.017702\n","Epoch:  1962 | train loss: 0.017259 | valid loss: 0.017796\n","Epoch:  1963 | train loss: 0.019192 | valid loss: 0.017791\n","Epoch:  1964 | train loss: 0.026251 | valid loss: 0.017913\n","Epoch:  1965 | train loss: 0.017752 | valid loss: 0.017851\n","Epoch:  1966 | train loss: 0.017410 | valid loss: 0.017886\n","Epoch:  1967 | train loss: 0.013121 | valid loss: 0.017916\n","Epoch:  1968 | train loss: 0.011863 | valid loss: 0.017945\n","Epoch:  1969 | train loss: 0.013021 | valid loss: 0.017736\n","Epoch:  1970 | train loss: 0.011308 | valid loss: 0.017797\n","Epoch:  1971 | train loss: 0.019517 | valid loss: 0.017765\n","Epoch:  1972 | train loss: 0.014322 | valid loss: 0.017721\n","Epoch:  1973 | train loss: 0.013206 | valid loss: 0.017797\n","Epoch:  1974 | train loss: 0.016039 | valid loss: 0.017817\n","Epoch:  1975 | train loss: 0.023676 | valid loss: 0.017766\n","Epoch:  1976 | train loss: 0.016704 | valid loss: 0.017801\n","Epoch:  1977 | train loss: 0.023651 | valid loss: 0.017792\n","Epoch:  1978 | train loss: 0.011391 | valid loss: 0.017824\n","Epoch:  1979 | train loss: 0.010889 | valid loss: 0.017907\n","Epoch:  1980 | train loss: 0.016006 | valid loss: 0.017799\n","Epoch:  1981 | train loss: 0.010216 | valid loss: 0.017853\n","Epoch:  1982 | train loss: 0.017815 | valid loss: 0.017902\n","Epoch:  1983 | train loss: 0.016041 | valid loss: 0.017785\n","Epoch:  1984 | train loss: 0.019908 | valid loss: 0.017740\n","Epoch:  1985 | train loss: 0.012442 | valid loss: 0.017865\n","Epoch:  1986 | train loss: 0.024528 | valid loss: 0.017772\n","Epoch:  1987 | train loss: 0.012770 | valid loss: 0.017782\n","Epoch:  1988 | train loss: 0.020940 | valid loss: 0.017841\n","Epoch:  1989 | train loss: 0.012631 | valid loss: 0.017860\n","Epoch:  1990 | train loss: 0.012473 | valid loss: 0.017838\n","Epoch:  1991 | train loss: 0.009507 | valid loss: 0.017889\n","Epoch:  1992 | train loss: 0.021612 | valid loss: 0.017815\n","Epoch:  1993 | train loss: 0.025145 | valid loss: 0.017888\n","Epoch:  1994 | train loss: 0.013703 | valid loss: 0.017866\n","Epoch:  1995 | train loss: 0.009010 | valid loss: 0.017975\n","Epoch:  1996 | train loss: 0.015668 | valid loss: 0.017875\n","Epoch:  1997 | train loss: 0.014665 | valid loss: 0.017911\n","Epoch:  1998 | train loss: 0.011402 | valid loss: 0.017797\n","Epoch:  1999 | train loss: 0.014793 | valid loss: 0.017849\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XllfVO9WdZTY","executionInfo":{"status":"ok","timestamp":1629653595087,"user_tz":-60,"elapsed":39,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"0c6668f0-980a-4b6e-93cf-4c5da93e78d6"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Train time: 303.9299807548523\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"gRMNX_E2CKhQ","executionInfo":{"status":"ok","timestamp":1629653595093,"user_tz":-60,"elapsed":24,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"43a44a78-c74e-47f2-e0d7-7758fc7c66e1"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":53},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9yBxg5WNCEQ","executionInfo":{"status":"ok","timestamp":1629653602941,"user_tz":-60,"elapsed":7860,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"3fcb8f09-8a8d-4bf6-a83e-9d36d9eb0265"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":54,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 0.0006536374322116014\n","MSE_err of valid data 0.0006951027914848182\n","MSE_err of test data 0.0006727315762977002\n","MSE_err of total data 0.0006596933838984277\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KTjo3r4av47b"},"source":["#### 32 variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2nG0QWhLeb4-","executionInfo":{"status":"ok","timestamp":1629653602942,"user_tz":-60,"elapsed":7,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"33d2064c-6256-4eed-9abb-b8ba8d0cd6b7"},"source":["print(\"compress to 32\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 2000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":55,"outputs":[{"output_type":"stream","text":["compress to 32\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0l2aW8tvee1y","executionInfo":{"status":"ok","timestamp":1629653840026,"user_tz":-60,"elapsed":236298,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"0e911637-5ecb-466b-c46b-36f9cf554599"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(32).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":56,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 1.534596 | valid loss: 1.544029\n","Epoch:  1 | train loss: 0.836672 | valid loss: 0.866109\n","Epoch:  2 | train loss: 0.303827 | valid loss: 0.306564\n","Epoch:  3 | train loss: 0.166490 | valid loss: 0.137367\n","Epoch:  4 | train loss: 0.115205 | valid loss: 0.099161\n","Epoch:  5 | train loss: 0.100293 | valid loss: 0.082609\n","Epoch:  6 | train loss: 0.066833 | valid loss: 0.072959\n","Epoch:  7 | train loss: 0.079017 | valid loss: 0.066276\n","Epoch:  8 | train loss: 0.058236 | valid loss: 0.061060\n","Epoch:  9 | train loss: 0.049930 | valid loss: 0.056709\n","Epoch:  10 | train loss: 0.055902 | valid loss: 0.052885\n","Epoch:  11 | train loss: 0.048904 | valid loss: 0.049488\n","Epoch:  12 | train loss: 0.051563 | valid loss: 0.046858\n","Epoch:  13 | train loss: 0.051284 | valid loss: 0.043956\n","Epoch:  14 | train loss: 0.042074 | valid loss: 0.041742\n","Epoch:  15 | train loss: 0.035798 | valid loss: 0.039641\n","Epoch:  16 | train loss: 0.042511 | valid loss: 0.037986\n","Epoch:  17 | train loss: 0.058768 | valid loss: 0.036319\n","Epoch:  18 | train loss: 0.037942 | valid loss: 0.034793\n","Epoch:  19 | train loss: 0.041395 | valid loss: 0.033357\n","Epoch:  20 | train loss: 0.020203 | valid loss: 0.032524\n","Epoch:  21 | train loss: 0.038800 | valid loss: 0.030469\n","Epoch:  22 | train loss: 0.039407 | valid loss: 0.030081\n","Epoch:  23 | train loss: 0.036423 | valid loss: 0.028364\n","Epoch:  24 | train loss: 0.020037 | valid loss: 0.027132\n","Epoch:  25 | train loss: 0.025109 | valid loss: 0.026587\n","Epoch:  26 | train loss: 0.025585 | valid loss: 0.025962\n","Epoch:  27 | train loss: 0.029096 | valid loss: 0.025046\n","Epoch:  28 | train loss: 0.021319 | valid loss: 0.024095\n","Epoch:  29 | train loss: 0.027231 | valid loss: 0.023297\n","Epoch:  30 | train loss: 0.020947 | valid loss: 0.022840\n","Epoch:  31 | train loss: 0.031109 | valid loss: 0.022333\n","Epoch:  32 | train loss: 0.023284 | valid loss: 0.021703\n","Epoch:  33 | train loss: 0.025772 | valid loss: 0.021000\n","Epoch:  34 | train loss: 0.016752 | valid loss: 0.020165\n","Epoch:  35 | train loss: 0.013686 | valid loss: 0.019757\n","Epoch:  36 | train loss: 0.012542 | valid loss: 0.019547\n","Epoch:  37 | train loss: 0.023463 | valid loss: 0.019000\n","Epoch:  38 | train loss: 0.017063 | valid loss: 0.018440\n","Epoch:  39 | train loss: 0.017795 | valid loss: 0.018146\n","Epoch:  40 | train loss: 0.018886 | valid loss: 0.018070\n","Epoch:  41 | train loss: 0.023686 | valid loss: 0.017374\n","Epoch:  42 | train loss: 0.015740 | valid loss: 0.017367\n","Epoch:  43 | train loss: 0.025735 | valid loss: 0.016492\n","Epoch:  44 | train loss: 0.012504 | valid loss: 0.017061\n","Epoch:  45 | train loss: 0.010985 | valid loss: 0.015847\n","Epoch:  46 | train loss: 0.014165 | valid loss: 0.015650\n","Epoch:  47 | train loss: 0.009373 | valid loss: 0.015271\n","Epoch:  48 | train loss: 0.029343 | valid loss: 0.015221\n","Epoch:  49 | train loss: 0.013020 | valid loss: 0.015080\n","Epoch:  50 | train loss: 0.013364 | valid loss: 0.014809\n","Epoch:  51 | train loss: 0.010723 | valid loss: 0.014413\n","Epoch:  52 | train loss: 0.012374 | valid loss: 0.013912\n","Epoch:  53 | train loss: 0.024274 | valid loss: 0.014065\n","Epoch:  54 | train loss: 0.014571 | valid loss: 0.013680\n","Epoch:  55 | train loss: 0.015593 | valid loss: 0.013935\n","Epoch:  56 | train loss: 0.012041 | valid loss: 0.013889\n","Epoch:  57 | train loss: 0.025850 | valid loss: 0.013896\n","Epoch:  58 | train loss: 0.013736 | valid loss: 0.013487\n","Epoch:  59 | train loss: 0.014872 | valid loss: 0.012908\n","Epoch:  60 | train loss: 0.022284 | valid loss: 0.012999\n","Epoch:  61 | train loss: 0.013750 | valid loss: 0.012773\n","Epoch:  62 | train loss: 0.019420 | valid loss: 0.012721\n","Epoch:  63 | train loss: 0.014614 | valid loss: 0.012639\n","Epoch:  64 | train loss: 0.012230 | valid loss: 0.012469\n","Epoch:  65 | train loss: 0.008763 | valid loss: 0.012326\n","Epoch:  66 | train loss: 0.012423 | valid loss: 0.012234\n","Epoch:  67 | train loss: 0.011153 | valid loss: 0.011979\n","Epoch:  68 | train loss: 0.020324 | valid loss: 0.011862\n","Epoch:  69 | train loss: 0.015390 | valid loss: 0.011826\n","Epoch:  70 | train loss: 0.008620 | valid loss: 0.011666\n","Epoch:  71 | train loss: 0.007932 | valid loss: 0.011534\n","Epoch:  72 | train loss: 0.015115 | valid loss: 0.011484\n","Epoch:  73 | train loss: 0.008846 | valid loss: 0.011539\n","Epoch:  74 | train loss: 0.020432 | valid loss: 0.011431\n","Epoch:  75 | train loss: 0.009154 | valid loss: 0.011057\n","Epoch:  76 | train loss: 0.007683 | valid loss: 0.011151\n","Epoch:  77 | train loss: 0.014426 | valid loss: 0.011115\n","Epoch:  78 | train loss: 0.007021 | valid loss: 0.010900\n","Epoch:  79 | train loss: 0.013902 | valid loss: 0.010823\n","Epoch:  80 | train loss: 0.013861 | valid loss: 0.010627\n","Epoch:  81 | train loss: 0.015594 | valid loss: 0.010576\n","Epoch:  82 | train loss: 0.009222 | valid loss: 0.010408\n","Epoch:  83 | train loss: 0.012296 | valid loss: 0.010577\n","Epoch:  84 | train loss: 0.008017 | valid loss: 0.010497\n","Epoch:  85 | train loss: 0.011176 | valid loss: 0.010484\n","Epoch:  86 | train loss: 0.006023 | valid loss: 0.010301\n","Epoch:  87 | train loss: 0.007236 | valid loss: 0.010256\n","Epoch:  88 | train loss: 0.014593 | valid loss: 0.010176\n","Epoch:  89 | train loss: 0.013198 | valid loss: 0.010159\n","Epoch:  90 | train loss: 0.008158 | valid loss: 0.010035\n","Epoch:  91 | train loss: 0.011893 | valid loss: 0.010235\n","Epoch:  92 | train loss: 0.008905 | valid loss: 0.009877\n","Epoch:  93 | train loss: 0.009211 | valid loss: 0.009829\n","Epoch:  94 | train loss: 0.010321 | valid loss: 0.009988\n","Epoch:  95 | train loss: 0.011385 | valid loss: 0.009824\n","Epoch:  96 | train loss: 0.009750 | valid loss: 0.009528\n","Epoch:  97 | train loss: 0.008005 | valid loss: 0.009598\n","Epoch:  98 | train loss: 0.006844 | valid loss: 0.009562\n","Epoch:  99 | train loss: 0.009981 | valid loss: 0.009383\n","Epoch:  100 | train loss: 0.010647 | valid loss: 0.009507\n","Epoch:  101 | train loss: 0.009302 | valid loss: 0.009414\n","Epoch:  102 | train loss: 0.007638 | valid loss: 0.009391\n","Epoch:  103 | train loss: 0.015602 | valid loss: 0.009234\n","Epoch:  104 | train loss: 0.008671 | valid loss: 0.009303\n","Epoch:  105 | train loss: 0.012441 | valid loss: 0.009221\n","Epoch:  106 | train loss: 0.006923 | valid loss: 0.009246\n","Epoch:  107 | train loss: 0.009884 | valid loss: 0.009138\n","Epoch:  108 | train loss: 0.010279 | valid loss: 0.009090\n","Epoch:  109 | train loss: 0.006395 | valid loss: 0.009058\n","Epoch:  110 | train loss: 0.008338 | valid loss: 0.008967\n","Epoch:  111 | train loss: 0.010517 | valid loss: 0.008959\n","Epoch:  112 | train loss: 0.011799 | valid loss: 0.008999\n","Epoch:  113 | train loss: 0.008784 | valid loss: 0.008865\n","Epoch:  114 | train loss: 0.010021 | valid loss: 0.008903\n","Epoch:  115 | train loss: 0.006737 | valid loss: 0.008842\n","Epoch:  116 | train loss: 0.006953 | valid loss: 0.008812\n","Epoch:  117 | train loss: 0.007061 | valid loss: 0.008743\n","Epoch:  118 | train loss: 0.006062 | valid loss: 0.008600\n","Epoch:  119 | train loss: 0.012940 | valid loss: 0.008815\n","Epoch:  120 | train loss: 0.008181 | valid loss: 0.008688\n","Epoch:  121 | train loss: 0.009235 | valid loss: 0.008832\n","Epoch:  122 | train loss: 0.006744 | valid loss: 0.008697\n","Epoch:  123 | train loss: 0.010171 | valid loss: 0.008613\n","Epoch:  124 | train loss: 0.010870 | valid loss: 0.008657\n","Epoch:  125 | train loss: 0.014758 | valid loss: 0.008560\n","Epoch:  126 | train loss: 0.008389 | valid loss: 0.008611\n","Epoch:  127 | train loss: 0.006434 | valid loss: 0.008560\n","Epoch:  128 | train loss: 0.007940 | valid loss: 0.008484\n","Epoch:  129 | train loss: 0.007205 | valid loss: 0.008581\n","Epoch:  130 | train loss: 0.013147 | valid loss: 0.008627\n","Epoch:  131 | train loss: 0.009050 | valid loss: 0.008396\n","Epoch:  132 | train loss: 0.007522 | valid loss: 0.008575\n","Epoch:  133 | train loss: 0.005811 | valid loss: 0.008448\n","Epoch:  134 | train loss: 0.008429 | valid loss: 0.008411\n","Epoch:  135 | train loss: 0.005284 | valid loss: 0.008674\n","Epoch:  136 | train loss: 0.005475 | valid loss: 0.008340\n","Epoch:  137 | train loss: 0.007344 | valid loss: 0.008459\n","Epoch:  138 | train loss: 0.006627 | valid loss: 0.008323\n","Epoch:  139 | train loss: 0.008216 | valid loss: 0.008222\n","Epoch:  140 | train loss: 0.009539 | valid loss: 0.008395\n","Epoch:  141 | train loss: 0.007075 | valid loss: 0.008320\n","Epoch:  142 | train loss: 0.009237 | valid loss: 0.008427\n","Epoch:  143 | train loss: 0.005313 | valid loss: 0.008243\n","Epoch:  144 | train loss: 0.006329 | valid loss: 0.008225\n","Epoch:  145 | train loss: 0.008813 | valid loss: 0.008361\n","Epoch:  146 | train loss: 0.006317 | valid loss: 0.008391\n","Epoch:  147 | train loss: 0.006934 | valid loss: 0.008347\n","Epoch:  148 | train loss: 0.008597 | valid loss: 0.008302\n","Epoch:  149 | train loss: 0.009769 | valid loss: 0.008300\n","Epoch:  150 | train loss: 0.007539 | valid loss: 0.008406\n","Epoch:  151 | train loss: 0.006704 | valid loss: 0.008208\n","Epoch:  152 | train loss: 0.005221 | valid loss: 0.008109\n","Epoch:  153 | train loss: 0.006390 | valid loss: 0.008314\n","Epoch:  154 | train loss: 0.011164 | valid loss: 0.008143\n","Epoch:  155 | train loss: 0.004163 | valid loss: 0.008240\n","Epoch:  156 | train loss: 0.006597 | valid loss: 0.008275\n","Epoch:  157 | train loss: 0.006992 | valid loss: 0.008028\n","Epoch:  158 | train loss: 0.008626 | valid loss: 0.008032\n","Epoch:  159 | train loss: 0.006225 | valid loss: 0.008103\n","Epoch:  160 | train loss: 0.013271 | valid loss: 0.008018\n","Epoch:  161 | train loss: 0.007577 | valid loss: 0.008011\n","Epoch:  162 | train loss: 0.006535 | valid loss: 0.008145\n","Epoch:  163 | train loss: 0.009746 | valid loss: 0.008037\n","Epoch:  164 | train loss: 0.005226 | valid loss: 0.008136\n","Epoch:  165 | train loss: 0.004658 | valid loss: 0.008019\n","Epoch:  166 | train loss: 0.005736 | valid loss: 0.008074\n","Epoch:  167 | train loss: 0.006470 | valid loss: 0.008042\n","Epoch:  168 | train loss: 0.008845 | valid loss: 0.007971\n","Epoch:  169 | train loss: 0.006264 | valid loss: 0.008087\n","Epoch:  170 | train loss: 0.009433 | valid loss: 0.007992\n","Epoch:  171 | train loss: 0.008288 | valid loss: 0.007920\n","Epoch:  172 | train loss: 0.007660 | valid loss: 0.008020\n","Epoch:  173 | train loss: 0.009217 | valid loss: 0.007950\n","Epoch:  174 | train loss: 0.008906 | valid loss: 0.007862\n","Epoch:  175 | train loss: 0.005993 | valid loss: 0.007975\n","Epoch:  176 | train loss: 0.008000 | valid loss: 0.008049\n","Epoch:  177 | train loss: 0.010495 | valid loss: 0.008012\n","Epoch:  178 | train loss: 0.005223 | valid loss: 0.007965\n","Epoch:  179 | train loss: 0.008072 | valid loss: 0.008146\n","Epoch:  180 | train loss: 0.009325 | valid loss: 0.007886\n","Epoch:  181 | train loss: 0.005729 | valid loss: 0.007921\n","Epoch:  182 | train loss: 0.009557 | valid loss: 0.007800\n","Epoch:  183 | train loss: 0.005584 | valid loss: 0.008049\n","Epoch:  184 | train loss: 0.004365 | valid loss: 0.007845\n","Epoch:  185 | train loss: 0.004780 | valid loss: 0.008004\n","Epoch:  186 | train loss: 0.007508 | valid loss: 0.008023\n","Epoch:  187 | train loss: 0.006714 | valid loss: 0.007781\n","Epoch:  188 | train loss: 0.006167 | valid loss: 0.007840\n","Epoch:  189 | train loss: 0.012458 | valid loss: 0.007840\n","Epoch:  190 | train loss: 0.005552 | valid loss: 0.007937\n","Epoch:  191 | train loss: 0.007147 | valid loss: 0.007885\n","Epoch:  192 | train loss: 0.009877 | valid loss: 0.007928\n","Epoch:  193 | train loss: 0.006963 | valid loss: 0.007974\n","Epoch:  194 | train loss: 0.008877 | valid loss: 0.007906\n","Epoch:  195 | train loss: 0.008802 | valid loss: 0.007830\n","Epoch:  196 | train loss: 0.007098 | valid loss: 0.007728\n","Epoch:  197 | train loss: 0.006280 | valid loss: 0.007730\n","Epoch:  198 | train loss: 0.007566 | valid loss: 0.008008\n","Epoch:  199 | train loss: 0.008940 | valid loss: 0.007899\n","Epoch:  200 | train loss: 0.006192 | valid loss: 0.007681\n","Epoch:  201 | train loss: 0.007417 | valid loss: 0.007831\n","Epoch:  202 | train loss: 0.009441 | valid loss: 0.007850\n","Epoch:  203 | train loss: 0.009880 | valid loss: 0.007778\n","Epoch:  204 | train loss: 0.010492 | valid loss: 0.007781\n","Epoch:  205 | train loss: 0.007350 | valid loss: 0.007794\n","Epoch:  206 | train loss: 0.010479 | valid loss: 0.007738\n","Epoch:  207 | train loss: 0.009593 | valid loss: 0.007734\n","Epoch:  208 | train loss: 0.006271 | valid loss: 0.007764\n","Epoch:  209 | train loss: 0.011591 | valid loss: 0.007783\n","Epoch:  210 | train loss: 0.007421 | valid loss: 0.007700\n","Epoch:  211 | train loss: 0.008584 | valid loss: 0.007717\n","Epoch:  212 | train loss: 0.006856 | valid loss: 0.007662\n","Epoch:  213 | train loss: 0.004399 | valid loss: 0.007759\n","Epoch:  214 | train loss: 0.007472 | valid loss: 0.007809\n","Epoch:  215 | train loss: 0.005732 | valid loss: 0.007877\n","Epoch:  216 | train loss: 0.009417 | valid loss: 0.007697\n","Epoch:  217 | train loss: 0.008241 | valid loss: 0.007759\n","Epoch:  218 | train loss: 0.007906 | valid loss: 0.007636\n","Epoch:  219 | train loss: 0.008907 | valid loss: 0.007648\n","Epoch:  220 | train loss: 0.006820 | valid loss: 0.007633\n","Epoch:  221 | train loss: 0.011204 | valid loss: 0.007666\n","Epoch:  222 | train loss: 0.007412 | valid loss: 0.007712\n","Epoch:  223 | train loss: 0.005801 | valid loss: 0.007734\n","Epoch:  224 | train loss: 0.005736 | valid loss: 0.007589\n","Epoch:  225 | train loss: 0.008648 | valid loss: 0.007775\n","Epoch:  226 | train loss: 0.006211 | valid loss: 0.007641\n","Epoch:  227 | train loss: 0.004971 | valid loss: 0.007705\n","Epoch:  228 | train loss: 0.004207 | valid loss: 0.007780\n","Epoch:  229 | train loss: 0.004191 | valid loss: 0.007693\n","Epoch:  230 | train loss: 0.005846 | valid loss: 0.007740\n","Epoch:  231 | train loss: 0.006482 | valid loss: 0.007668\n","Epoch:  232 | train loss: 0.008443 | valid loss: 0.007666\n","Epoch:  233 | train loss: 0.010819 | valid loss: 0.007650\n","Epoch:  234 | train loss: 0.006942 | valid loss: 0.007555\n","Epoch:  235 | train loss: 0.004746 | valid loss: 0.007667\n","Epoch:  236 | train loss: 0.005097 | valid loss: 0.007751\n","Epoch:  237 | train loss: 0.004020 | valid loss: 0.007689\n","Epoch:  238 | train loss: 0.005507 | valid loss: 0.007654\n","Epoch:  239 | train loss: 0.009200 | valid loss: 0.007775\n","Epoch:  240 | train loss: 0.005338 | valid loss: 0.007790\n","Epoch:  241 | train loss: 0.007400 | valid loss: 0.007639\n","Epoch:  242 | train loss: 0.006690 | valid loss: 0.007628\n","Epoch:  243 | train loss: 0.005885 | valid loss: 0.007591\n","Epoch:  244 | train loss: 0.007221 | valid loss: 0.007688\n","Epoch:  245 | train loss: 0.007694 | valid loss: 0.007601\n","Epoch:  246 | train loss: 0.008765 | valid loss: 0.007602\n","Epoch:  247 | train loss: 0.005053 | valid loss: 0.007797\n","Epoch:  248 | train loss: 0.005011 | valid loss: 0.007595\n","Epoch:  249 | train loss: 0.007703 | valid loss: 0.007603\n","Epoch:  250 | train loss: 0.006050 | valid loss: 0.007572\n","Epoch:  251 | train loss: 0.006596 | valid loss: 0.007656\n","Epoch:  252 | train loss: 0.009362 | valid loss: 0.007686\n","Epoch:  253 | train loss: 0.007958 | valid loss: 0.007782\n","Epoch:  254 | train loss: 0.008076 | valid loss: 0.007670\n","Epoch:  255 | train loss: 0.006756 | valid loss: 0.007620\n","Epoch:  256 | train loss: 0.007667 | valid loss: 0.007640\n","Epoch:  257 | train loss: 0.005896 | valid loss: 0.007642\n","Epoch:  258 | train loss: 0.007730 | valid loss: 0.007641\n","Epoch:  259 | train loss: 0.008783 | valid loss: 0.007725\n","Epoch:  260 | train loss: 0.007952 | valid loss: 0.007620\n","Epoch:  261 | train loss: 0.011146 | valid loss: 0.007635\n","Epoch:  262 | train loss: 0.005455 | valid loss: 0.007693\n","Epoch:  263 | train loss: 0.007960 | valid loss: 0.007585\n","Epoch:  264 | train loss: 0.007265 | valid loss: 0.007608\n","Epoch:  265 | train loss: 0.006105 | valid loss: 0.007702\n","Epoch:  266 | train loss: 0.004574 | valid loss: 0.007633\n","Epoch:  267 | train loss: 0.006655 | valid loss: 0.007757\n","Epoch:  268 | train loss: 0.006969 | valid loss: 0.007691\n","Epoch:  269 | train loss: 0.006877 | valid loss: 0.007677\n","Epoch:  270 | train loss: 0.006178 | valid loss: 0.007589\n","Epoch:  271 | train loss: 0.007669 | valid loss: 0.007658\n","Epoch:  272 | train loss: 0.008105 | valid loss: 0.007550\n","Epoch:  273 | train loss: 0.004976 | valid loss: 0.007587\n","Epoch:  274 | train loss: 0.006899 | valid loss: 0.007632\n","Epoch:  275 | train loss: 0.008129 | valid loss: 0.007586\n","Epoch:  276 | train loss: 0.005380 | valid loss: 0.007555\n","Epoch:  277 | train loss: 0.008608 | valid loss: 0.007588\n","Epoch:  278 | train loss: 0.008597 | valid loss: 0.007630\n","Epoch:  279 | train loss: 0.007942 | valid loss: 0.007544\n","Epoch:  280 | train loss: 0.011271 | valid loss: 0.007618\n","Epoch:  281 | train loss: 0.005485 | valid loss: 0.007610\n","Epoch:  282 | train loss: 0.004181 | valid loss: 0.007601\n","Epoch:  283 | train loss: 0.006392 | valid loss: 0.007576\n","Epoch:  284 | train loss: 0.009622 | valid loss: 0.007601\n","Epoch:  285 | train loss: 0.010033 | valid loss: 0.007588\n","Epoch:  286 | train loss: 0.006409 | valid loss: 0.007532\n","Epoch:  287 | train loss: 0.007192 | valid loss: 0.007699\n","Epoch:  288 | train loss: 0.006341 | valid loss: 0.007699\n","Epoch:  289 | train loss: 0.006502 | valid loss: 0.007581\n","Epoch:  290 | train loss: 0.005065 | valid loss: 0.007596\n","Epoch:  291 | train loss: 0.009915 | valid loss: 0.007613\n","Epoch:  292 | train loss: 0.010973 | valid loss: 0.007759\n","Epoch:  293 | train loss: 0.005662 | valid loss: 0.007623\n","Epoch:  294 | train loss: 0.010134 | valid loss: 0.007682\n","Epoch:  295 | train loss: 0.005967 | valid loss: 0.007716\n","Epoch:  296 | train loss: 0.009541 | valid loss: 0.007624\n","Epoch:  297 | train loss: 0.007544 | valid loss: 0.007693\n","Epoch:  298 | train loss: 0.005805 | valid loss: 0.007603\n","Epoch:  299 | train loss: 0.005935 | valid loss: 0.007565\n","Epoch:  300 | train loss: 0.008382 | valid loss: 0.007577\n","Epoch:  301 | train loss: 0.007365 | valid loss: 0.007633\n","Epoch:  302 | train loss: 0.006197 | valid loss: 0.007597\n","Epoch:  303 | train loss: 0.005301 | valid loss: 0.007617\n","Epoch:  304 | train loss: 0.008059 | valid loss: 0.007711\n","Epoch:  305 | train loss: 0.006745 | valid loss: 0.007588\n","Epoch:  306 | train loss: 0.008803 | valid loss: 0.007537\n","Epoch:  307 | train loss: 0.008334 | valid loss: 0.007711\n","Epoch:  308 | train loss: 0.009556 | valid loss: 0.007596\n","Epoch:  309 | train loss: 0.004857 | valid loss: 0.007585\n","Epoch:  310 | train loss: 0.004810 | valid loss: 0.007567\n","Epoch:  311 | train loss: 0.005976 | valid loss: 0.007517\n","Epoch:  312 | train loss: 0.007246 | valid loss: 0.007610\n","Epoch:  313 | train loss: 0.005909 | valid loss: 0.007618\n","Epoch:  314 | train loss: 0.007413 | valid loss: 0.007576\n","Epoch:  315 | train loss: 0.009266 | valid loss: 0.007628\n","Epoch:  316 | train loss: 0.005635 | valid loss: 0.007742\n","Epoch:  317 | train loss: 0.005526 | valid loss: 0.007716\n","Epoch:  318 | train loss: 0.007266 | valid loss: 0.007602\n","Epoch:  319 | train loss: 0.005475 | valid loss: 0.007717\n","Epoch:  320 | train loss: 0.005336 | valid loss: 0.007520\n","Epoch:  321 | train loss: 0.009151 | valid loss: 0.007621\n","Epoch:  322 | train loss: 0.004795 | valid loss: 0.007844\n","Epoch:  323 | train loss: 0.007870 | valid loss: 0.007575\n","Epoch:  324 | train loss: 0.007837 | valid loss: 0.007588\n","Epoch:  325 | train loss: 0.008603 | valid loss: 0.007832\n","Epoch:  326 | train loss: 0.007956 | valid loss: 0.007730\n","Epoch:  327 | train loss: 0.006197 | valid loss: 0.007621\n","Epoch:  328 | train loss: 0.008904 | valid loss: 0.007660\n","Epoch:  329 | train loss: 0.005447 | valid loss: 0.007567\n","Epoch:  330 | train loss: 0.006807 | valid loss: 0.007611\n","Epoch:  331 | train loss: 0.008168 | valid loss: 0.007713\n","Epoch:  332 | train loss: 0.005631 | valid loss: 0.007692\n","Epoch:  333 | train loss: 0.007083 | valid loss: 0.007667\n","Epoch:  334 | train loss: 0.005986 | valid loss: 0.007613\n","Epoch:  335 | train loss: 0.005576 | valid loss: 0.007545\n","Epoch:  336 | train loss: 0.003461 | valid loss: 0.007491\n","Epoch:  337 | train loss: 0.007271 | valid loss: 0.007627\n","Epoch:  338 | train loss: 0.007915 | valid loss: 0.007558\n","Epoch:  339 | train loss: 0.007294 | valid loss: 0.007536\n","Epoch:  340 | train loss: 0.007168 | valid loss: 0.007629\n","Epoch:  341 | train loss: 0.010590 | valid loss: 0.007619\n","Epoch:  342 | train loss: 0.005536 | valid loss: 0.007690\n","Epoch:  343 | train loss: 0.005655 | valid loss: 0.007676\n","Epoch:  344 | train loss: 0.006915 | valid loss: 0.007703\n","Epoch:  345 | train loss: 0.006388 | valid loss: 0.007652\n","Epoch:  346 | train loss: 0.005671 | valid loss: 0.007586\n","Epoch:  347 | train loss: 0.005456 | valid loss: 0.007480\n","Epoch:  348 | train loss: 0.008996 | valid loss: 0.007637\n","Epoch:  349 | train loss: 0.004697 | valid loss: 0.007650\n","Epoch:  350 | train loss: 0.006941 | valid loss: 0.007599\n","Epoch:  351 | train loss: 0.005804 | valid loss: 0.007605\n","Epoch:  352 | train loss: 0.007308 | valid loss: 0.007599\n","Epoch:  353 | train loss: 0.011137 | valid loss: 0.007726\n","Epoch:  354 | train loss: 0.006672 | valid loss: 0.007743\n","Epoch:  355 | train loss: 0.005797 | valid loss: 0.007498\n","Epoch:  356 | train loss: 0.004283 | valid loss: 0.007541\n","Epoch:  357 | train loss: 0.007936 | valid loss: 0.007591\n","Epoch:  358 | train loss: 0.008195 | valid loss: 0.007662\n","Epoch:  359 | train loss: 0.006290 | valid loss: 0.007690\n","Epoch:  360 | train loss: 0.004050 | valid loss: 0.007680\n","Epoch:  361 | train loss: 0.006780 | valid loss: 0.007682\n","Epoch:  362 | train loss: 0.006807 | valid loss: 0.007644\n","Epoch:  363 | train loss: 0.005092 | valid loss: 0.007625\n","Epoch:  364 | train loss: 0.006368 | valid loss: 0.007811\n","Epoch:  365 | train loss: 0.007458 | valid loss: 0.007782\n","Epoch:  366 | train loss: 0.005170 | valid loss: 0.007579\n","Epoch:  367 | train loss: 0.014975 | valid loss: 0.007497\n","Epoch:  368 | train loss: 0.005419 | valid loss: 0.007571\n","Epoch:  369 | train loss: 0.006551 | valid loss: 0.007616\n","Epoch:  370 | train loss: 0.004023 | valid loss: 0.007501\n","Epoch:  371 | train loss: 0.009608 | valid loss: 0.007573\n","Epoch:  372 | train loss: 0.004461 | valid loss: 0.007585\n","Epoch:  373 | train loss: 0.010302 | valid loss: 0.007567\n","Epoch:  374 | train loss: 0.007118 | valid loss: 0.007553\n","Epoch:  375 | train loss: 0.010851 | valid loss: 0.007659\n","Epoch:  376 | train loss: 0.006399 | valid loss: 0.007605\n","Epoch:  377 | train loss: 0.005607 | valid loss: 0.007482\n","Epoch:  378 | train loss: 0.006464 | valid loss: 0.007553\n","Epoch:  379 | train loss: 0.005436 | valid loss: 0.007553\n","Epoch:  380 | train loss: 0.006591 | valid loss: 0.007637\n","Epoch:  381 | train loss: 0.006573 | valid loss: 0.007791\n","Epoch:  382 | train loss: 0.005634 | valid loss: 0.007578\n","Epoch:  383 | train loss: 0.008154 | valid loss: 0.007581\n","Epoch:  384 | train loss: 0.008535 | valid loss: 0.007691\n","Epoch:  385 | train loss: 0.006640 | valid loss: 0.007555\n","Epoch:  386 | train loss: 0.006875 | valid loss: 0.007640\n","Epoch:  387 | train loss: 0.006198 | valid loss: 0.007622\n","Epoch:  388 | train loss: 0.009801 | valid loss: 0.007578\n","Epoch:  389 | train loss: 0.006812 | valid loss: 0.007556\n","Epoch:  390 | train loss: 0.003784 | valid loss: 0.007577\n","Epoch:  391 | train loss: 0.005664 | valid loss: 0.007517\n","Epoch:  392 | train loss: 0.005049 | valid loss: 0.007634\n","Epoch:  393 | train loss: 0.006948 | valid loss: 0.007509\n","Epoch:  394 | train loss: 0.006565 | valid loss: 0.007495\n","Epoch:  395 | train loss: 0.006703 | valid loss: 0.007639\n","Epoch:  396 | train loss: 0.010225 | valid loss: 0.007600\n","Epoch:  397 | train loss: 0.004039 | valid loss: 0.007591\n","Epoch:  398 | train loss: 0.008094 | valid loss: 0.007587\n","Epoch:  399 | train loss: 0.008867 | valid loss: 0.007537\n","Epoch:  400 | train loss: 0.006513 | valid loss: 0.007628\n","Epoch:  401 | train loss: 0.005550 | valid loss: 0.007660\n","Epoch:  402 | train loss: 0.005462 | valid loss: 0.007554\n","Epoch:  403 | train loss: 0.010086 | valid loss: 0.007599\n","Epoch:  404 | train loss: 0.008473 | valid loss: 0.007631\n","Epoch:  405 | train loss: 0.006940 | valid loss: 0.007544\n","Epoch:  406 | train loss: 0.006211 | valid loss: 0.007543\n","Epoch:  407 | train loss: 0.005702 | valid loss: 0.007612\n","Epoch:  408 | train loss: 0.006585 | valid loss: 0.007566\n","Epoch:  409 | train loss: 0.010910 | valid loss: 0.007665\n","Epoch:  410 | train loss: 0.008131 | valid loss: 0.007750\n","Epoch:  411 | train loss: 0.004208 | valid loss: 0.007605\n","Epoch:  412 | train loss: 0.007441 | valid loss: 0.007550\n","Epoch:  413 | train loss: 0.005527 | valid loss: 0.007693\n","Epoch:  414 | train loss: 0.005173 | valid loss: 0.007481\n","Epoch:  415 | train loss: 0.006239 | valid loss: 0.007600\n","Epoch:  416 | train loss: 0.004587 | valid loss: 0.007580\n","Epoch:  417 | train loss: 0.007158 | valid loss: 0.007537\n","Epoch:  418 | train loss: 0.008570 | valid loss: 0.007607\n","Epoch:  419 | train loss: 0.008621 | valid loss: 0.007563\n","Epoch:  420 | train loss: 0.008862 | valid loss: 0.007601\n","Epoch:  421 | train loss: 0.005658 | valid loss: 0.007564\n","Epoch:  422 | train loss: 0.006749 | valid loss: 0.007591\n","Epoch:  423 | train loss: 0.007882 | valid loss: 0.007698\n","Epoch:  424 | train loss: 0.004569 | valid loss: 0.007628\n","Epoch:  425 | train loss: 0.005151 | valid loss: 0.007661\n","Epoch:  426 | train loss: 0.005549 | valid loss: 0.007652\n","Epoch:  427 | train loss: 0.008391 | valid loss: 0.007577\n","Epoch:  428 | train loss: 0.005942 | valid loss: 0.007637\n","Epoch:  429 | train loss: 0.007985 | valid loss: 0.007634\n","Epoch:  430 | train loss: 0.005447 | valid loss: 0.007624\n","Epoch:  431 | train loss: 0.005572 | valid loss: 0.007591\n","Epoch:  432 | train loss: 0.004704 | valid loss: 0.007674\n","Epoch:  433 | train loss: 0.010542 | valid loss: 0.007730\n","Epoch:  434 | train loss: 0.006935 | valid loss: 0.007549\n","Epoch:  435 | train loss: 0.010125 | valid loss: 0.007535\n","Epoch:  436 | train loss: 0.007327 | valid loss: 0.007618\n","Epoch:  437 | train loss: 0.009427 | valid loss: 0.007621\n","Epoch:  438 | train loss: 0.005465 | valid loss: 0.007629\n","Epoch:  439 | train loss: 0.004702 | valid loss: 0.007733\n","Epoch:  440 | train loss: 0.006720 | valid loss: 0.007707\n","Epoch:  441 | train loss: 0.005916 | valid loss: 0.007646\n","Epoch:  442 | train loss: 0.006919 | valid loss: 0.007534\n","Epoch:  443 | train loss: 0.006832 | valid loss: 0.007728\n","Epoch:  444 | train loss: 0.005292 | valid loss: 0.007609\n","Epoch:  445 | train loss: 0.008241 | valid loss: 0.007692\n","Epoch:  446 | train loss: 0.007387 | valid loss: 0.007623\n","Epoch:  447 | train loss: 0.004831 | valid loss: 0.007652\n","Epoch:  448 | train loss: 0.004924 | valid loss: 0.007556\n","Epoch:  449 | train loss: 0.007417 | valid loss: 0.007603\n","Epoch:  450 | train loss: 0.006637 | valid loss: 0.007623\n","Epoch:  451 | train loss: 0.007590 | valid loss: 0.007567\n","Epoch:  452 | train loss: 0.004802 | valid loss: 0.007668\n","Epoch:  453 | train loss: 0.007070 | valid loss: 0.007678\n","Epoch:  454 | train loss: 0.004637 | valid loss: 0.007686\n","Epoch:  455 | train loss: 0.004488 | valid loss: 0.007566\n","Epoch:  456 | train loss: 0.004160 | valid loss: 0.007505\n","Epoch:  457 | train loss: 0.005644 | valid loss: 0.007621\n","Epoch:  458 | train loss: 0.007086 | valid loss: 0.007547\n","Epoch:  459 | train loss: 0.007489 | valid loss: 0.007656\n","Epoch:  460 | train loss: 0.007777 | valid loss: 0.007662\n","Epoch:  461 | train loss: 0.005603 | valid loss: 0.007721\n","Epoch:  462 | train loss: 0.005518 | valid loss: 0.007715\n","Epoch:  463 | train loss: 0.008657 | valid loss: 0.007727\n","Epoch:  464 | train loss: 0.006318 | valid loss: 0.007597\n","Epoch:  465 | train loss: 0.008380 | valid loss: 0.007573\n","Epoch:  466 | train loss: 0.007187 | valid loss: 0.007599\n","Epoch:  467 | train loss: 0.008965 | valid loss: 0.007549\n","Epoch:  468 | train loss: 0.009748 | valid loss: 0.007651\n","Epoch:  469 | train loss: 0.007347 | valid loss: 0.007535\n","Epoch:  470 | train loss: 0.007383 | valid loss: 0.007682\n","Epoch:  471 | train loss: 0.006755 | valid loss: 0.007665\n","Epoch:  472 | train loss: 0.006725 | valid loss: 0.007642\n","Epoch:  473 | train loss: 0.009029 | valid loss: 0.007718\n","Epoch:  474 | train loss: 0.006136 | valid loss: 0.007804\n","Epoch:  475 | train loss: 0.005521 | valid loss: 0.007716\n","Epoch:  476 | train loss: 0.006951 | valid loss: 0.007764\n","Epoch:  477 | train loss: 0.007468 | valid loss: 0.007666\n","Epoch:  478 | train loss: 0.006029 | valid loss: 0.007651\n","Epoch:  479 | train loss: 0.006076 | valid loss: 0.007678\n","Epoch:  480 | train loss: 0.006991 | valid loss: 0.007669\n","Epoch:  481 | train loss: 0.005382 | valid loss: 0.007694\n","Epoch:  482 | train loss: 0.004209 | valid loss: 0.007637\n","Epoch:  483 | train loss: 0.005235 | valid loss: 0.007556\n","Epoch:  484 | train loss: 0.007576 | valid loss: 0.007626\n","Epoch:  485 | train loss: 0.008329 | valid loss: 0.007606\n","Epoch:  486 | train loss: 0.008347 | valid loss: 0.007628\n","Epoch:  487 | train loss: 0.006280 | valid loss: 0.007679\n","Epoch:  488 | train loss: 0.009626 | valid loss: 0.007695\n","Epoch:  489 | train loss: 0.007632 | valid loss: 0.007597\n","Epoch:  490 | train loss: 0.006270 | valid loss: 0.007603\n","Epoch:  491 | train loss: 0.007961 | valid loss: 0.007657\n","Epoch:  492 | train loss: 0.007729 | valid loss: 0.007691\n","Epoch:  493 | train loss: 0.004895 | valid loss: 0.007633\n","Epoch:  494 | train loss: 0.007179 | valid loss: 0.007660\n","Epoch:  495 | train loss: 0.004632 | valid loss: 0.007601\n","Epoch:  496 | train loss: 0.009431 | valid loss: 0.007611\n","Epoch:  497 | train loss: 0.007025 | valid loss: 0.007653\n","Epoch:  498 | train loss: 0.007294 | valid loss: 0.007651\n","Epoch:  499 | train loss: 0.006470 | valid loss: 0.007580\n","Epoch:  500 | train loss: 0.006769 | valid loss: 0.007597\n","Epoch:  501 | train loss: 0.006308 | valid loss: 0.007660\n","Epoch:  502 | train loss: 0.011182 | valid loss: 0.007780\n","Epoch:  503 | train loss: 0.008367 | valid loss: 0.007714\n","Epoch:  504 | train loss: 0.004564 | valid loss: 0.007785\n","Epoch:  505 | train loss: 0.006617 | valid loss: 0.007670\n","Epoch:  506 | train loss: 0.005530 | valid loss: 0.007626\n","Epoch:  507 | train loss: 0.011820 | valid loss: 0.007583\n","Epoch:  508 | train loss: 0.004329 | valid loss: 0.007661\n","Epoch:  509 | train loss: 0.005767 | valid loss: 0.007890\n","Epoch:  510 | train loss: 0.009878 | valid loss: 0.007806\n","Epoch:  511 | train loss: 0.005647 | valid loss: 0.007740\n","Epoch:  512 | train loss: 0.006704 | valid loss: 0.007576\n","Epoch:  513 | train loss: 0.006948 | valid loss: 0.007645\n","Epoch:  514 | train loss: 0.004805 | valid loss: 0.007690\n","Epoch:  515 | train loss: 0.007408 | valid loss: 0.007601\n","Epoch:  516 | train loss: 0.006832 | valid loss: 0.007569\n","Epoch:  517 | train loss: 0.007903 | valid loss: 0.007571\n","Epoch:  518 | train loss: 0.006645 | valid loss: 0.007664\n","Epoch:  519 | train loss: 0.007588 | valid loss: 0.007617\n","Epoch:  520 | train loss: 0.007508 | valid loss: 0.007785\n","Epoch:  521 | train loss: 0.007509 | valid loss: 0.007634\n","Epoch:  522 | train loss: 0.005745 | valid loss: 0.007771\n","Epoch:  523 | train loss: 0.004515 | valid loss: 0.007633\n","Epoch:  524 | train loss: 0.004713 | valid loss: 0.007849\n","Epoch:  525 | train loss: 0.007032 | valid loss: 0.007669\n","Epoch:  526 | train loss: 0.008227 | valid loss: 0.007893\n","Epoch:  527 | train loss: 0.006625 | valid loss: 0.007695\n","Epoch:  528 | train loss: 0.005906 | valid loss: 0.007589\n","Epoch:  529 | train loss: 0.006070 | valid loss: 0.007639\n","Epoch:  530 | train loss: 0.004410 | valid loss: 0.007756\n","Epoch:  531 | train loss: 0.004819 | valid loss: 0.007582\n","Epoch:  532 | train loss: 0.010440 | valid loss: 0.007675\n","Epoch:  533 | train loss: 0.006529 | valid loss: 0.007694\n","Epoch:  534 | train loss: 0.007774 | valid loss: 0.007673\n","Epoch:  535 | train loss: 0.005689 | valid loss: 0.007702\n","Epoch:  536 | train loss: 0.008113 | valid loss: 0.007832\n","Epoch:  537 | train loss: 0.006875 | valid loss: 0.007686\n","Epoch:  538 | train loss: 0.007673 | valid loss: 0.007658\n","Epoch:  539 | train loss: 0.006748 | valid loss: 0.007661\n","Epoch:  540 | train loss: 0.007062 | valid loss: 0.007679\n","Epoch:  541 | train loss: 0.005802 | valid loss: 0.007899\n","Epoch:  542 | train loss: 0.004866 | valid loss: 0.007727\n","Epoch:  543 | train loss: 0.007897 | valid loss: 0.007696\n","Epoch:  544 | train loss: 0.006023 | valid loss: 0.007736\n","Epoch:  545 | train loss: 0.010632 | valid loss: 0.007692\n","Epoch:  546 | train loss: 0.005264 | valid loss: 0.007634\n","Epoch:  547 | train loss: 0.005866 | valid loss: 0.007544\n","Epoch:  548 | train loss: 0.007305 | valid loss: 0.007695\n","Epoch:  549 | train loss: 0.007516 | valid loss: 0.007560\n","Epoch:  550 | train loss: 0.005796 | valid loss: 0.007729\n","Epoch:  551 | train loss: 0.006668 | valid loss: 0.007671\n","Epoch:  552 | train loss: 0.005532 | valid loss: 0.007634\n","Epoch:  553 | train loss: 0.006125 | valid loss: 0.007658\n","Epoch:  554 | train loss: 0.004146 | valid loss: 0.007620\n","Epoch:  555 | train loss: 0.009332 | valid loss: 0.007743\n","Epoch:  556 | train loss: 0.006332 | valid loss: 0.007710\n","Epoch:  557 | train loss: 0.007610 | valid loss: 0.007760\n","Epoch:  558 | train loss: 0.006590 | valid loss: 0.007667\n","Epoch:  559 | train loss: 0.006703 | valid loss: 0.007767\n","Epoch:  560 | train loss: 0.008617 | valid loss: 0.007626\n","Epoch:  561 | train loss: 0.007651 | valid loss: 0.007700\n","Epoch:  562 | train loss: 0.006025 | valid loss: 0.007660\n","Epoch:  563 | train loss: 0.009409 | valid loss: 0.007645\n","Epoch:  564 | train loss: 0.005309 | valid loss: 0.007779\n","Epoch:  565 | train loss: 0.004967 | valid loss: 0.007726\n","Epoch:  566 | train loss: 0.005882 | valid loss: 0.007593\n","Epoch:  567 | train loss: 0.006272 | valid loss: 0.007726\n","Epoch:  568 | train loss: 0.006184 | valid loss: 0.007548\n","Epoch:  569 | train loss: 0.007863 | valid loss: 0.007621\n","Epoch:  570 | train loss: 0.003268 | valid loss: 0.007664\n","Epoch:  571 | train loss: 0.006471 | valid loss: 0.007546\n","Epoch:  572 | train loss: 0.005662 | valid loss: 0.007633\n","Epoch:  573 | train loss: 0.010577 | valid loss: 0.007613\n","Epoch:  574 | train loss: 0.006844 | valid loss: 0.007714\n","Epoch:  575 | train loss: 0.007080 | valid loss: 0.007609\n","Epoch:  576 | train loss: 0.008155 | valid loss: 0.007731\n","Epoch:  577 | train loss: 0.006583 | valid loss: 0.007729\n","Epoch:  578 | train loss: 0.010074 | valid loss: 0.007648\n","Epoch:  579 | train loss: 0.006389 | valid loss: 0.007597\n","Epoch:  580 | train loss: 0.006002 | valid loss: 0.007849\n","Epoch:  581 | train loss: 0.005695 | valid loss: 0.007677\n","Epoch:  582 | train loss: 0.005382 | valid loss: 0.007660\n","Epoch:  583 | train loss: 0.005063 | valid loss: 0.007850\n","Epoch:  584 | train loss: 0.008287 | valid loss: 0.007614\n","Epoch:  585 | train loss: 0.007748 | valid loss: 0.007720\n","Epoch:  586 | train loss: 0.007658 | valid loss: 0.007579\n","Epoch:  587 | train loss: 0.002783 | valid loss: 0.007743\n","Epoch:  588 | train loss: 0.004405 | valid loss: 0.007582\n","Epoch:  589 | train loss: 0.006778 | valid loss: 0.007705\n","Epoch:  590 | train loss: 0.005339 | valid loss: 0.007714\n","Epoch:  591 | train loss: 0.009416 | valid loss: 0.007753\n","Epoch:  592 | train loss: 0.006498 | valid loss: 0.007650\n","Epoch:  593 | train loss: 0.004431 | valid loss: 0.007708\n","Epoch:  594 | train loss: 0.006398 | valid loss: 0.007672\n","Epoch:  595 | train loss: 0.004469 | valid loss: 0.007529\n","Epoch:  596 | train loss: 0.007781 | valid loss: 0.007715\n","Epoch:  597 | train loss: 0.008327 | valid loss: 0.007780\n","Epoch:  598 | train loss: 0.007099 | valid loss: 0.007735\n","Epoch:  599 | train loss: 0.008942 | valid loss: 0.007858\n","Epoch:  600 | train loss: 0.009607 | valid loss: 0.007611\n","Epoch:  601 | train loss: 0.008272 | valid loss: 0.007739\n","Epoch:  602 | train loss: 0.007500 | valid loss: 0.007797\n","Epoch:  603 | train loss: 0.005851 | valid loss: 0.007659\n","Epoch:  604 | train loss: 0.008922 | valid loss: 0.007649\n","Epoch:  605 | train loss: 0.005680 | valid loss: 0.007890\n","Epoch:  606 | train loss: 0.004501 | valid loss: 0.007751\n","Epoch:  607 | train loss: 0.006902 | valid loss: 0.007819\n","Epoch:  608 | train loss: 0.004233 | valid loss: 0.007700\n","Epoch:  609 | train loss: 0.005430 | valid loss: 0.007779\n","Epoch:  610 | train loss: 0.006366 | valid loss: 0.007735\n","Epoch:  611 | train loss: 0.005611 | valid loss: 0.007691\n","Epoch:  612 | train loss: 0.005845 | valid loss: 0.007781\n","Epoch:  613 | train loss: 0.004331 | valid loss: 0.007727\n","Epoch:  614 | train loss: 0.008661 | valid loss: 0.007658\n","Epoch:  615 | train loss: 0.003805 | valid loss: 0.007738\n","Epoch:  616 | train loss: 0.005024 | valid loss: 0.007743\n","Epoch:  617 | train loss: 0.006017 | valid loss: 0.007735\n","Epoch:  618 | train loss: 0.005761 | valid loss: 0.007792\n","Epoch:  619 | train loss: 0.005556 | valid loss: 0.007639\n","Epoch:  620 | train loss: 0.007706 | valid loss: 0.007679\n","Epoch:  621 | train loss: 0.006222 | valid loss: 0.007726\n","Epoch:  622 | train loss: 0.006441 | valid loss: 0.007714\n","Epoch:  623 | train loss: 0.004570 | valid loss: 0.007736\n","Epoch:  624 | train loss: 0.005945 | valid loss: 0.007704\n","Epoch:  625 | train loss: 0.006414 | valid loss: 0.007621\n","Epoch:  626 | train loss: 0.007701 | valid loss: 0.007767\n","Epoch:  627 | train loss: 0.005340 | valid loss: 0.007698\n","Epoch:  628 | train loss: 0.004047 | valid loss: 0.007762\n","Epoch:  629 | train loss: 0.009760 | valid loss: 0.007683\n","Epoch:  630 | train loss: 0.009085 | valid loss: 0.007700\n","Epoch:  631 | train loss: 0.007853 | valid loss: 0.007694\n","Epoch:  632 | train loss: 0.011256 | valid loss: 0.007822\n","Epoch:  633 | train loss: 0.008036 | valid loss: 0.007643\n","Epoch:  634 | train loss: 0.007712 | valid loss: 0.007871\n","Epoch:  635 | train loss: 0.004913 | valid loss: 0.007655\n","Epoch:  636 | train loss: 0.005623 | valid loss: 0.007780\n","Epoch:  637 | train loss: 0.008824 | valid loss: 0.007791\n","Epoch:  638 | train loss: 0.005456 | valid loss: 0.007919\n","Epoch:  639 | train loss: 0.007556 | valid loss: 0.007813\n","Epoch:  640 | train loss: 0.005323 | valid loss: 0.007767\n","Epoch:  641 | train loss: 0.007422 | valid loss: 0.007652\n","Epoch:  642 | train loss: 0.005870 | valid loss: 0.007675\n","Epoch:  643 | train loss: 0.005663 | valid loss: 0.007549\n","Epoch:  644 | train loss: 0.008103 | valid loss: 0.007628\n","Epoch:  645 | train loss: 0.005551 | valid loss: 0.007628\n","Epoch:  646 | train loss: 0.006464 | valid loss: 0.007595\n","Epoch:  647 | train loss: 0.006331 | valid loss: 0.007908\n","Epoch:  648 | train loss: 0.009044 | valid loss: 0.007608\n","Epoch:  649 | train loss: 0.007624 | valid loss: 0.007783\n","Epoch:  650 | train loss: 0.006340 | valid loss: 0.007680\n","Epoch:  651 | train loss: 0.007861 | valid loss: 0.007635\n","Epoch:  652 | train loss: 0.005891 | valid loss: 0.007802\n","Epoch:  653 | train loss: 0.005214 | valid loss: 0.007780\n","Epoch:  654 | train loss: 0.005637 | valid loss: 0.008194\n","Epoch:  655 | train loss: 0.005087 | valid loss: 0.007640\n","Epoch:  656 | train loss: 0.004610 | valid loss: 0.007814\n","Epoch:  657 | train loss: 0.004990 | valid loss: 0.007682\n","Epoch:  658 | train loss: 0.006702 | valid loss: 0.007618\n","Epoch:  659 | train loss: 0.003423 | valid loss: 0.007723\n","Epoch:  660 | train loss: 0.007452 | valid loss: 0.007794\n","Epoch:  661 | train loss: 0.007585 | valid loss: 0.007669\n","Epoch:  662 | train loss: 0.006977 | valid loss: 0.007678\n","Epoch:  663 | train loss: 0.006960 | valid loss: 0.007755\n","Epoch:  664 | train loss: 0.007617 | valid loss: 0.007932\n","Epoch:  665 | train loss: 0.003707 | valid loss: 0.007772\n","Epoch:  666 | train loss: 0.007832 | valid loss: 0.007698\n","Epoch:  667 | train loss: 0.007110 | valid loss: 0.007855\n","Epoch:  668 | train loss: 0.008123 | valid loss: 0.007751\n","Epoch:  669 | train loss: 0.004226 | valid loss: 0.007719\n","Epoch:  670 | train loss: 0.004656 | valid loss: 0.007776\n","Epoch:  671 | train loss: 0.006622 | valid loss: 0.007706\n","Epoch:  672 | train loss: 0.005421 | valid loss: 0.007812\n","Epoch:  673 | train loss: 0.003453 | valid loss: 0.007668\n","Epoch:  674 | train loss: 0.008156 | valid loss: 0.007834\n","Epoch:  675 | train loss: 0.006948 | valid loss: 0.007750\n","Epoch:  676 | train loss: 0.005798 | valid loss: 0.007971\n","Epoch:  677 | train loss: 0.008803 | valid loss: 0.007694\n","Epoch:  678 | train loss: 0.008165 | valid loss: 0.007817\n","Epoch:  679 | train loss: 0.005697 | valid loss: 0.007612\n","Epoch:  680 | train loss: 0.006930 | valid loss: 0.007846\n","Epoch:  681 | train loss: 0.007534 | valid loss: 0.007731\n","Epoch:  682 | train loss: 0.007986 | valid loss: 0.007923\n","Epoch:  683 | train loss: 0.004486 | valid loss: 0.007650\n","Epoch:  684 | train loss: 0.005383 | valid loss: 0.007904\n","Epoch:  685 | train loss: 0.005033 | valid loss: 0.007799\n","Epoch:  686 | train loss: 0.004511 | valid loss: 0.007901\n","Epoch:  687 | train loss: 0.005548 | valid loss: 0.007874\n","Epoch:  688 | train loss: 0.006422 | valid loss: 0.007789\n","Epoch:  689 | train loss: 0.006056 | valid loss: 0.007935\n","Epoch:  690 | train loss: 0.007823 | valid loss: 0.007717\n","Epoch:  691 | train loss: 0.006584 | valid loss: 0.007729\n","Epoch:  692 | train loss: 0.008327 | valid loss: 0.007890\n","Epoch:  693 | train loss: 0.007036 | valid loss: 0.007736\n","Epoch:  694 | train loss: 0.004467 | valid loss: 0.007702\n","Epoch:  695 | train loss: 0.007823 | valid loss: 0.007686\n","Epoch:  696 | train loss: 0.004036 | valid loss: 0.007785\n","Epoch:  697 | train loss: 0.006804 | valid loss: 0.007707\n","Epoch:  698 | train loss: 0.005157 | valid loss: 0.007725\n","Epoch:  699 | train loss: 0.006178 | valid loss: 0.007760\n","Epoch:  700 | train loss: 0.007768 | valid loss: 0.007810\n","Epoch:  701 | train loss: 0.003537 | valid loss: 0.007775\n","Epoch:  702 | train loss: 0.003802 | valid loss: 0.007720\n","Epoch:  703 | train loss: 0.008804 | valid loss: 0.007744\n","Epoch:  704 | train loss: 0.006050 | valid loss: 0.007684\n","Epoch:  705 | train loss: 0.006452 | valid loss: 0.007814\n","Epoch:  706 | train loss: 0.007615 | valid loss: 0.007675\n","Epoch:  707 | train loss: 0.006616 | valid loss: 0.007818\n","Epoch:  708 | train loss: 0.005407 | valid loss: 0.007965\n","Epoch:  709 | train loss: 0.005556 | valid loss: 0.007859\n","Epoch:  710 | train loss: 0.005221 | valid loss: 0.007677\n","Epoch:  711 | train loss: 0.010651 | valid loss: 0.007809\n","Epoch:  712 | train loss: 0.004386 | valid loss: 0.007602\n","Epoch:  713 | train loss: 0.004594 | valid loss: 0.007744\n","Epoch:  714 | train loss: 0.010557 | valid loss: 0.007777\n","Epoch:  715 | train loss: 0.003022 | valid loss: 0.007630\n","Epoch:  716 | train loss: 0.008341 | valid loss: 0.007678\n","Epoch:  717 | train loss: 0.008416 | valid loss: 0.007565\n","Epoch:  718 | train loss: 0.009676 | valid loss: 0.007687\n","Epoch:  719 | train loss: 0.006478 | valid loss: 0.007740\n","Epoch:  720 | train loss: 0.007579 | valid loss: 0.007877\n","Epoch:  721 | train loss: 0.007647 | valid loss: 0.007877\n","Epoch:  722 | train loss: 0.006764 | valid loss: 0.007715\n","Epoch:  723 | train loss: 0.005340 | valid loss: 0.007762\n","Epoch:  724 | train loss: 0.006793 | valid loss: 0.007898\n","Epoch:  725 | train loss: 0.008170 | valid loss: 0.007663\n","Epoch:  726 | train loss: 0.007862 | valid loss: 0.007857\n","Epoch:  727 | train loss: 0.005623 | valid loss: 0.007803\n","Epoch:  728 | train loss: 0.006603 | valid loss: 0.007717\n","Epoch:  729 | train loss: 0.008728 | valid loss: 0.007798\n","Epoch:  730 | train loss: 0.004751 | valid loss: 0.007751\n","Epoch:  731 | train loss: 0.007160 | valid loss: 0.007805\n","Epoch:  732 | train loss: 0.007501 | valid loss: 0.007709\n","Epoch:  733 | train loss: 0.008382 | valid loss: 0.007838\n","Epoch:  734 | train loss: 0.007226 | valid loss: 0.007820\n","Epoch:  735 | train loss: 0.003810 | valid loss: 0.007790\n","Epoch:  736 | train loss: 0.010327 | valid loss: 0.007812\n","Epoch:  737 | train loss: 0.006945 | valid loss: 0.007729\n","Epoch:  738 | train loss: 0.008068 | valid loss: 0.007728\n","Epoch:  739 | train loss: 0.007541 | valid loss: 0.007775\n","Epoch:  740 | train loss: 0.010178 | valid loss: 0.007785\n","Epoch:  741 | train loss: 0.014070 | valid loss: 0.007774\n","Epoch:  742 | train loss: 0.005591 | valid loss: 0.007764\n","Epoch:  743 | train loss: 0.004796 | valid loss: 0.007728\n","Epoch:  744 | train loss: 0.008628 | valid loss: 0.007587\n","Epoch:  745 | train loss: 0.010320 | valid loss: 0.007742\n","Epoch:  746 | train loss: 0.005942 | valid loss: 0.007798\n","Epoch:  747 | train loss: 0.005325 | valid loss: 0.007900\n","Epoch:  748 | train loss: 0.003761 | valid loss: 0.007691\n","Epoch:  749 | train loss: 0.003627 | valid loss: 0.007829\n","Epoch:  750 | train loss: 0.005609 | valid loss: 0.007726\n","Epoch:  751 | train loss: 0.007037 | valid loss: 0.007747\n","Epoch:  752 | train loss: 0.008807 | valid loss: 0.007628\n","Epoch:  753 | train loss: 0.007269 | valid loss: 0.007742\n","Epoch:  754 | train loss: 0.006853 | valid loss: 0.007698\n","Epoch:  755 | train loss: 0.006600 | valid loss: 0.007783\n","Epoch:  756 | train loss: 0.003946 | valid loss: 0.007761\n","Epoch:  757 | train loss: 0.008835 | valid loss: 0.007827\n","Epoch:  758 | train loss: 0.007527 | valid loss: 0.007914\n","Epoch:  759 | train loss: 0.003927 | valid loss: 0.007934\n","Epoch:  760 | train loss: 0.006606 | valid loss: 0.007806\n","Epoch:  761 | train loss: 0.005975 | valid loss: 0.007773\n","Epoch:  762 | train loss: 0.004136 | valid loss: 0.007753\n","Epoch:  763 | train loss: 0.009199 | valid loss: 0.007717\n","Epoch:  764 | train loss: 0.006218 | valid loss: 0.007788\n","Epoch:  765 | train loss: 0.004707 | valid loss: 0.007730\n","Epoch:  766 | train loss: 0.006790 | valid loss: 0.007795\n","Epoch:  767 | train loss: 0.010431 | valid loss: 0.007780\n","Epoch:  768 | train loss: 0.007957 | valid loss: 0.007799\n","Epoch:  769 | train loss: 0.008268 | valid loss: 0.007769\n","Epoch:  770 | train loss: 0.004637 | valid loss: 0.007897\n","Epoch:  771 | train loss: 0.005571 | valid loss: 0.007890\n","Epoch:  772 | train loss: 0.005205 | valid loss: 0.007851\n","Epoch:  773 | train loss: 0.006428 | valid loss: 0.007767\n","Epoch:  774 | train loss: 0.007465 | valid loss: 0.007721\n","Epoch:  775 | train loss: 0.005740 | valid loss: 0.008040\n","Epoch:  776 | train loss: 0.005916 | valid loss: 0.007780\n","Epoch:  777 | train loss: 0.004696 | valid loss: 0.007807\n","Epoch:  778 | train loss: 0.005063 | valid loss: 0.007720\n","Epoch:  779 | train loss: 0.007081 | valid loss: 0.007863\n","Epoch:  780 | train loss: 0.007857 | valid loss: 0.007864\n","Epoch:  781 | train loss: 0.006414 | valid loss: 0.007777\n","Epoch:  782 | train loss: 0.008760 | valid loss: 0.007814\n","Epoch:  783 | train loss: 0.006032 | valid loss: 0.007692\n","Epoch:  784 | train loss: 0.008991 | valid loss: 0.007798\n","Epoch:  785 | train loss: 0.008480 | valid loss: 0.007829\n","Epoch:  786 | train loss: 0.004948 | valid loss: 0.007792\n","Epoch:  787 | train loss: 0.007170 | valid loss: 0.007945\n","Epoch:  788 | train loss: 0.005382 | valid loss: 0.007773\n","Epoch:  789 | train loss: 0.010242 | valid loss: 0.007760\n","Epoch:  790 | train loss: 0.005634 | valid loss: 0.007839\n","Epoch:  791 | train loss: 0.011431 | valid loss: 0.007781\n","Epoch:  792 | train loss: 0.007629 | valid loss: 0.007815\n","Epoch:  793 | train loss: 0.006424 | valid loss: 0.007923\n","Epoch:  794 | train loss: 0.005981 | valid loss: 0.007755\n","Epoch:  795 | train loss: 0.003887 | valid loss: 0.007916\n","Epoch:  796 | train loss: 0.008159 | valid loss: 0.007820\n","Epoch:  797 | train loss: 0.006259 | valid loss: 0.007841\n","Epoch:  798 | train loss: 0.008508 | valid loss: 0.007735\n","Epoch:  799 | train loss: 0.009831 | valid loss: 0.007775\n","Epoch:  800 | train loss: 0.004787 | valid loss: 0.007814\n","Epoch:  801 | train loss: 0.008206 | valid loss: 0.007897\n","Epoch:  802 | train loss: 0.006087 | valid loss: 0.007804\n","Epoch:  803 | train loss: 0.006198 | valid loss: 0.007893\n","Epoch:  804 | train loss: 0.005065 | valid loss: 0.007750\n","Epoch:  805 | train loss: 0.005404 | valid loss: 0.007694\n","Epoch:  806 | train loss: 0.008853 | valid loss: 0.007838\n","Epoch:  807 | train loss: 0.005346 | valid loss: 0.007829\n","Epoch:  808 | train loss: 0.004530 | valid loss: 0.007988\n","Epoch:  809 | train loss: 0.006374 | valid loss: 0.007832\n","Epoch:  810 | train loss: 0.006511 | valid loss: 0.007781\n","Epoch:  811 | train loss: 0.007646 | valid loss: 0.007754\n","Epoch:  812 | train loss: 0.004618 | valid loss: 0.007870\n","Epoch:  813 | train loss: 0.006821 | valid loss: 0.007812\n","Epoch:  814 | train loss: 0.004764 | valid loss: 0.007753\n","Epoch:  815 | train loss: 0.007250 | valid loss: 0.007894\n","Epoch:  816 | train loss: 0.008227 | valid loss: 0.007831\n","Epoch:  817 | train loss: 0.006887 | valid loss: 0.008291\n","Epoch:  818 | train loss: 0.005697 | valid loss: 0.007842\n","Epoch:  819 | train loss: 0.006377 | valid loss: 0.007903\n","Epoch:  820 | train loss: 0.005040 | valid loss: 0.007741\n","Epoch:  821 | train loss: 0.004940 | valid loss: 0.007777\n","Epoch:  822 | train loss: 0.007994 | valid loss: 0.007840\n","Epoch:  823 | train loss: 0.005563 | valid loss: 0.007778\n","Epoch:  824 | train loss: 0.006063 | valid loss: 0.007777\n","Epoch:  825 | train loss: 0.006680 | valid loss: 0.007956\n","Epoch:  826 | train loss: 0.005517 | valid loss: 0.007741\n","Epoch:  827 | train loss: 0.006537 | valid loss: 0.007805\n","Epoch:  828 | train loss: 0.006449 | valid loss: 0.007776\n","Epoch:  829 | train loss: 0.006333 | valid loss: 0.007796\n","Epoch:  830 | train loss: 0.007036 | valid loss: 0.007783\n","Epoch:  831 | train loss: 0.006212 | valid loss: 0.007822\n","Epoch:  832 | train loss: 0.009800 | valid loss: 0.007998\n","Epoch:  833 | train loss: 0.005839 | valid loss: 0.007772\n","Epoch:  834 | train loss: 0.007197 | valid loss: 0.007758\n","Epoch:  835 | train loss: 0.008746 | valid loss: 0.007879\n","Epoch:  836 | train loss: 0.004876 | valid loss: 0.007875\n","Epoch:  837 | train loss: 0.011047 | valid loss: 0.007753\n","Epoch:  838 | train loss: 0.004799 | valid loss: 0.007792\n","Epoch:  839 | train loss: 0.007764 | valid loss: 0.007897\n","Epoch:  840 | train loss: 0.006822 | valid loss: 0.007814\n","Epoch:  841 | train loss: 0.008855 | valid loss: 0.007855\n","Epoch:  842 | train loss: 0.006366 | valid loss: 0.007854\n","Epoch:  843 | train loss: 0.005296 | valid loss: 0.007908\n","Epoch:  844 | train loss: 0.006175 | valid loss: 0.007804\n","Epoch:  845 | train loss: 0.006155 | valid loss: 0.007825\n","Epoch:  846 | train loss: 0.006425 | valid loss: 0.007825\n","Epoch:  847 | train loss: 0.006298 | valid loss: 0.008064\n","Epoch:  848 | train loss: 0.005261 | valid loss: 0.007886\n","Epoch:  849 | train loss: 0.005126 | valid loss: 0.007852\n","Epoch:  850 | train loss: 0.004040 | valid loss: 0.007856\n","Epoch:  851 | train loss: 0.006283 | valid loss: 0.007933\n","Epoch:  852 | train loss: 0.006028 | valid loss: 0.007912\n","Epoch:  853 | train loss: 0.006250 | valid loss: 0.007832\n","Epoch:  854 | train loss: 0.004651 | valid loss: 0.007796\n","Epoch:  855 | train loss: 0.005713 | valid loss: 0.007929\n","Epoch:  856 | train loss: 0.005374 | valid loss: 0.007788\n","Epoch:  857 | train loss: 0.004044 | valid loss: 0.007812\n","Epoch:  858 | train loss: 0.005511 | valid loss: 0.007843\n","Epoch:  859 | train loss: 0.005108 | valid loss: 0.007771\n","Epoch:  860 | train loss: 0.008694 | valid loss: 0.007910\n","Epoch:  861 | train loss: 0.011511 | valid loss: 0.007960\n","Epoch:  862 | train loss: 0.005582 | valid loss: 0.007933\n","Epoch:  863 | train loss: 0.005931 | valid loss: 0.007820\n","Epoch:  864 | train loss: 0.006687 | valid loss: 0.007759\n","Epoch:  865 | train loss: 0.006736 | valid loss: 0.007999\n","Epoch:  866 | train loss: 0.006993 | valid loss: 0.007945\n","Epoch:  867 | train loss: 0.007355 | valid loss: 0.007891\n","Epoch:  868 | train loss: 0.007092 | valid loss: 0.007926\n","Epoch:  869 | train loss: 0.005548 | valid loss: 0.007855\n","Epoch:  870 | train loss: 0.007722 | valid loss: 0.007824\n","Epoch:  871 | train loss: 0.005683 | valid loss: 0.008139\n","Epoch:  872 | train loss: 0.008442 | valid loss: 0.007878\n","Epoch:  873 | train loss: 0.008522 | valid loss: 0.007895\n","Epoch:  874 | train loss: 0.006194 | valid loss: 0.007815\n","Epoch:  875 | train loss: 0.009819 | valid loss: 0.007869\n","Epoch:  876 | train loss: 0.006799 | valid loss: 0.007845\n","Epoch:  877 | train loss: 0.008654 | valid loss: 0.007923\n","Epoch:  878 | train loss: 0.003829 | valid loss: 0.007920\n","Epoch:  879 | train loss: 0.007217 | valid loss: 0.007823\n","Epoch:  880 | train loss: 0.010343 | valid loss: 0.007859\n","Epoch:  881 | train loss: 0.003852 | valid loss: 0.008017\n","Epoch:  882 | train loss: 0.007786 | valid loss: 0.007965\n","Epoch:  883 | train loss: 0.007202 | valid loss: 0.007965\n","Epoch:  884 | train loss: 0.005888 | valid loss: 0.007877\n","Epoch:  885 | train loss: 0.007882 | valid loss: 0.007901\n","Epoch:  886 | train loss: 0.004056 | valid loss: 0.007793\n","Epoch:  887 | train loss: 0.005145 | valid loss: 0.007882\n","Epoch:  888 | train loss: 0.006775 | valid loss: 0.007980\n","Epoch:  889 | train loss: 0.004695 | valid loss: 0.008000\n","Epoch:  890 | train loss: 0.004580 | valid loss: 0.007895\n","Epoch:  891 | train loss: 0.005728 | valid loss: 0.007974\n","Epoch:  892 | train loss: 0.008079 | valid loss: 0.007969\n","Epoch:  893 | train loss: 0.006159 | valid loss: 0.007862\n","Epoch:  894 | train loss: 0.008065 | valid loss: 0.007858\n","Epoch:  895 | train loss: 0.008533 | valid loss: 0.007838\n","Epoch:  896 | train loss: 0.003710 | valid loss: 0.007796\n","Epoch:  897 | train loss: 0.005903 | valid loss: 0.007862\n","Epoch:  898 | train loss: 0.006024 | valid loss: 0.007832\n","Epoch:  899 | train loss: 0.008024 | valid loss: 0.007923\n","Epoch:  900 | train loss: 0.008355 | valid loss: 0.007910\n","Epoch:  901 | train loss: 0.008712 | valid loss: 0.007893\n","Epoch:  902 | train loss: 0.006566 | valid loss: 0.007727\n","Epoch:  903 | train loss: 0.007916 | valid loss: 0.007840\n","Epoch:  904 | train loss: 0.004074 | valid loss: 0.008188\n","Epoch:  905 | train loss: 0.005648 | valid loss: 0.007823\n","Epoch:  906 | train loss: 0.007027 | valid loss: 0.007978\n","Epoch:  907 | train loss: 0.006006 | valid loss: 0.007823\n","Epoch:  908 | train loss: 0.007046 | valid loss: 0.007866\n","Epoch:  909 | train loss: 0.006401 | valid loss: 0.007904\n","Epoch:  910 | train loss: 0.003589 | valid loss: 0.007768\n","Epoch:  911 | train loss: 0.006069 | valid loss: 0.007931\n","Epoch:  912 | train loss: 0.006901 | valid loss: 0.007837\n","Epoch:  913 | train loss: 0.004468 | valid loss: 0.008101\n","Epoch:  914 | train loss: 0.004648 | valid loss: 0.007974\n","Epoch:  915 | train loss: 0.004259 | valid loss: 0.007938\n","Epoch:  916 | train loss: 0.004831 | valid loss: 0.008000\n","Epoch:  917 | train loss: 0.007837 | valid loss: 0.008166\n","Epoch:  918 | train loss: 0.005148 | valid loss: 0.007980\n","Epoch:  919 | train loss: 0.006796 | valid loss: 0.007912\n","Epoch:  920 | train loss: 0.007824 | valid loss: 0.007826\n","Epoch:  921 | train loss: 0.006051 | valid loss: 0.007831\n","Epoch:  922 | train loss: 0.003973 | valid loss: 0.007832\n","Epoch:  923 | train loss: 0.005249 | valid loss: 0.007852\n","Epoch:  924 | train loss: 0.006468 | valid loss: 0.007856\n","Epoch:  925 | train loss: 0.005911 | valid loss: 0.007877\n","Epoch:  926 | train loss: 0.005289 | valid loss: 0.007927\n","Epoch:  927 | train loss: 0.009978 | valid loss: 0.007799\n","Epoch:  928 | train loss: 0.008472 | valid loss: 0.007921\n","Epoch:  929 | train loss: 0.007605 | valid loss: 0.007881\n","Epoch:  930 | train loss: 0.004824 | valid loss: 0.007902\n","Epoch:  931 | train loss: 0.007939 | valid loss: 0.007969\n","Epoch:  932 | train loss: 0.007625 | valid loss: 0.008077\n","Epoch:  933 | train loss: 0.005665 | valid loss: 0.007889\n","Epoch:  934 | train loss: 0.006135 | valid loss: 0.007956\n","Epoch:  935 | train loss: 0.004997 | valid loss: 0.007853\n","Epoch:  936 | train loss: 0.010019 | valid loss: 0.007945\n","Epoch:  937 | train loss: 0.006867 | valid loss: 0.007946\n","Epoch:  938 | train loss: 0.009725 | valid loss: 0.008062\n","Epoch:  939 | train loss: 0.005853 | valid loss: 0.007886\n","Epoch:  940 | train loss: 0.006119 | valid loss: 0.007869\n","Epoch:  941 | train loss: 0.005965 | valid loss: 0.007987\n","Epoch:  942 | train loss: 0.005457 | valid loss: 0.007855\n","Epoch:  943 | train loss: 0.005987 | valid loss: 0.007914\n","Epoch:  944 | train loss: 0.010237 | valid loss: 0.007732\n","Epoch:  945 | train loss: 0.003536 | valid loss: 0.008000\n","Epoch:  946 | train loss: 0.006430 | valid loss: 0.007884\n","Epoch:  947 | train loss: 0.006330 | valid loss: 0.007962\n","Epoch:  948 | train loss: 0.007264 | valid loss: 0.007872\n","Epoch:  949 | train loss: 0.007977 | valid loss: 0.007986\n","Epoch:  950 | train loss: 0.005794 | valid loss: 0.007915\n","Epoch:  951 | train loss: 0.004495 | valid loss: 0.007959\n","Epoch:  952 | train loss: 0.007153 | valid loss: 0.008004\n","Epoch:  953 | train loss: 0.007469 | valid loss: 0.008022\n","Epoch:  954 | train loss: 0.006634 | valid loss: 0.007849\n","Epoch:  955 | train loss: 0.006186 | valid loss: 0.007830\n","Epoch:  956 | train loss: 0.006317 | valid loss: 0.007891\n","Epoch:  957 | train loss: 0.005011 | valid loss: 0.007875\n","Epoch:  958 | train loss: 0.005421 | valid loss: 0.007937\n","Epoch:  959 | train loss: 0.006250 | valid loss: 0.008122\n","Epoch:  960 | train loss: 0.007455 | valid loss: 0.007947\n","Epoch:  961 | train loss: 0.009960 | valid loss: 0.007961\n","Epoch:  962 | train loss: 0.004958 | valid loss: 0.007825\n","Epoch:  963 | train loss: 0.006814 | valid loss: 0.007879\n","Epoch:  964 | train loss: 0.008392 | valid loss: 0.007855\n","Epoch:  965 | train loss: 0.007726 | valid loss: 0.007913\n","Epoch:  966 | train loss: 0.004761 | valid loss: 0.007882\n","Epoch:  967 | train loss: 0.007175 | valid loss: 0.007831\n","Epoch:  968 | train loss: 0.006127 | valid loss: 0.008017\n","Epoch:  969 | train loss: 0.005457 | valid loss: 0.007970\n","Epoch:  970 | train loss: 0.007832 | valid loss: 0.007980\n","Epoch:  971 | train loss: 0.006108 | valid loss: 0.007972\n","Epoch:  972 | train loss: 0.006824 | valid loss: 0.008015\n","Epoch:  973 | train loss: 0.005924 | valid loss: 0.007969\n","Epoch:  974 | train loss: 0.004038 | valid loss: 0.007952\n","Epoch:  975 | train loss: 0.006734 | valid loss: 0.008054\n","Epoch:  976 | train loss: 0.006923 | valid loss: 0.007958\n","Epoch:  977 | train loss: 0.006522 | valid loss: 0.007963\n","Epoch:  978 | train loss: 0.008653 | valid loss: 0.007899\n","Epoch:  979 | train loss: 0.006020 | valid loss: 0.007978\n","Epoch:  980 | train loss: 0.005152 | valid loss: 0.007911\n","Epoch:  981 | train loss: 0.009087 | valid loss: 0.008184\n","Epoch:  982 | train loss: 0.006406 | valid loss: 0.008211\n","Epoch:  983 | train loss: 0.007276 | valid loss: 0.008009\n","Epoch:  984 | train loss: 0.009768 | valid loss: 0.008120\n","Epoch:  985 | train loss: 0.009884 | valid loss: 0.008000\n","Epoch:  986 | train loss: 0.004426 | valid loss: 0.007907\n","Epoch:  987 | train loss: 0.009648 | valid loss: 0.007953\n","Epoch:  988 | train loss: 0.004019 | valid loss: 0.007879\n","Epoch:  989 | train loss: 0.007889 | valid loss: 0.007867\n","Epoch:  990 | train loss: 0.006642 | valid loss: 0.007872\n","Epoch:  991 | train loss: 0.004640 | valid loss: 0.007960\n","Epoch:  992 | train loss: 0.006171 | valid loss: 0.007946\n","Epoch:  993 | train loss: 0.007276 | valid loss: 0.008243\n","Epoch:  994 | train loss: 0.006902 | valid loss: 0.008030\n","Epoch:  995 | train loss: 0.005192 | valid loss: 0.007917\n","Epoch:  996 | train loss: 0.011188 | valid loss: 0.007934\n","Epoch:  997 | train loss: 0.009332 | valid loss: 0.008054\n","Epoch:  998 | train loss: 0.008085 | valid loss: 0.007996\n","Epoch:  999 | train loss: 0.006461 | valid loss: 0.008010\n","Epoch:  1000 | train loss: 0.005235 | valid loss: 0.008066\n","Epoch:  1001 | train loss: 0.009503 | valid loss: 0.007921\n","Epoch:  1002 | train loss: 0.006769 | valid loss: 0.007950\n","Epoch:  1003 | train loss: 0.005326 | valid loss: 0.007993\n","Epoch:  1004 | train loss: 0.006659 | valid loss: 0.007931\n","Epoch:  1005 | train loss: 0.006543 | valid loss: 0.007902\n","Epoch:  1006 | train loss: 0.004903 | valid loss: 0.007898\n","Epoch:  1007 | train loss: 0.006711 | valid loss: 0.007895\n","Epoch:  1008 | train loss: 0.006639 | valid loss: 0.007865\n","Epoch:  1009 | train loss: 0.005398 | valid loss: 0.008021\n","Epoch:  1010 | train loss: 0.003613 | valid loss: 0.007934\n","Epoch:  1011 | train loss: 0.007136 | valid loss: 0.008118\n","Epoch:  1012 | train loss: 0.005505 | valid loss: 0.008158\n","Epoch:  1013 | train loss: 0.004906 | valid loss: 0.008237\n","Epoch:  1014 | train loss: 0.007617 | valid loss: 0.008172\n","Epoch:  1015 | train loss: 0.006770 | valid loss: 0.008164\n","Epoch:  1016 | train loss: 0.006735 | valid loss: 0.007915\n","Epoch:  1017 | train loss: 0.006344 | valid loss: 0.007908\n","Epoch:  1018 | train loss: 0.005140 | valid loss: 0.007858\n","Epoch:  1019 | train loss: 0.007408 | valid loss: 0.007913\n","Epoch:  1020 | train loss: 0.006708 | valid loss: 0.007915\n","Epoch:  1021 | train loss: 0.006607 | valid loss: 0.007829\n","Epoch:  1022 | train loss: 0.006143 | valid loss: 0.007843\n","Epoch:  1023 | train loss: 0.007262 | valid loss: 0.007967\n","Epoch:  1024 | train loss: 0.005026 | valid loss: 0.007966\n","Epoch:  1025 | train loss: 0.006148 | valid loss: 0.007934\n","Epoch:  1026 | train loss: 0.010095 | valid loss: 0.007975\n","Epoch:  1027 | train loss: 0.007656 | valid loss: 0.007976\n","Epoch:  1028 | train loss: 0.005012 | valid loss: 0.007986\n","Epoch:  1029 | train loss: 0.005892 | valid loss: 0.007880\n","Epoch:  1030 | train loss: 0.004545 | valid loss: 0.008044\n","Epoch:  1031 | train loss: 0.006105 | valid loss: 0.007789\n","Epoch:  1032 | train loss: 0.004874 | valid loss: 0.007929\n","Epoch:  1033 | train loss: 0.004024 | valid loss: 0.008068\n","Epoch:  1034 | train loss: 0.006691 | valid loss: 0.008002\n","Epoch:  1035 | train loss: 0.005310 | valid loss: 0.008025\n","Epoch:  1036 | train loss: 0.007239 | valid loss: 0.007880\n","Epoch:  1037 | train loss: 0.005168 | valid loss: 0.007938\n","Epoch:  1038 | train loss: 0.005818 | valid loss: 0.007967\n","Epoch:  1039 | train loss: 0.004161 | valid loss: 0.007921\n","Epoch:  1040 | train loss: 0.007842 | valid loss: 0.007946\n","Epoch:  1041 | train loss: 0.006772 | valid loss: 0.007833\n","Epoch:  1042 | train loss: 0.003862 | valid loss: 0.008088\n","Epoch:  1043 | train loss: 0.005581 | valid loss: 0.008080\n","Epoch:  1044 | train loss: 0.007629 | valid loss: 0.007834\n","Epoch:  1045 | train loss: 0.004404 | valid loss: 0.008000\n","Epoch:  1046 | train loss: 0.005073 | valid loss: 0.007979\n","Epoch:  1047 | train loss: 0.007263 | valid loss: 0.007951\n","Epoch:  1048 | train loss: 0.008138 | valid loss: 0.007873\n","Epoch:  1049 | train loss: 0.007924 | valid loss: 0.008095\n","Epoch:  1050 | train loss: 0.008578 | valid loss: 0.008062\n","Epoch:  1051 | train loss: 0.005394 | valid loss: 0.008134\n","Epoch:  1052 | train loss: 0.003398 | valid loss: 0.008014\n","Epoch:  1053 | train loss: 0.007224 | valid loss: 0.008019\n","Epoch:  1054 | train loss: 0.005700 | valid loss: 0.008094\n","Epoch:  1055 | train loss: 0.004373 | valid loss: 0.007919\n","Epoch:  1056 | train loss: 0.007917 | valid loss: 0.008110\n","Epoch:  1057 | train loss: 0.008072 | valid loss: 0.007973\n","Epoch:  1058 | train loss: 0.006720 | valid loss: 0.008014\n","Epoch:  1059 | train loss: 0.008042 | valid loss: 0.007923\n","Epoch:  1060 | train loss: 0.004348 | valid loss: 0.007989\n","Epoch:  1061 | train loss: 0.005397 | valid loss: 0.008083\n","Epoch:  1062 | train loss: 0.005939 | valid loss: 0.007994\n","Epoch:  1063 | train loss: 0.008439 | valid loss: 0.008016\n","Epoch:  1064 | train loss: 0.006024 | valid loss: 0.008101\n","Epoch:  1065 | train loss: 0.005375 | valid loss: 0.007980\n","Epoch:  1066 | train loss: 0.008531 | valid loss: 0.008168\n","Epoch:  1067 | train loss: 0.006741 | valid loss: 0.008027\n","Epoch:  1068 | train loss: 0.004928 | valid loss: 0.008021\n","Epoch:  1069 | train loss: 0.009166 | valid loss: 0.008044\n","Epoch:  1070 | train loss: 0.007462 | valid loss: 0.007955\n","Epoch:  1071 | train loss: 0.004722 | valid loss: 0.008135\n","Epoch:  1072 | train loss: 0.006024 | valid loss: 0.008025\n","Epoch:  1073 | train loss: 0.007580 | valid loss: 0.008016\n","Epoch:  1074 | train loss: 0.006096 | valid loss: 0.007946\n","Epoch:  1075 | train loss: 0.006098 | valid loss: 0.007880\n","Epoch:  1076 | train loss: 0.005544 | valid loss: 0.008030\n","Epoch:  1077 | train loss: 0.005427 | valid loss: 0.007989\n","Epoch:  1078 | train loss: 0.007942 | valid loss: 0.007928\n","Epoch:  1079 | train loss: 0.008414 | valid loss: 0.007982\n","Epoch:  1080 | train loss: 0.004746 | valid loss: 0.007964\n","Epoch:  1081 | train loss: 0.007220 | valid loss: 0.008005\n","Epoch:  1082 | train loss: 0.004764 | valid loss: 0.008088\n","Epoch:  1083 | train loss: 0.003442 | valid loss: 0.007902\n","Epoch:  1084 | train loss: 0.003802 | valid loss: 0.007905\n","Epoch:  1085 | train loss: 0.003856 | valid loss: 0.007937\n","Epoch:  1086 | train loss: 0.006036 | valid loss: 0.008038\n","Epoch:  1087 | train loss: 0.004692 | valid loss: 0.008002\n","Epoch:  1088 | train loss: 0.005741 | valid loss: 0.007976\n","Epoch:  1089 | train loss: 0.005807 | valid loss: 0.008052\n","Epoch:  1090 | train loss: 0.008909 | valid loss: 0.008023\n","Epoch:  1091 | train loss: 0.007096 | valid loss: 0.007992\n","Epoch:  1092 | train loss: 0.008284 | valid loss: 0.008046\n","Epoch:  1093 | train loss: 0.006340 | valid loss: 0.008064\n","Epoch:  1094 | train loss: 0.008562 | valid loss: 0.008016\n","Epoch:  1095 | train loss: 0.007389 | valid loss: 0.008183\n","Epoch:  1096 | train loss: 0.006215 | valid loss: 0.008022\n","Epoch:  1097 | train loss: 0.004752 | valid loss: 0.008056\n","Epoch:  1098 | train loss: 0.011709 | valid loss: 0.008025\n","Epoch:  1099 | train loss: 0.007290 | valid loss: 0.008060\n","Epoch:  1100 | train loss: 0.005755 | valid loss: 0.008025\n","Epoch:  1101 | train loss: 0.005292 | valid loss: 0.007985\n","Epoch:  1102 | train loss: 0.006366 | valid loss: 0.008015\n","Epoch:  1103 | train loss: 0.004570 | valid loss: 0.008102\n","Epoch:  1104 | train loss: 0.008524 | valid loss: 0.008264\n","Epoch:  1105 | train loss: 0.008533 | valid loss: 0.008205\n","Epoch:  1106 | train loss: 0.005264 | valid loss: 0.007927\n","Epoch:  1107 | train loss: 0.004526 | valid loss: 0.008085\n","Epoch:  1108 | train loss: 0.004574 | valid loss: 0.008012\n","Epoch:  1109 | train loss: 0.008259 | valid loss: 0.007980\n","Epoch:  1110 | train loss: 0.005761 | valid loss: 0.008119\n","Epoch:  1111 | train loss: 0.005625 | valid loss: 0.008085\n","Epoch:  1112 | train loss: 0.004511 | valid loss: 0.007979\n","Epoch:  1113 | train loss: 0.007364 | valid loss: 0.008082\n","Epoch:  1114 | train loss: 0.005338 | valid loss: 0.007911\n","Epoch:  1115 | train loss: 0.008807 | valid loss: 0.008106\n","Epoch:  1116 | train loss: 0.007402 | valid loss: 0.008074\n","Epoch:  1117 | train loss: 0.007055 | valid loss: 0.008126\n","Epoch:  1118 | train loss: 0.004738 | valid loss: 0.008115\n","Epoch:  1119 | train loss: 0.006941 | valid loss: 0.008093\n","Epoch:  1120 | train loss: 0.008407 | valid loss: 0.007949\n","Epoch:  1121 | train loss: 0.008196 | valid loss: 0.008055\n","Epoch:  1122 | train loss: 0.006135 | valid loss: 0.007957\n","Epoch:  1123 | train loss: 0.005374 | valid loss: 0.008039\n","Epoch:  1124 | train loss: 0.004122 | valid loss: 0.008166\n","Epoch:  1125 | train loss: 0.006991 | valid loss: 0.007998\n","Epoch:  1126 | train loss: 0.007219 | valid loss: 0.008094\n","Epoch:  1127 | train loss: 0.006284 | valid loss: 0.008053\n","Epoch:  1128 | train loss: 0.003042 | valid loss: 0.007986\n","Epoch:  1129 | train loss: 0.005668 | valid loss: 0.007959\n","Epoch:  1130 | train loss: 0.012075 | valid loss: 0.008163\n","Epoch:  1131 | train loss: 0.008390 | valid loss: 0.008035\n","Epoch:  1132 | train loss: 0.008239 | valid loss: 0.008148\n","Epoch:  1133 | train loss: 0.006847 | valid loss: 0.007989\n","Epoch:  1134 | train loss: 0.005433 | valid loss: 0.008202\n","Epoch:  1135 | train loss: 0.006125 | valid loss: 0.008009\n","Epoch:  1136 | train loss: 0.004022 | valid loss: 0.008147\n","Epoch:  1137 | train loss: 0.006015 | valid loss: 0.008108\n","Epoch:  1138 | train loss: 0.004087 | valid loss: 0.008166\n","Epoch:  1139 | train loss: 0.004567 | valid loss: 0.008124\n","Epoch:  1140 | train loss: 0.009955 | valid loss: 0.008147\n","Epoch:  1141 | train loss: 0.006366 | valid loss: 0.008072\n","Epoch:  1142 | train loss: 0.008982 | valid loss: 0.008097\n","Epoch:  1143 | train loss: 0.008501 | valid loss: 0.008510\n","Epoch:  1144 | train loss: 0.006553 | valid loss: 0.008003\n","Epoch:  1145 | train loss: 0.008118 | valid loss: 0.008074\n","Epoch:  1146 | train loss: 0.005254 | valid loss: 0.008024\n","Epoch:  1147 | train loss: 0.007030 | valid loss: 0.007965\n","Epoch:  1148 | train loss: 0.005895 | valid loss: 0.007981\n","Epoch:  1149 | train loss: 0.008227 | valid loss: 0.008055\n","Epoch:  1150 | train loss: 0.006540 | valid loss: 0.007973\n","Epoch:  1151 | train loss: 0.006233 | valid loss: 0.008121\n","Epoch:  1152 | train loss: 0.004727 | valid loss: 0.008003\n","Epoch:  1153 | train loss: 0.004855 | valid loss: 0.008138\n","Epoch:  1154 | train loss: 0.007587 | valid loss: 0.007966\n","Epoch:  1155 | train loss: 0.004835 | valid loss: 0.007919\n","Epoch:  1156 | train loss: 0.004978 | valid loss: 0.008096\n","Epoch:  1157 | train loss: 0.005681 | valid loss: 0.008160\n","Epoch:  1158 | train loss: 0.005410 | valid loss: 0.008154\n","Epoch:  1159 | train loss: 0.006462 | valid loss: 0.007939\n","Epoch:  1160 | train loss: 0.006405 | valid loss: 0.008034\n","Epoch:  1161 | train loss: 0.006605 | valid loss: 0.008035\n","Epoch:  1162 | train loss: 0.007042 | valid loss: 0.007956\n","Epoch:  1163 | train loss: 0.005053 | valid loss: 0.007958\n","Epoch:  1164 | train loss: 0.006959 | valid loss: 0.008072\n","Epoch:  1165 | train loss: 0.006386 | valid loss: 0.008006\n","Epoch:  1166 | train loss: 0.003895 | valid loss: 0.008009\n","Epoch:  1167 | train loss: 0.007134 | valid loss: 0.008095\n","Epoch:  1168 | train loss: 0.008771 | valid loss: 0.008062\n","Epoch:  1169 | train loss: 0.005395 | valid loss: 0.008070\n","Epoch:  1170 | train loss: 0.009938 | valid loss: 0.008097\n","Epoch:  1171 | train loss: 0.009443 | valid loss: 0.008115\n","Epoch:  1172 | train loss: 0.005241 | valid loss: 0.008129\n","Epoch:  1173 | train loss: 0.007162 | valid loss: 0.007966\n","Epoch:  1174 | train loss: 0.007714 | valid loss: 0.008067\n","Epoch:  1175 | train loss: 0.004879 | valid loss: 0.008048\n","Epoch:  1176 | train loss: 0.005531 | valid loss: 0.008011\n","Epoch:  1177 | train loss: 0.005113 | valid loss: 0.008239\n","Epoch:  1178 | train loss: 0.005868 | valid loss: 0.008090\n","Epoch:  1179 | train loss: 0.006620 | valid loss: 0.008109\n","Epoch:  1180 | train loss: 0.004361 | valid loss: 0.008109\n","Epoch:  1181 | train loss: 0.004805 | valid loss: 0.008082\n","Epoch:  1182 | train loss: 0.006917 | valid loss: 0.008046\n","Epoch:  1183 | train loss: 0.006400 | valid loss: 0.008117\n","Epoch:  1184 | train loss: 0.008130 | valid loss: 0.008089\n","Epoch:  1185 | train loss: 0.004539 | valid loss: 0.008148\n","Epoch:  1186 | train loss: 0.005794 | valid loss: 0.008093\n","Epoch:  1187 | train loss: 0.005357 | valid loss: 0.007959\n","Epoch:  1188 | train loss: 0.008640 | valid loss: 0.008121\n","Epoch:  1189 | train loss: 0.008269 | valid loss: 0.008093\n","Epoch:  1190 | train loss: 0.007189 | valid loss: 0.007930\n","Epoch:  1191 | train loss: 0.006398 | valid loss: 0.008026\n","Epoch:  1192 | train loss: 0.005824 | valid loss: 0.007974\n","Epoch:  1193 | train loss: 0.005532 | valid loss: 0.008112\n","Epoch:  1194 | train loss: 0.005605 | valid loss: 0.008018\n","Epoch:  1195 | train loss: 0.005526 | valid loss: 0.007989\n","Epoch:  1196 | train loss: 0.006565 | valid loss: 0.008070\n","Epoch:  1197 | train loss: 0.005366 | valid loss: 0.008061\n","Epoch:  1198 | train loss: 0.005243 | valid loss: 0.008240\n","Epoch:  1199 | train loss: 0.007975 | valid loss: 0.008251\n","Epoch:  1200 | train loss: 0.007837 | valid loss: 0.008220\n","Epoch:  1201 | train loss: 0.004865 | valid loss: 0.008101\n","Epoch:  1202 | train loss: 0.007114 | valid loss: 0.008121\n","Epoch:  1203 | train loss: 0.005651 | valid loss: 0.008234\n","Epoch:  1204 | train loss: 0.004428 | valid loss: 0.008059\n","Epoch:  1205 | train loss: 0.009522 | valid loss: 0.008198\n","Epoch:  1206 | train loss: 0.007209 | valid loss: 0.008198\n","Epoch:  1207 | train loss: 0.007167 | valid loss: 0.008024\n","Epoch:  1208 | train loss: 0.008782 | valid loss: 0.007995\n","Epoch:  1209 | train loss: 0.005370 | valid loss: 0.008068\n","Epoch:  1210 | train loss: 0.006733 | valid loss: 0.008057\n","Epoch:  1211 | train loss: 0.006828 | valid loss: 0.008131\n","Epoch:  1212 | train loss: 0.006366 | valid loss: 0.008016\n","Epoch:  1213 | train loss: 0.008216 | valid loss: 0.008144\n","Epoch:  1214 | train loss: 0.006023 | valid loss: 0.008052\n","Epoch:  1215 | train loss: 0.004058 | valid loss: 0.008145\n","Epoch:  1216 | train loss: 0.005653 | valid loss: 0.007980\n","Epoch:  1217 | train loss: 0.003784 | valid loss: 0.008071\n","Epoch:  1218 | train loss: 0.007121 | valid loss: 0.008128\n","Epoch:  1219 | train loss: 0.005322 | valid loss: 0.008054\n","Epoch:  1220 | train loss: 0.009444 | valid loss: 0.008036\n","Epoch:  1221 | train loss: 0.006561 | valid loss: 0.008242\n","Epoch:  1222 | train loss: 0.006519 | valid loss: 0.008200\n","Epoch:  1223 | train loss: 0.007126 | valid loss: 0.008199\n","Epoch:  1224 | train loss: 0.006230 | valid loss: 0.008142\n","Epoch:  1225 | train loss: 0.006910 | valid loss: 0.008061\n","Epoch:  1226 | train loss: 0.006026 | valid loss: 0.008032\n","Epoch:  1227 | train loss: 0.006301 | valid loss: 0.008132\n","Epoch:  1228 | train loss: 0.006159 | valid loss: 0.008171\n","Epoch:  1229 | train loss: 0.006850 | valid loss: 0.008134\n","Epoch:  1230 | train loss: 0.008337 | valid loss: 0.008047\n","Epoch:  1231 | train loss: 0.005522 | valid loss: 0.008114\n","Epoch:  1232 | train loss: 0.004067 | valid loss: 0.008172\n","Epoch:  1233 | train loss: 0.004911 | valid loss: 0.008085\n","Epoch:  1234 | train loss: 0.008149 | valid loss: 0.008079\n","Epoch:  1235 | train loss: 0.007688 | valid loss: 0.008131\n","Epoch:  1236 | train loss: 0.005186 | valid loss: 0.007995\n","Epoch:  1237 | train loss: 0.006122 | valid loss: 0.008096\n","Epoch:  1238 | train loss: 0.004985 | valid loss: 0.008123\n","Epoch:  1239 | train loss: 0.005470 | valid loss: 0.008101\n","Epoch:  1240 | train loss: 0.006162 | valid loss: 0.008085\n","Epoch:  1241 | train loss: 0.006860 | valid loss: 0.008148\n","Epoch:  1242 | train loss: 0.004388 | valid loss: 0.008264\n","Epoch:  1243 | train loss: 0.006938 | valid loss: 0.008237\n","Epoch:  1244 | train loss: 0.006389 | valid loss: 0.007971\n","Epoch:  1245 | train loss: 0.003778 | valid loss: 0.008018\n","Epoch:  1246 | train loss: 0.007637 | valid loss: 0.008048\n","Epoch:  1247 | train loss: 0.006292 | valid loss: 0.008156\n","Epoch:  1248 | train loss: 0.010729 | valid loss: 0.008225\n","Epoch:  1249 | train loss: 0.005329 | valid loss: 0.008026\n","Epoch:  1250 | train loss: 0.007149 | valid loss: 0.008084\n","Epoch:  1251 | train loss: 0.006267 | valid loss: 0.008153\n","Epoch:  1252 | train loss: 0.007544 | valid loss: 0.007959\n","Epoch:  1253 | train loss: 0.009155 | valid loss: 0.008133\n","Epoch:  1254 | train loss: 0.007443 | valid loss: 0.008053\n","Epoch:  1255 | train loss: 0.006407 | valid loss: 0.008218\n","Epoch:  1256 | train loss: 0.005918 | valid loss: 0.007992\n","Epoch:  1257 | train loss: 0.006016 | valid loss: 0.008067\n","Epoch:  1258 | train loss: 0.003678 | valid loss: 0.008205\n","Epoch:  1259 | train loss: 0.005315 | valid loss: 0.008029\n","Epoch:  1260 | train loss: 0.007842 | valid loss: 0.008133\n","Epoch:  1261 | train loss: 0.004012 | valid loss: 0.008197\n","Epoch:  1262 | train loss: 0.008785 | valid loss: 0.008236\n","Epoch:  1263 | train loss: 0.004978 | valid loss: 0.008134\n","Epoch:  1264 | train loss: 0.005710 | valid loss: 0.008190\n","Epoch:  1265 | train loss: 0.009468 | valid loss: 0.008134\n","Epoch:  1266 | train loss: 0.006099 | valid loss: 0.008238\n","Epoch:  1267 | train loss: 0.004819 | valid loss: 0.008245\n","Epoch:  1268 | train loss: 0.004504 | valid loss: 0.008090\n","Epoch:  1269 | train loss: 0.004849 | valid loss: 0.008235\n","Epoch:  1270 | train loss: 0.003583 | valid loss: 0.007929\n","Epoch:  1271 | train loss: 0.003752 | valid loss: 0.008049\n","Epoch:  1272 | train loss: 0.005504 | valid loss: 0.008041\n","Epoch:  1273 | train loss: 0.005936 | valid loss: 0.008091\n","Epoch:  1274 | train loss: 0.005262 | valid loss: 0.008210\n","Epoch:  1275 | train loss: 0.005635 | valid loss: 0.008209\n","Epoch:  1276 | train loss: 0.005463 | valid loss: 0.008229\n","Epoch:  1277 | train loss: 0.004175 | valid loss: 0.008058\n","Epoch:  1278 | train loss: 0.007694 | valid loss: 0.008149\n","Epoch:  1279 | train loss: 0.005957 | valid loss: 0.008354\n","Epoch:  1280 | train loss: 0.008778 | valid loss: 0.008258\n","Epoch:  1281 | train loss: 0.008824 | valid loss: 0.008209\n","Epoch:  1282 | train loss: 0.007522 | valid loss: 0.008180\n","Epoch:  1283 | train loss: 0.008094 | valid loss: 0.008115\n","Epoch:  1284 | train loss: 0.005482 | valid loss: 0.008059\n","Epoch:  1285 | train loss: 0.006387 | valid loss: 0.008135\n","Epoch:  1286 | train loss: 0.007242 | valid loss: 0.008534\n","Epoch:  1287 | train loss: 0.006729 | valid loss: 0.008256\n","Epoch:  1288 | train loss: 0.003766 | valid loss: 0.008274\n","Epoch:  1289 | train loss: 0.008552 | valid loss: 0.008074\n","Epoch:  1290 | train loss: 0.006528 | valid loss: 0.008279\n","Epoch:  1291 | train loss: 0.007216 | valid loss: 0.008117\n","Epoch:  1292 | train loss: 0.006984 | valid loss: 0.008086\n","Epoch:  1293 | train loss: 0.006265 | valid loss: 0.008028\n","Epoch:  1294 | train loss: 0.005336 | valid loss: 0.008150\n","Epoch:  1295 | train loss: 0.004266 | valid loss: 0.008121\n","Epoch:  1296 | train loss: 0.005689 | valid loss: 0.008249\n","Epoch:  1297 | train loss: 0.003816 | valid loss: 0.008099\n","Epoch:  1298 | train loss: 0.008301 | valid loss: 0.008095\n","Epoch:  1299 | train loss: 0.008707 | valid loss: 0.008251\n","Epoch:  1300 | train loss: 0.006787 | valid loss: 0.008150\n","Epoch:  1301 | train loss: 0.004915 | valid loss: 0.008132\n","Epoch:  1302 | train loss: 0.005242 | valid loss: 0.008428\n","Epoch:  1303 | train loss: 0.008809 | valid loss: 0.008236\n","Epoch:  1304 | train loss: 0.004546 | valid loss: 0.008011\n","Epoch:  1305 | train loss: 0.007502 | valid loss: 0.008106\n","Epoch:  1306 | train loss: 0.004770 | valid loss: 0.008077\n","Epoch:  1307 | train loss: 0.006180 | valid loss: 0.008124\n","Epoch:  1308 | train loss: 0.004139 | valid loss: 0.008072\n","Epoch:  1309 | train loss: 0.006566 | valid loss: 0.008089\n","Epoch:  1310 | train loss: 0.006220 | valid loss: 0.008073\n","Epoch:  1311 | train loss: 0.006090 | valid loss: 0.008167\n","Epoch:  1312 | train loss: 0.004295 | valid loss: 0.008208\n","Epoch:  1313 | train loss: 0.010304 | valid loss: 0.008181\n","Epoch:  1314 | train loss: 0.004530 | valid loss: 0.008079\n","Epoch:  1315 | train loss: 0.008395 | valid loss: 0.008086\n","Epoch:  1316 | train loss: 0.005577 | valid loss: 0.008127\n","Epoch:  1317 | train loss: 0.004085 | valid loss: 0.008075\n","Epoch:  1318 | train loss: 0.005312 | valid loss: 0.008206\n","Epoch:  1319 | train loss: 0.007333 | valid loss: 0.008125\n","Epoch:  1320 | train loss: 0.007547 | valid loss: 0.008288\n","Epoch:  1321 | train loss: 0.006292 | valid loss: 0.008190\n","Epoch:  1322 | train loss: 0.006868 | valid loss: 0.008078\n","Epoch:  1323 | train loss: 0.006639 | valid loss: 0.008120\n","Epoch:  1324 | train loss: 0.008110 | valid loss: 0.008179\n","Epoch:  1325 | train loss: 0.005501 | valid loss: 0.008148\n","Epoch:  1326 | train loss: 0.005422 | valid loss: 0.008100\n","Epoch:  1327 | train loss: 0.009221 | valid loss: 0.008100\n","Epoch:  1328 | train loss: 0.008072 | valid loss: 0.008197\n","Epoch:  1329 | train loss: 0.004947 | valid loss: 0.008233\n","Epoch:  1330 | train loss: 0.006128 | valid loss: 0.008268\n","Epoch:  1331 | train loss: 0.006417 | valid loss: 0.008216\n","Epoch:  1332 | train loss: 0.004476 | valid loss: 0.008118\n","Epoch:  1333 | train loss: 0.005101 | valid loss: 0.008080\n","Epoch:  1334 | train loss: 0.009135 | valid loss: 0.008137\n","Epoch:  1335 | train loss: 0.007840 | valid loss: 0.008175\n","Epoch:  1336 | train loss: 0.006670 | valid loss: 0.008167\n","Epoch:  1337 | train loss: 0.008797 | valid loss: 0.008102\n","Epoch:  1338 | train loss: 0.004579 | valid loss: 0.008212\n","Epoch:  1339 | train loss: 0.011256 | valid loss: 0.008194\n","Epoch:  1340 | train loss: 0.005777 | valid loss: 0.008017\n","Epoch:  1341 | train loss: 0.005958 | valid loss: 0.008094\n","Epoch:  1342 | train loss: 0.006304 | valid loss: 0.008115\n","Epoch:  1343 | train loss: 0.008242 | valid loss: 0.008114\n","Epoch:  1344 | train loss: 0.006984 | valid loss: 0.008178\n","Epoch:  1345 | train loss: 0.007906 | valid loss: 0.008078\n","Epoch:  1346 | train loss: 0.009662 | valid loss: 0.008143\n","Epoch:  1347 | train loss: 0.004305 | valid loss: 0.008182\n","Epoch:  1348 | train loss: 0.004896 | valid loss: 0.008199\n","Epoch:  1349 | train loss: 0.004619 | valid loss: 0.008092\n","Epoch:  1350 | train loss: 0.006950 | valid loss: 0.008248\n","Epoch:  1351 | train loss: 0.004417 | valid loss: 0.008179\n","Epoch:  1352 | train loss: 0.005141 | valid loss: 0.008044\n","Epoch:  1353 | train loss: 0.003121 | valid loss: 0.008126\n","Epoch:  1354 | train loss: 0.009542 | valid loss: 0.008131\n","Epoch:  1355 | train loss: 0.010698 | valid loss: 0.008174\n","Epoch:  1356 | train loss: 0.005886 | valid loss: 0.008113\n","Epoch:  1357 | train loss: 0.004884 | valid loss: 0.008196\n","Epoch:  1358 | train loss: 0.004609 | valid loss: 0.008137\n","Epoch:  1359 | train loss: 0.007940 | valid loss: 0.008226\n","Epoch:  1360 | train loss: 0.007416 | valid loss: 0.008113\n","Epoch:  1361 | train loss: 0.006919 | valid loss: 0.008197\n","Epoch:  1362 | train loss: 0.004055 | valid loss: 0.008155\n","Epoch:  1363 | train loss: 0.006805 | valid loss: 0.008399\n","Epoch:  1364 | train loss: 0.012311 | valid loss: 0.008071\n","Epoch:  1365 | train loss: 0.005718 | valid loss: 0.008169\n","Epoch:  1366 | train loss: 0.005839 | valid loss: 0.008201\n","Epoch:  1367 | train loss: 0.004358 | valid loss: 0.008236\n","Epoch:  1368 | train loss: 0.005240 | valid loss: 0.008083\n","Epoch:  1369 | train loss: 0.003686 | valid loss: 0.008238\n","Epoch:  1370 | train loss: 0.007046 | valid loss: 0.008258\n","Epoch:  1371 | train loss: 0.006046 | valid loss: 0.008088\n","Epoch:  1372 | train loss: 0.005077 | valid loss: 0.008148\n","Epoch:  1373 | train loss: 0.005659 | valid loss: 0.008107\n","Epoch:  1374 | train loss: 0.006500 | valid loss: 0.008178\n","Epoch:  1375 | train loss: 0.005264 | valid loss: 0.008229\n","Epoch:  1376 | train loss: 0.004265 | valid loss: 0.008095\n","Epoch:  1377 | train loss: 0.006328 | valid loss: 0.008334\n","Epoch:  1378 | train loss: 0.006962 | valid loss: 0.008270\n","Epoch:  1379 | train loss: 0.006459 | valid loss: 0.008189\n","Epoch:  1380 | train loss: 0.004910 | valid loss: 0.008095\n","Epoch:  1381 | train loss: 0.006731 | valid loss: 0.008263\n","Epoch:  1382 | train loss: 0.008453 | valid loss: 0.008170\n","Epoch:  1383 | train loss: 0.004589 | valid loss: 0.008170\n","Epoch:  1384 | train loss: 0.007253 | valid loss: 0.008089\n","Epoch:  1385 | train loss: 0.004672 | valid loss: 0.008164\n","Epoch:  1386 | train loss: 0.007366 | valid loss: 0.008198\n","Epoch:  1387 | train loss: 0.008034 | valid loss: 0.008159\n","Epoch:  1388 | train loss: 0.004645 | valid loss: 0.008188\n","Epoch:  1389 | train loss: 0.006051 | valid loss: 0.008362\n","Epoch:  1390 | train loss: 0.008898 | valid loss: 0.008363\n","Epoch:  1391 | train loss: 0.005335 | valid loss: 0.008239\n","Epoch:  1392 | train loss: 0.005176 | valid loss: 0.008202\n","Epoch:  1393 | train loss: 0.011552 | valid loss: 0.008182\n","Epoch:  1394 | train loss: 0.006075 | valid loss: 0.008270\n","Epoch:  1395 | train loss: 0.007611 | valid loss: 0.008102\n","Epoch:  1396 | train loss: 0.005387 | valid loss: 0.008288\n","Epoch:  1397 | train loss: 0.003862 | valid loss: 0.008106\n","Epoch:  1398 | train loss: 0.006603 | valid loss: 0.008112\n","Epoch:  1399 | train loss: 0.005079 | valid loss: 0.008183\n","Epoch:  1400 | train loss: 0.006105 | valid loss: 0.008070\n","Epoch:  1401 | train loss: 0.008440 | valid loss: 0.008186\n","Epoch:  1402 | train loss: 0.007598 | valid loss: 0.008312\n","Epoch:  1403 | train loss: 0.006250 | valid loss: 0.008227\n","Epoch:  1404 | train loss: 0.005776 | valid loss: 0.008135\n","Epoch:  1405 | train loss: 0.006663 | valid loss: 0.008346\n","Epoch:  1406 | train loss: 0.004186 | valid loss: 0.008268\n","Epoch:  1407 | train loss: 0.005184 | valid loss: 0.008518\n","Epoch:  1408 | train loss: 0.007157 | valid loss: 0.008349\n","Epoch:  1409 | train loss: 0.006347 | valid loss: 0.008474\n","Epoch:  1410 | train loss: 0.005425 | valid loss: 0.008224\n","Epoch:  1411 | train loss: 0.007042 | valid loss: 0.008153\n","Epoch:  1412 | train loss: 0.006195 | valid loss: 0.008241\n","Epoch:  1413 | train loss: 0.005366 | valid loss: 0.008153\n","Epoch:  1414 | train loss: 0.007889 | valid loss: 0.008226\n","Epoch:  1415 | train loss: 0.006348 | valid loss: 0.008216\n","Epoch:  1416 | train loss: 0.011069 | valid loss: 0.008300\n","Epoch:  1417 | train loss: 0.007790 | valid loss: 0.008317\n","Epoch:  1418 | train loss: 0.010915 | valid loss: 0.008377\n","Epoch:  1419 | train loss: 0.003472 | valid loss: 0.008262\n","Epoch:  1420 | train loss: 0.006606 | valid loss: 0.008233\n","Epoch:  1421 | train loss: 0.005292 | valid loss: 0.008179\n","Epoch:  1422 | train loss: 0.006017 | valid loss: 0.008159\n","Epoch:  1423 | train loss: 0.005808 | valid loss: 0.008185\n","Epoch:  1424 | train loss: 0.005522 | valid loss: 0.008304\n","Epoch:  1425 | train loss: 0.009790 | valid loss: 0.008220\n","Epoch:  1426 | train loss: 0.007200 | valid loss: 0.008258\n","Epoch:  1427 | train loss: 0.005911 | valid loss: 0.008410\n","Epoch:  1428 | train loss: 0.007067 | valid loss: 0.008228\n","Epoch:  1429 | train loss: 0.005406 | valid loss: 0.008131\n","Epoch:  1430 | train loss: 0.005154 | valid loss: 0.008148\n","Epoch:  1431 | train loss: 0.006546 | valid loss: 0.008287\n","Epoch:  1432 | train loss: 0.004046 | valid loss: 0.008239\n","Epoch:  1433 | train loss: 0.008087 | valid loss: 0.008238\n","Epoch:  1434 | train loss: 0.008489 | valid loss: 0.008238\n","Epoch:  1435 | train loss: 0.007884 | valid loss: 0.008541\n","Epoch:  1436 | train loss: 0.007906 | valid loss: 0.008339\n","Epoch:  1437 | train loss: 0.005942 | valid loss: 0.008345\n","Epoch:  1438 | train loss: 0.007765 | valid loss: 0.008101\n","Epoch:  1439 | train loss: 0.005188 | valid loss: 0.008121\n","Epoch:  1440 | train loss: 0.006230 | valid loss: 0.008247\n","Epoch:  1441 | train loss: 0.007671 | valid loss: 0.008209\n","Epoch:  1442 | train loss: 0.004719 | valid loss: 0.008266\n","Epoch:  1443 | train loss: 0.006982 | valid loss: 0.008372\n","Epoch:  1444 | train loss: 0.008402 | valid loss: 0.008198\n","Epoch:  1445 | train loss: 0.007786 | valid loss: 0.008298\n","Epoch:  1446 | train loss: 0.003030 | valid loss: 0.008194\n","Epoch:  1447 | train loss: 0.008061 | valid loss: 0.008199\n","Epoch:  1448 | train loss: 0.006763 | valid loss: 0.008279\n","Epoch:  1449 | train loss: 0.007305 | valid loss: 0.008274\n","Epoch:  1450 | train loss: 0.007553 | valid loss: 0.008242\n","Epoch:  1451 | train loss: 0.006854 | valid loss: 0.008259\n","Epoch:  1452 | train loss: 0.007261 | valid loss: 0.008154\n","Epoch:  1453 | train loss: 0.003870 | valid loss: 0.008234\n","Epoch:  1454 | train loss: 0.006237 | valid loss: 0.008234\n","Epoch:  1455 | train loss: 0.006103 | valid loss: 0.008280\n","Epoch:  1456 | train loss: 0.007793 | valid loss: 0.008144\n","Epoch:  1457 | train loss: 0.005234 | valid loss: 0.008321\n","Epoch:  1458 | train loss: 0.009059 | valid loss: 0.008239\n","Epoch:  1459 | train loss: 0.006089 | valid loss: 0.008216\n","Epoch:  1460 | train loss: 0.008670 | valid loss: 0.008263\n","Epoch:  1461 | train loss: 0.005342 | valid loss: 0.008164\n","Epoch:  1462 | train loss: 0.004761 | valid loss: 0.008180\n","Epoch:  1463 | train loss: 0.006558 | valid loss: 0.008246\n","Epoch:  1464 | train loss: 0.008289 | valid loss: 0.008320\n","Epoch:  1465 | train loss: 0.006475 | valid loss: 0.008434\n","Epoch:  1466 | train loss: 0.004676 | valid loss: 0.008141\n","Epoch:  1467 | train loss: 0.009021 | valid loss: 0.008145\n","Epoch:  1468 | train loss: 0.007629 | valid loss: 0.008143\n","Epoch:  1469 | train loss: 0.007459 | valid loss: 0.008289\n","Epoch:  1470 | train loss: 0.004936 | valid loss: 0.008271\n","Epoch:  1471 | train loss: 0.008271 | valid loss: 0.008168\n","Epoch:  1472 | train loss: 0.005335 | valid loss: 0.008259\n","Epoch:  1473 | train loss: 0.005286 | valid loss: 0.008249\n","Epoch:  1474 | train loss: 0.006294 | valid loss: 0.008191\n","Epoch:  1475 | train loss: 0.005543 | valid loss: 0.008252\n","Epoch:  1476 | train loss: 0.005731 | valid loss: 0.008246\n","Epoch:  1477 | train loss: 0.007058 | valid loss: 0.008200\n","Epoch:  1478 | train loss: 0.007994 | valid loss: 0.008264\n","Epoch:  1479 | train loss: 0.007032 | valid loss: 0.008284\n","Epoch:  1480 | train loss: 0.005109 | valid loss: 0.008201\n","Epoch:  1481 | train loss: 0.009095 | valid loss: 0.008279\n","Epoch:  1482 | train loss: 0.005594 | valid loss: 0.008380\n","Epoch:  1483 | train loss: 0.007862 | valid loss: 0.008123\n","Epoch:  1484 | train loss: 0.007096 | valid loss: 0.008258\n","Epoch:  1485 | train loss: 0.007680 | valid loss: 0.008311\n","Epoch:  1486 | train loss: 0.005392 | valid loss: 0.008087\n","Epoch:  1487 | train loss: 0.007313 | valid loss: 0.008241\n","Epoch:  1488 | train loss: 0.009653 | valid loss: 0.008322\n","Epoch:  1489 | train loss: 0.005376 | valid loss: 0.008394\n","Epoch:  1490 | train loss: 0.006508 | valid loss: 0.008335\n","Epoch:  1491 | train loss: 0.005465 | valid loss: 0.008137\n","Epoch:  1492 | train loss: 0.005733 | valid loss: 0.008165\n","Epoch:  1493 | train loss: 0.004308 | valid loss: 0.008407\n","Epoch:  1494 | train loss: 0.003974 | valid loss: 0.008239\n","Epoch:  1495 | train loss: 0.007688 | valid loss: 0.008232\n","Epoch:  1496 | train loss: 0.006049 | valid loss: 0.008283\n","Epoch:  1497 | train loss: 0.007001 | valid loss: 0.008274\n","Epoch:  1498 | train loss: 0.005868 | valid loss: 0.008291\n","Epoch:  1499 | train loss: 0.004722 | valid loss: 0.008242\n","Epoch:  1500 | train loss: 0.005194 | valid loss: 0.008255\n","Epoch:  1501 | train loss: 0.007966 | valid loss: 0.008211\n","Epoch:  1502 | train loss: 0.004658 | valid loss: 0.008369\n","Epoch:  1503 | train loss: 0.007053 | valid loss: 0.008309\n","Epoch:  1504 | train loss: 0.005815 | valid loss: 0.008276\n","Epoch:  1505 | train loss: 0.006429 | valid loss: 0.008129\n","Epoch:  1506 | train loss: 0.005101 | valid loss: 0.008205\n","Epoch:  1507 | train loss: 0.006341 | valid loss: 0.008090\n","Epoch:  1508 | train loss: 0.005175 | valid loss: 0.008233\n","Epoch:  1509 | train loss: 0.004761 | valid loss: 0.008159\n","Epoch:  1510 | train loss: 0.007763 | valid loss: 0.008252\n","Epoch:  1511 | train loss: 0.006040 | valid loss: 0.008295\n","Epoch:  1512 | train loss: 0.007447 | valid loss: 0.008363\n","Epoch:  1513 | train loss: 0.006717 | valid loss: 0.008431\n","Epoch:  1514 | train loss: 0.005977 | valid loss: 0.008232\n","Epoch:  1515 | train loss: 0.003471 | valid loss: 0.008319\n","Epoch:  1516 | train loss: 0.003614 | valid loss: 0.008274\n","Epoch:  1517 | train loss: 0.004224 | valid loss: 0.008340\n","Epoch:  1518 | train loss: 0.005299 | valid loss: 0.008249\n","Epoch:  1519 | train loss: 0.005188 | valid loss: 0.008294\n","Epoch:  1520 | train loss: 0.004886 | valid loss: 0.008301\n","Epoch:  1521 | train loss: 0.003803 | valid loss: 0.008085\n","Epoch:  1522 | train loss: 0.004984 | valid loss: 0.008172\n","Epoch:  1523 | train loss: 0.006331 | valid loss: 0.008276\n","Epoch:  1524 | train loss: 0.006232 | valid loss: 0.008321\n","Epoch:  1525 | train loss: 0.003936 | valid loss: 0.008295\n","Epoch:  1526 | train loss: 0.005375 | valid loss: 0.008184\n","Epoch:  1527 | train loss: 0.005559 | valid loss: 0.008458\n","Epoch:  1528 | train loss: 0.006662 | valid loss: 0.008191\n","Epoch:  1529 | train loss: 0.004597 | valid loss: 0.008214\n","Epoch:  1530 | train loss: 0.004727 | valid loss: 0.008149\n","Epoch:  1531 | train loss: 0.003409 | valid loss: 0.008202\n","Epoch:  1532 | train loss: 0.006163 | valid loss: 0.008235\n","Epoch:  1533 | train loss: 0.009356 | valid loss: 0.008281\n","Epoch:  1534 | train loss: 0.006733 | valid loss: 0.008365\n","Epoch:  1535 | train loss: 0.005597 | valid loss: 0.008143\n","Epoch:  1536 | train loss: 0.004759 | valid loss: 0.008474\n","Epoch:  1537 | train loss: 0.008661 | valid loss: 0.008316\n","Epoch:  1538 | train loss: 0.009565 | valid loss: 0.008265\n","Epoch:  1539 | train loss: 0.005792 | valid loss: 0.008419\n","Epoch:  1540 | train loss: 0.008444 | valid loss: 0.008568\n","Epoch:  1541 | train loss: 0.005334 | valid loss: 0.008384\n","Epoch:  1542 | train loss: 0.006285 | valid loss: 0.008305\n","Epoch:  1543 | train loss: 0.004856 | valid loss: 0.008266\n","Epoch:  1544 | train loss: 0.006166 | valid loss: 0.008246\n","Epoch:  1545 | train loss: 0.005168 | valid loss: 0.008117\n","Epoch:  1546 | train loss: 0.005467 | valid loss: 0.008209\n","Epoch:  1547 | train loss: 0.004596 | valid loss: 0.008232\n","Epoch:  1548 | train loss: 0.007592 | valid loss: 0.008212\n","Epoch:  1549 | train loss: 0.007992 | valid loss: 0.008215\n","Epoch:  1550 | train loss: 0.006303 | valid loss: 0.008329\n","Epoch:  1551 | train loss: 0.006151 | valid loss: 0.008322\n","Epoch:  1552 | train loss: 0.006153 | valid loss: 0.008406\n","Epoch:  1553 | train loss: 0.009905 | valid loss: 0.008190\n","Epoch:  1554 | train loss: 0.005650 | valid loss: 0.008259\n","Epoch:  1555 | train loss: 0.005304 | valid loss: 0.008242\n","Epoch:  1556 | train loss: 0.003447 | valid loss: 0.008368\n","Epoch:  1557 | train loss: 0.007530 | valid loss: 0.008356\n","Epoch:  1558 | train loss: 0.006302 | valid loss: 0.008302\n","Epoch:  1559 | train loss: 0.005072 | valid loss: 0.008237\n","Epoch:  1560 | train loss: 0.008216 | valid loss: 0.008222\n","Epoch:  1561 | train loss: 0.008272 | valid loss: 0.008323\n","Epoch:  1562 | train loss: 0.004250 | valid loss: 0.008405\n","Epoch:  1563 | train loss: 0.008476 | valid loss: 0.008290\n","Epoch:  1564 | train loss: 0.004519 | valid loss: 0.008327\n","Epoch:  1565 | train loss: 0.004722 | valid loss: 0.008356\n","Epoch:  1566 | train loss: 0.005959 | valid loss: 0.008320\n","Epoch:  1567 | train loss: 0.006918 | valid loss: 0.008324\n","Epoch:  1568 | train loss: 0.006927 | valid loss: 0.008192\n","Epoch:  1569 | train loss: 0.008802 | valid loss: 0.008307\n","Epoch:  1570 | train loss: 0.009086 | valid loss: 0.008304\n","Epoch:  1571 | train loss: 0.004506 | valid loss: 0.008279\n","Epoch:  1572 | train loss: 0.008460 | valid loss: 0.008310\n","Epoch:  1573 | train loss: 0.008375 | valid loss: 0.008298\n","Epoch:  1574 | train loss: 0.005711 | valid loss: 0.008370\n","Epoch:  1575 | train loss: 0.005009 | valid loss: 0.008243\n","Epoch:  1576 | train loss: 0.005461 | valid loss: 0.008268\n","Epoch:  1577 | train loss: 0.003707 | valid loss: 0.008475\n","Epoch:  1578 | train loss: 0.004051 | valid loss: 0.008266\n","Epoch:  1579 | train loss: 0.005700 | valid loss: 0.008301\n","Epoch:  1580 | train loss: 0.007085 | valid loss: 0.008474\n","Epoch:  1581 | train loss: 0.011389 | valid loss: 0.008366\n","Epoch:  1582 | train loss: 0.005958 | valid loss: 0.008386\n","Epoch:  1583 | train loss: 0.007606 | valid loss: 0.008284\n","Epoch:  1584 | train loss: 0.004768 | valid loss: 0.008265\n","Epoch:  1585 | train loss: 0.006704 | valid loss: 0.008265\n","Epoch:  1586 | train loss: 0.003226 | valid loss: 0.008151\n","Epoch:  1587 | train loss: 0.005890 | valid loss: 0.008224\n","Epoch:  1588 | train loss: 0.009292 | valid loss: 0.008379\n","Epoch:  1589 | train loss: 0.008782 | valid loss: 0.008337\n","Epoch:  1590 | train loss: 0.004868 | valid loss: 0.008411\n","Epoch:  1591 | train loss: 0.007288 | valid loss: 0.008294\n","Epoch:  1592 | train loss: 0.007015 | valid loss: 0.008248\n","Epoch:  1593 | train loss: 0.008915 | valid loss: 0.008359\n","Epoch:  1594 | train loss: 0.007856 | valid loss: 0.008294\n","Epoch:  1595 | train loss: 0.005698 | valid loss: 0.008237\n","Epoch:  1596 | train loss: 0.006218 | valid loss: 0.008314\n","Epoch:  1597 | train loss: 0.006017 | valid loss: 0.008390\n","Epoch:  1598 | train loss: 0.006330 | valid loss: 0.008370\n","Epoch:  1599 | train loss: 0.006153 | valid loss: 0.008296\n","Epoch:  1600 | train loss: 0.006687 | valid loss: 0.008433\n","Epoch:  1601 | train loss: 0.006785 | valid loss: 0.008616\n","Epoch:  1602 | train loss: 0.005043 | valid loss: 0.008229\n","Epoch:  1603 | train loss: 0.005793 | valid loss: 0.008269\n","Epoch:  1604 | train loss: 0.004442 | valid loss: 0.008225\n","Epoch:  1605 | train loss: 0.007086 | valid loss: 0.008215\n","Epoch:  1606 | train loss: 0.006251 | valid loss: 0.008458\n","Epoch:  1607 | train loss: 0.005557 | valid loss: 0.008307\n","Epoch:  1608 | train loss: 0.005911 | valid loss: 0.008308\n","Epoch:  1609 | train loss: 0.003230 | valid loss: 0.008330\n","Epoch:  1610 | train loss: 0.010188 | valid loss: 0.008296\n","Epoch:  1611 | train loss: 0.006441 | valid loss: 0.008303\n","Epoch:  1612 | train loss: 0.007157 | valid loss: 0.008428\n","Epoch:  1613 | train loss: 0.006860 | valid loss: 0.008274\n","Epoch:  1614 | train loss: 0.006221 | valid loss: 0.008401\n","Epoch:  1615 | train loss: 0.005414 | valid loss: 0.008412\n","Epoch:  1616 | train loss: 0.007715 | valid loss: 0.008391\n","Epoch:  1617 | train loss: 0.008603 | valid loss: 0.008293\n","Epoch:  1618 | train loss: 0.009423 | valid loss: 0.008297\n","Epoch:  1619 | train loss: 0.006527 | valid loss: 0.008460\n","Epoch:  1620 | train loss: 0.012897 | valid loss: 0.008284\n","Epoch:  1621 | train loss: 0.004025 | valid loss: 0.008324\n","Epoch:  1622 | train loss: 0.007039 | valid loss: 0.008321\n","Epoch:  1623 | train loss: 0.008393 | valid loss: 0.008352\n","Epoch:  1624 | train loss: 0.005210 | valid loss: 0.008337\n","Epoch:  1625 | train loss: 0.005090 | valid loss: 0.008354\n","Epoch:  1626 | train loss: 0.004626 | valid loss: 0.008382\n","Epoch:  1627 | train loss: 0.007459 | valid loss: 0.008454\n","Epoch:  1628 | train loss: 0.008002 | valid loss: 0.008487\n","Epoch:  1629 | train loss: 0.007984 | valid loss: 0.008417\n","Epoch:  1630 | train loss: 0.007635 | valid loss: 0.008288\n","Epoch:  1631 | train loss: 0.007916 | valid loss: 0.008463\n","Epoch:  1632 | train loss: 0.006379 | valid loss: 0.008390\n","Epoch:  1633 | train loss: 0.007586 | valid loss: 0.008360\n","Epoch:  1634 | train loss: 0.003979 | valid loss: 0.008334\n","Epoch:  1635 | train loss: 0.005836 | valid loss: 0.008318\n","Epoch:  1636 | train loss: 0.010897 | valid loss: 0.008259\n","Epoch:  1637 | train loss: 0.003444 | valid loss: 0.008407\n","Epoch:  1638 | train loss: 0.008933 | valid loss: 0.008142\n","Epoch:  1639 | train loss: 0.005477 | valid loss: 0.008377\n","Epoch:  1640 | train loss: 0.008847 | valid loss: 0.008456\n","Epoch:  1641 | train loss: 0.005779 | valid loss: 0.008351\n","Epoch:  1642 | train loss: 0.006594 | valid loss: 0.008387\n","Epoch:  1643 | train loss: 0.004824 | valid loss: 0.008370\n","Epoch:  1644 | train loss: 0.004592 | valid loss: 0.008323\n","Epoch:  1645 | train loss: 0.005392 | valid loss: 0.008312\n","Epoch:  1646 | train loss: 0.003793 | valid loss: 0.008325\n","Epoch:  1647 | train loss: 0.005230 | valid loss: 0.008118\n","Epoch:  1648 | train loss: 0.006456 | valid loss: 0.008447\n","Epoch:  1649 | train loss: 0.004425 | valid loss: 0.008225\n","Epoch:  1650 | train loss: 0.005164 | valid loss: 0.008336\n","Epoch:  1651 | train loss: 0.004084 | valid loss: 0.008284\n","Epoch:  1652 | train loss: 0.004802 | valid loss: 0.008332\n","Epoch:  1653 | train loss: 0.008080 | valid loss: 0.008400\n","Epoch:  1654 | train loss: 0.004288 | valid loss: 0.008525\n","Epoch:  1655 | train loss: 0.007550 | valid loss: 0.008269\n","Epoch:  1656 | train loss: 0.006045 | valid loss: 0.008497\n","Epoch:  1657 | train loss: 0.007240 | valid loss: 0.008479\n","Epoch:  1658 | train loss: 0.006112 | valid loss: 0.008328\n","Epoch:  1659 | train loss: 0.006009 | valid loss: 0.008402\n","Epoch:  1660 | train loss: 0.007894 | valid loss: 0.008289\n","Epoch:  1661 | train loss: 0.006627 | valid loss: 0.008343\n","Epoch:  1662 | train loss: 0.004687 | valid loss: 0.008212\n","Epoch:  1663 | train loss: 0.005570 | valid loss: 0.008242\n","Epoch:  1664 | train loss: 0.005447 | valid loss: 0.008298\n","Epoch:  1665 | train loss: 0.004045 | valid loss: 0.008335\n","Epoch:  1666 | train loss: 0.007297 | valid loss: 0.008326\n","Epoch:  1667 | train loss: 0.007852 | valid loss: 0.008321\n","Epoch:  1668 | train loss: 0.005924 | valid loss: 0.008293\n","Epoch:  1669 | train loss: 0.005752 | valid loss: 0.008361\n","Epoch:  1670 | train loss: 0.003496 | valid loss: 0.008439\n","Epoch:  1671 | train loss: 0.007063 | valid loss: 0.008251\n","Epoch:  1672 | train loss: 0.005752 | valid loss: 0.008381\n","Epoch:  1673 | train loss: 0.007455 | valid loss: 0.008346\n","Epoch:  1674 | train loss: 0.004044 | valid loss: 0.008349\n","Epoch:  1675 | train loss: 0.009895 | valid loss: 0.008634\n","Epoch:  1676 | train loss: 0.006275 | valid loss: 0.008439\n","Epoch:  1677 | train loss: 0.005675 | valid loss: 0.008482\n","Epoch:  1678 | train loss: 0.006965 | valid loss: 0.008518\n","Epoch:  1679 | train loss: 0.003336 | valid loss: 0.008284\n","Epoch:  1680 | train loss: 0.004689 | valid loss: 0.008273\n","Epoch:  1681 | train loss: 0.006869 | valid loss: 0.008239\n","Epoch:  1682 | train loss: 0.009015 | valid loss: 0.008327\n","Epoch:  1683 | train loss: 0.003538 | valid loss: 0.008469\n","Epoch:  1684 | train loss: 0.004703 | valid loss: 0.008333\n","Epoch:  1685 | train loss: 0.006801 | valid loss: 0.008423\n","Epoch:  1686 | train loss: 0.006249 | valid loss: 0.008160\n","Epoch:  1687 | train loss: 0.008658 | valid loss: 0.008317\n","Epoch:  1688 | train loss: 0.005002 | valid loss: 0.008372\n","Epoch:  1689 | train loss: 0.008905 | valid loss: 0.008287\n","Epoch:  1690 | train loss: 0.005601 | valid loss: 0.008372\n","Epoch:  1691 | train loss: 0.005509 | valid loss: 0.008455\n","Epoch:  1692 | train loss: 0.007416 | valid loss: 0.008410\n","Epoch:  1693 | train loss: 0.009867 | valid loss: 0.008345\n","Epoch:  1694 | train loss: 0.007258 | valid loss: 0.008237\n","Epoch:  1695 | train loss: 0.003870 | valid loss: 0.008308\n","Epoch:  1696 | train loss: 0.005830 | valid loss: 0.008366\n","Epoch:  1697 | train loss: 0.006084 | valid loss: 0.008294\n","Epoch:  1698 | train loss: 0.005474 | valid loss: 0.008380\n","Epoch:  1699 | train loss: 0.008103 | valid loss: 0.008383\n","Epoch:  1700 | train loss: 0.007496 | valid loss: 0.008330\n","Epoch:  1701 | train loss: 0.006845 | valid loss: 0.008382\n","Epoch:  1702 | train loss: 0.004996 | valid loss: 0.008194\n","Epoch:  1703 | train loss: 0.006435 | valid loss: 0.008240\n","Epoch:  1704 | train loss: 0.008352 | valid loss: 0.008345\n","Epoch:  1705 | train loss: 0.007807 | valid loss: 0.008460\n","Epoch:  1706 | train loss: 0.008049 | valid loss: 0.008335\n","Epoch:  1707 | train loss: 0.006419 | valid loss: 0.008365\n","Epoch:  1708 | train loss: 0.006163 | valid loss: 0.008420\n","Epoch:  1709 | train loss: 0.005181 | valid loss: 0.008426\n","Epoch:  1710 | train loss: 0.009258 | valid loss: 0.008409\n","Epoch:  1711 | train loss: 0.007271 | valid loss: 0.008695\n","Epoch:  1712 | train loss: 0.006354 | valid loss: 0.008360\n","Epoch:  1713 | train loss: 0.004888 | valid loss: 0.008414\n","Epoch:  1714 | train loss: 0.004289 | valid loss: 0.008384\n","Epoch:  1715 | train loss: 0.006061 | valid loss: 0.008306\n","Epoch:  1716 | train loss: 0.010543 | valid loss: 0.008496\n","Epoch:  1717 | train loss: 0.006210 | valid loss: 0.008358\n","Epoch:  1718 | train loss: 0.005433 | valid loss: 0.008718\n","Epoch:  1719 | train loss: 0.005766 | valid loss: 0.008358\n","Epoch:  1720 | train loss: 0.008396 | valid loss: 0.008328\n","Epoch:  1721 | train loss: 0.004819 | valid loss: 0.008339\n","Epoch:  1722 | train loss: 0.005234 | valid loss: 0.008341\n","Epoch:  1723 | train loss: 0.005575 | valid loss: 0.008341\n","Epoch:  1724 | train loss: 0.003898 | valid loss: 0.008248\n","Epoch:  1725 | train loss: 0.007640 | valid loss: 0.008363\n","Epoch:  1726 | train loss: 0.005113 | valid loss: 0.008447\n","Epoch:  1727 | train loss: 0.006484 | valid loss: 0.008430\n","Epoch:  1728 | train loss: 0.005669 | valid loss: 0.008471\n","Epoch:  1729 | train loss: 0.005616 | valid loss: 0.008221\n","Epoch:  1730 | train loss: 0.004681 | valid loss: 0.008384\n","Epoch:  1731 | train loss: 0.005889 | valid loss: 0.008552\n","Epoch:  1732 | train loss: 0.008994 | valid loss: 0.008396\n","Epoch:  1733 | train loss: 0.005713 | valid loss: 0.008390\n","Epoch:  1734 | train loss: 0.005524 | valid loss: 0.008526\n","Epoch:  1735 | train loss: 0.004343 | valid loss: 0.008351\n","Epoch:  1736 | train loss: 0.005161 | valid loss: 0.008259\n","Epoch:  1737 | train loss: 0.004317 | valid loss: 0.008517\n","Epoch:  1738 | train loss: 0.007720 | valid loss: 0.008448\n","Epoch:  1739 | train loss: 0.006955 | valid loss: 0.008328\n","Epoch:  1740 | train loss: 0.006806 | valid loss: 0.008333\n","Epoch:  1741 | train loss: 0.008753 | valid loss: 0.008336\n","Epoch:  1742 | train loss: 0.005754 | valid loss: 0.008472\n","Epoch:  1743 | train loss: 0.005152 | valid loss: 0.008301\n","Epoch:  1744 | train loss: 0.009943 | valid loss: 0.008324\n","Epoch:  1745 | train loss: 0.007553 | valid loss: 0.008353\n","Epoch:  1746 | train loss: 0.006461 | valid loss: 0.008385\n","Epoch:  1747 | train loss: 0.004013 | valid loss: 0.008430\n","Epoch:  1748 | train loss: 0.004623 | valid loss: 0.008334\n","Epoch:  1749 | train loss: 0.007228 | valid loss: 0.008437\n","Epoch:  1750 | train loss: 0.005205 | valid loss: 0.008405\n","Epoch:  1751 | train loss: 0.008496 | valid loss: 0.008534\n","Epoch:  1752 | train loss: 0.005856 | valid loss: 0.008443\n","Epoch:  1753 | train loss: 0.006164 | valid loss: 0.008521\n","Epoch:  1754 | train loss: 0.004365 | valid loss: 0.008369\n","Epoch:  1755 | train loss: 0.005125 | valid loss: 0.008418\n","Epoch:  1756 | train loss: 0.003592 | valid loss: 0.008353\n","Epoch:  1757 | train loss: 0.009607 | valid loss: 0.008484\n","Epoch:  1758 | train loss: 0.004767 | valid loss: 0.008469\n","Epoch:  1759 | train loss: 0.008843 | valid loss: 0.008406\n","Epoch:  1760 | train loss: 0.005111 | valid loss: 0.008433\n","Epoch:  1761 | train loss: 0.008036 | valid loss: 0.008364\n","Epoch:  1762 | train loss: 0.008769 | valid loss: 0.008361\n","Epoch:  1763 | train loss: 0.004542 | valid loss: 0.008438\n","Epoch:  1764 | train loss: 0.008373 | valid loss: 0.008493\n","Epoch:  1765 | train loss: 0.006616 | valid loss: 0.008279\n","Epoch:  1766 | train loss: 0.005072 | valid loss: 0.008465\n","Epoch:  1767 | train loss: 0.006625 | valid loss: 0.008477\n","Epoch:  1768 | train loss: 0.003801 | valid loss: 0.008598\n","Epoch:  1769 | train loss: 0.006825 | valid loss: 0.008509\n","Epoch:  1770 | train loss: 0.005894 | valid loss: 0.008559\n","Epoch:  1771 | train loss: 0.005542 | valid loss: 0.008296\n","Epoch:  1772 | train loss: 0.005533 | valid loss: 0.008429\n","Epoch:  1773 | train loss: 0.005789 | valid loss: 0.008385\n","Epoch:  1774 | train loss: 0.011706 | valid loss: 0.008333\n","Epoch:  1775 | train loss: 0.010813 | valid loss: 0.008465\n","Epoch:  1776 | train loss: 0.004896 | valid loss: 0.008330\n","Epoch:  1777 | train loss: 0.005709 | valid loss: 0.008445\n","Epoch:  1778 | train loss: 0.007394 | valid loss: 0.008385\n","Epoch:  1779 | train loss: 0.007244 | valid loss: 0.008496\n","Epoch:  1780 | train loss: 0.010543 | valid loss: 0.008403\n","Epoch:  1781 | train loss: 0.006192 | valid loss: 0.008607\n","Epoch:  1782 | train loss: 0.005589 | valid loss: 0.008577\n","Epoch:  1783 | train loss: 0.006868 | valid loss: 0.008713\n","Epoch:  1784 | train loss: 0.005671 | valid loss: 0.008620\n","Epoch:  1785 | train loss: 0.006794 | valid loss: 0.008415\n","Epoch:  1786 | train loss: 0.005786 | valid loss: 0.008327\n","Epoch:  1787 | train loss: 0.006499 | valid loss: 0.008317\n","Epoch:  1788 | train loss: 0.009220 | valid loss: 0.008429\n","Epoch:  1789 | train loss: 0.004679 | valid loss: 0.008736\n","Epoch:  1790 | train loss: 0.006701 | valid loss: 0.008418\n","Epoch:  1791 | train loss: 0.007666 | valid loss: 0.008502\n","Epoch:  1792 | train loss: 0.005687 | valid loss: 0.008362\n","Epoch:  1793 | train loss: 0.005032 | valid loss: 0.008329\n","Epoch:  1794 | train loss: 0.006019 | valid loss: 0.008323\n","Epoch:  1795 | train loss: 0.004941 | valid loss: 0.008520\n","Epoch:  1796 | train loss: 0.005457 | valid loss: 0.008322\n","Epoch:  1797 | train loss: 0.007583 | valid loss: 0.008621\n","Epoch:  1798 | train loss: 0.006659 | valid loss: 0.008397\n","Epoch:  1799 | train loss: 0.005783 | valid loss: 0.008479\n","Epoch:  1800 | train loss: 0.005087 | valid loss: 0.008380\n","Epoch:  1801 | train loss: 0.006444 | valid loss: 0.008472\n","Epoch:  1802 | train loss: 0.005251 | valid loss: 0.008436\n","Epoch:  1803 | train loss: 0.006003 | valid loss: 0.008314\n","Epoch:  1804 | train loss: 0.006907 | valid loss: 0.008370\n","Epoch:  1805 | train loss: 0.006316 | valid loss: 0.008484\n","Epoch:  1806 | train loss: 0.006467 | valid loss: 0.008217\n","Epoch:  1807 | train loss: 0.005550 | valid loss: 0.008431\n","Epoch:  1808 | train loss: 0.005907 | valid loss: 0.008601\n","Epoch:  1809 | train loss: 0.005540 | valid loss: 0.008301\n","Epoch:  1810 | train loss: 0.007923 | valid loss: 0.008601\n","Epoch:  1811 | train loss: 0.007307 | valid loss: 0.008497\n","Epoch:  1812 | train loss: 0.005815 | valid loss: 0.008587\n","Epoch:  1813 | train loss: 0.006417 | valid loss: 0.008494\n","Epoch:  1814 | train loss: 0.005102 | valid loss: 0.008531\n","Epoch:  1815 | train loss: 0.006835 | valid loss: 0.008523\n","Epoch:  1816 | train loss: 0.004446 | valid loss: 0.008406\n","Epoch:  1817 | train loss: 0.007645 | valid loss: 0.008459\n","Epoch:  1818 | train loss: 0.003187 | valid loss: 0.008508\n","Epoch:  1819 | train loss: 0.004330 | valid loss: 0.008687\n","Epoch:  1820 | train loss: 0.003731 | valid loss: 0.008540\n","Epoch:  1821 | train loss: 0.009212 | valid loss: 0.008481\n","Epoch:  1822 | train loss: 0.008978 | valid loss: 0.008490\n","Epoch:  1823 | train loss: 0.007813 | valid loss: 0.008545\n","Epoch:  1824 | train loss: 0.006082 | valid loss: 0.008346\n","Epoch:  1825 | train loss: 0.005952 | valid loss: 0.008695\n","Epoch:  1826 | train loss: 0.007841 | valid loss: 0.008432\n","Epoch:  1827 | train loss: 0.006361 | valid loss: 0.008484\n","Epoch:  1828 | train loss: 0.004717 | valid loss: 0.008413\n","Epoch:  1829 | train loss: 0.004604 | valid loss: 0.008409\n","Epoch:  1830 | train loss: 0.003883 | valid loss: 0.008433\n","Epoch:  1831 | train loss: 0.008921 | valid loss: 0.008387\n","Epoch:  1832 | train loss: 0.004214 | valid loss: 0.008455\n","Epoch:  1833 | train loss: 0.003031 | valid loss: 0.008628\n","Epoch:  1834 | train loss: 0.008206 | valid loss: 0.008568\n","Epoch:  1835 | train loss: 0.005535 | valid loss: 0.008550\n","Epoch:  1836 | train loss: 0.005546 | valid loss: 0.008427\n","Epoch:  1837 | train loss: 0.005965 | valid loss: 0.008478\n","Epoch:  1838 | train loss: 0.004538 | valid loss: 0.008440\n","Epoch:  1839 | train loss: 0.002884 | valid loss: 0.008484\n","Epoch:  1840 | train loss: 0.011480 | valid loss: 0.008524\n","Epoch:  1841 | train loss: 0.006279 | valid loss: 0.008563\n","Epoch:  1842 | train loss: 0.007732 | valid loss: 0.008478\n","Epoch:  1843 | train loss: 0.005269 | valid loss: 0.008381\n","Epoch:  1844 | train loss: 0.007502 | valid loss: 0.008385\n","Epoch:  1845 | train loss: 0.006226 | valid loss: 0.008376\n","Epoch:  1846 | train loss: 0.007645 | valid loss: 0.008421\n","Epoch:  1847 | train loss: 0.003637 | valid loss: 0.008440\n","Epoch:  1848 | train loss: 0.006110 | valid loss: 0.008410\n","Epoch:  1849 | train loss: 0.004941 | valid loss: 0.008401\n","Epoch:  1850 | train loss: 0.007236 | valid loss: 0.008490\n","Epoch:  1851 | train loss: 0.004572 | valid loss: 0.008565\n","Epoch:  1852 | train loss: 0.007888 | valid loss: 0.008650\n","Epoch:  1853 | train loss: 0.008399 | valid loss: 0.008600\n","Epoch:  1854 | train loss: 0.009467 | valid loss: 0.008596\n","Epoch:  1855 | train loss: 0.007038 | valid loss: 0.008542\n","Epoch:  1856 | train loss: 0.007470 | valid loss: 0.008432\n","Epoch:  1857 | train loss: 0.007330 | valid loss: 0.008445\n","Epoch:  1858 | train loss: 0.004871 | valid loss: 0.008500\n","Epoch:  1859 | train loss: 0.010267 | valid loss: 0.008268\n","Epoch:  1860 | train loss: 0.009587 | valid loss: 0.008409\n","Epoch:  1861 | train loss: 0.005758 | valid loss: 0.008356\n","Epoch:  1862 | train loss: 0.007451 | valid loss: 0.008496\n","Epoch:  1863 | train loss: 0.007848 | valid loss: 0.008447\n","Epoch:  1864 | train loss: 0.004668 | valid loss: 0.008474\n","Epoch:  1865 | train loss: 0.005137 | valid loss: 0.008369\n","Epoch:  1866 | train loss: 0.007505 | valid loss: 0.008395\n","Epoch:  1867 | train loss: 0.005817 | valid loss: 0.008545\n","Epoch:  1868 | train loss: 0.008464 | valid loss: 0.008549\n","Epoch:  1869 | train loss: 0.004028 | valid loss: 0.008427\n","Epoch:  1870 | train loss: 0.005603 | valid loss: 0.008471\n","Epoch:  1871 | train loss: 0.004945 | valid loss: 0.008477\n","Epoch:  1872 | train loss: 0.004192 | valid loss: 0.008309\n","Epoch:  1873 | train loss: 0.006640 | valid loss: 0.008503\n","Epoch:  1874 | train loss: 0.005168 | valid loss: 0.008730\n","Epoch:  1875 | train loss: 0.010795 | valid loss: 0.008578\n","Epoch:  1876 | train loss: 0.006387 | valid loss: 0.008714\n","Epoch:  1877 | train loss: 0.005998 | valid loss: 0.008446\n","Epoch:  1878 | train loss: 0.007675 | valid loss: 0.008550\n","Epoch:  1879 | train loss: 0.006432 | valid loss: 0.008355\n","Epoch:  1880 | train loss: 0.006513 | valid loss: 0.008491\n","Epoch:  1881 | train loss: 0.004521 | valid loss: 0.008329\n","Epoch:  1882 | train loss: 0.006807 | valid loss: 0.008406\n","Epoch:  1883 | train loss: 0.004634 | valid loss: 0.008341\n","Epoch:  1884 | train loss: 0.006038 | valid loss: 0.008384\n","Epoch:  1885 | train loss: 0.006147 | valid loss: 0.008439\n","Epoch:  1886 | train loss: 0.007390 | valid loss: 0.008410\n","Epoch:  1887 | train loss: 0.005697 | valid loss: 0.008585\n","Epoch:  1888 | train loss: 0.006981 | valid loss: 0.008592\n","Epoch:  1889 | train loss: 0.008072 | valid loss: 0.008479\n","Epoch:  1890 | train loss: 0.003914 | valid loss: 0.008579\n","Epoch:  1891 | train loss: 0.005557 | valid loss: 0.008399\n","Epoch:  1892 | train loss: 0.005251 | valid loss: 0.008525\n","Epoch:  1893 | train loss: 0.004997 | valid loss: 0.008425\n","Epoch:  1894 | train loss: 0.006752 | valid loss: 0.008452\n","Epoch:  1895 | train loss: 0.005271 | valid loss: 0.008494\n","Epoch:  1896 | train loss: 0.006521 | valid loss: 0.008581\n","Epoch:  1897 | train loss: 0.006724 | valid loss: 0.008469\n","Epoch:  1898 | train loss: 0.005481 | valid loss: 0.008567\n","Epoch:  1899 | train loss: 0.006391 | valid loss: 0.008504\n","Epoch:  1900 | train loss: 0.005799 | valid loss: 0.008532\n","Epoch:  1901 | train loss: 0.005294 | valid loss: 0.008574\n","Epoch:  1902 | train loss: 0.004680 | valid loss: 0.008403\n","Epoch:  1903 | train loss: 0.006725 | valid loss: 0.008408\n","Epoch:  1904 | train loss: 0.007081 | valid loss: 0.008470\n","Epoch:  1905 | train loss: 0.004846 | valid loss: 0.008556\n","Epoch:  1906 | train loss: 0.007256 | valid loss: 0.008552\n","Epoch:  1907 | train loss: 0.011015 | valid loss: 0.008574\n","Epoch:  1908 | train loss: 0.006281 | valid loss: 0.008560\n","Epoch:  1909 | train loss: 0.004609 | valid loss: 0.008401\n","Epoch:  1910 | train loss: 0.009600 | valid loss: 0.008579\n","Epoch:  1911 | train loss: 0.005856 | valid loss: 0.008457\n","Epoch:  1912 | train loss: 0.009481 | valid loss: 0.008307\n","Epoch:  1913 | train loss: 0.006234 | valid loss: 0.008441\n","Epoch:  1914 | train loss: 0.007442 | valid loss: 0.008488\n","Epoch:  1915 | train loss: 0.006443 | valid loss: 0.008464\n","Epoch:  1916 | train loss: 0.009657 | valid loss: 0.008487\n","Epoch:  1917 | train loss: 0.006612 | valid loss: 0.008430\n","Epoch:  1918 | train loss: 0.007278 | valid loss: 0.008574\n","Epoch:  1919 | train loss: 0.007375 | valid loss: 0.008503\n","Epoch:  1920 | train loss: 0.004795 | valid loss: 0.008589\n","Epoch:  1921 | train loss: 0.005267 | valid loss: 0.008465\n","Epoch:  1922 | train loss: 0.005464 | valid loss: 0.008645\n","Epoch:  1923 | train loss: 0.003748 | valid loss: 0.008377\n","Epoch:  1924 | train loss: 0.006008 | valid loss: 0.008550\n","Epoch:  1925 | train loss: 0.004400 | valid loss: 0.008391\n","Epoch:  1926 | train loss: 0.006471 | valid loss: 0.008518\n","Epoch:  1927 | train loss: 0.007819 | valid loss: 0.008465\n","Epoch:  1928 | train loss: 0.009323 | valid loss: 0.008591\n","Epoch:  1929 | train loss: 0.005398 | valid loss: 0.008677\n","Epoch:  1930 | train loss: 0.007074 | valid loss: 0.008732\n","Epoch:  1931 | train loss: 0.003860 | valid loss: 0.008505\n","Epoch:  1932 | train loss: 0.003467 | valid loss: 0.008394\n","Epoch:  1933 | train loss: 0.005003 | valid loss: 0.008508\n","Epoch:  1934 | train loss: 0.006846 | valid loss: 0.008496\n","Epoch:  1935 | train loss: 0.004734 | valid loss: 0.008470\n","Epoch:  1936 | train loss: 0.004862 | valid loss: 0.008383\n","Epoch:  1937 | train loss: 0.006601 | valid loss: 0.008447\n","Epoch:  1938 | train loss: 0.007156 | valid loss: 0.008517\n","Epoch:  1939 | train loss: 0.006258 | valid loss: 0.008379\n","Epoch:  1940 | train loss: 0.006311 | valid loss: 0.008412\n","Epoch:  1941 | train loss: 0.008240 | valid loss: 0.008583\n","Epoch:  1942 | train loss: 0.006879 | valid loss: 0.008441\n","Epoch:  1943 | train loss: 0.008593 | valid loss: 0.008501\n","Epoch:  1944 | train loss: 0.007971 | valid loss: 0.008498\n","Epoch:  1945 | train loss: 0.003767 | valid loss: 0.008460\n","Epoch:  1946 | train loss: 0.007045 | valid loss: 0.008522\n","Epoch:  1947 | train loss: 0.007189 | valid loss: 0.008544\n","Epoch:  1948 | train loss: 0.006633 | valid loss: 0.008513\n","Epoch:  1949 | train loss: 0.005811 | valid loss: 0.008515\n","Epoch:  1950 | train loss: 0.003953 | valid loss: 0.008402\n","Epoch:  1951 | train loss: 0.007043 | valid loss: 0.008456\n","Epoch:  1952 | train loss: 0.007644 | valid loss: 0.008396\n","Epoch:  1953 | train loss: 0.005051 | valid loss: 0.008521\n","Epoch:  1954 | train loss: 0.005187 | valid loss: 0.008425\n","Epoch:  1955 | train loss: 0.004836 | valid loss: 0.008455\n","Epoch:  1956 | train loss: 0.006895 | valid loss: 0.008401\n","Epoch:  1957 | train loss: 0.007518 | valid loss: 0.008568\n","Epoch:  1958 | train loss: 0.010576 | valid loss: 0.008508\n","Epoch:  1959 | train loss: 0.006126 | valid loss: 0.008622\n","Epoch:  1960 | train loss: 0.007667 | valid loss: 0.008522\n","Epoch:  1961 | train loss: 0.003846 | valid loss: 0.008488\n","Epoch:  1962 | train loss: 0.007837 | valid loss: 0.008400\n","Epoch:  1963 | train loss: 0.008825 | valid loss: 0.008438\n","Epoch:  1964 | train loss: 0.007554 | valid loss: 0.008507\n","Epoch:  1965 | train loss: 0.007058 | valid loss: 0.008558\n","Epoch:  1966 | train loss: 0.009142 | valid loss: 0.008497\n","Epoch:  1967 | train loss: 0.004620 | valid loss: 0.008543\n","Epoch:  1968 | train loss: 0.003256 | valid loss: 0.008574\n","Epoch:  1969 | train loss: 0.006983 | valid loss: 0.008410\n","Epoch:  1970 | train loss: 0.005473 | valid loss: 0.008575\n","Epoch:  1971 | train loss: 0.011030 | valid loss: 0.008391\n","Epoch:  1972 | train loss: 0.005805 | valid loss: 0.008490\n","Epoch:  1973 | train loss: 0.006638 | valid loss: 0.008494\n","Epoch:  1974 | train loss: 0.010569 | valid loss: 0.008480\n","Epoch:  1975 | train loss: 0.004939 | valid loss: 0.008501\n","Epoch:  1976 | train loss: 0.004870 | valid loss: 0.008359\n","Epoch:  1977 | train loss: 0.004695 | valid loss: 0.008465\n","Epoch:  1978 | train loss: 0.005962 | valid loss: 0.008401\n","Epoch:  1979 | train loss: 0.008328 | valid loss: 0.008374\n","Epoch:  1980 | train loss: 0.006247 | valid loss: 0.008407\n","Epoch:  1981 | train loss: 0.008585 | valid loss: 0.008440\n","Epoch:  1982 | train loss: 0.002939 | valid loss: 0.008489\n","Epoch:  1983 | train loss: 0.008770 | valid loss: 0.008505\n","Epoch:  1984 | train loss: 0.006093 | valid loss: 0.008461\n","Epoch:  1985 | train loss: 0.006319 | valid loss: 0.008575\n","Epoch:  1986 | train loss: 0.004804 | valid loss: 0.008487\n","Epoch:  1987 | train loss: 0.009659 | valid loss: 0.008669\n","Epoch:  1988 | train loss: 0.005053 | valid loss: 0.008451\n","Epoch:  1989 | train loss: 0.005536 | valid loss: 0.008642\n","Epoch:  1990 | train loss: 0.007633 | valid loss: 0.008437\n","Epoch:  1991 | train loss: 0.005978 | valid loss: 0.008629\n","Epoch:  1992 | train loss: 0.009924 | valid loss: 0.008286\n","Epoch:  1993 | train loss: 0.006005 | valid loss: 0.008649\n","Epoch:  1994 | train loss: 0.006103 | valid loss: 0.008823\n","Epoch:  1995 | train loss: 0.006800 | valid loss: 0.008413\n","Epoch:  1996 | train loss: 0.007721 | valid loss: 0.008654\n","Epoch:  1997 | train loss: 0.004363 | valid loss: 0.008492\n","Epoch:  1998 | train loss: 0.006338 | valid loss: 0.008467\n","Epoch:  1999 | train loss: 0.005030 | valid loss: 0.008464\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o9baklnpdanZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629653840027,"user_tz":-60,"elapsed":46,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"aab090b7-5464-4a8a-d35e-92f060d3d1e1"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Train time: 301.5214948654175\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nh5YMhij1n_i","colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"status":"ok","timestamp":1629653840973,"user_tz":-60,"elapsed":965,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"610a7029-4d80-417b-d228-0fb6aed73ca0"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":58},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"3cgcpSx_NHDp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629653848796,"user_tz":-60,"elapsed":7839,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"1eec8427-0d11-4ff1-89dc-37772b4d8027"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":59,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 0.0002455052433054167\n","MSE_err of valid data 0.0003297486623886775\n","MSE_err of test data 0.00031839224790477155\n","MSE_err of total data 0.0002612182833253852\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_eGr4ujSv6sk"},"source":["#### 64 variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMLqFsoAc6pz","executionInfo":{"status":"ok","timestamp":1629656353766,"user_tz":-60,"elapsed":16,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"00b19897-d460-4018-fd5b-19b0ae6261b9"},"source":["print(\"compress to 64\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 2000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["compress to 64\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtZnc3cgc68C","executionInfo":{"status":"ok","timestamp":1629656626198,"user_tz":-60,"elapsed":272446,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"12ff5ddc-448c-42af-f039-e98c810d9750"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(64).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 1.308584 | valid loss: 1.286966\n","Epoch:  1 | train loss: 0.423341 | valid loss: 0.381867\n","Epoch:  2 | train loss: 0.112331 | valid loss: 0.111830\n","Epoch:  3 | train loss: 0.078977 | valid loss: 0.083386\n","Epoch:  4 | train loss: 0.064398 | valid loss: 0.071504\n","Epoch:  5 | train loss: 0.045680 | valid loss: 0.063081\n","Epoch:  6 | train loss: 0.053517 | valid loss: 0.055157\n","Epoch:  7 | train loss: 0.044922 | valid loss: 0.050023\n","Epoch:  8 | train loss: 0.031365 | valid loss: 0.045218\n","Epoch:  9 | train loss: 0.051838 | valid loss: 0.042191\n","Epoch:  10 | train loss: 0.041166 | valid loss: 0.038607\n","Epoch:  11 | train loss: 0.044585 | valid loss: 0.035963\n","Epoch:  12 | train loss: 0.038234 | valid loss: 0.033597\n","Epoch:  13 | train loss: 0.034391 | valid loss: 0.030934\n","Epoch:  14 | train loss: 0.024493 | valid loss: 0.029053\n","Epoch:  15 | train loss: 0.034987 | valid loss: 0.027692\n","Epoch:  16 | train loss: 0.024472 | valid loss: 0.026555\n","Epoch:  17 | train loss: 0.020478 | valid loss: 0.024817\n","Epoch:  18 | train loss: 0.024939 | valid loss: 0.023441\n","Epoch:  19 | train loss: 0.024385 | valid loss: 0.022460\n","Epoch:  20 | train loss: 0.020426 | valid loss: 0.021492\n","Epoch:  21 | train loss: 0.025885 | valid loss: 0.020920\n","Epoch:  22 | train loss: 0.038519 | valid loss: 0.019987\n","Epoch:  23 | train loss: 0.020958 | valid loss: 0.019276\n","Epoch:  24 | train loss: 0.021189 | valid loss: 0.018875\n","Epoch:  25 | train loss: 0.020462 | valid loss: 0.018344\n","Epoch:  26 | train loss: 0.019298 | valid loss: 0.018197\n","Epoch:  27 | train loss: 0.014652 | valid loss: 0.017217\n","Epoch:  28 | train loss: 0.016192 | valid loss: 0.016262\n","Epoch:  29 | train loss: 0.011841 | valid loss: 0.015755\n","Epoch:  30 | train loss: 0.009679 | valid loss: 0.015477\n","Epoch:  31 | train loss: 0.014529 | valid loss: 0.015066\n","Epoch:  32 | train loss: 0.017216 | valid loss: 0.014854\n","Epoch:  33 | train loss: 0.017339 | valid loss: 0.014077\n","Epoch:  34 | train loss: 0.013023 | valid loss: 0.013978\n","Epoch:  35 | train loss: 0.018081 | valid loss: 0.013644\n","Epoch:  36 | train loss: 0.010449 | valid loss: 0.013139\n","Epoch:  37 | train loss: 0.018996 | valid loss: 0.012666\n","Epoch:  38 | train loss: 0.007215 | valid loss: 0.012533\n","Epoch:  39 | train loss: 0.009618 | valid loss: 0.012118\n","Epoch:  40 | train loss: 0.011930 | valid loss: 0.011718\n","Epoch:  41 | train loss: 0.009909 | valid loss: 0.011548\n","Epoch:  42 | train loss: 0.011045 | valid loss: 0.010998\n","Epoch:  43 | train loss: 0.010459 | valid loss: 0.011436\n","Epoch:  44 | train loss: 0.008647 | valid loss: 0.010618\n","Epoch:  45 | train loss: 0.014332 | valid loss: 0.010741\n","Epoch:  46 | train loss: 0.008978 | valid loss: 0.010159\n","Epoch:  47 | train loss: 0.009424 | valid loss: 0.010355\n","Epoch:  48 | train loss: 0.011541 | valid loss: 0.009602\n","Epoch:  49 | train loss: 0.011260 | valid loss: 0.009579\n","Epoch:  50 | train loss: 0.009645 | valid loss: 0.009171\n","Epoch:  51 | train loss: 0.008778 | valid loss: 0.009136\n","Epoch:  52 | train loss: 0.006519 | valid loss: 0.008645\n","Epoch:  53 | train loss: 0.009493 | valid loss: 0.008873\n","Epoch:  54 | train loss: 0.008391 | valid loss: 0.008515\n","Epoch:  55 | train loss: 0.009438 | valid loss: 0.008406\n","Epoch:  56 | train loss: 0.012791 | valid loss: 0.008134\n","Epoch:  57 | train loss: 0.005386 | valid loss: 0.008001\n","Epoch:  58 | train loss: 0.008246 | valid loss: 0.007961\n","Epoch:  59 | train loss: 0.006776 | valid loss: 0.007862\n","Epoch:  60 | train loss: 0.007967 | valid loss: 0.007685\n","Epoch:  61 | train loss: 0.007229 | valid loss: 0.007645\n","Epoch:  62 | train loss: 0.005520 | valid loss: 0.007387\n","Epoch:  63 | train loss: 0.007723 | valid loss: 0.007634\n","Epoch:  64 | train loss: 0.006783 | valid loss: 0.007286\n","Epoch:  65 | train loss: 0.008459 | valid loss: 0.007307\n","Epoch:  66 | train loss: 0.005356 | valid loss: 0.007148\n","Epoch:  67 | train loss: 0.007128 | valid loss: 0.007432\n","Epoch:  68 | train loss: 0.005759 | valid loss: 0.006761\n","Epoch:  69 | train loss: 0.005800 | valid loss: 0.007176\n","Epoch:  70 | train loss: 0.005066 | valid loss: 0.006915\n","Epoch:  71 | train loss: 0.007588 | valid loss: 0.006952\n","Epoch:  72 | train loss: 0.006851 | valid loss: 0.006714\n","Epoch:  73 | train loss: 0.003992 | valid loss: 0.006521\n","Epoch:  74 | train loss: 0.003867 | valid loss: 0.006475\n","Epoch:  75 | train loss: 0.006234 | valid loss: 0.006261\n","Epoch:  76 | train loss: 0.005149 | valid loss: 0.006474\n","Epoch:  77 | train loss: 0.006525 | valid loss: 0.006546\n","Epoch:  78 | train loss: 0.004737 | valid loss: 0.006039\n","Epoch:  79 | train loss: 0.004698 | valid loss: 0.006275\n","Epoch:  80 | train loss: 0.005344 | valid loss: 0.005977\n","Epoch:  81 | train loss: 0.005681 | valid loss: 0.006001\n","Epoch:  82 | train loss: 0.004450 | valid loss: 0.006243\n","Epoch:  83 | train loss: 0.004166 | valid loss: 0.006029\n","Epoch:  84 | train loss: 0.007246 | valid loss: 0.005810\n","Epoch:  85 | train loss: 0.005152 | valid loss: 0.006139\n","Epoch:  86 | train loss: 0.005110 | valid loss: 0.005800\n","Epoch:  87 | train loss: 0.005660 | valid loss: 0.005783\n","Epoch:  88 | train loss: 0.004925 | valid loss: 0.005671\n","Epoch:  89 | train loss: 0.004738 | valid loss: 0.005916\n","Epoch:  90 | train loss: 0.006795 | valid loss: 0.005825\n","Epoch:  91 | train loss: 0.009083 | valid loss: 0.005580\n","Epoch:  92 | train loss: 0.005360 | valid loss: 0.005613\n","Epoch:  93 | train loss: 0.007277 | valid loss: 0.005775\n","Epoch:  94 | train loss: 0.004844 | valid loss: 0.005373\n","Epoch:  95 | train loss: 0.006810 | valid loss: 0.005452\n","Epoch:  96 | train loss: 0.004742 | valid loss: 0.005563\n","Epoch:  97 | train loss: 0.006226 | valid loss: 0.005377\n","Epoch:  98 | train loss: 0.005415 | valid loss: 0.005685\n","Epoch:  99 | train loss: 0.003802 | valid loss: 0.005352\n","Epoch:  100 | train loss: 0.007246 | valid loss: 0.005346\n","Epoch:  101 | train loss: 0.005415 | valid loss: 0.005455\n","Epoch:  102 | train loss: 0.004131 | valid loss: 0.005185\n","Epoch:  103 | train loss: 0.007142 | valid loss: 0.005441\n","Epoch:  104 | train loss: 0.004544 | valid loss: 0.005402\n","Epoch:  105 | train loss: 0.003529 | valid loss: 0.005026\n","Epoch:  106 | train loss: 0.004906 | valid loss: 0.005128\n","Epoch:  107 | train loss: 0.004801 | valid loss: 0.004931\n","Epoch:  108 | train loss: 0.005214 | valid loss: 0.005166\n","Epoch:  109 | train loss: 0.005939 | valid loss: 0.005025\n","Epoch:  110 | train loss: 0.005531 | valid loss: 0.005059\n","Epoch:  111 | train loss: 0.003844 | valid loss: 0.004881\n","Epoch:  112 | train loss: 0.004961 | valid loss: 0.004847\n","Epoch:  113 | train loss: 0.004994 | valid loss: 0.005133\n","Epoch:  114 | train loss: 0.004310 | valid loss: 0.004953\n","Epoch:  115 | train loss: 0.004166 | valid loss: 0.004874\n","Epoch:  116 | train loss: 0.006376 | valid loss: 0.005021\n","Epoch:  117 | train loss: 0.003397 | valid loss: 0.005079\n","Epoch:  118 | train loss: 0.004710 | valid loss: 0.004736\n","Epoch:  119 | train loss: 0.003435 | valid loss: 0.004933\n","Epoch:  120 | train loss: 0.003305 | valid loss: 0.004645\n","Epoch:  121 | train loss: 0.003155 | valid loss: 0.004617\n","Epoch:  122 | train loss: 0.004727 | valid loss: 0.004532\n","Epoch:  123 | train loss: 0.003357 | valid loss: 0.004958\n","Epoch:  124 | train loss: 0.003579 | valid loss: 0.004709\n","Epoch:  125 | train loss: 0.004424 | valid loss: 0.004825\n","Epoch:  126 | train loss: 0.004286 | valid loss: 0.004698\n","Epoch:  127 | train loss: 0.003417 | valid loss: 0.004614\n","Epoch:  128 | train loss: 0.003869 | valid loss: 0.004548\n","Epoch:  129 | train loss: 0.004630 | valid loss: 0.004807\n","Epoch:  130 | train loss: 0.003701 | valid loss: 0.004711\n","Epoch:  131 | train loss: 0.003810 | valid loss: 0.004786\n","Epoch:  132 | train loss: 0.004742 | valid loss: 0.004699\n","Epoch:  133 | train loss: 0.004614 | valid loss: 0.004634\n","Epoch:  134 | train loss: 0.003295 | valid loss: 0.004566\n","Epoch:  135 | train loss: 0.003121 | valid loss: 0.004579\n","Epoch:  136 | train loss: 0.004026 | valid loss: 0.004467\n","Epoch:  137 | train loss: 0.003895 | valid loss: 0.004628\n","Epoch:  138 | train loss: 0.003588 | valid loss: 0.004745\n","Epoch:  139 | train loss: 0.004825 | valid loss: 0.004561\n","Epoch:  140 | train loss: 0.003272 | valid loss: 0.004630\n","Epoch:  141 | train loss: 0.004684 | valid loss: 0.004610\n","Epoch:  142 | train loss: 0.003075 | valid loss: 0.004370\n","Epoch:  143 | train loss: 0.002944 | valid loss: 0.004265\n","Epoch:  144 | train loss: 0.003759 | valid loss: 0.004423\n","Epoch:  145 | train loss: 0.003159 | valid loss: 0.004403\n","Epoch:  146 | train loss: 0.003372 | valid loss: 0.004439\n","Epoch:  147 | train loss: 0.003916 | valid loss: 0.004203\n","Epoch:  148 | train loss: 0.003024 | valid loss: 0.004239\n","Epoch:  149 | train loss: 0.003348 | valid loss: 0.004268\n","Epoch:  150 | train loss: 0.004794 | valid loss: 0.004308\n","Epoch:  151 | train loss: 0.002626 | valid loss: 0.004439\n","Epoch:  152 | train loss: 0.003854 | valid loss: 0.004236\n","Epoch:  153 | train loss: 0.002850 | valid loss: 0.004290\n","Epoch:  154 | train loss: 0.003334 | valid loss: 0.004270\n","Epoch:  155 | train loss: 0.004679 | valid loss: 0.004267\n","Epoch:  156 | train loss: 0.003058 | valid loss: 0.004408\n","Epoch:  157 | train loss: 0.003825 | valid loss: 0.004357\n","Epoch:  158 | train loss: 0.003666 | valid loss: 0.004255\n","Epoch:  159 | train loss: 0.003106 | valid loss: 0.004161\n","Epoch:  160 | train loss: 0.003541 | valid loss: 0.004140\n","Epoch:  161 | train loss: 0.004042 | valid loss: 0.004288\n","Epoch:  162 | train loss: 0.003841 | valid loss: 0.004139\n","Epoch:  163 | train loss: 0.004418 | valid loss: 0.004201\n","Epoch:  164 | train loss: 0.003870 | valid loss: 0.004211\n","Epoch:  165 | train loss: 0.003450 | valid loss: 0.004143\n","Epoch:  166 | train loss: 0.004046 | valid loss: 0.004130\n","Epoch:  167 | train loss: 0.003442 | valid loss: 0.004136\n","Epoch:  168 | train loss: 0.002999 | valid loss: 0.004187\n","Epoch:  169 | train loss: 0.002479 | valid loss: 0.004137\n","Epoch:  170 | train loss: 0.002397 | valid loss: 0.004173\n","Epoch:  171 | train loss: 0.002984 | valid loss: 0.004116\n","Epoch:  172 | train loss: 0.002424 | valid loss: 0.004137\n","Epoch:  173 | train loss: 0.003722 | valid loss: 0.003957\n","Epoch:  174 | train loss: 0.003849 | valid loss: 0.003961\n","Epoch:  175 | train loss: 0.003402 | valid loss: 0.004015\n","Epoch:  176 | train loss: 0.004086 | valid loss: 0.003985\n","Epoch:  177 | train loss: 0.003921 | valid loss: 0.003977\n","Epoch:  178 | train loss: 0.003358 | valid loss: 0.004312\n","Epoch:  179 | train loss: 0.003122 | valid loss: 0.004001\n","Epoch:  180 | train loss: 0.002471 | valid loss: 0.004006\n","Epoch:  181 | train loss: 0.003438 | valid loss: 0.003929\n","Epoch:  182 | train loss: 0.002688 | valid loss: 0.004293\n","Epoch:  183 | train loss: 0.004259 | valid loss: 0.003899\n","Epoch:  184 | train loss: 0.003466 | valid loss: 0.004057\n","Epoch:  185 | train loss: 0.002723 | valid loss: 0.003982\n","Epoch:  186 | train loss: 0.003450 | valid loss: 0.003944\n","Epoch:  187 | train loss: 0.003459 | valid loss: 0.003890\n","Epoch:  188 | train loss: 0.003513 | valid loss: 0.003814\n","Epoch:  189 | train loss: 0.003367 | valid loss: 0.003833\n","Epoch:  190 | train loss: 0.003527 | valid loss: 0.004058\n","Epoch:  191 | train loss: 0.002772 | valid loss: 0.003924\n","Epoch:  192 | train loss: 0.003229 | valid loss: 0.003823\n","Epoch:  193 | train loss: 0.003293 | valid loss: 0.003890\n","Epoch:  194 | train loss: 0.003044 | valid loss: 0.003910\n","Epoch:  195 | train loss: 0.003210 | valid loss: 0.003930\n","Epoch:  196 | train loss: 0.003453 | valid loss: 0.003852\n","Epoch:  197 | train loss: 0.002246 | valid loss: 0.003820\n","Epoch:  198 | train loss: 0.003894 | valid loss: 0.003956\n","Epoch:  199 | train loss: 0.004047 | valid loss: 0.003966\n","Epoch:  200 | train loss: 0.003374 | valid loss: 0.004005\n","Epoch:  201 | train loss: 0.002577 | valid loss: 0.003806\n","Epoch:  202 | train loss: 0.003212 | valid loss: 0.003985\n","Epoch:  203 | train loss: 0.002587 | valid loss: 0.004191\n","Epoch:  204 | train loss: 0.003093 | valid loss: 0.003884\n","Epoch:  205 | train loss: 0.002713 | valid loss: 0.003825\n","Epoch:  206 | train loss: 0.002559 | valid loss: 0.003877\n","Epoch:  207 | train loss: 0.003448 | valid loss: 0.004432\n","Epoch:  208 | train loss: 0.002663 | valid loss: 0.003826\n","Epoch:  209 | train loss: 0.002054 | valid loss: 0.003792\n","Epoch:  210 | train loss: 0.002947 | valid loss: 0.003951\n","Epoch:  211 | train loss: 0.003524 | valid loss: 0.003893\n","Epoch:  212 | train loss: 0.003754 | valid loss: 0.003838\n","Epoch:  213 | train loss: 0.002374 | valid loss: 0.003765\n","Epoch:  214 | train loss: 0.002129 | valid loss: 0.003910\n","Epoch:  215 | train loss: 0.002271 | valid loss: 0.003702\n","Epoch:  216 | train loss: 0.002703 | valid loss: 0.003693\n","Epoch:  217 | train loss: 0.003413 | valid loss: 0.003923\n","Epoch:  218 | train loss: 0.003079 | valid loss: 0.003655\n","Epoch:  219 | train loss: 0.002782 | valid loss: 0.003724\n","Epoch:  220 | train loss: 0.003585 | valid loss: 0.003735\n","Epoch:  221 | train loss: 0.002909 | valid loss: 0.003685\n","Epoch:  222 | train loss: 0.002418 | valid loss: 0.003621\n","Epoch:  223 | train loss: 0.007407 | valid loss: 0.003727\n","Epoch:  224 | train loss: 0.003058 | valid loss: 0.003701\n","Epoch:  225 | train loss: 0.002630 | valid loss: 0.003794\n","Epoch:  226 | train loss: 0.002725 | valid loss: 0.003756\n","Epoch:  227 | train loss: 0.003267 | valid loss: 0.003690\n","Epoch:  228 | train loss: 0.003256 | valid loss: 0.004020\n","Epoch:  229 | train loss: 0.002127 | valid loss: 0.003888\n","Epoch:  230 | train loss: 0.003396 | valid loss: 0.003664\n","Epoch:  231 | train loss: 0.004028 | valid loss: 0.003953\n","Epoch:  232 | train loss: 0.003196 | valid loss: 0.003634\n","Epoch:  233 | train loss: 0.001808 | valid loss: 0.003748\n","Epoch:  234 | train loss: 0.002817 | valid loss: 0.003890\n","Epoch:  235 | train loss: 0.003581 | valid loss: 0.003718\n","Epoch:  236 | train loss: 0.002145 | valid loss: 0.003638\n","Epoch:  237 | train loss: 0.002098 | valid loss: 0.003825\n","Epoch:  238 | train loss: 0.003422 | valid loss: 0.003681\n","Epoch:  239 | train loss: 0.002939 | valid loss: 0.003645\n","Epoch:  240 | train loss: 0.003344 | valid loss: 0.003735\n","Epoch:  241 | train loss: 0.002527 | valid loss: 0.003795\n","Epoch:  242 | train loss: 0.007355 | valid loss: 0.003767\n","Epoch:  243 | train loss: 0.002846 | valid loss: 0.003710\n","Epoch:  244 | train loss: 0.003177 | valid loss: 0.004076\n","Epoch:  245 | train loss: 0.002346 | valid loss: 0.003675\n","Epoch:  246 | train loss: 0.003885 | valid loss: 0.003923\n","Epoch:  247 | train loss: 0.002836 | valid loss: 0.003624\n","Epoch:  248 | train loss: 0.002531 | valid loss: 0.003768\n","Epoch:  249 | train loss: 0.002111 | valid loss: 0.003654\n","Epoch:  250 | train loss: 0.002805 | valid loss: 0.003695\n","Epoch:  251 | train loss: 0.002344 | valid loss: 0.003639\n","Epoch:  252 | train loss: 0.002098 | valid loss: 0.003686\n","Epoch:  253 | train loss: 0.002003 | valid loss: 0.003853\n","Epoch:  254 | train loss: 0.002793 | valid loss: 0.003603\n","Epoch:  255 | train loss: 0.003300 | valid loss: 0.003641\n","Epoch:  256 | train loss: 0.002678 | valid loss: 0.003752\n","Epoch:  257 | train loss: 0.001774 | valid loss: 0.003724\n","Epoch:  258 | train loss: 0.004704 | valid loss: 0.003696\n","Epoch:  259 | train loss: 0.002554 | valid loss: 0.003607\n","Epoch:  260 | train loss: 0.002841 | valid loss: 0.003796\n","Epoch:  261 | train loss: 0.003146 | valid loss: 0.004132\n","Epoch:  262 | train loss: 0.002397 | valid loss: 0.003891\n","Epoch:  263 | train loss: 0.003274 | valid loss: 0.003844\n","Epoch:  264 | train loss: 0.002560 | valid loss: 0.003586\n","Epoch:  265 | train loss: 0.002313 | valid loss: 0.003603\n","Epoch:  266 | train loss: 0.006584 | valid loss: 0.003548\n","Epoch:  267 | train loss: 0.001646 | valid loss: 0.003664\n","Epoch:  268 | train loss: 0.002333 | valid loss: 0.003517\n","Epoch:  269 | train loss: 0.002348 | valid loss: 0.003632\n","Epoch:  270 | train loss: 0.001900 | valid loss: 0.003586\n","Epoch:  271 | train loss: 0.002280 | valid loss: 0.003723\n","Epoch:  272 | train loss: 0.002942 | valid loss: 0.003707\n","Epoch:  273 | train loss: 0.002628 | valid loss: 0.003616\n","Epoch:  274 | train loss: 0.002784 | valid loss: 0.003772\n","Epoch:  275 | train loss: 0.002089 | valid loss: 0.003771\n","Epoch:  276 | train loss: 0.002802 | valid loss: 0.003817\n","Epoch:  277 | train loss: 0.002932 | valid loss: 0.003680\n","Epoch:  278 | train loss: 0.002212 | valid loss: 0.003667\n","Epoch:  279 | train loss: 0.002437 | valid loss: 0.003685\n","Epoch:  280 | train loss: 0.002999 | valid loss: 0.003786\n","Epoch:  281 | train loss: 0.002885 | valid loss: 0.003613\n","Epoch:  282 | train loss: 0.003360 | valid loss: 0.003709\n","Epoch:  283 | train loss: 0.002780 | valid loss: 0.003756\n","Epoch:  284 | train loss: 0.003352 | valid loss: 0.003731\n","Epoch:  285 | train loss: 0.003057 | valid loss: 0.003663\n","Epoch:  286 | train loss: 0.002790 | valid loss: 0.003745\n","Epoch:  287 | train loss: 0.002783 | valid loss: 0.003795\n","Epoch:  288 | train loss: 0.002519 | valid loss: 0.003656\n","Epoch:  289 | train loss: 0.002693 | valid loss: 0.003773\n","Epoch:  290 | train loss: 0.002677 | valid loss: 0.003653\n","Epoch:  291 | train loss: 0.002487 | valid loss: 0.003633\n","Epoch:  292 | train loss: 0.002664 | valid loss: 0.003607\n","Epoch:  293 | train loss: 0.003170 | valid loss: 0.003651\n","Epoch:  294 | train loss: 0.002311 | valid loss: 0.003718\n","Epoch:  295 | train loss: 0.002305 | valid loss: 0.003602\n","Epoch:  296 | train loss: 0.001886 | valid loss: 0.003667\n","Epoch:  297 | train loss: 0.002934 | valid loss: 0.003704\n","Epoch:  298 | train loss: 0.002517 | valid loss: 0.003860\n","Epoch:  299 | train loss: 0.002813 | valid loss: 0.003751\n","Epoch:  300 | train loss: 0.002641 | valid loss: 0.003700\n","Epoch:  301 | train loss: 0.002439 | valid loss: 0.003759\n","Epoch:  302 | train loss: 0.002363 | valid loss: 0.003655\n","Epoch:  303 | train loss: 0.002683 | valid loss: 0.003565\n","Epoch:  304 | train loss: 0.002245 | valid loss: 0.003582\n","Epoch:  305 | train loss: 0.002678 | valid loss: 0.003633\n","Epoch:  306 | train loss: 0.002602 | valid loss: 0.003790\n","Epoch:  307 | train loss: 0.002432 | valid loss: 0.003675\n","Epoch:  308 | train loss: 0.003536 | valid loss: 0.003997\n","Epoch:  309 | train loss: 0.002167 | valid loss: 0.003676\n","Epoch:  310 | train loss: 0.002548 | valid loss: 0.003597\n","Epoch:  311 | train loss: 0.002237 | valid loss: 0.003717\n","Epoch:  312 | train loss: 0.002975 | valid loss: 0.003536\n","Epoch:  313 | train loss: 0.002226 | valid loss: 0.003499\n","Epoch:  314 | train loss: 0.001734 | valid loss: 0.003598\n","Epoch:  315 | train loss: 0.001938 | valid loss: 0.003584\n","Epoch:  316 | train loss: 0.002614 | valid loss: 0.003668\n","Epoch:  317 | train loss: 0.001877 | valid loss: 0.003625\n","Epoch:  318 | train loss: 0.002153 | valid loss: 0.003950\n","Epoch:  319 | train loss: 0.002101 | valid loss: 0.003730\n","Epoch:  320 | train loss: 0.002024 | valid loss: 0.003729\n","Epoch:  321 | train loss: 0.002692 | valid loss: 0.003675\n","Epoch:  322 | train loss: 0.002028 | valid loss: 0.003617\n","Epoch:  323 | train loss: 0.002381 | valid loss: 0.003559\n","Epoch:  324 | train loss: 0.002071 | valid loss: 0.003724\n","Epoch:  325 | train loss: 0.002483 | valid loss: 0.003638\n","Epoch:  326 | train loss: 0.002110 | valid loss: 0.003614\n","Epoch:  327 | train loss: 0.002414 | valid loss: 0.003709\n","Epoch:  328 | train loss: 0.002719 | valid loss: 0.003781\n","Epoch:  329 | train loss: 0.002274 | valid loss: 0.003657\n","Epoch:  330 | train loss: 0.002334 | valid loss: 0.003587\n","Epoch:  331 | train loss: 0.002131 | valid loss: 0.003616\n","Epoch:  332 | train loss: 0.002399 | valid loss: 0.003695\n","Epoch:  333 | train loss: 0.002839 | valid loss: 0.003675\n","Epoch:  334 | train loss: 0.002459 | valid loss: 0.003694\n","Epoch:  335 | train loss: 0.003278 | valid loss: 0.003792\n","Epoch:  336 | train loss: 0.003369 | valid loss: 0.003792\n","Epoch:  337 | train loss: 0.002999 | valid loss: 0.003577\n","Epoch:  338 | train loss: 0.002793 | valid loss: 0.003568\n","Epoch:  339 | train loss: 0.001862 | valid loss: 0.003617\n","Epoch:  340 | train loss: 0.002489 | valid loss: 0.003606\n","Epoch:  341 | train loss: 0.002444 | valid loss: 0.003780\n","Epoch:  342 | train loss: 0.002207 | valid loss: 0.003573\n","Epoch:  343 | train loss: 0.002275 | valid loss: 0.003620\n","Epoch:  344 | train loss: 0.003098 | valid loss: 0.003588\n","Epoch:  345 | train loss: 0.002398 | valid loss: 0.003605\n","Epoch:  346 | train loss: 0.003004 | valid loss: 0.003653\n","Epoch:  347 | train loss: 0.002528 | valid loss: 0.003758\n","Epoch:  348 | train loss: 0.003890 | valid loss: 0.003856\n","Epoch:  349 | train loss: 0.001636 | valid loss: 0.003600\n","Epoch:  350 | train loss: 0.002351 | valid loss: 0.003531\n","Epoch:  351 | train loss: 0.002289 | valid loss: 0.003563\n","Epoch:  352 | train loss: 0.002643 | valid loss: 0.003702\n","Epoch:  353 | train loss: 0.003382 | valid loss: 0.003711\n","Epoch:  354 | train loss: 0.002097 | valid loss: 0.003643\n","Epoch:  355 | train loss: 0.002458 | valid loss: 0.003627\n","Epoch:  356 | train loss: 0.002290 | valid loss: 0.003689\n","Epoch:  357 | train loss: 0.002457 | valid loss: 0.003774\n","Epoch:  358 | train loss: 0.002693 | valid loss: 0.003708\n","Epoch:  359 | train loss: 0.002451 | valid loss: 0.003807\n","Epoch:  360 | train loss: 0.002067 | valid loss: 0.003569\n","Epoch:  361 | train loss: 0.001754 | valid loss: 0.003714\n","Epoch:  362 | train loss: 0.002768 | valid loss: 0.003621\n","Epoch:  363 | train loss: 0.003081 | valid loss: 0.003616\n","Epoch:  364 | train loss: 0.002387 | valid loss: 0.003617\n","Epoch:  365 | train loss: 0.002972 | valid loss: 0.003620\n","Epoch:  366 | train loss: 0.002061 | valid loss: 0.003717\n","Epoch:  367 | train loss: 0.004462 | valid loss: 0.003879\n","Epoch:  368 | train loss: 0.002006 | valid loss: 0.003694\n","Epoch:  369 | train loss: 0.002010 | valid loss: 0.003819\n","Epoch:  370 | train loss: 0.002894 | valid loss: 0.003635\n","Epoch:  371 | train loss: 0.002228 | valid loss: 0.003741\n","Epoch:  372 | train loss: 0.002226 | valid loss: 0.003682\n","Epoch:  373 | train loss: 0.002532 | valid loss: 0.003799\n","Epoch:  374 | train loss: 0.003048 | valid loss: 0.003695\n","Epoch:  375 | train loss: 0.002629 | valid loss: 0.003572\n","Epoch:  376 | train loss: 0.002305 | valid loss: 0.003576\n","Epoch:  377 | train loss: 0.002554 | valid loss: 0.003542\n","Epoch:  378 | train loss: 0.003020 | valid loss: 0.003573\n","Epoch:  379 | train loss: 0.002172 | valid loss: 0.003606\n","Epoch:  380 | train loss: 0.002242 | valid loss: 0.003654\n","Epoch:  381 | train loss: 0.002351 | valid loss: 0.003652\n","Epoch:  382 | train loss: 0.002107 | valid loss: 0.003767\n","Epoch:  383 | train loss: 0.003247 | valid loss: 0.003689\n","Epoch:  384 | train loss: 0.002138 | valid loss: 0.003639\n","Epoch:  385 | train loss: 0.002478 | valid loss: 0.003593\n","Epoch:  386 | train loss: 0.003259 | valid loss: 0.003699\n","Epoch:  387 | train loss: 0.002012 | valid loss: 0.003714\n","Epoch:  388 | train loss: 0.002313 | valid loss: 0.003981\n","Epoch:  389 | train loss: 0.002573 | valid loss: 0.003795\n","Epoch:  390 | train loss: 0.002819 | valid loss: 0.003668\n","Epoch:  391 | train loss: 0.001986 | valid loss: 0.003534\n","Epoch:  392 | train loss: 0.003432 | valid loss: 0.003677\n","Epoch:  393 | train loss: 0.002756 | valid loss: 0.003523\n","Epoch:  394 | train loss: 0.002371 | valid loss: 0.003660\n","Epoch:  395 | train loss: 0.002341 | valid loss: 0.003613\n","Epoch:  396 | train loss: 0.001854 | valid loss: 0.003637\n","Epoch:  397 | train loss: 0.002634 | valid loss: 0.003607\n","Epoch:  398 | train loss: 0.002367 | valid loss: 0.003682\n","Epoch:  399 | train loss: 0.001907 | valid loss: 0.003528\n","Epoch:  400 | train loss: 0.002740 | valid loss: 0.003840\n","Epoch:  401 | train loss: 0.003283 | valid loss: 0.003617\n","Epoch:  402 | train loss: 0.003206 | valid loss: 0.003791\n","Epoch:  403 | train loss: 0.002154 | valid loss: 0.003518\n","Epoch:  404 | train loss: 0.002050 | valid loss: 0.003599\n","Epoch:  405 | train loss: 0.002242 | valid loss: 0.003664\n","Epoch:  406 | train loss: 0.002444 | valid loss: 0.003616\n","Epoch:  407 | train loss: 0.002338 | valid loss: 0.003652\n","Epoch:  408 | train loss: 0.002056 | valid loss: 0.003621\n","Epoch:  409 | train loss: 0.002808 | valid loss: 0.003652\n","Epoch:  410 | train loss: 0.002330 | valid loss: 0.003947\n","Epoch:  411 | train loss: 0.002818 | valid loss: 0.003672\n","Epoch:  412 | train loss: 0.002892 | valid loss: 0.003732\n","Epoch:  413 | train loss: 0.001909 | valid loss: 0.003625\n","Epoch:  414 | train loss: 0.002443 | valid loss: 0.003613\n","Epoch:  415 | train loss: 0.001917 | valid loss: 0.003597\n","Epoch:  416 | train loss: 0.002404 | valid loss: 0.004021\n","Epoch:  417 | train loss: 0.002233 | valid loss: 0.003702\n","Epoch:  418 | train loss: 0.002065 | valid loss: 0.003657\n","Epoch:  419 | train loss: 0.001578 | valid loss: 0.003650\n","Epoch:  420 | train loss: 0.001542 | valid loss: 0.003597\n","Epoch:  421 | train loss: 0.002924 | valid loss: 0.003701\n","Epoch:  422 | train loss: 0.002747 | valid loss: 0.003936\n","Epoch:  423 | train loss: 0.001800 | valid loss: 0.003735\n","Epoch:  424 | train loss: 0.002194 | valid loss: 0.003666\n","Epoch:  425 | train loss: 0.002608 | valid loss: 0.003609\n","Epoch:  426 | train loss: 0.001805 | valid loss: 0.003654\n","Epoch:  427 | train loss: 0.002549 | valid loss: 0.003844\n","Epoch:  428 | train loss: 0.002205 | valid loss: 0.003796\n","Epoch:  429 | train loss: 0.002513 | valid loss: 0.003755\n","Epoch:  430 | train loss: 0.001804 | valid loss: 0.003557\n","Epoch:  431 | train loss: 0.003121 | valid loss: 0.003608\n","Epoch:  432 | train loss: 0.002042 | valid loss: 0.003664\n","Epoch:  433 | train loss: 0.001943 | valid loss: 0.003534\n","Epoch:  434 | train loss: 0.002019 | valid loss: 0.003610\n","Epoch:  435 | train loss: 0.002061 | valid loss: 0.003672\n","Epoch:  436 | train loss: 0.002218 | valid loss: 0.003593\n","Epoch:  437 | train loss: 0.002042 | valid loss: 0.003677\n","Epoch:  438 | train loss: 0.002648 | valid loss: 0.003704\n","Epoch:  439 | train loss: 0.002403 | valid loss: 0.003617\n","Epoch:  440 | train loss: 0.002630 | valid loss: 0.003661\n","Epoch:  441 | train loss: 0.002340 | valid loss: 0.003725\n","Epoch:  442 | train loss: 0.002274 | valid loss: 0.003684\n","Epoch:  443 | train loss: 0.002520 | valid loss: 0.003941\n","Epoch:  444 | train loss: 0.002928 | valid loss: 0.003650\n","Epoch:  445 | train loss: 0.001903 | valid loss: 0.003644\n","Epoch:  446 | train loss: 0.003057 | valid loss: 0.003885\n","Epoch:  447 | train loss: 0.001921 | valid loss: 0.003586\n","Epoch:  448 | train loss: 0.002352 | valid loss: 0.003609\n","Epoch:  449 | train loss: 0.002741 | valid loss: 0.003556\n","Epoch:  450 | train loss: 0.001999 | valid loss: 0.003799\n","Epoch:  451 | train loss: 0.002526 | valid loss: 0.003649\n","Epoch:  452 | train loss: 0.002403 | valid loss: 0.003606\n","Epoch:  453 | train loss: 0.002178 | valid loss: 0.003929\n","Epoch:  454 | train loss: 0.001485 | valid loss: 0.003736\n","Epoch:  455 | train loss: 0.002993 | valid loss: 0.003652\n","Epoch:  456 | train loss: 0.002772 | valid loss: 0.003812\n","Epoch:  457 | train loss: 0.001968 | valid loss: 0.003660\n","Epoch:  458 | train loss: 0.002116 | valid loss: 0.003725\n","Epoch:  459 | train loss: 0.002926 | valid loss: 0.003662\n","Epoch:  460 | train loss: 0.003310 | valid loss: 0.003609\n","Epoch:  461 | train loss: 0.002535 | valid loss: 0.003655\n","Epoch:  462 | train loss: 0.002756 | valid loss: 0.003763\n","Epoch:  463 | train loss: 0.001755 | valid loss: 0.003745\n","Epoch:  464 | train loss: 0.001880 | valid loss: 0.003680\n","Epoch:  465 | train loss: 0.001667 | valid loss: 0.003748\n","Epoch:  466 | train loss: 0.002439 | valid loss: 0.003688\n","Epoch:  467 | train loss: 0.001651 | valid loss: 0.003639\n","Epoch:  468 | train loss: 0.001706 | valid loss: 0.003567\n","Epoch:  469 | train loss: 0.006959 | valid loss: 0.003683\n","Epoch:  470 | train loss: 0.002788 | valid loss: 0.003730\n","Epoch:  471 | train loss: 0.001766 | valid loss: 0.003707\n","Epoch:  472 | train loss: 0.002313 | valid loss: 0.003744\n","Epoch:  473 | train loss: 0.003012 | valid loss: 0.003740\n","Epoch:  474 | train loss: 0.002133 | valid loss: 0.003769\n","Epoch:  475 | train loss: 0.002586 | valid loss: 0.003664\n","Epoch:  476 | train loss: 0.002349 | valid loss: 0.003612\n","Epoch:  477 | train loss: 0.002373 | valid loss: 0.003606\n","Epoch:  478 | train loss: 0.002103 | valid loss: 0.003832\n","Epoch:  479 | train loss: 0.002833 | valid loss: 0.003636\n","Epoch:  480 | train loss: 0.002086 | valid loss: 0.003926\n","Epoch:  481 | train loss: 0.002456 | valid loss: 0.003796\n","Epoch:  482 | train loss: 0.006751 | valid loss: 0.003790\n","Epoch:  483 | train loss: 0.003076 | valid loss: 0.003667\n","Epoch:  484 | train loss: 0.001752 | valid loss: 0.003655\n","Epoch:  485 | train loss: 0.002576 | valid loss: 0.003539\n","Epoch:  486 | train loss: 0.005653 | valid loss: 0.003655\n","Epoch:  487 | train loss: 0.002176 | valid loss: 0.003678\n","Epoch:  488 | train loss: 0.002774 | valid loss: 0.003577\n","Epoch:  489 | train loss: 0.002758 | valid loss: 0.003740\n","Epoch:  490 | train loss: 0.001826 | valid loss: 0.003966\n","Epoch:  491 | train loss: 0.002960 | valid loss: 0.003743\n","Epoch:  492 | train loss: 0.001927 | valid loss: 0.003683\n","Epoch:  493 | train loss: 0.002032 | valid loss: 0.003804\n","Epoch:  494 | train loss: 0.002164 | valid loss: 0.003669\n","Epoch:  495 | train loss: 0.001867 | valid loss: 0.003615\n","Epoch:  496 | train loss: 0.001696 | valid loss: 0.003626\n","Epoch:  497 | train loss: 0.002207 | valid loss: 0.003834\n","Epoch:  498 | train loss: 0.003126 | valid loss: 0.003770\n","Epoch:  499 | train loss: 0.002745 | valid loss: 0.003710\n","Epoch:  500 | train loss: 0.002396 | valid loss: 0.003640\n","Epoch:  501 | train loss: 0.003083 | valid loss: 0.003606\n","Epoch:  502 | train loss: 0.002472 | valid loss: 0.003619\n","Epoch:  503 | train loss: 0.002308 | valid loss: 0.003562\n","Epoch:  504 | train loss: 0.002074 | valid loss: 0.003758\n","Epoch:  505 | train loss: 0.001810 | valid loss: 0.003679\n","Epoch:  506 | train loss: 0.003267 | valid loss: 0.003608\n","Epoch:  507 | train loss: 0.002011 | valid loss: 0.003769\n","Epoch:  508 | train loss: 0.004038 | valid loss: 0.003770\n","Epoch:  509 | train loss: 0.001517 | valid loss: 0.003734\n","Epoch:  510 | train loss: 0.002702 | valid loss: 0.003575\n","Epoch:  511 | train loss: 0.002685 | valid loss: 0.003865\n","Epoch:  512 | train loss: 0.002145 | valid loss: 0.003723\n","Epoch:  513 | train loss: 0.002567 | valid loss: 0.003661\n","Epoch:  514 | train loss: 0.002434 | valid loss: 0.003679\n","Epoch:  515 | train loss: 0.002417 | valid loss: 0.003768\n","Epoch:  516 | train loss: 0.002583 | valid loss: 0.003668\n","Epoch:  517 | train loss: 0.002438 | valid loss: 0.003602\n","Epoch:  518 | train loss: 0.002572 | valid loss: 0.003725\n","Epoch:  519 | train loss: 0.001844 | valid loss: 0.003619\n","Epoch:  520 | train loss: 0.002615 | valid loss: 0.003750\n","Epoch:  521 | train loss: 0.002268 | valid loss: 0.003618\n","Epoch:  522 | train loss: 0.002678 | valid loss: 0.003632\n","Epoch:  523 | train loss: 0.001582 | valid loss: 0.003624\n","Epoch:  524 | train loss: 0.001841 | valid loss: 0.003853\n","Epoch:  525 | train loss: 0.002251 | valid loss: 0.003782\n","Epoch:  526 | train loss: 0.002045 | valid loss: 0.003755\n","Epoch:  527 | train loss: 0.003015 | valid loss: 0.003671\n","Epoch:  528 | train loss: 0.002523 | valid loss: 0.003668\n","Epoch:  529 | train loss: 0.002152 | valid loss: 0.003707\n","Epoch:  530 | train loss: 0.002402 | valid loss: 0.003641\n","Epoch:  531 | train loss: 0.001783 | valid loss: 0.003649\n","Epoch:  532 | train loss: 0.002820 | valid loss: 0.003723\n","Epoch:  533 | train loss: 0.003296 | valid loss: 0.003942\n","Epoch:  534 | train loss: 0.002426 | valid loss: 0.003776\n","Epoch:  535 | train loss: 0.002074 | valid loss: 0.003749\n","Epoch:  536 | train loss: 0.002299 | valid loss: 0.003634\n","Epoch:  537 | train loss: 0.002262 | valid loss: 0.003692\n","Epoch:  538 | train loss: 0.001633 | valid loss: 0.003549\n","Epoch:  539 | train loss: 0.003167 | valid loss: 0.003825\n","Epoch:  540 | train loss: 0.002037 | valid loss: 0.003718\n","Epoch:  541 | train loss: 0.002026 | valid loss: 0.003622\n","Epoch:  542 | train loss: 0.005010 | valid loss: 0.003773\n","Epoch:  543 | train loss: 0.002328 | valid loss: 0.003690\n","Epoch:  544 | train loss: 0.001622 | valid loss: 0.003900\n","Epoch:  545 | train loss: 0.002549 | valid loss: 0.003758\n","Epoch:  546 | train loss: 0.001683 | valid loss: 0.003780\n","Epoch:  547 | train loss: 0.002361 | valid loss: 0.003628\n","Epoch:  548 | train loss: 0.002222 | valid loss: 0.003785\n","Epoch:  549 | train loss: 0.001863 | valid loss: 0.003616\n","Epoch:  550 | train loss: 0.001990 | valid loss: 0.003727\n","Epoch:  551 | train loss: 0.001857 | valid loss: 0.003661\n","Epoch:  552 | train loss: 0.002418 | valid loss: 0.003704\n","Epoch:  553 | train loss: 0.001986 | valid loss: 0.003762\n","Epoch:  554 | train loss: 0.002113 | valid loss: 0.003891\n","Epoch:  555 | train loss: 0.002316 | valid loss: 0.003844\n","Epoch:  556 | train loss: 0.002376 | valid loss: 0.003687\n","Epoch:  557 | train loss: 0.002483 | valid loss: 0.003710\n","Epoch:  558 | train loss: 0.003051 | valid loss: 0.003583\n","Epoch:  559 | train loss: 0.001541 | valid loss: 0.003687\n","Epoch:  560 | train loss: 0.002125 | valid loss: 0.003802\n","Epoch:  561 | train loss: 0.001938 | valid loss: 0.004170\n","Epoch:  562 | train loss: 0.002457 | valid loss: 0.003784\n","Epoch:  563 | train loss: 0.002404 | valid loss: 0.003636\n","Epoch:  564 | train loss: 0.001767 | valid loss: 0.003708\n","Epoch:  565 | train loss: 0.002128 | valid loss: 0.003621\n","Epoch:  566 | train loss: 0.002524 | valid loss: 0.003733\n","Epoch:  567 | train loss: 0.002317 | valid loss: 0.003651\n","Epoch:  568 | train loss: 0.002048 | valid loss: 0.003666\n","Epoch:  569 | train loss: 0.002001 | valid loss: 0.003639\n","Epoch:  570 | train loss: 0.002536 | valid loss: 0.003624\n","Epoch:  571 | train loss: 0.002460 | valid loss: 0.003651\n","Epoch:  572 | train loss: 0.001431 | valid loss: 0.003662\n","Epoch:  573 | train loss: 0.001590 | valid loss: 0.003672\n","Epoch:  574 | train loss: 0.001627 | valid loss: 0.003847\n","Epoch:  575 | train loss: 0.001840 | valid loss: 0.003932\n","Epoch:  576 | train loss: 0.002201 | valid loss: 0.003765\n","Epoch:  577 | train loss: 0.003116 | valid loss: 0.003822\n","Epoch:  578 | train loss: 0.002230 | valid loss: 0.003881\n","Epoch:  579 | train loss: 0.002567 | valid loss: 0.003832\n","Epoch:  580 | train loss: 0.001986 | valid loss: 0.003845\n","Epoch:  581 | train loss: 0.001734 | valid loss: 0.003672\n","Epoch:  582 | train loss: 0.002881 | valid loss: 0.003609\n","Epoch:  583 | train loss: 0.001982 | valid loss: 0.003546\n","Epoch:  584 | train loss: 0.002832 | valid loss: 0.003663\n","Epoch:  585 | train loss: 0.001887 | valid loss: 0.003728\n","Epoch:  586 | train loss: 0.002126 | valid loss: 0.003656\n","Epoch:  587 | train loss: 0.003222 | valid loss: 0.003937\n","Epoch:  588 | train loss: 0.002286 | valid loss: 0.003710\n","Epoch:  589 | train loss: 0.003056 | valid loss: 0.003662\n","Epoch:  590 | train loss: 0.002003 | valid loss: 0.003817\n","Epoch:  591 | train loss: 0.001569 | valid loss: 0.003687\n","Epoch:  592 | train loss: 0.002161 | valid loss: 0.003820\n","Epoch:  593 | train loss: 0.002179 | valid loss: 0.003650\n","Epoch:  594 | train loss: 0.002222 | valid loss: 0.003641\n","Epoch:  595 | train loss: 0.002177 | valid loss: 0.003725\n","Epoch:  596 | train loss: 0.003308 | valid loss: 0.003693\n","Epoch:  597 | train loss: 0.002453 | valid loss: 0.003664\n","Epoch:  598 | train loss: 0.002367 | valid loss: 0.003693\n","Epoch:  599 | train loss: 0.002560 | valid loss: 0.003726\n","Epoch:  600 | train loss: 0.002046 | valid loss: 0.003824\n","Epoch:  601 | train loss: 0.003169 | valid loss: 0.003807\n","Epoch:  602 | train loss: 0.002259 | valid loss: 0.003764\n","Epoch:  603 | train loss: 0.002104 | valid loss: 0.003682\n","Epoch:  604 | train loss: 0.002328 | valid loss: 0.003721\n","Epoch:  605 | train loss: 0.002050 | valid loss: 0.003627\n","Epoch:  606 | train loss: 0.002113 | valid loss: 0.003631\n","Epoch:  607 | train loss: 0.002684 | valid loss: 0.003770\n","Epoch:  608 | train loss: 0.002639 | valid loss: 0.003621\n","Epoch:  609 | train loss: 0.002804 | valid loss: 0.003606\n","Epoch:  610 | train loss: 0.002773 | valid loss: 0.003763\n","Epoch:  611 | train loss: 0.003424 | valid loss: 0.003709\n","Epoch:  612 | train loss: 0.002452 | valid loss: 0.003709\n","Epoch:  613 | train loss: 0.002185 | valid loss: 0.003712\n","Epoch:  614 | train loss: 0.001549 | valid loss: 0.003747\n","Epoch:  615 | train loss: 0.001737 | valid loss: 0.003833\n","Epoch:  616 | train loss: 0.002548 | valid loss: 0.003692\n","Epoch:  617 | train loss: 0.002390 | valid loss: 0.003783\n","Epoch:  618 | train loss: 0.002690 | valid loss: 0.003902\n","Epoch:  619 | train loss: 0.002199 | valid loss: 0.004037\n","Epoch:  620 | train loss: 0.002160 | valid loss: 0.004011\n","Epoch:  621 | train loss: 0.002605 | valid loss: 0.003855\n","Epoch:  622 | train loss: 0.002510 | valid loss: 0.003709\n","Epoch:  623 | train loss: 0.001857 | valid loss: 0.003798\n","Epoch:  624 | train loss: 0.002860 | valid loss: 0.003662\n","Epoch:  625 | train loss: 0.002567 | valid loss: 0.004018\n","Epoch:  626 | train loss: 0.002137 | valid loss: 0.003750\n","Epoch:  627 | train loss: 0.001942 | valid loss: 0.003712\n","Epoch:  628 | train loss: 0.001619 | valid loss: 0.003645\n","Epoch:  629 | train loss: 0.002269 | valid loss: 0.003684\n","Epoch:  630 | train loss: 0.002104 | valid loss: 0.003712\n","Epoch:  631 | train loss: 0.002445 | valid loss: 0.003616\n","Epoch:  632 | train loss: 0.002907 | valid loss: 0.003651\n","Epoch:  633 | train loss: 0.002295 | valid loss: 0.003722\n","Epoch:  634 | train loss: 0.002752 | valid loss: 0.003777\n","Epoch:  635 | train loss: 0.002160 | valid loss: 0.003864\n","Epoch:  636 | train loss: 0.002920 | valid loss: 0.003733\n","Epoch:  637 | train loss: 0.002270 | valid loss: 0.003811\n","Epoch:  638 | train loss: 0.001931 | valid loss: 0.003713\n","Epoch:  639 | train loss: 0.002909 | valid loss: 0.003824\n","Epoch:  640 | train loss: 0.001809 | valid loss: 0.003699\n","Epoch:  641 | train loss: 0.003114 | valid loss: 0.003754\n","Epoch:  642 | train loss: 0.003225 | valid loss: 0.003701\n","Epoch:  643 | train loss: 0.002034 | valid loss: 0.003654\n","Epoch:  644 | train loss: 0.002088 | valid loss: 0.003766\n","Epoch:  645 | train loss: 0.002266 | valid loss: 0.003663\n","Epoch:  646 | train loss: 0.001965 | valid loss: 0.003672\n","Epoch:  647 | train loss: 0.002344 | valid loss: 0.003704\n","Epoch:  648 | train loss: 0.002464 | valid loss: 0.003671\n","Epoch:  649 | train loss: 0.001989 | valid loss: 0.003894\n","Epoch:  650 | train loss: 0.002557 | valid loss: 0.003759\n","Epoch:  651 | train loss: 0.002516 | valid loss: 0.003784\n","Epoch:  652 | train loss: 0.003605 | valid loss: 0.003781\n","Epoch:  653 | train loss: 0.002130 | valid loss: 0.003699\n","Epoch:  654 | train loss: 0.001806 | valid loss: 0.003915\n","Epoch:  655 | train loss: 0.002282 | valid loss: 0.003648\n","Epoch:  656 | train loss: 0.003034 | valid loss: 0.003764\n","Epoch:  657 | train loss: 0.001570 | valid loss: 0.003906\n","Epoch:  658 | train loss: 0.001949 | valid loss: 0.003738\n","Epoch:  659 | train loss: 0.002528 | valid loss: 0.003683\n","Epoch:  660 | train loss: 0.002863 | valid loss: 0.003674\n","Epoch:  661 | train loss: 0.002717 | valid loss: 0.003641\n","Epoch:  662 | train loss: 0.002741 | valid loss: 0.003807\n","Epoch:  663 | train loss: 0.002269 | valid loss: 0.003691\n","Epoch:  664 | train loss: 0.001808 | valid loss: 0.003735\n","Epoch:  665 | train loss: 0.001943 | valid loss: 0.003708\n","Epoch:  666 | train loss: 0.003568 | valid loss: 0.003647\n","Epoch:  667 | train loss: 0.002029 | valid loss: 0.003911\n","Epoch:  668 | train loss: 0.001607 | valid loss: 0.003687\n","Epoch:  669 | train loss: 0.002569 | valid loss: 0.003895\n","Epoch:  670 | train loss: 0.002459 | valid loss: 0.003939\n","Epoch:  671 | train loss: 0.002563 | valid loss: 0.003915\n","Epoch:  672 | train loss: 0.002072 | valid loss: 0.004003\n","Epoch:  673 | train loss: 0.002796 | valid loss: 0.003848\n","Epoch:  674 | train loss: 0.002270 | valid loss: 0.003706\n","Epoch:  675 | train loss: 0.002425 | valid loss: 0.003594\n","Epoch:  676 | train loss: 0.001833 | valid loss: 0.003678\n","Epoch:  677 | train loss: 0.002515 | valid loss: 0.003762\n","Epoch:  678 | train loss: 0.002423 | valid loss: 0.003816\n","Epoch:  679 | train loss: 0.002963 | valid loss: 0.003731\n","Epoch:  680 | train loss: 0.002156 | valid loss: 0.003664\n","Epoch:  681 | train loss: 0.002524 | valid loss: 0.003682\n","Epoch:  682 | train loss: 0.002003 | valid loss: 0.003682\n","Epoch:  683 | train loss: 0.001542 | valid loss: 0.003729\n","Epoch:  684 | train loss: 0.002299 | valid loss: 0.003626\n","Epoch:  685 | train loss: 0.002841 | valid loss: 0.004008\n","Epoch:  686 | train loss: 0.002605 | valid loss: 0.003852\n","Epoch:  687 | train loss: 0.002458 | valid loss: 0.003835\n","Epoch:  688 | train loss: 0.002749 | valid loss: 0.003743\n","Epoch:  689 | train loss: 0.003062 | valid loss: 0.003722\n","Epoch:  690 | train loss: 0.003102 | valid loss: 0.003759\n","Epoch:  691 | train loss: 0.001609 | valid loss: 0.003724\n","Epoch:  692 | train loss: 0.002498 | valid loss: 0.003682\n","Epoch:  693 | train loss: 0.001675 | valid loss: 0.003656\n","Epoch:  694 | train loss: 0.002035 | valid loss: 0.003764\n","Epoch:  695 | train loss: 0.002621 | valid loss: 0.003729\n","Epoch:  696 | train loss: 0.001839 | valid loss: 0.003830\n","Epoch:  697 | train loss: 0.002057 | valid loss: 0.003681\n","Epoch:  698 | train loss: 0.001957 | valid loss: 0.003837\n","Epoch:  699 | train loss: 0.004673 | valid loss: 0.004068\n","Epoch:  700 | train loss: 0.002427 | valid loss: 0.003984\n","Epoch:  701 | train loss: 0.003364 | valid loss: 0.003772\n","Epoch:  702 | train loss: 0.002357 | valid loss: 0.003793\n","Epoch:  703 | train loss: 0.001970 | valid loss: 0.003603\n","Epoch:  704 | train loss: 0.001621 | valid loss: 0.003640\n","Epoch:  705 | train loss: 0.001273 | valid loss: 0.003808\n","Epoch:  706 | train loss: 0.001938 | valid loss: 0.003678\n","Epoch:  707 | train loss: 0.001774 | valid loss: 0.003750\n","Epoch:  708 | train loss: 0.002430 | valid loss: 0.003768\n","Epoch:  709 | train loss: 0.002500 | valid loss: 0.003686\n","Epoch:  710 | train loss: 0.002792 | valid loss: 0.003850\n","Epoch:  711 | train loss: 0.002554 | valid loss: 0.003860\n","Epoch:  712 | train loss: 0.002264 | valid loss: 0.003827\n","Epoch:  713 | train loss: 0.002428 | valid loss: 0.003815\n","Epoch:  714 | train loss: 0.001980 | valid loss: 0.003675\n","Epoch:  715 | train loss: 0.002162 | valid loss: 0.003754\n","Epoch:  716 | train loss: 0.002874 | valid loss: 0.003763\n","Epoch:  717 | train loss: 0.002418 | valid loss: 0.003882\n","Epoch:  718 | train loss: 0.002767 | valid loss: 0.003706\n","Epoch:  719 | train loss: 0.002618 | valid loss: 0.003760\n","Epoch:  720 | train loss: 0.003118 | valid loss: 0.003719\n","Epoch:  721 | train loss: 0.002101 | valid loss: 0.003952\n","Epoch:  722 | train loss: 0.001919 | valid loss: 0.003735\n","Epoch:  723 | train loss: 0.002465 | valid loss: 0.003830\n","Epoch:  724 | train loss: 0.001664 | valid loss: 0.003744\n","Epoch:  725 | train loss: 0.001861 | valid loss: 0.003712\n","Epoch:  726 | train loss: 0.001507 | valid loss: 0.003708\n","Epoch:  727 | train loss: 0.002413 | valid loss: 0.003742\n","Epoch:  728 | train loss: 0.002085 | valid loss: 0.003858\n","Epoch:  729 | train loss: 0.002382 | valid loss: 0.003770\n","Epoch:  730 | train loss: 0.001900 | valid loss: 0.003619\n","Epoch:  731 | train loss: 0.002314 | valid loss: 0.003875\n","Epoch:  732 | train loss: 0.002144 | valid loss: 0.003905\n","Epoch:  733 | train loss: 0.002591 | valid loss: 0.003735\n","Epoch:  734 | train loss: 0.002891 | valid loss: 0.003673\n","Epoch:  735 | train loss: 0.003426 | valid loss: 0.003880\n","Epoch:  736 | train loss: 0.002175 | valid loss: 0.003890\n","Epoch:  737 | train loss: 0.002052 | valid loss: 0.003956\n","Epoch:  738 | train loss: 0.002386 | valid loss: 0.003926\n","Epoch:  739 | train loss: 0.001814 | valid loss: 0.003836\n","Epoch:  740 | train loss: 0.002277 | valid loss: 0.004121\n","Epoch:  741 | train loss: 0.002357 | valid loss: 0.003902\n","Epoch:  742 | train loss: 0.002132 | valid loss: 0.003740\n","Epoch:  743 | train loss: 0.001323 | valid loss: 0.003697\n","Epoch:  744 | train loss: 0.001932 | valid loss: 0.003663\n","Epoch:  745 | train loss: 0.002635 | valid loss: 0.003704\n","Epoch:  746 | train loss: 0.001719 | valid loss: 0.003684\n","Epoch:  747 | train loss: 0.002119 | valid loss: 0.003668\n","Epoch:  748 | train loss: 0.001740 | valid loss: 0.003683\n","Epoch:  749 | train loss: 0.002563 | valid loss: 0.003691\n","Epoch:  750 | train loss: 0.002625 | valid loss: 0.003703\n","Epoch:  751 | train loss: 0.002008 | valid loss: 0.003716\n","Epoch:  752 | train loss: 0.002511 | valid loss: 0.003939\n","Epoch:  753 | train loss: 0.001880 | valid loss: 0.003873\n","Epoch:  754 | train loss: 0.003404 | valid loss: 0.003998\n","Epoch:  755 | train loss: 0.001964 | valid loss: 0.003934\n","Epoch:  756 | train loss: 0.003754 | valid loss: 0.003760\n","Epoch:  757 | train loss: 0.002198 | valid loss: 0.003706\n","Epoch:  758 | train loss: 0.002318 | valid loss: 0.003703\n","Epoch:  759 | train loss: 0.002274 | valid loss: 0.003568\n","Epoch:  760 | train loss: 0.002078 | valid loss: 0.003765\n","Epoch:  761 | train loss: 0.002218 | valid loss: 0.003727\n","Epoch:  762 | train loss: 0.001411 | valid loss: 0.003651\n","Epoch:  763 | train loss: 0.002541 | valid loss: 0.003818\n","Epoch:  764 | train loss: 0.002299 | valid loss: 0.003856\n","Epoch:  765 | train loss: 0.002212 | valid loss: 0.003820\n","Epoch:  766 | train loss: 0.001538 | valid loss: 0.003980\n","Epoch:  767 | train loss: 0.002469 | valid loss: 0.003878\n","Epoch:  768 | train loss: 0.002376 | valid loss: 0.003877\n","Epoch:  769 | train loss: 0.002371 | valid loss: 0.003838\n","Epoch:  770 | train loss: 0.002309 | valid loss: 0.003717\n","Epoch:  771 | train loss: 0.001689 | valid loss: 0.003719\n","Epoch:  772 | train loss: 0.001619 | valid loss: 0.003727\n","Epoch:  773 | train loss: 0.002960 | valid loss: 0.003749\n","Epoch:  774 | train loss: 0.001890 | valid loss: 0.003718\n","Epoch:  775 | train loss: 0.001835 | valid loss: 0.003884\n","Epoch:  776 | train loss: 0.001631 | valid loss: 0.003802\n","Epoch:  777 | train loss: 0.002684 | valid loss: 0.003712\n","Epoch:  778 | train loss: 0.003138 | valid loss: 0.003774\n","Epoch:  779 | train loss: 0.001846 | valid loss: 0.003812\n","Epoch:  780 | train loss: 0.002189 | valid loss: 0.003676\n","Epoch:  781 | train loss: 0.001754 | valid loss: 0.003755\n","Epoch:  782 | train loss: 0.001592 | valid loss: 0.003654\n","Epoch:  783 | train loss: 0.002770 | valid loss: 0.003660\n","Epoch:  784 | train loss: 0.002221 | valid loss: 0.003800\n","Epoch:  785 | train loss: 0.001997 | valid loss: 0.003768\n","Epoch:  786 | train loss: 0.002618 | valid loss: 0.003792\n","Epoch:  787 | train loss: 0.001836 | valid loss: 0.003900\n","Epoch:  788 | train loss: 0.002688 | valid loss: 0.003884\n","Epoch:  789 | train loss: 0.002404 | valid loss: 0.003972\n","Epoch:  790 | train loss: 0.002174 | valid loss: 0.003927\n","Epoch:  791 | train loss: 0.001831 | valid loss: 0.004081\n","Epoch:  792 | train loss: 0.002000 | valid loss: 0.003820\n","Epoch:  793 | train loss: 0.002741 | valid loss: 0.003952\n","Epoch:  794 | train loss: 0.001616 | valid loss: 0.003884\n","Epoch:  795 | train loss: 0.002486 | valid loss: 0.003753\n","Epoch:  796 | train loss: 0.002146 | valid loss: 0.003772\n","Epoch:  797 | train loss: 0.001552 | valid loss: 0.003679\n","Epoch:  798 | train loss: 0.002647 | valid loss: 0.003832\n","Epoch:  799 | train loss: 0.002496 | valid loss: 0.003777\n","Epoch:  800 | train loss: 0.002131 | valid loss: 0.003768\n","Epoch:  801 | train loss: 0.002270 | valid loss: 0.003870\n","Epoch:  802 | train loss: 0.002765 | valid loss: 0.003861\n","Epoch:  803 | train loss: 0.005757 | valid loss: 0.003769\n","Epoch:  804 | train loss: 0.002446 | valid loss: 0.003652\n","Epoch:  805 | train loss: 0.002018 | valid loss: 0.003764\n","Epoch:  806 | train loss: 0.002006 | valid loss: 0.003695\n","Epoch:  807 | train loss: 0.002406 | valid loss: 0.003804\n","Epoch:  808 | train loss: 0.002655 | valid loss: 0.003750\n","Epoch:  809 | train loss: 0.002957 | valid loss: 0.003998\n","Epoch:  810 | train loss: 0.002283 | valid loss: 0.003960\n","Epoch:  811 | train loss: 0.002364 | valid loss: 0.003754\n","Epoch:  812 | train loss: 0.002037 | valid loss: 0.003917\n","Epoch:  813 | train loss: 0.001675 | valid loss: 0.003831\n","Epoch:  814 | train loss: 0.002080 | valid loss: 0.003822\n","Epoch:  815 | train loss: 0.002777 | valid loss: 0.004073\n","Epoch:  816 | train loss: 0.001970 | valid loss: 0.003951\n","Epoch:  817 | train loss: 0.003159 | valid loss: 0.003822\n","Epoch:  818 | train loss: 0.002122 | valid loss: 0.003824\n","Epoch:  819 | train loss: 0.002610 | valid loss: 0.003797\n","Epoch:  820 | train loss: 0.002269 | valid loss: 0.003882\n","Epoch:  821 | train loss: 0.002056 | valid loss: 0.003787\n","Epoch:  822 | train loss: 0.001939 | valid loss: 0.003797\n","Epoch:  823 | train loss: 0.002871 | valid loss: 0.003798\n","Epoch:  824 | train loss: 0.002096 | valid loss: 0.003831\n","Epoch:  825 | train loss: 0.002085 | valid loss: 0.003790\n","Epoch:  826 | train loss: 0.003653 | valid loss: 0.003814\n","Epoch:  827 | train loss: 0.002401 | valid loss: 0.003780\n","Epoch:  828 | train loss: 0.001897 | valid loss: 0.003782\n","Epoch:  829 | train loss: 0.002759 | valid loss: 0.003849\n","Epoch:  830 | train loss: 0.001616 | valid loss: 0.003954\n","Epoch:  831 | train loss: 0.001824 | valid loss: 0.003863\n","Epoch:  832 | train loss: 0.002828 | valid loss: 0.003660\n","Epoch:  833 | train loss: 0.002148 | valid loss: 0.003992\n","Epoch:  834 | train loss: 0.001964 | valid loss: 0.003818\n","Epoch:  835 | train loss: 0.001932 | valid loss: 0.003860\n","Epoch:  836 | train loss: 0.002188 | valid loss: 0.003897\n","Epoch:  837 | train loss: 0.002096 | valid loss: 0.003822\n","Epoch:  838 | train loss: 0.003728 | valid loss: 0.003999\n","Epoch:  839 | train loss: 0.002516 | valid loss: 0.003939\n","Epoch:  840 | train loss: 0.002789 | valid loss: 0.003968\n","Epoch:  841 | train loss: 0.002473 | valid loss: 0.003871\n","Epoch:  842 | train loss: 0.003252 | valid loss: 0.003948\n","Epoch:  843 | train loss: 0.002031 | valid loss: 0.003839\n","Epoch:  844 | train loss: 0.002397 | valid loss: 0.003779\n","Epoch:  845 | train loss: 0.002488 | valid loss: 0.003973\n","Epoch:  846 | train loss: 0.002025 | valid loss: 0.003805\n","Epoch:  847 | train loss: 0.002405 | valid loss: 0.003765\n","Epoch:  848 | train loss: 0.002238 | valid loss: 0.003995\n","Epoch:  849 | train loss: 0.002599 | valid loss: 0.004019\n","Epoch:  850 | train loss: 0.002278 | valid loss: 0.003784\n","Epoch:  851 | train loss: 0.001967 | valid loss: 0.003911\n","Epoch:  852 | train loss: 0.002922 | valid loss: 0.003985\n","Epoch:  853 | train loss: 0.002035 | valid loss: 0.003747\n","Epoch:  854 | train loss: 0.002084 | valid loss: 0.003891\n","Epoch:  855 | train loss: 0.002199 | valid loss: 0.003693\n","Epoch:  856 | train loss: 0.001667 | valid loss: 0.003915\n","Epoch:  857 | train loss: 0.002111 | valid loss: 0.003863\n","Epoch:  858 | train loss: 0.002111 | valid loss: 0.003919\n","Epoch:  859 | train loss: 0.002236 | valid loss: 0.004016\n","Epoch:  860 | train loss: 0.002888 | valid loss: 0.003865\n","Epoch:  861 | train loss: 0.001688 | valid loss: 0.003890\n","Epoch:  862 | train loss: 0.002333 | valid loss: 0.003954\n","Epoch:  863 | train loss: 0.002677 | valid loss: 0.003782\n","Epoch:  864 | train loss: 0.002887 | valid loss: 0.003801\n","Epoch:  865 | train loss: 0.002374 | valid loss: 0.003873\n","Epoch:  866 | train loss: 0.002148 | valid loss: 0.004010\n","Epoch:  867 | train loss: 0.003218 | valid loss: 0.004145\n","Epoch:  868 | train loss: 0.001813 | valid loss: 0.003985\n","Epoch:  869 | train loss: 0.002453 | valid loss: 0.003896\n","Epoch:  870 | train loss: 0.002401 | valid loss: 0.003923\n","Epoch:  871 | train loss: 0.001905 | valid loss: 0.003814\n","Epoch:  872 | train loss: 0.003127 | valid loss: 0.003920\n","Epoch:  873 | train loss: 0.001665 | valid loss: 0.003821\n","Epoch:  874 | train loss: 0.001874 | valid loss: 0.003734\n","Epoch:  875 | train loss: 0.002034 | valid loss: 0.003924\n","Epoch:  876 | train loss: 0.001833 | valid loss: 0.004091\n","Epoch:  877 | train loss: 0.002027 | valid loss: 0.004127\n","Epoch:  878 | train loss: 0.002988 | valid loss: 0.003933\n","Epoch:  879 | train loss: 0.001916 | valid loss: 0.003698\n","Epoch:  880 | train loss: 0.001456 | valid loss: 0.003827\n","Epoch:  881 | train loss: 0.002590 | valid loss: 0.003849\n","Epoch:  882 | train loss: 0.001768 | valid loss: 0.003816\n","Epoch:  883 | train loss: 0.002096 | valid loss: 0.003808\n","Epoch:  884 | train loss: 0.002551 | valid loss: 0.003880\n","Epoch:  885 | train loss: 0.002372 | valid loss: 0.003856\n","Epoch:  886 | train loss: 0.001498 | valid loss: 0.003932\n","Epoch:  887 | train loss: 0.001637 | valid loss: 0.003924\n","Epoch:  888 | train loss: 0.002226 | valid loss: 0.003901\n","Epoch:  889 | train loss: 0.001721 | valid loss: 0.003814\n","Epoch:  890 | train loss: 0.002249 | valid loss: 0.003967\n","Epoch:  891 | train loss: 0.002295 | valid loss: 0.003786\n","Epoch:  892 | train loss: 0.002142 | valid loss: 0.003855\n","Epoch:  893 | train loss: 0.002588 | valid loss: 0.003740\n","Epoch:  894 | train loss: 0.002557 | valid loss: 0.003834\n","Epoch:  895 | train loss: 0.001789 | valid loss: 0.003913\n","Epoch:  896 | train loss: 0.003016 | valid loss: 0.003907\n","Epoch:  897 | train loss: 0.001752 | valid loss: 0.003936\n","Epoch:  898 | train loss: 0.002537 | valid loss: 0.003961\n","Epoch:  899 | train loss: 0.003454 | valid loss: 0.004070\n","Epoch:  900 | train loss: 0.002008 | valid loss: 0.004023\n","Epoch:  901 | train loss: 0.001274 | valid loss: 0.004030\n","Epoch:  902 | train loss: 0.002375 | valid loss: 0.003804\n","Epoch:  903 | train loss: 0.002535 | valid loss: 0.003876\n","Epoch:  904 | train loss: 0.001575 | valid loss: 0.003844\n","Epoch:  905 | train loss: 0.002129 | valid loss: 0.003871\n","Epoch:  906 | train loss: 0.002341 | valid loss: 0.003845\n","Epoch:  907 | train loss: 0.002378 | valid loss: 0.003859\n","Epoch:  908 | train loss: 0.001654 | valid loss: 0.003864\n","Epoch:  909 | train loss: 0.001778 | valid loss: 0.004019\n","Epoch:  910 | train loss: 0.001998 | valid loss: 0.004066\n","Epoch:  911 | train loss: 0.002552 | valid loss: 0.003982\n","Epoch:  912 | train loss: 0.002309 | valid loss: 0.003995\n","Epoch:  913 | train loss: 0.001791 | valid loss: 0.003905\n","Epoch:  914 | train loss: 0.001997 | valid loss: 0.003870\n","Epoch:  915 | train loss: 0.001545 | valid loss: 0.003880\n","Epoch:  916 | train loss: 0.002211 | valid loss: 0.003902\n","Epoch:  917 | train loss: 0.002604 | valid loss: 0.003918\n","Epoch:  918 | train loss: 0.002303 | valid loss: 0.003953\n","Epoch:  919 | train loss: 0.001864 | valid loss: 0.003922\n","Epoch:  920 | train loss: 0.001574 | valid loss: 0.003964\n","Epoch:  921 | train loss: 0.002357 | valid loss: 0.003943\n","Epoch:  922 | train loss: 0.001662 | valid loss: 0.004155\n","Epoch:  923 | train loss: 0.002141 | valid loss: 0.003996\n","Epoch:  924 | train loss: 0.002254 | valid loss: 0.004013\n","Epoch:  925 | train loss: 0.002350 | valid loss: 0.004065\n","Epoch:  926 | train loss: 0.002543 | valid loss: 0.003898\n","Epoch:  927 | train loss: 0.002932 | valid loss: 0.004022\n","Epoch:  928 | train loss: 0.002671 | valid loss: 0.004043\n","Epoch:  929 | train loss: 0.002375 | valid loss: 0.004026\n","Epoch:  930 | train loss: 0.001760 | valid loss: 0.004035\n","Epoch:  931 | train loss: 0.002528 | valid loss: 0.003959\n","Epoch:  932 | train loss: 0.002109 | valid loss: 0.003943\n","Epoch:  933 | train loss: 0.002509 | valid loss: 0.003907\n","Epoch:  934 | train loss: 0.002550 | valid loss: 0.004059\n","Epoch:  935 | train loss: 0.001955 | valid loss: 0.003915\n","Epoch:  936 | train loss: 0.002050 | valid loss: 0.004046\n","Epoch:  937 | train loss: 0.002683 | valid loss: 0.003974\n","Epoch:  938 | train loss: 0.002588 | valid loss: 0.003990\n","Epoch:  939 | train loss: 0.002645 | valid loss: 0.004040\n","Epoch:  940 | train loss: 0.001904 | valid loss: 0.003947\n","Epoch:  941 | train loss: 0.002034 | valid loss: 0.003966\n","Epoch:  942 | train loss: 0.002427 | valid loss: 0.003920\n","Epoch:  943 | train loss: 0.002389 | valid loss: 0.003951\n","Epoch:  944 | train loss: 0.002041 | valid loss: 0.003975\n","Epoch:  945 | train loss: 0.002330 | valid loss: 0.003906\n","Epoch:  946 | train loss: 0.001765 | valid loss: 0.003965\n","Epoch:  947 | train loss: 0.002058 | valid loss: 0.003980\n","Epoch:  948 | train loss: 0.002034 | valid loss: 0.003972\n","Epoch:  949 | train loss: 0.002079 | valid loss: 0.003932\n","Epoch:  950 | train loss: 0.002335 | valid loss: 0.004249\n","Epoch:  951 | train loss: 0.001924 | valid loss: 0.003966\n","Epoch:  952 | train loss: 0.002519 | valid loss: 0.004083\n","Epoch:  953 | train loss: 0.002327 | valid loss: 0.003995\n","Epoch:  954 | train loss: 0.002055 | valid loss: 0.003920\n","Epoch:  955 | train loss: 0.002116 | valid loss: 0.004047\n","Epoch:  956 | train loss: 0.001942 | valid loss: 0.003913\n","Epoch:  957 | train loss: 0.001555 | valid loss: 0.003964\n","Epoch:  958 | train loss: 0.002724 | valid loss: 0.003923\n","Epoch:  959 | train loss: 0.002259 | valid loss: 0.003969\n","Epoch:  960 | train loss: 0.001754 | valid loss: 0.003874\n","Epoch:  961 | train loss: 0.003020 | valid loss: 0.003913\n","Epoch:  962 | train loss: 0.002000 | valid loss: 0.004051\n","Epoch:  963 | train loss: 0.001810 | valid loss: 0.003892\n","Epoch:  964 | train loss: 0.002638 | valid loss: 0.003917\n","Epoch:  965 | train loss: 0.002506 | valid loss: 0.003962\n","Epoch:  966 | train loss: 0.001767 | valid loss: 0.004035\n","Epoch:  967 | train loss: 0.002140 | valid loss: 0.004087\n","Epoch:  968 | train loss: 0.002376 | valid loss: 0.003922\n","Epoch:  969 | train loss: 0.002441 | valid loss: 0.003947\n","Epoch:  970 | train loss: 0.001445 | valid loss: 0.003999\n","Epoch:  971 | train loss: 0.001931 | valid loss: 0.003940\n","Epoch:  972 | train loss: 0.002359 | valid loss: 0.003933\n","Epoch:  973 | train loss: 0.001973 | valid loss: 0.003950\n","Epoch:  974 | train loss: 0.002210 | valid loss: 0.003960\n","Epoch:  975 | train loss: 0.002122 | valid loss: 0.003942\n","Epoch:  976 | train loss: 0.002899 | valid loss: 0.004030\n","Epoch:  977 | train loss: 0.002813 | valid loss: 0.004090\n","Epoch:  978 | train loss: 0.004217 | valid loss: 0.004145\n","Epoch:  979 | train loss: 0.002089 | valid loss: 0.004247\n","Epoch:  980 | train loss: 0.002590 | valid loss: 0.004260\n","Epoch:  981 | train loss: 0.002275 | valid loss: 0.004053\n","Epoch:  982 | train loss: 0.002103 | valid loss: 0.003923\n","Epoch:  983 | train loss: 0.002027 | valid loss: 0.003848\n","Epoch:  984 | train loss: 0.002252 | valid loss: 0.003923\n","Epoch:  985 | train loss: 0.001837 | valid loss: 0.003962\n","Epoch:  986 | train loss: 0.002360 | valid loss: 0.003996\n","Epoch:  987 | train loss: 0.002027 | valid loss: 0.004057\n","Epoch:  988 | train loss: 0.001623 | valid loss: 0.004070\n","Epoch:  989 | train loss: 0.001760 | valid loss: 0.004010\n","Epoch:  990 | train loss: 0.001920 | valid loss: 0.003991\n","Epoch:  991 | train loss: 0.002855 | valid loss: 0.003979\n","Epoch:  992 | train loss: 0.001472 | valid loss: 0.004009\n","Epoch:  993 | train loss: 0.002470 | valid loss: 0.004100\n","Epoch:  994 | train loss: 0.003084 | valid loss: 0.004018\n","Epoch:  995 | train loss: 0.002966 | valid loss: 0.004087\n","Epoch:  996 | train loss: 0.002093 | valid loss: 0.004137\n","Epoch:  997 | train loss: 0.002410 | valid loss: 0.004029\n","Epoch:  998 | train loss: 0.002290 | valid loss: 0.004059\n","Epoch:  999 | train loss: 0.002420 | valid loss: 0.003997\n","Epoch:  1000 | train loss: 0.002275 | valid loss: 0.004069\n","Epoch:  1001 | train loss: 0.002907 | valid loss: 0.004156\n","Epoch:  1002 | train loss: 0.002298 | valid loss: 0.003926\n","Epoch:  1003 | train loss: 0.005529 | valid loss: 0.003895\n","Epoch:  1004 | train loss: 0.002467 | valid loss: 0.003976\n","Epoch:  1005 | train loss: 0.002252 | valid loss: 0.003960\n","Epoch:  1006 | train loss: 0.002294 | valid loss: 0.004079\n","Epoch:  1007 | train loss: 0.001898 | valid loss: 0.003989\n","Epoch:  1008 | train loss: 0.002072 | valid loss: 0.003981\n","Epoch:  1009 | train loss: 0.002798 | valid loss: 0.004058\n","Epoch:  1010 | train loss: 0.002135 | valid loss: 0.004089\n","Epoch:  1011 | train loss: 0.001634 | valid loss: 0.004149\n","Epoch:  1012 | train loss: 0.002919 | valid loss: 0.004114\n","Epoch:  1013 | train loss: 0.002131 | valid loss: 0.003949\n","Epoch:  1014 | train loss: 0.001477 | valid loss: 0.004255\n","Epoch:  1015 | train loss: 0.002469 | valid loss: 0.004045\n","Epoch:  1016 | train loss: 0.001416 | valid loss: 0.003946\n","Epoch:  1017 | train loss: 0.002492 | valid loss: 0.003939\n","Epoch:  1018 | train loss: 0.002292 | valid loss: 0.003939\n","Epoch:  1019 | train loss: 0.001901 | valid loss: 0.004158\n","Epoch:  1020 | train loss: 0.001895 | valid loss: 0.004171\n","Epoch:  1021 | train loss: 0.002633 | valid loss: 0.003961\n","Epoch:  1022 | train loss: 0.001902 | valid loss: 0.003979\n","Epoch:  1023 | train loss: 0.002133 | valid loss: 0.003898\n","Epoch:  1024 | train loss: 0.001564 | valid loss: 0.004127\n","Epoch:  1025 | train loss: 0.002420 | valid loss: 0.004043\n","Epoch:  1026 | train loss: 0.001588 | valid loss: 0.004019\n","Epoch:  1027 | train loss: 0.001636 | valid loss: 0.004021\n","Epoch:  1028 | train loss: 0.001728 | valid loss: 0.004009\n","Epoch:  1029 | train loss: 0.002242 | valid loss: 0.003994\n","Epoch:  1030 | train loss: 0.002041 | valid loss: 0.003946\n","Epoch:  1031 | train loss: 0.002500 | valid loss: 0.004040\n","Epoch:  1032 | train loss: 0.002235 | valid loss: 0.004174\n","Epoch:  1033 | train loss: 0.002369 | valid loss: 0.004129\n","Epoch:  1034 | train loss: 0.002612 | valid loss: 0.004219\n","Epoch:  1035 | train loss: 0.001584 | valid loss: 0.004125\n","Epoch:  1036 | train loss: 0.001532 | valid loss: 0.004144\n","Epoch:  1037 | train loss: 0.002265 | valid loss: 0.004026\n","Epoch:  1038 | train loss: 0.002877 | valid loss: 0.004085\n","Epoch:  1039 | train loss: 0.002100 | valid loss: 0.004038\n","Epoch:  1040 | train loss: 0.002449 | valid loss: 0.004059\n","Epoch:  1041 | train loss: 0.002280 | valid loss: 0.004204\n","Epoch:  1042 | train loss: 0.001729 | valid loss: 0.004017\n","Epoch:  1043 | train loss: 0.003220 | valid loss: 0.004084\n","Epoch:  1044 | train loss: 0.002605 | valid loss: 0.004115\n","Epoch:  1045 | train loss: 0.002807 | valid loss: 0.004046\n","Epoch:  1046 | train loss: 0.001825 | valid loss: 0.004078\n","Epoch:  1047 | train loss: 0.002138 | valid loss: 0.004064\n","Epoch:  1048 | train loss: 0.001795 | valid loss: 0.004179\n","Epoch:  1049 | train loss: 0.001898 | valid loss: 0.004443\n","Epoch:  1050 | train loss: 0.001820 | valid loss: 0.004113\n","Epoch:  1051 | train loss: 0.001574 | valid loss: 0.004104\n","Epoch:  1052 | train loss: 0.002629 | valid loss: 0.004198\n","Epoch:  1053 | train loss: 0.001315 | valid loss: 0.003977\n","Epoch:  1054 | train loss: 0.001901 | valid loss: 0.004057\n","Epoch:  1055 | train loss: 0.002231 | valid loss: 0.003968\n","Epoch:  1056 | train loss: 0.001972 | valid loss: 0.004026\n","Epoch:  1057 | train loss: 0.002090 | valid loss: 0.003965\n","Epoch:  1058 | train loss: 0.002254 | valid loss: 0.004073\n","Epoch:  1059 | train loss: 0.001912 | valid loss: 0.004098\n","Epoch:  1060 | train loss: 0.002099 | valid loss: 0.003946\n","Epoch:  1061 | train loss: 0.002150 | valid loss: 0.004024\n","Epoch:  1062 | train loss: 0.002088 | valid loss: 0.003964\n","Epoch:  1063 | train loss: 0.002946 | valid loss: 0.004135\n","Epoch:  1064 | train loss: 0.002125 | valid loss: 0.004085\n","Epoch:  1065 | train loss: 0.003345 | valid loss: 0.004083\n","Epoch:  1066 | train loss: 0.002448 | valid loss: 0.004151\n","Epoch:  1067 | train loss: 0.002201 | valid loss: 0.004117\n","Epoch:  1068 | train loss: 0.002521 | valid loss: 0.004232\n","Epoch:  1069 | train loss: 0.002293 | valid loss: 0.004240\n","Epoch:  1070 | train loss: 0.002805 | valid loss: 0.004275\n","Epoch:  1071 | train loss: 0.003064 | valid loss: 0.004100\n","Epoch:  1072 | train loss: 0.002262 | valid loss: 0.004142\n","Epoch:  1073 | train loss: 0.002511 | valid loss: 0.004127\n","Epoch:  1074 | train loss: 0.001867 | valid loss: 0.004038\n","Epoch:  1075 | train loss: 0.002197 | valid loss: 0.004234\n","Epoch:  1076 | train loss: 0.001443 | valid loss: 0.004019\n","Epoch:  1077 | train loss: 0.001872 | valid loss: 0.003983\n","Epoch:  1078 | train loss: 0.001984 | valid loss: 0.004043\n","Epoch:  1079 | train loss: 0.003788 | valid loss: 0.004139\n","Epoch:  1080 | train loss: 0.002891 | valid loss: 0.004091\n","Epoch:  1081 | train loss: 0.001450 | valid loss: 0.004158\n","Epoch:  1082 | train loss: 0.001713 | valid loss: 0.004059\n","Epoch:  1083 | train loss: 0.001847 | valid loss: 0.004118\n","Epoch:  1084 | train loss: 0.003231 | valid loss: 0.004150\n","Epoch:  1085 | train loss: 0.002713 | valid loss: 0.004213\n","Epoch:  1086 | train loss: 0.006426 | valid loss: 0.004187\n","Epoch:  1087 | train loss: 0.001561 | valid loss: 0.004071\n","Epoch:  1088 | train loss: 0.002217 | valid loss: 0.004229\n","Epoch:  1089 | train loss: 0.002555 | valid loss: 0.004288\n","Epoch:  1090 | train loss: 0.002048 | valid loss: 0.004234\n","Epoch:  1091 | train loss: 0.001935 | valid loss: 0.004124\n","Epoch:  1092 | train loss: 0.002899 | valid loss: 0.004131\n","Epoch:  1093 | train loss: 0.001877 | valid loss: 0.004051\n","Epoch:  1094 | train loss: 0.002452 | valid loss: 0.004136\n","Epoch:  1095 | train loss: 0.002654 | valid loss: 0.004059\n","Epoch:  1096 | train loss: 0.002073 | valid loss: 0.004138\n","Epoch:  1097 | train loss: 0.001933 | valid loss: 0.004116\n","Epoch:  1098 | train loss: 0.001794 | valid loss: 0.004237\n","Epoch:  1099 | train loss: 0.002226 | valid loss: 0.004504\n","Epoch:  1100 | train loss: 0.002183 | valid loss: 0.004267\n","Epoch:  1101 | train loss: 0.002380 | valid loss: 0.004106\n","Epoch:  1102 | train loss: 0.001859 | valid loss: 0.004062\n","Epoch:  1103 | train loss: 0.002244 | valid loss: 0.004107\n","Epoch:  1104 | train loss: 0.002359 | valid loss: 0.004180\n","Epoch:  1105 | train loss: 0.001744 | valid loss: 0.004174\n","Epoch:  1106 | train loss: 0.003539 | valid loss: 0.004231\n","Epoch:  1107 | train loss: 0.001472 | valid loss: 0.004229\n","Epoch:  1108 | train loss: 0.002918 | valid loss: 0.004302\n","Epoch:  1109 | train loss: 0.001655 | valid loss: 0.004190\n","Epoch:  1110 | train loss: 0.002504 | valid loss: 0.004151\n","Epoch:  1111 | train loss: 0.001563 | valid loss: 0.004168\n","Epoch:  1112 | train loss: 0.001364 | valid loss: 0.004156\n","Epoch:  1113 | train loss: 0.002232 | valid loss: 0.004083\n","Epoch:  1114 | train loss: 0.002643 | valid loss: 0.004070\n","Epoch:  1115 | train loss: 0.001973 | valid loss: 0.004273\n","Epoch:  1116 | train loss: 0.002022 | valid loss: 0.004069\n","Epoch:  1117 | train loss: 0.001546 | valid loss: 0.004119\n","Epoch:  1118 | train loss: 0.002474 | valid loss: 0.004113\n","Epoch:  1119 | train loss: 0.002073 | valid loss: 0.004188\n","Epoch:  1120 | train loss: 0.001777 | valid loss: 0.004160\n","Epoch:  1121 | train loss: 0.002707 | valid loss: 0.004284\n","Epoch:  1122 | train loss: 0.002493 | valid loss: 0.004201\n","Epoch:  1123 | train loss: 0.002427 | valid loss: 0.004120\n","Epoch:  1124 | train loss: 0.001487 | valid loss: 0.004200\n","Epoch:  1125 | train loss: 0.002214 | valid loss: 0.004073\n","Epoch:  1126 | train loss: 0.001960 | valid loss: 0.004166\n","Epoch:  1127 | train loss: 0.002924 | valid loss: 0.004230\n","Epoch:  1128 | train loss: 0.002818 | valid loss: 0.004079\n","Epoch:  1129 | train loss: 0.002785 | valid loss: 0.004119\n","Epoch:  1130 | train loss: 0.002280 | valid loss: 0.004154\n","Epoch:  1131 | train loss: 0.001328 | valid loss: 0.004264\n","Epoch:  1132 | train loss: 0.001592 | valid loss: 0.004050\n","Epoch:  1133 | train loss: 0.002660 | valid loss: 0.004148\n","Epoch:  1134 | train loss: 0.002820 | valid loss: 0.004178\n","Epoch:  1135 | train loss: 0.001559 | valid loss: 0.004150\n","Epoch:  1136 | train loss: 0.002286 | valid loss: 0.004133\n","Epoch:  1137 | train loss: 0.002171 | valid loss: 0.004144\n","Epoch:  1138 | train loss: 0.001651 | valid loss: 0.004168\n","Epoch:  1139 | train loss: 0.001436 | valid loss: 0.004242\n","Epoch:  1140 | train loss: 0.002149 | valid loss: 0.004181\n","Epoch:  1141 | train loss: 0.002917 | valid loss: 0.004222\n","Epoch:  1142 | train loss: 0.002655 | valid loss: 0.004329\n","Epoch:  1143 | train loss: 0.001556 | valid loss: 0.004227\n","Epoch:  1144 | train loss: 0.002169 | valid loss: 0.004174\n","Epoch:  1145 | train loss: 0.001867 | valid loss: 0.004129\n","Epoch:  1146 | train loss: 0.002243 | valid loss: 0.004252\n","Epoch:  1147 | train loss: 0.002265 | valid loss: 0.004226\n","Epoch:  1148 | train loss: 0.001918 | valid loss: 0.004071\n","Epoch:  1149 | train loss: 0.001470 | valid loss: 0.004123\n","Epoch:  1150 | train loss: 0.001385 | valid loss: 0.004157\n","Epoch:  1151 | train loss: 0.001875 | valid loss: 0.004357\n","Epoch:  1152 | train loss: 0.001609 | valid loss: 0.004231\n","Epoch:  1153 | train loss: 0.002480 | valid loss: 0.004192\n","Epoch:  1154 | train loss: 0.002722 | valid loss: 0.004382\n","Epoch:  1155 | train loss: 0.001326 | valid loss: 0.004183\n","Epoch:  1156 | train loss: 0.002770 | valid loss: 0.004137\n","Epoch:  1157 | train loss: 0.002166 | valid loss: 0.004285\n","Epoch:  1158 | train loss: 0.003297 | valid loss: 0.004280\n","Epoch:  1159 | train loss: 0.002362 | valid loss: 0.004276\n","Epoch:  1160 | train loss: 0.002425 | valid loss: 0.004387\n","Epoch:  1161 | train loss: 0.001797 | valid loss: 0.004261\n","Epoch:  1162 | train loss: 0.003317 | valid loss: 0.004531\n","Epoch:  1163 | train loss: 0.001620 | valid loss: 0.004193\n","Epoch:  1164 | train loss: 0.002110 | valid loss: 0.004176\n","Epoch:  1165 | train loss: 0.002067 | valid loss: 0.004103\n","Epoch:  1166 | train loss: 0.002254 | valid loss: 0.004125\n","Epoch:  1167 | train loss: 0.002100 | valid loss: 0.004156\n","Epoch:  1168 | train loss: 0.002492 | valid loss: 0.004221\n","Epoch:  1169 | train loss: 0.002090 | valid loss: 0.004221\n","Epoch:  1170 | train loss: 0.002093 | valid loss: 0.004183\n","Epoch:  1171 | train loss: 0.001938 | valid loss: 0.004370\n","Epoch:  1172 | train loss: 0.002673 | valid loss: 0.004374\n","Epoch:  1173 | train loss: 0.001877 | valid loss: 0.004266\n","Epoch:  1174 | train loss: 0.002471 | valid loss: 0.004242\n","Epoch:  1175 | train loss: 0.003288 | valid loss: 0.004301\n","Epoch:  1176 | train loss: 0.002165 | valid loss: 0.004303\n","Epoch:  1177 | train loss: 0.002294 | valid loss: 0.004174\n","Epoch:  1178 | train loss: 0.001338 | valid loss: 0.004156\n","Epoch:  1179 | train loss: 0.001715 | valid loss: 0.004088\n","Epoch:  1180 | train loss: 0.001415 | valid loss: 0.004161\n","Epoch:  1181 | train loss: 0.001590 | valid loss: 0.004217\n","Epoch:  1182 | train loss: 0.002676 | valid loss: 0.004286\n","Epoch:  1183 | train loss: 0.001838 | valid loss: 0.004249\n","Epoch:  1184 | train loss: 0.001877 | valid loss: 0.004354\n","Epoch:  1185 | train loss: 0.002020 | valid loss: 0.004221\n","Epoch:  1186 | train loss: 0.002941 | valid loss: 0.004203\n","Epoch:  1187 | train loss: 0.002518 | valid loss: 0.004357\n","Epoch:  1188 | train loss: 0.002041 | valid loss: 0.004339\n","Epoch:  1189 | train loss: 0.003013 | valid loss: 0.004500\n","Epoch:  1190 | train loss: 0.002021 | valid loss: 0.004341\n","Epoch:  1191 | train loss: 0.002155 | valid loss: 0.004361\n","Epoch:  1192 | train loss: 0.001305 | valid loss: 0.004191\n","Epoch:  1193 | train loss: 0.002060 | valid loss: 0.004257\n","Epoch:  1194 | train loss: 0.002554 | valid loss: 0.004218\n","Epoch:  1195 | train loss: 0.001913 | valid loss: 0.004267\n","Epoch:  1196 | train loss: 0.002536 | valid loss: 0.004173\n","Epoch:  1197 | train loss: 0.001798 | valid loss: 0.004227\n","Epoch:  1198 | train loss: 0.002009 | valid loss: 0.004086\n","Epoch:  1199 | train loss: 0.001933 | valid loss: 0.004266\n","Epoch:  1200 | train loss: 0.001659 | valid loss: 0.004203\n","Epoch:  1201 | train loss: 0.002456 | valid loss: 0.004275\n","Epoch:  1202 | train loss: 0.002510 | valid loss: 0.004305\n","Epoch:  1203 | train loss: 0.002087 | valid loss: 0.004233\n","Epoch:  1204 | train loss: 0.001795 | valid loss: 0.004190\n","Epoch:  1205 | train loss: 0.002968 | valid loss: 0.004268\n","Epoch:  1206 | train loss: 0.002221 | valid loss: 0.004186\n","Epoch:  1207 | train loss: 0.002516 | valid loss: 0.004572\n","Epoch:  1208 | train loss: 0.002381 | valid loss: 0.004354\n","Epoch:  1209 | train loss: 0.001869 | valid loss: 0.004276\n","Epoch:  1210 | train loss: 0.001802 | valid loss: 0.004356\n","Epoch:  1211 | train loss: 0.001743 | valid loss: 0.004262\n","Epoch:  1212 | train loss: 0.002443 | valid loss: 0.004236\n","Epoch:  1213 | train loss: 0.001882 | valid loss: 0.004152\n","Epoch:  1214 | train loss: 0.002042 | valid loss: 0.004257\n","Epoch:  1215 | train loss: 0.002368 | valid loss: 0.004290\n","Epoch:  1216 | train loss: 0.002483 | valid loss: 0.004456\n","Epoch:  1217 | train loss: 0.001798 | valid loss: 0.004259\n","Epoch:  1218 | train loss: 0.001642 | valid loss: 0.004434\n","Epoch:  1219 | train loss: 0.002181 | valid loss: 0.004347\n","Epoch:  1220 | train loss: 0.001754 | valid loss: 0.004156\n","Epoch:  1221 | train loss: 0.001976 | valid loss: 0.004408\n","Epoch:  1222 | train loss: 0.001498 | valid loss: 0.004428\n","Epoch:  1223 | train loss: 0.002515 | valid loss: 0.004357\n","Epoch:  1224 | train loss: 0.002488 | valid loss: 0.004273\n","Epoch:  1225 | train loss: 0.001692 | valid loss: 0.004291\n","Epoch:  1226 | train loss: 0.001657 | valid loss: 0.004365\n","Epoch:  1227 | train loss: 0.002647 | valid loss: 0.004364\n","Epoch:  1228 | train loss: 0.002832 | valid loss: 0.004198\n","Epoch:  1229 | train loss: 0.001370 | valid loss: 0.004399\n","Epoch:  1230 | train loss: 0.001862 | valid loss: 0.004155\n","Epoch:  1231 | train loss: 0.001777 | valid loss: 0.004469\n","Epoch:  1232 | train loss: 0.001777 | valid loss: 0.004220\n","Epoch:  1233 | train loss: 0.002017 | valid loss: 0.004431\n","Epoch:  1234 | train loss: 0.001785 | valid loss: 0.004192\n","Epoch:  1235 | train loss: 0.001691 | valid loss: 0.004238\n","Epoch:  1236 | train loss: 0.002099 | valid loss: 0.004373\n","Epoch:  1237 | train loss: 0.002838 | valid loss: 0.004291\n","Epoch:  1238 | train loss: 0.002118 | valid loss: 0.004365\n","Epoch:  1239 | train loss: 0.002077 | valid loss: 0.004306\n","Epoch:  1240 | train loss: 0.002501 | valid loss: 0.004287\n","Epoch:  1241 | train loss: 0.002194 | valid loss: 0.004164\n","Epoch:  1242 | train loss: 0.002734 | valid loss: 0.004351\n","Epoch:  1243 | train loss: 0.002039 | valid loss: 0.004307\n","Epoch:  1244 | train loss: 0.003425 | valid loss: 0.004222\n","Epoch:  1245 | train loss: 0.002018 | valid loss: 0.004331\n","Epoch:  1246 | train loss: 0.002368 | valid loss: 0.004201\n","Epoch:  1247 | train loss: 0.002001 | valid loss: 0.004466\n","Epoch:  1248 | train loss: 0.001760 | valid loss: 0.004229\n","Epoch:  1249 | train loss: 0.002363 | valid loss: 0.004291\n","Epoch:  1250 | train loss: 0.002164 | valid loss: 0.004406\n","Epoch:  1251 | train loss: 0.001673 | valid loss: 0.004409\n","Epoch:  1252 | train loss: 0.001936 | valid loss: 0.004424\n","Epoch:  1253 | train loss: 0.002354 | valid loss: 0.004445\n","Epoch:  1254 | train loss: 0.002236 | valid loss: 0.004326\n","Epoch:  1255 | train loss: 0.001696 | valid loss: 0.004365\n","Epoch:  1256 | train loss: 0.001522 | valid loss: 0.004416\n","Epoch:  1257 | train loss: 0.002008 | valid loss: 0.004377\n","Epoch:  1258 | train loss: 0.001954 | valid loss: 0.004274\n","Epoch:  1259 | train loss: 0.002114 | valid loss: 0.004250\n","Epoch:  1260 | train loss: 0.002545 | valid loss: 0.004330\n","Epoch:  1261 | train loss: 0.002071 | valid loss: 0.004319\n","Epoch:  1262 | train loss: 0.001873 | valid loss: 0.004268\n","Epoch:  1263 | train loss: 0.001992 | valid loss: 0.004206\n","Epoch:  1264 | train loss: 0.001772 | valid loss: 0.004435\n","Epoch:  1265 | train loss: 0.002070 | valid loss: 0.004319\n","Epoch:  1266 | train loss: 0.002746 | valid loss: 0.004377\n","Epoch:  1267 | train loss: 0.001971 | valid loss: 0.004460\n","Epoch:  1268 | train loss: 0.001908 | valid loss: 0.004303\n","Epoch:  1269 | train loss: 0.001478 | valid loss: 0.004338\n","Epoch:  1270 | train loss: 0.002328 | valid loss: 0.004311\n","Epoch:  1271 | train loss: 0.002309 | valid loss: 0.004465\n","Epoch:  1272 | train loss: 0.002395 | valid loss: 0.004376\n","Epoch:  1273 | train loss: 0.001553 | valid loss: 0.004351\n","Epoch:  1274 | train loss: 0.002497 | valid loss: 0.004141\n","Epoch:  1275 | train loss: 0.001924 | valid loss: 0.004380\n","Epoch:  1276 | train loss: 0.002010 | valid loss: 0.004246\n","Epoch:  1277 | train loss: 0.002373 | valid loss: 0.004287\n","Epoch:  1278 | train loss: 0.002773 | valid loss: 0.004409\n","Epoch:  1279 | train loss: 0.001816 | valid loss: 0.004325\n","Epoch:  1280 | train loss: 0.002210 | valid loss: 0.004410\n","Epoch:  1281 | train loss: 0.002213 | valid loss: 0.004435\n","Epoch:  1282 | train loss: 0.001866 | valid loss: 0.004329\n","Epoch:  1283 | train loss: 0.001855 | valid loss: 0.004507\n","Epoch:  1284 | train loss: 0.002287 | valid loss: 0.004416\n","Epoch:  1285 | train loss: 0.002039 | valid loss: 0.004387\n","Epoch:  1286 | train loss: 0.001817 | valid loss: 0.004376\n","Epoch:  1287 | train loss: 0.002261 | valid loss: 0.004347\n","Epoch:  1288 | train loss: 0.002061 | valid loss: 0.004580\n","Epoch:  1289 | train loss: 0.002025 | valid loss: 0.004426\n","Epoch:  1290 | train loss: 0.002540 | valid loss: 0.004547\n","Epoch:  1291 | train loss: 0.001911 | valid loss: 0.004295\n","Epoch:  1292 | train loss: 0.002565 | valid loss: 0.004381\n","Epoch:  1293 | train loss: 0.003015 | valid loss: 0.004355\n","Epoch:  1294 | train loss: 0.002338 | valid loss: 0.004323\n","Epoch:  1295 | train loss: 0.002042 | valid loss: 0.004363\n","Epoch:  1296 | train loss: 0.001844 | valid loss: 0.004423\n","Epoch:  1297 | train loss: 0.002312 | valid loss: 0.004443\n","Epoch:  1298 | train loss: 0.002243 | valid loss: 0.004399\n","Epoch:  1299 | train loss: 0.001876 | valid loss: 0.004292\n","Epoch:  1300 | train loss: 0.001877 | valid loss: 0.004401\n","Epoch:  1301 | train loss: 0.001976 | valid loss: 0.004370\n","Epoch:  1302 | train loss: 0.002854 | valid loss: 0.004507\n","Epoch:  1303 | train loss: 0.002117 | valid loss: 0.004449\n","Epoch:  1304 | train loss: 0.002086 | valid loss: 0.004575\n","Epoch:  1305 | train loss: 0.001817 | valid loss: 0.004465\n","Epoch:  1306 | train loss: 0.002810 | valid loss: 0.004436\n","Epoch:  1307 | train loss: 0.003218 | valid loss: 0.004469\n","Epoch:  1308 | train loss: 0.002600 | valid loss: 0.004549\n","Epoch:  1309 | train loss: 0.001785 | valid loss: 0.004344\n","Epoch:  1310 | train loss: 0.002232 | valid loss: 0.004372\n","Epoch:  1311 | train loss: 0.002137 | valid loss: 0.004486\n","Epoch:  1312 | train loss: 0.002278 | valid loss: 0.004475\n","Epoch:  1313 | train loss: 0.002206 | valid loss: 0.004401\n","Epoch:  1314 | train loss: 0.002096 | valid loss: 0.004386\n","Epoch:  1315 | train loss: 0.001834 | valid loss: 0.004318\n","Epoch:  1316 | train loss: 0.001386 | valid loss: 0.004335\n","Epoch:  1317 | train loss: 0.002548 | valid loss: 0.004416\n","Epoch:  1318 | train loss: 0.003249 | valid loss: 0.004279\n","Epoch:  1319 | train loss: 0.001553 | valid loss: 0.004352\n","Epoch:  1320 | train loss: 0.002134 | valid loss: 0.004469\n","Epoch:  1321 | train loss: 0.002039 | valid loss: 0.004319\n","Epoch:  1322 | train loss: 0.002790 | valid loss: 0.004415\n","Epoch:  1323 | train loss: 0.002036 | valid loss: 0.004486\n","Epoch:  1324 | train loss: 0.002073 | valid loss: 0.004396\n","Epoch:  1325 | train loss: 0.001397 | valid loss: 0.004382\n","Epoch:  1326 | train loss: 0.003008 | valid loss: 0.004320\n","Epoch:  1327 | train loss: 0.001545 | valid loss: 0.004497\n","Epoch:  1328 | train loss: 0.002378 | valid loss: 0.004457\n","Epoch:  1329 | train loss: 0.001980 | valid loss: 0.004467\n","Epoch:  1330 | train loss: 0.002540 | valid loss: 0.004409\n","Epoch:  1331 | train loss: 0.002222 | valid loss: 0.004426\n","Epoch:  1332 | train loss: 0.002007 | valid loss: 0.004399\n","Epoch:  1333 | train loss: 0.001507 | valid loss: 0.004518\n","Epoch:  1334 | train loss: 0.002419 | valid loss: 0.004388\n","Epoch:  1335 | train loss: 0.001975 | valid loss: 0.004365\n","Epoch:  1336 | train loss: 0.001792 | valid loss: 0.004385\n","Epoch:  1337 | train loss: 0.001547 | valid loss: 0.004402\n","Epoch:  1338 | train loss: 0.002215 | valid loss: 0.004401\n","Epoch:  1339 | train loss: 0.002460 | valid loss: 0.004578\n","Epoch:  1340 | train loss: 0.002389 | valid loss: 0.004278\n","Epoch:  1341 | train loss: 0.001888 | valid loss: 0.004372\n","Epoch:  1342 | train loss: 0.001744 | valid loss: 0.004433\n","Epoch:  1343 | train loss: 0.002670 | valid loss: 0.004364\n","Epoch:  1344 | train loss: 0.002106 | valid loss: 0.004448\n","Epoch:  1345 | train loss: 0.002138 | valid loss: 0.004458\n","Epoch:  1346 | train loss: 0.001808 | valid loss: 0.004411\n","Epoch:  1347 | train loss: 0.002916 | valid loss: 0.004463\n","Epoch:  1348 | train loss: 0.001843 | valid loss: 0.004479\n","Epoch:  1349 | train loss: 0.001563 | valid loss: 0.004343\n","Epoch:  1350 | train loss: 0.002243 | valid loss: 0.004436\n","Epoch:  1351 | train loss: 0.002762 | valid loss: 0.004502\n","Epoch:  1352 | train loss: 0.002112 | valid loss: 0.004587\n","Epoch:  1353 | train loss: 0.002664 | valid loss: 0.004374\n","Epoch:  1354 | train loss: 0.002238 | valid loss: 0.004383\n","Epoch:  1355 | train loss: 0.002147 | valid loss: 0.004585\n","Epoch:  1356 | train loss: 0.002317 | valid loss: 0.004519\n","Epoch:  1357 | train loss: 0.001913 | valid loss: 0.005130\n","Epoch:  1358 | train loss: 0.003025 | valid loss: 0.004383\n","Epoch:  1359 | train loss: 0.002005 | valid loss: 0.004486\n","Epoch:  1360 | train loss: 0.002089 | valid loss: 0.004448\n","Epoch:  1361 | train loss: 0.001974 | valid loss: 0.004561\n","Epoch:  1362 | train loss: 0.002321 | valid loss: 0.004338\n","Epoch:  1363 | train loss: 0.001957 | valid loss: 0.004478\n","Epoch:  1364 | train loss: 0.002413 | valid loss: 0.004407\n","Epoch:  1365 | train loss: 0.002359 | valid loss: 0.004559\n","Epoch:  1366 | train loss: 0.001686 | valid loss: 0.004439\n","Epoch:  1367 | train loss: 0.001521 | valid loss: 0.004447\n","Epoch:  1368 | train loss: 0.002608 | valid loss: 0.004390\n","Epoch:  1369 | train loss: 0.001819 | valid loss: 0.004630\n","Epoch:  1370 | train loss: 0.003153 | valid loss: 0.004486\n","Epoch:  1371 | train loss: 0.002738 | valid loss: 0.004456\n","Epoch:  1372 | train loss: 0.002345 | valid loss: 0.004513\n","Epoch:  1373 | train loss: 0.001890 | valid loss: 0.004500\n","Epoch:  1374 | train loss: 0.002277 | valid loss: 0.004548\n","Epoch:  1375 | train loss: 0.002122 | valid loss: 0.004633\n","Epoch:  1376 | train loss: 0.002263 | valid loss: 0.004477\n","Epoch:  1377 | train loss: 0.002179 | valid loss: 0.004398\n","Epoch:  1378 | train loss: 0.001380 | valid loss: 0.004432\n","Epoch:  1379 | train loss: 0.002278 | valid loss: 0.004363\n","Epoch:  1380 | train loss: 0.002023 | valid loss: 0.004492\n","Epoch:  1381 | train loss: 0.002348 | valid loss: 0.004505\n","Epoch:  1382 | train loss: 0.001882 | valid loss: 0.004406\n","Epoch:  1383 | train loss: 0.001795 | valid loss: 0.004520\n","Epoch:  1384 | train loss: 0.001339 | valid loss: 0.004452\n","Epoch:  1385 | train loss: 0.002563 | valid loss: 0.004642\n","Epoch:  1386 | train loss: 0.002648 | valid loss: 0.004580\n","Epoch:  1387 | train loss: 0.002426 | valid loss: 0.004477\n","Epoch:  1388 | train loss: 0.002333 | valid loss: 0.004561\n","Epoch:  1389 | train loss: 0.002485 | valid loss: 0.004533\n","Epoch:  1390 | train loss: 0.001850 | valid loss: 0.004663\n","Epoch:  1391 | train loss: 0.002017 | valid loss: 0.004441\n","Epoch:  1392 | train loss: 0.001485 | valid loss: 0.004397\n","Epoch:  1393 | train loss: 0.002249 | valid loss: 0.004335\n","Epoch:  1394 | train loss: 0.001791 | valid loss: 0.004480\n","Epoch:  1395 | train loss: 0.002196 | valid loss: 0.004529\n","Epoch:  1396 | train loss: 0.002453 | valid loss: 0.004574\n","Epoch:  1397 | train loss: 0.001530 | valid loss: 0.004448\n","Epoch:  1398 | train loss: 0.001895 | valid loss: 0.004546\n","Epoch:  1399 | train loss: 0.002628 | valid loss: 0.004513\n","Epoch:  1400 | train loss: 0.002315 | valid loss: 0.004436\n","Epoch:  1401 | train loss: 0.001859 | valid loss: 0.004488\n","Epoch:  1402 | train loss: 0.002182 | valid loss: 0.004536\n","Epoch:  1403 | train loss: 0.002215 | valid loss: 0.004479\n","Epoch:  1404 | train loss: 0.002700 | valid loss: 0.004456\n","Epoch:  1405 | train loss: 0.001768 | valid loss: 0.004444\n","Epoch:  1406 | train loss: 0.001891 | valid loss: 0.004483\n","Epoch:  1407 | train loss: 0.002215 | valid loss: 0.004557\n","Epoch:  1408 | train loss: 0.002584 | valid loss: 0.004495\n","Epoch:  1409 | train loss: 0.003082 | valid loss: 0.004499\n","Epoch:  1410 | train loss: 0.001340 | valid loss: 0.004504\n","Epoch:  1411 | train loss: 0.002209 | valid loss: 0.004433\n","Epoch:  1412 | train loss: 0.002233 | valid loss: 0.004574\n","Epoch:  1413 | train loss: 0.002071 | valid loss: 0.004412\n","Epoch:  1414 | train loss: 0.002496 | valid loss: 0.004468\n","Epoch:  1415 | train loss: 0.002205 | valid loss: 0.004581\n","Epoch:  1416 | train loss: 0.002855 | valid loss: 0.004551\n","Epoch:  1417 | train loss: 0.002187 | valid loss: 0.004575\n","Epoch:  1418 | train loss: 0.001443 | valid loss: 0.004633\n","Epoch:  1419 | train loss: 0.001655 | valid loss: 0.004777\n","Epoch:  1420 | train loss: 0.001824 | valid loss: 0.004574\n","Epoch:  1421 | train loss: 0.001522 | valid loss: 0.004504\n","Epoch:  1422 | train loss: 0.001762 | valid loss: 0.004471\n","Epoch:  1423 | train loss: 0.001900 | valid loss: 0.004573\n","Epoch:  1424 | train loss: 0.001908 | valid loss: 0.004508\n","Epoch:  1425 | train loss: 0.001329 | valid loss: 0.004696\n","Epoch:  1426 | train loss: 0.002346 | valid loss: 0.004578\n","Epoch:  1427 | train loss: 0.002057 | valid loss: 0.004532\n","Epoch:  1428 | train loss: 0.001709 | valid loss: 0.004517\n","Epoch:  1429 | train loss: 0.002244 | valid loss: 0.004477\n","Epoch:  1430 | train loss: 0.002259 | valid loss: 0.004615\n","Epoch:  1431 | train loss: 0.002109 | valid loss: 0.004579\n","Epoch:  1432 | train loss: 0.001282 | valid loss: 0.004461\n","Epoch:  1433 | train loss: 0.001715 | valid loss: 0.004515\n","Epoch:  1434 | train loss: 0.002712 | valid loss: 0.004399\n","Epoch:  1435 | train loss: 0.002488 | valid loss: 0.004543\n","Epoch:  1436 | train loss: 0.001700 | valid loss: 0.004538\n","Epoch:  1437 | train loss: 0.001790 | valid loss: 0.004566\n","Epoch:  1438 | train loss: 0.001541 | valid loss: 0.004492\n","Epoch:  1439 | train loss: 0.001757 | valid loss: 0.004435\n","Epoch:  1440 | train loss: 0.001827 | valid loss: 0.004571\n","Epoch:  1441 | train loss: 0.002384 | valid loss: 0.004507\n","Epoch:  1442 | train loss: 0.002178 | valid loss: 0.004484\n","Epoch:  1443 | train loss: 0.002409 | valid loss: 0.004563\n","Epoch:  1444 | train loss: 0.002529 | valid loss: 0.004490\n","Epoch:  1445 | train loss: 0.001942 | valid loss: 0.004530\n","Epoch:  1446 | train loss: 0.002229 | valid loss: 0.004439\n","Epoch:  1447 | train loss: 0.003125 | valid loss: 0.004523\n","Epoch:  1448 | train loss: 0.002315 | valid loss: 0.004490\n","Epoch:  1449 | train loss: 0.002089 | valid loss: 0.004482\n","Epoch:  1450 | train loss: 0.002928 | valid loss: 0.004616\n","Epoch:  1451 | train loss: 0.002487 | valid loss: 0.004423\n","Epoch:  1452 | train loss: 0.001899 | valid loss: 0.004505\n","Epoch:  1453 | train loss: 0.002014 | valid loss: 0.004493\n","Epoch:  1454 | train loss: 0.002780 | valid loss: 0.004465\n","Epoch:  1455 | train loss: 0.002319 | valid loss: 0.004518\n","Epoch:  1456 | train loss: 0.002530 | valid loss: 0.004419\n","Epoch:  1457 | train loss: 0.002956 | valid loss: 0.004589\n","Epoch:  1458 | train loss: 0.003577 | valid loss: 0.004722\n","Epoch:  1459 | train loss: 0.002340 | valid loss: 0.004572\n","Epoch:  1460 | train loss: 0.002998 | valid loss: 0.004955\n","Epoch:  1461 | train loss: 0.002556 | valid loss: 0.004603\n","Epoch:  1462 | train loss: 0.002611 | valid loss: 0.004671\n","Epoch:  1463 | train loss: 0.002105 | valid loss: 0.004408\n","Epoch:  1464 | train loss: 0.002605 | valid loss: 0.004487\n","Epoch:  1465 | train loss: 0.001913 | valid loss: 0.004446\n","Epoch:  1466 | train loss: 0.001944 | valid loss: 0.004512\n","Epoch:  1467 | train loss: 0.002133 | valid loss: 0.004478\n","Epoch:  1468 | train loss: 0.001879 | valid loss: 0.004457\n","Epoch:  1469 | train loss: 0.001836 | valid loss: 0.004625\n","Epoch:  1470 | train loss: 0.001576 | valid loss: 0.004637\n","Epoch:  1471 | train loss: 0.002035 | valid loss: 0.004582\n","Epoch:  1472 | train loss: 0.002103 | valid loss: 0.004470\n","Epoch:  1473 | train loss: 0.001520 | valid loss: 0.004684\n","Epoch:  1474 | train loss: 0.002617 | valid loss: 0.004544\n","Epoch:  1475 | train loss: 0.002359 | valid loss: 0.004832\n","Epoch:  1476 | train loss: 0.002667 | valid loss: 0.004613\n","Epoch:  1477 | train loss: 0.001616 | valid loss: 0.004564\n","Epoch:  1478 | train loss: 0.001950 | valid loss: 0.004494\n","Epoch:  1479 | train loss: 0.001697 | valid loss: 0.004721\n","Epoch:  1480 | train loss: 0.002330 | valid loss: 0.004458\n","Epoch:  1481 | train loss: 0.002224 | valid loss: 0.004403\n","Epoch:  1482 | train loss: 0.002189 | valid loss: 0.004432\n","Epoch:  1483 | train loss: 0.001782 | valid loss: 0.004501\n","Epoch:  1484 | train loss: 0.001526 | valid loss: 0.004344\n","Epoch:  1485 | train loss: 0.002274 | valid loss: 0.004487\n","Epoch:  1486 | train loss: 0.001796 | valid loss: 0.004586\n","Epoch:  1487 | train loss: 0.002887 | valid loss: 0.004603\n","Epoch:  1488 | train loss: 0.002062 | valid loss: 0.004563\n","Epoch:  1489 | train loss: 0.002019 | valid loss: 0.004636\n","Epoch:  1490 | train loss: 0.002697 | valid loss: 0.004751\n","Epoch:  1491 | train loss: 0.002364 | valid loss: 0.004579\n","Epoch:  1492 | train loss: 0.002641 | valid loss: 0.004585\n","Epoch:  1493 | train loss: 0.002662 | valid loss: 0.004559\n","Epoch:  1494 | train loss: 0.001371 | valid loss: 0.004632\n","Epoch:  1495 | train loss: 0.002203 | valid loss: 0.004533\n","Epoch:  1496 | train loss: 0.002143 | valid loss: 0.004596\n","Epoch:  1497 | train loss: 0.003463 | valid loss: 0.004704\n","Epoch:  1498 | train loss: 0.002109 | valid loss: 0.004564\n","Epoch:  1499 | train loss: 0.002527 | valid loss: 0.004532\n","Epoch:  1500 | train loss: 0.002306 | valid loss: 0.004536\n","Epoch:  1501 | train loss: 0.002096 | valid loss: 0.004626\n","Epoch:  1502 | train loss: 0.002087 | valid loss: 0.004683\n","Epoch:  1503 | train loss: 0.002287 | valid loss: 0.004638\n","Epoch:  1504 | train loss: 0.002155 | valid loss: 0.004591\n","Epoch:  1505 | train loss: 0.002253 | valid loss: 0.004499\n","Epoch:  1506 | train loss: 0.001815 | valid loss: 0.004546\n","Epoch:  1507 | train loss: 0.002118 | valid loss: 0.004474\n","Epoch:  1508 | train loss: 0.001859 | valid loss: 0.004564\n","Epoch:  1509 | train loss: 0.001812 | valid loss: 0.004699\n","Epoch:  1510 | train loss: 0.002472 | valid loss: 0.004553\n","Epoch:  1511 | train loss: 0.003031 | valid loss: 0.004780\n","Epoch:  1512 | train loss: 0.001822 | valid loss: 0.004618\n","Epoch:  1513 | train loss: 0.002607 | valid loss: 0.004545\n","Epoch:  1514 | train loss: 0.002419 | valid loss: 0.004560\n","Epoch:  1515 | train loss: 0.005458 | valid loss: 0.004530\n","Epoch:  1516 | train loss: 0.002671 | valid loss: 0.004431\n","Epoch:  1517 | train loss: 0.002071 | valid loss: 0.004523\n","Epoch:  1518 | train loss: 0.002144 | valid loss: 0.004555\n","Epoch:  1519 | train loss: 0.002054 | valid loss: 0.004609\n","Epoch:  1520 | train loss: 0.002152 | valid loss: 0.004564\n","Epoch:  1521 | train loss: 0.002532 | valid loss: 0.004839\n","Epoch:  1522 | train loss: 0.001970 | valid loss: 0.004607\n","Epoch:  1523 | train loss: 0.002205 | valid loss: 0.004765\n","Epoch:  1524 | train loss: 0.001460 | valid loss: 0.004755\n","Epoch:  1525 | train loss: 0.002164 | valid loss: 0.004509\n","Epoch:  1526 | train loss: 0.002303 | valid loss: 0.004524\n","Epoch:  1527 | train loss: 0.002385 | valid loss: 0.004533\n","Epoch:  1528 | train loss: 0.002658 | valid loss: 0.004540\n","Epoch:  1529 | train loss: 0.001994 | valid loss: 0.004455\n","Epoch:  1530 | train loss: 0.002384 | valid loss: 0.004575\n","Epoch:  1531 | train loss: 0.002094 | valid loss: 0.004669\n","Epoch:  1532 | train loss: 0.002280 | valid loss: 0.004595\n","Epoch:  1533 | train loss: 0.002991 | valid loss: 0.004565\n","Epoch:  1534 | train loss: 0.002479 | valid loss: 0.004436\n","Epoch:  1535 | train loss: 0.002706 | valid loss: 0.004585\n","Epoch:  1536 | train loss: 0.001771 | valid loss: 0.004474\n","Epoch:  1537 | train loss: 0.002398 | valid loss: 0.004519\n","Epoch:  1538 | train loss: 0.002631 | valid loss: 0.004705\n","Epoch:  1539 | train loss: 0.001836 | valid loss: 0.004761\n","Epoch:  1540 | train loss: 0.001768 | valid loss: 0.004578\n","Epoch:  1541 | train loss: 0.002759 | valid loss: 0.004621\n","Epoch:  1542 | train loss: 0.001719 | valid loss: 0.004649\n","Epoch:  1543 | train loss: 0.002261 | valid loss: 0.004542\n","Epoch:  1544 | train loss: 0.002130 | valid loss: 0.004627\n","Epoch:  1545 | train loss: 0.002201 | valid loss: 0.004511\n","Epoch:  1546 | train loss: 0.002146 | valid loss: 0.004539\n","Epoch:  1547 | train loss: 0.001925 | valid loss: 0.004576\n","Epoch:  1548 | train loss: 0.001914 | valid loss: 0.004696\n","Epoch:  1549 | train loss: 0.002158 | valid loss: 0.004662\n","Epoch:  1550 | train loss: 0.001889 | valid loss: 0.004546\n","Epoch:  1551 | train loss: 0.002825 | valid loss: 0.004809\n","Epoch:  1552 | train loss: 0.001577 | valid loss: 0.004649\n","Epoch:  1553 | train loss: 0.002448 | valid loss: 0.004725\n","Epoch:  1554 | train loss: 0.001989 | valid loss: 0.004627\n","Epoch:  1555 | train loss: 0.002126 | valid loss: 0.004652\n","Epoch:  1556 | train loss: 0.001386 | valid loss: 0.004459\n","Epoch:  1557 | train loss: 0.001585 | valid loss: 0.004526\n","Epoch:  1558 | train loss: 0.001753 | valid loss: 0.004493\n","Epoch:  1559 | train loss: 0.002445 | valid loss: 0.004517\n","Epoch:  1560 | train loss: 0.001782 | valid loss: 0.004606\n","Epoch:  1561 | train loss: 0.001971 | valid loss: 0.004505\n","Epoch:  1562 | train loss: 0.001707 | valid loss: 0.004645\n","Epoch:  1563 | train loss: 0.001833 | valid loss: 0.004542\n","Epoch:  1564 | train loss: 0.002829 | valid loss: 0.004835\n","Epoch:  1565 | train loss: 0.002022 | valid loss: 0.004568\n","Epoch:  1566 | train loss: 0.002458 | valid loss: 0.004728\n","Epoch:  1567 | train loss: 0.001953 | valid loss: 0.004631\n","Epoch:  1568 | train loss: 0.002222 | valid loss: 0.004612\n","Epoch:  1569 | train loss: 0.002056 | valid loss: 0.004558\n","Epoch:  1570 | train loss: 0.002076 | valid loss: 0.004628\n","Epoch:  1571 | train loss: 0.001317 | valid loss: 0.004483\n","Epoch:  1572 | train loss: 0.001345 | valid loss: 0.004567\n","Epoch:  1573 | train loss: 0.001710 | valid loss: 0.004596\n","Epoch:  1574 | train loss: 0.001903 | valid loss: 0.004455\n","Epoch:  1575 | train loss: 0.001788 | valid loss: 0.004623\n","Epoch:  1576 | train loss: 0.001764 | valid loss: 0.004530\n","Epoch:  1577 | train loss: 0.002330 | valid loss: 0.004520\n","Epoch:  1578 | train loss: 0.002379 | valid loss: 0.004716\n","Epoch:  1579 | train loss: 0.002518 | valid loss: 0.004708\n","Epoch:  1580 | train loss: 0.002555 | valid loss: 0.004692\n","Epoch:  1581 | train loss: 0.002124 | valid loss: 0.004499\n","Epoch:  1582 | train loss: 0.002133 | valid loss: 0.004538\n","Epoch:  1583 | train loss: 0.002177 | valid loss: 0.004488\n","Epoch:  1584 | train loss: 0.002312 | valid loss: 0.004526\n","Epoch:  1585 | train loss: 0.001774 | valid loss: 0.004618\n","Epoch:  1586 | train loss: 0.002200 | valid loss: 0.004713\n","Epoch:  1587 | train loss: 0.002042 | valid loss: 0.004738\n","Epoch:  1588 | train loss: 0.001948 | valid loss: 0.004654\n","Epoch:  1589 | train loss: 0.001559 | valid loss: 0.004491\n","Epoch:  1590 | train loss: 0.001231 | valid loss: 0.004614\n","Epoch:  1591 | train loss: 0.001802 | valid loss: 0.004583\n","Epoch:  1592 | train loss: 0.001130 | valid loss: 0.004613\n","Epoch:  1593 | train loss: 0.002189 | valid loss: 0.004631\n","Epoch:  1594 | train loss: 0.001818 | valid loss: 0.004526\n","Epoch:  1595 | train loss: 0.001865 | valid loss: 0.004587\n","Epoch:  1596 | train loss: 0.001662 | valid loss: 0.004573\n","Epoch:  1597 | train loss: 0.002273 | valid loss: 0.004545\n","Epoch:  1598 | train loss: 0.001906 | valid loss: 0.004657\n","Epoch:  1599 | train loss: 0.001691 | valid loss: 0.004728\n","Epoch:  1600 | train loss: 0.002058 | valid loss: 0.004727\n","Epoch:  1601 | train loss: 0.001871 | valid loss: 0.004646\n","Epoch:  1602 | train loss: 0.002042 | valid loss: 0.004653\n","Epoch:  1603 | train loss: 0.002464 | valid loss: 0.004685\n","Epoch:  1604 | train loss: 0.002178 | valid loss: 0.004567\n","Epoch:  1605 | train loss: 0.001734 | valid loss: 0.004566\n","Epoch:  1606 | train loss: 0.002618 | valid loss: 0.004610\n","Epoch:  1607 | train loss: 0.001492 | valid loss: 0.004687\n","Epoch:  1608 | train loss: 0.002832 | valid loss: 0.004543\n","Epoch:  1609 | train loss: 0.002456 | valid loss: 0.004589\n","Epoch:  1610 | train loss: 0.002341 | valid loss: 0.004547\n","Epoch:  1611 | train loss: 0.001866 | valid loss: 0.004684\n","Epoch:  1612 | train loss: 0.002290 | valid loss: 0.004591\n","Epoch:  1613 | train loss: 0.003141 | valid loss: 0.004586\n","Epoch:  1614 | train loss: 0.002854 | valid loss: 0.004517\n","Epoch:  1615 | train loss: 0.002331 | valid loss: 0.004736\n","Epoch:  1616 | train loss: 0.002692 | valid loss: 0.004735\n","Epoch:  1617 | train loss: 0.001898 | valid loss: 0.004621\n","Epoch:  1618 | train loss: 0.002089 | valid loss: 0.004530\n","Epoch:  1619 | train loss: 0.001998 | valid loss: 0.004662\n","Epoch:  1620 | train loss: 0.002483 | valid loss: 0.004620\n","Epoch:  1621 | train loss: 0.001994 | valid loss: 0.004715\n","Epoch:  1622 | train loss: 0.002132 | valid loss: 0.004777\n","Epoch:  1623 | train loss: 0.001624 | valid loss: 0.004599\n","Epoch:  1624 | train loss: 0.001837 | valid loss: 0.004651\n","Epoch:  1625 | train loss: 0.002736 | valid loss: 0.004747\n","Epoch:  1626 | train loss: 0.002385 | valid loss: 0.004594\n","Epoch:  1627 | train loss: 0.001670 | valid loss: 0.004600\n","Epoch:  1628 | train loss: 0.002296 | valid loss: 0.004546\n","Epoch:  1629 | train loss: 0.001700 | valid loss: 0.004586\n","Epoch:  1630 | train loss: 0.002174 | valid loss: 0.004692\n","Epoch:  1631 | train loss: 0.002990 | valid loss: 0.004766\n","Epoch:  1632 | train loss: 0.002133 | valid loss: 0.004586\n","Epoch:  1633 | train loss: 0.002495 | valid loss: 0.004660\n","Epoch:  1634 | train loss: 0.002451 | valid loss: 0.004760\n","Epoch:  1635 | train loss: 0.001625 | valid loss: 0.004628\n","Epoch:  1636 | train loss: 0.001793 | valid loss: 0.004534\n","Epoch:  1637 | train loss: 0.001370 | valid loss: 0.004527\n","Epoch:  1638 | train loss: 0.001859 | valid loss: 0.004617\n","Epoch:  1639 | train loss: 0.002168 | valid loss: 0.004685\n","Epoch:  1640 | train loss: 0.001919 | valid loss: 0.004693\n","Epoch:  1641 | train loss: 0.001796 | valid loss: 0.004592\n","Epoch:  1642 | train loss: 0.001883 | valid loss: 0.004696\n","Epoch:  1643 | train loss: 0.001669 | valid loss: 0.004687\n","Epoch:  1644 | train loss: 0.001842 | valid loss: 0.004716\n","Epoch:  1645 | train loss: 0.001542 | valid loss: 0.004630\n","Epoch:  1646 | train loss: 0.002234 | valid loss: 0.004708\n","Epoch:  1647 | train loss: 0.002062 | valid loss: 0.004601\n","Epoch:  1648 | train loss: 0.002013 | valid loss: 0.004589\n","Epoch:  1649 | train loss: 0.002325 | valid loss: 0.004758\n","Epoch:  1650 | train loss: 0.001382 | valid loss: 0.004697\n","Epoch:  1651 | train loss: 0.002012 | valid loss: 0.004713\n","Epoch:  1652 | train loss: 0.001448 | valid loss: 0.004829\n","Epoch:  1653 | train loss: 0.001705 | valid loss: 0.004548\n","Epoch:  1654 | train loss: 0.002415 | valid loss: 0.004612\n","Epoch:  1655 | train loss: 0.003776 | valid loss: 0.004578\n","Epoch:  1656 | train loss: 0.002251 | valid loss: 0.004556\n","Epoch:  1657 | train loss: 0.001777 | valid loss: 0.004671\n","Epoch:  1658 | train loss: 0.002652 | valid loss: 0.004535\n","Epoch:  1659 | train loss: 0.001742 | valid loss: 0.004752\n","Epoch:  1660 | train loss: 0.001696 | valid loss: 0.004633\n","Epoch:  1661 | train loss: 0.002505 | valid loss: 0.004718\n","Epoch:  1662 | train loss: 0.001376 | valid loss: 0.004646\n","Epoch:  1663 | train loss: 0.002461 | valid loss: 0.004797\n","Epoch:  1664 | train loss: 0.001494 | valid loss: 0.004668\n","Epoch:  1665 | train loss: 0.001796 | valid loss: 0.004808\n","Epoch:  1666 | train loss: 0.001811 | valid loss: 0.004758\n","Epoch:  1667 | train loss: 0.002371 | valid loss: 0.004813\n","Epoch:  1668 | train loss: 0.002202 | valid loss: 0.004689\n","Epoch:  1669 | train loss: 0.001763 | valid loss: 0.004643\n","Epoch:  1670 | train loss: 0.001731 | valid loss: 0.004552\n","Epoch:  1671 | train loss: 0.002383 | valid loss: 0.004457\n","Epoch:  1672 | train loss: 0.002117 | valid loss: 0.004513\n","Epoch:  1673 | train loss: 0.002301 | valid loss: 0.004579\n","Epoch:  1674 | train loss: 0.001654 | valid loss: 0.004536\n","Epoch:  1675 | train loss: 0.001740 | valid loss: 0.004708\n","Epoch:  1676 | train loss: 0.002224 | valid loss: 0.004688\n","Epoch:  1677 | train loss: 0.002161 | valid loss: 0.004737\n","Epoch:  1678 | train loss: 0.001492 | valid loss: 0.004719\n","Epoch:  1679 | train loss: 0.001462 | valid loss: 0.004608\n","Epoch:  1680 | train loss: 0.002234 | valid loss: 0.004682\n","Epoch:  1681 | train loss: 0.001986 | valid loss: 0.004622\n","Epoch:  1682 | train loss: 0.002142 | valid loss: 0.004775\n","Epoch:  1683 | train loss: 0.001832 | valid loss: 0.004803\n","Epoch:  1684 | train loss: 0.002270 | valid loss: 0.004665\n","Epoch:  1685 | train loss: 0.002143 | valid loss: 0.004667\n","Epoch:  1686 | train loss: 0.001653 | valid loss: 0.004723\n","Epoch:  1687 | train loss: 0.002177 | valid loss: 0.004702\n","Epoch:  1688 | train loss: 0.001847 | valid loss: 0.004669\n","Epoch:  1689 | train loss: 0.001405 | valid loss: 0.004759\n","Epoch:  1690 | train loss: 0.001766 | valid loss: 0.004593\n","Epoch:  1691 | train loss: 0.002158 | valid loss: 0.004727\n","Epoch:  1692 | train loss: 0.002316 | valid loss: 0.004649\n","Epoch:  1693 | train loss: 0.001576 | valid loss: 0.004667\n","Epoch:  1694 | train loss: 0.001889 | valid loss: 0.004547\n","Epoch:  1695 | train loss: 0.002145 | valid loss: 0.004572\n","Epoch:  1696 | train loss: 0.002800 | valid loss: 0.004707\n","Epoch:  1697 | train loss: 0.001891 | valid loss: 0.004555\n","Epoch:  1698 | train loss: 0.001767 | valid loss: 0.004621\n","Epoch:  1699 | train loss: 0.002019 | valid loss: 0.004703\n","Epoch:  1700 | train loss: 0.001690 | valid loss: 0.004798\n","Epoch:  1701 | train loss: 0.002505 | valid loss: 0.004790\n","Epoch:  1702 | train loss: 0.001566 | valid loss: 0.004726\n","Epoch:  1703 | train loss: 0.001683 | valid loss: 0.004755\n","Epoch:  1704 | train loss: 0.002461 | valid loss: 0.004627\n","Epoch:  1705 | train loss: 0.001974 | valid loss: 0.004516\n","Epoch:  1706 | train loss: 0.001748 | valid loss: 0.004601\n","Epoch:  1707 | train loss: 0.002151 | valid loss: 0.004697\n","Epoch:  1708 | train loss: 0.002248 | valid loss: 0.004632\n","Epoch:  1709 | train loss: 0.002610 | valid loss: 0.004586\n","Epoch:  1710 | train loss: 0.002215 | valid loss: 0.004883\n","Epoch:  1711 | train loss: 0.002409 | valid loss: 0.004867\n","Epoch:  1712 | train loss: 0.001473 | valid loss: 0.004726\n","Epoch:  1713 | train loss: 0.002328 | valid loss: 0.004786\n","Epoch:  1714 | train loss: 0.001825 | valid loss: 0.004747\n","Epoch:  1715 | train loss: 0.001328 | valid loss: 0.004606\n","Epoch:  1716 | train loss: 0.001825 | valid loss: 0.004747\n","Epoch:  1717 | train loss: 0.002107 | valid loss: 0.004776\n","Epoch:  1718 | train loss: 0.001604 | valid loss: 0.004714\n","Epoch:  1719 | train loss: 0.001669 | valid loss: 0.004755\n","Epoch:  1720 | train loss: 0.002965 | valid loss: 0.004807\n","Epoch:  1721 | train loss: 0.001556 | valid loss: 0.004681\n","Epoch:  1722 | train loss: 0.002958 | valid loss: 0.004676\n","Epoch:  1723 | train loss: 0.001806 | valid loss: 0.004669\n","Epoch:  1724 | train loss: 0.002611 | valid loss: 0.004661\n","Epoch:  1725 | train loss: 0.001804 | valid loss: 0.004706\n","Epoch:  1726 | train loss: 0.001955 | valid loss: 0.004636\n","Epoch:  1727 | train loss: 0.002471 | valid loss: 0.004693\n","Epoch:  1728 | train loss: 0.001697 | valid loss: 0.004774\n","Epoch:  1729 | train loss: 0.002362 | valid loss: 0.004766\n","Epoch:  1730 | train loss: 0.002449 | valid loss: 0.004717\n","Epoch:  1731 | train loss: 0.001920 | valid loss: 0.004707\n","Epoch:  1732 | train loss: 0.001950 | valid loss: 0.004697\n","Epoch:  1733 | train loss: 0.001712 | valid loss: 0.004575\n","Epoch:  1734 | train loss: 0.001597 | valid loss: 0.004714\n","Epoch:  1735 | train loss: 0.001795 | valid loss: 0.004577\n","Epoch:  1736 | train loss: 0.001650 | valid loss: 0.004716\n","Epoch:  1737 | train loss: 0.002203 | valid loss: 0.004668\n","Epoch:  1738 | train loss: 0.003167 | valid loss: 0.004866\n","Epoch:  1739 | train loss: 0.002133 | valid loss: 0.004777\n","Epoch:  1740 | train loss: 0.002049 | valid loss: 0.004656\n","Epoch:  1741 | train loss: 0.002264 | valid loss: 0.004699\n","Epoch:  1742 | train loss: 0.001760 | valid loss: 0.004836\n","Epoch:  1743 | train loss: 0.002276 | valid loss: 0.004691\n","Epoch:  1744 | train loss: 0.001626 | valid loss: 0.004820\n","Epoch:  1745 | train loss: 0.001854 | valid loss: 0.004530\n","Epoch:  1746 | train loss: 0.001940 | valid loss: 0.004626\n","Epoch:  1747 | train loss: 0.002351 | valid loss: 0.004671\n","Epoch:  1748 | train loss: 0.002050 | valid loss: 0.004655\n","Epoch:  1749 | train loss: 0.002230 | valid loss: 0.004666\n","Epoch:  1750 | train loss: 0.001705 | valid loss: 0.004653\n","Epoch:  1751 | train loss: 0.001848 | valid loss: 0.004743\n","Epoch:  1752 | train loss: 0.002817 | valid loss: 0.004891\n","Epoch:  1753 | train loss: 0.003140 | valid loss: 0.004802\n","Epoch:  1754 | train loss: 0.002005 | valid loss: 0.004821\n","Epoch:  1755 | train loss: 0.001770 | valid loss: 0.004762\n","Epoch:  1756 | train loss: 0.002306 | valid loss: 0.004802\n","Epoch:  1757 | train loss: 0.002651 | valid loss: 0.004659\n","Epoch:  1758 | train loss: 0.001668 | valid loss: 0.004655\n","Epoch:  1759 | train loss: 0.001092 | valid loss: 0.004585\n","Epoch:  1760 | train loss: 0.001823 | valid loss: 0.004725\n","Epoch:  1761 | train loss: 0.002615 | valid loss: 0.004591\n","Epoch:  1762 | train loss: 0.002503 | valid loss: 0.004568\n","Epoch:  1763 | train loss: 0.002169 | valid loss: 0.004672\n","Epoch:  1764 | train loss: 0.001936 | valid loss: 0.004639\n","Epoch:  1765 | train loss: 0.002809 | valid loss: 0.004696\n","Epoch:  1766 | train loss: 0.002392 | valid loss: 0.004736\n","Epoch:  1767 | train loss: 0.001670 | valid loss: 0.004553\n","Epoch:  1768 | train loss: 0.002744 | valid loss: 0.004599\n","Epoch:  1769 | train loss: 0.001403 | valid loss: 0.004556\n","Epoch:  1770 | train loss: 0.002406 | valid loss: 0.004630\n","Epoch:  1771 | train loss: 0.002940 | valid loss: 0.004688\n","Epoch:  1772 | train loss: 0.001569 | valid loss: 0.004701\n","Epoch:  1773 | train loss: 0.001832 | valid loss: 0.004628\n","Epoch:  1774 | train loss: 0.003185 | valid loss: 0.004640\n","Epoch:  1775 | train loss: 0.002805 | valid loss: 0.004565\n","Epoch:  1776 | train loss: 0.001525 | valid loss: 0.004651\n","Epoch:  1777 | train loss: 0.001956 | valid loss: 0.004564\n","Epoch:  1778 | train loss: 0.001541 | valid loss: 0.004668\n","Epoch:  1779 | train loss: 0.001477 | valid loss: 0.004621\n","Epoch:  1780 | train loss: 0.001131 | valid loss: 0.004656\n","Epoch:  1781 | train loss: 0.002246 | valid loss: 0.004749\n","Epoch:  1782 | train loss: 0.001651 | valid loss: 0.004755\n","Epoch:  1783 | train loss: 0.002211 | valid loss: 0.004705\n","Epoch:  1784 | train loss: 0.001312 | valid loss: 0.004789\n","Epoch:  1785 | train loss: 0.001861 | valid loss: 0.004599\n","Epoch:  1786 | train loss: 0.001785 | valid loss: 0.004854\n","Epoch:  1787 | train loss: 0.002383 | valid loss: 0.004602\n","Epoch:  1788 | train loss: 0.001738 | valid loss: 0.004570\n","Epoch:  1789 | train loss: 0.001664 | valid loss: 0.004732\n","Epoch:  1790 | train loss: 0.001740 | valid loss: 0.004662\n","Epoch:  1791 | train loss: 0.001806 | valid loss: 0.004683\n","Epoch:  1792 | train loss: 0.002229 | valid loss: 0.004643\n","Epoch:  1793 | train loss: 0.002776 | valid loss: 0.004644\n","Epoch:  1794 | train loss: 0.002635 | valid loss: 0.004598\n","Epoch:  1795 | train loss: 0.001273 | valid loss: 0.004656\n","Epoch:  1796 | train loss: 0.002671 | valid loss: 0.004536\n","Epoch:  1797 | train loss: 0.001978 | valid loss: 0.004647\n","Epoch:  1798 | train loss: 0.002075 | valid loss: 0.004707\n","Epoch:  1799 | train loss: 0.002373 | valid loss: 0.004766\n","Epoch:  1800 | train loss: 0.002431 | valid loss: 0.004735\n","Epoch:  1801 | train loss: 0.001983 | valid loss: 0.004774\n","Epoch:  1802 | train loss: 0.002006 | valid loss: 0.004674\n","Epoch:  1803 | train loss: 0.001955 | valid loss: 0.004590\n","Epoch:  1804 | train loss: 0.002263 | valid loss: 0.004773\n","Epoch:  1805 | train loss: 0.002637 | valid loss: 0.004637\n","Epoch:  1806 | train loss: 0.001834 | valid loss: 0.004670\n","Epoch:  1807 | train loss: 0.001487 | valid loss: 0.004748\n","Epoch:  1808 | train loss: 0.002000 | valid loss: 0.005033\n","Epoch:  1809 | train loss: 0.002294 | valid loss: 0.004875\n","Epoch:  1810 | train loss: 0.005225 | valid loss: 0.004692\n","Epoch:  1811 | train loss: 0.002741 | valid loss: 0.004786\n","Epoch:  1812 | train loss: 0.001938 | valid loss: 0.004818\n","Epoch:  1813 | train loss: 0.002078 | valid loss: 0.004670\n","Epoch:  1814 | train loss: 0.003619 | valid loss: 0.004742\n","Epoch:  1815 | train loss: 0.002394 | valid loss: 0.004824\n","Epoch:  1816 | train loss: 0.002779 | valid loss: 0.004838\n","Epoch:  1817 | train loss: 0.001751 | valid loss: 0.004816\n","Epoch:  1818 | train loss: 0.003103 | valid loss: 0.004762\n","Epoch:  1819 | train loss: 0.003016 | valid loss: 0.004587\n","Epoch:  1820 | train loss: 0.001927 | valid loss: 0.004581\n","Epoch:  1821 | train loss: 0.002576 | valid loss: 0.004604\n","Epoch:  1822 | train loss: 0.002428 | valid loss: 0.004608\n","Epoch:  1823 | train loss: 0.001886 | valid loss: 0.004661\n","Epoch:  1824 | train loss: 0.001715 | valid loss: 0.004482\n","Epoch:  1825 | train loss: 0.004515 | valid loss: 0.004604\n","Epoch:  1826 | train loss: 0.002087 | valid loss: 0.004724\n","Epoch:  1827 | train loss: 0.002852 | valid loss: 0.004745\n","Epoch:  1828 | train loss: 0.002260 | valid loss: 0.004905\n","Epoch:  1829 | train loss: 0.002318 | valid loss: 0.004683\n","Epoch:  1830 | train loss: 0.001567 | valid loss: 0.004806\n","Epoch:  1831 | train loss: 0.001721 | valid loss: 0.004671\n","Epoch:  1832 | train loss: 0.001728 | valid loss: 0.004697\n","Epoch:  1833 | train loss: 0.001462 | valid loss: 0.004745\n","Epoch:  1834 | train loss: 0.002219 | valid loss: 0.004754\n","Epoch:  1835 | train loss: 0.003608 | valid loss: 0.004951\n","Epoch:  1836 | train loss: 0.002207 | valid loss: 0.004924\n","Epoch:  1837 | train loss: 0.002690 | valid loss: 0.004555\n","Epoch:  1838 | train loss: 0.001754 | valid loss: 0.004601\n","Epoch:  1839 | train loss: 0.003161 | valid loss: 0.004522\n","Epoch:  1840 | train loss: 0.002393 | valid loss: 0.004611\n","Epoch:  1841 | train loss: 0.001447 | valid loss: 0.004589\n","Epoch:  1842 | train loss: 0.002654 | valid loss: 0.004607\n","Epoch:  1843 | train loss: 0.002602 | valid loss: 0.004672\n","Epoch:  1844 | train loss: 0.001949 | valid loss: 0.004598\n","Epoch:  1845 | train loss: 0.001631 | valid loss: 0.004795\n","Epoch:  1846 | train loss: 0.002501 | valid loss: 0.004863\n","Epoch:  1847 | train loss: 0.001932 | valid loss: 0.004671\n","Epoch:  1848 | train loss: 0.001898 | valid loss: 0.004767\n","Epoch:  1849 | train loss: 0.001533 | valid loss: 0.004683\n","Epoch:  1850 | train loss: 0.001928 | valid loss: 0.004649\n","Epoch:  1851 | train loss: 0.002691 | valid loss: 0.004636\n","Epoch:  1852 | train loss: 0.002086 | valid loss: 0.004548\n","Epoch:  1853 | train loss: 0.001749 | valid loss: 0.004666\n","Epoch:  1854 | train loss: 0.002089 | valid loss: 0.004789\n","Epoch:  1855 | train loss: 0.001457 | valid loss: 0.004594\n","Epoch:  1856 | train loss: 0.002450 | valid loss: 0.004807\n","Epoch:  1857 | train loss: 0.002262 | valid loss: 0.004754\n","Epoch:  1858 | train loss: 0.002106 | valid loss: 0.004740\n","Epoch:  1859 | train loss: 0.002159 | valid loss: 0.004979\n","Epoch:  1860 | train loss: 0.002285 | valid loss: 0.004873\n","Epoch:  1861 | train loss: 0.001445 | valid loss: 0.004736\n","Epoch:  1862 | train loss: 0.002284 | valid loss: 0.004732\n","Epoch:  1863 | train loss: 0.001464 | valid loss: 0.004666\n","Epoch:  1864 | train loss: 0.002153 | valid loss: 0.004774\n","Epoch:  1865 | train loss: 0.001564 | valid loss: 0.004771\n","Epoch:  1866 | train loss: 0.002963 | valid loss: 0.004798\n","Epoch:  1867 | train loss: 0.001381 | valid loss: 0.004659\n","Epoch:  1868 | train loss: 0.001020 | valid loss: 0.004588\n","Epoch:  1869 | train loss: 0.001549 | valid loss: 0.004610\n","Epoch:  1870 | train loss: 0.002736 | valid loss: 0.004585\n","Epoch:  1871 | train loss: 0.001668 | valid loss: 0.004601\n","Epoch:  1872 | train loss: 0.002192 | valid loss: 0.004765\n","Epoch:  1873 | train loss: 0.002467 | valid loss: 0.004776\n","Epoch:  1874 | train loss: 0.002121 | valid loss: 0.004799\n","Epoch:  1875 | train loss: 0.001405 | valid loss: 0.004728\n","Epoch:  1876 | train loss: 0.001969 | valid loss: 0.004625\n","Epoch:  1877 | train loss: 0.002917 | valid loss: 0.004617\n","Epoch:  1878 | train loss: 0.001590 | valid loss: 0.004632\n","Epoch:  1879 | train loss: 0.001850 | valid loss: 0.004577\n","Epoch:  1880 | train loss: 0.002532 | valid loss: 0.004587\n","Epoch:  1881 | train loss: 0.001732 | valid loss: 0.004574\n","Epoch:  1882 | train loss: 0.002759 | valid loss: 0.004718\n","Epoch:  1883 | train loss: 0.001816 | valid loss: 0.004644\n","Epoch:  1884 | train loss: 0.002665 | valid loss: 0.004756\n","Epoch:  1885 | train loss: 0.001622 | valid loss: 0.004714\n","Epoch:  1886 | train loss: 0.001989 | valid loss: 0.004786\n","Epoch:  1887 | train loss: 0.002363 | valid loss: 0.005007\n","Epoch:  1888 | train loss: 0.002615 | valid loss: 0.004787\n","Epoch:  1889 | train loss: 0.001946 | valid loss: 0.004644\n","Epoch:  1890 | train loss: 0.001683 | valid loss: 0.004715\n","Epoch:  1891 | train loss: 0.002637 | valid loss: 0.004684\n","Epoch:  1892 | train loss: 0.002351 | valid loss: 0.004626\n","Epoch:  1893 | train loss: 0.002258 | valid loss: 0.004639\n","Epoch:  1894 | train loss: 0.002266 | valid loss: 0.004673\n","Epoch:  1895 | train loss: 0.002303 | valid loss: 0.004675\n","Epoch:  1896 | train loss: 0.001260 | valid loss: 0.004719\n","Epoch:  1897 | train loss: 0.001663 | valid loss: 0.004733\n","Epoch:  1898 | train loss: 0.002558 | valid loss: 0.004859\n","Epoch:  1899 | train loss: 0.001706 | valid loss: 0.004767\n","Epoch:  1900 | train loss: 0.002166 | valid loss: 0.005054\n","Epoch:  1901 | train loss: 0.002659 | valid loss: 0.004660\n","Epoch:  1902 | train loss: 0.001948 | valid loss: 0.004835\n","Epoch:  1903 | train loss: 0.002767 | valid loss: 0.004740\n","Epoch:  1904 | train loss: 0.001618 | valid loss: 0.004909\n","Epoch:  1905 | train loss: 0.002479 | valid loss: 0.004738\n","Epoch:  1906 | train loss: 0.002544 | valid loss: 0.004713\n","Epoch:  1907 | train loss: 0.002113 | valid loss: 0.004736\n","Epoch:  1908 | train loss: 0.001938 | valid loss: 0.004702\n","Epoch:  1909 | train loss: 0.001595 | valid loss: 0.004632\n","Epoch:  1910 | train loss: 0.002320 | valid loss: 0.004602\n","Epoch:  1911 | train loss: 0.001425 | valid loss: 0.004630\n","Epoch:  1912 | train loss: 0.001881 | valid loss: 0.004676\n","Epoch:  1913 | train loss: 0.001626 | valid loss: 0.004905\n","Epoch:  1914 | train loss: 0.001985 | valid loss: 0.004816\n","Epoch:  1915 | train loss: 0.002278 | valid loss: 0.004657\n","Epoch:  1916 | train loss: 0.002760 | valid loss: 0.004746\n","Epoch:  1917 | train loss: 0.001794 | valid loss: 0.004581\n","Epoch:  1918 | train loss: 0.001659 | valid loss: 0.004777\n","Epoch:  1919 | train loss: 0.001361 | valid loss: 0.004605\n","Epoch:  1920 | train loss: 0.002120 | valid loss: 0.004744\n","Epoch:  1921 | train loss: 0.001669 | valid loss: 0.004724\n","Epoch:  1922 | train loss: 0.001804 | valid loss: 0.004687\n","Epoch:  1923 | train loss: 0.002595 | valid loss: 0.004999\n","Epoch:  1924 | train loss: 0.004294 | valid loss: 0.004869\n","Epoch:  1925 | train loss: 0.002436 | valid loss: 0.004582\n","Epoch:  1926 | train loss: 0.002348 | valid loss: 0.004787\n","Epoch:  1927 | train loss: 0.001432 | valid loss: 0.004769\n","Epoch:  1928 | train loss: 0.002080 | valid loss: 0.004678\n","Epoch:  1929 | train loss: 0.001579 | valid loss: 0.004583\n","Epoch:  1930 | train loss: 0.001340 | valid loss: 0.004661\n","Epoch:  1931 | train loss: 0.001794 | valid loss: 0.004744\n","Epoch:  1932 | train loss: 0.001122 | valid loss: 0.004817\n","Epoch:  1933 | train loss: 0.002340 | valid loss: 0.004753\n","Epoch:  1934 | train loss: 0.002771 | valid loss: 0.004723\n","Epoch:  1935 | train loss: 0.002338 | valid loss: 0.004614\n","Epoch:  1936 | train loss: 0.002653 | valid loss: 0.004842\n","Epoch:  1937 | train loss: 0.002329 | valid loss: 0.004772\n","Epoch:  1938 | train loss: 0.003781 | valid loss: 0.004677\n","Epoch:  1939 | train loss: 0.002686 | valid loss: 0.004758\n","Epoch:  1940 | train loss: 0.002160 | valid loss: 0.005019\n","Epoch:  1941 | train loss: 0.002549 | valid loss: 0.004838\n","Epoch:  1942 | train loss: 0.002172 | valid loss: 0.004730\n","Epoch:  1943 | train loss: 0.001750 | valid loss: 0.004790\n","Epoch:  1944 | train loss: 0.002433 | valid loss: 0.004759\n","Epoch:  1945 | train loss: 0.002208 | valid loss: 0.004735\n","Epoch:  1946 | train loss: 0.003186 | valid loss: 0.004718\n","Epoch:  1947 | train loss: 0.002225 | valid loss: 0.004728\n","Epoch:  1948 | train loss: 0.001912 | valid loss: 0.004748\n","Epoch:  1949 | train loss: 0.001814 | valid loss: 0.004842\n","Epoch:  1950 | train loss: 0.002251 | valid loss: 0.004721\n","Epoch:  1951 | train loss: 0.001182 | valid loss: 0.004624\n","Epoch:  1952 | train loss: 0.001255 | valid loss: 0.004714\n","Epoch:  1953 | train loss: 0.002082 | valid loss: 0.004595\n","Epoch:  1954 | train loss: 0.001649 | valid loss: 0.004735\n","Epoch:  1955 | train loss: 0.002672 | valid loss: 0.004972\n","Epoch:  1956 | train loss: 0.003116 | valid loss: 0.004714\n","Epoch:  1957 | train loss: 0.002146 | valid loss: 0.004789\n","Epoch:  1958 | train loss: 0.001859 | valid loss: 0.004772\n","Epoch:  1959 | train loss: 0.002786 | valid loss: 0.004724\n","Epoch:  1960 | train loss: 0.002150 | valid loss: 0.004739\n","Epoch:  1961 | train loss: 0.002873 | valid loss: 0.004766\n","Epoch:  1962 | train loss: 0.002546 | valid loss: 0.004727\n","Epoch:  1963 | train loss: 0.002342 | valid loss: 0.004860\n","Epoch:  1964 | train loss: 0.001510 | valid loss: 0.004790\n","Epoch:  1965 | train loss: 0.002523 | valid loss: 0.004717\n","Epoch:  1966 | train loss: 0.001596 | valid loss: 0.004637\n","Epoch:  1967 | train loss: 0.002470 | valid loss: 0.004783\n","Epoch:  1968 | train loss: 0.001643 | valid loss: 0.004775\n","Epoch:  1969 | train loss: 0.001469 | valid loss: 0.004925\n","Epoch:  1970 | train loss: 0.001964 | valid loss: 0.004622\n","Epoch:  1971 | train loss: 0.002615 | valid loss: 0.004786\n","Epoch:  1972 | train loss: 0.002184 | valid loss: 0.004778\n","Epoch:  1973 | train loss: 0.001691 | valid loss: 0.004605\n","Epoch:  1974 | train loss: 0.001995 | valid loss: 0.004679\n","Epoch:  1975 | train loss: 0.001262 | valid loss: 0.004654\n","Epoch:  1976 | train loss: 0.002206 | valid loss: 0.004808\n","Epoch:  1977 | train loss: 0.001974 | valid loss: 0.004918\n","Epoch:  1978 | train loss: 0.002736 | valid loss: 0.004783\n","Epoch:  1979 | train loss: 0.002676 | valid loss: 0.004893\n","Epoch:  1980 | train loss: 0.002316 | valid loss: 0.004868\n","Epoch:  1981 | train loss: 0.001929 | valid loss: 0.004789\n","Epoch:  1982 | train loss: 0.001964 | valid loss: 0.004695\n","Epoch:  1983 | train loss: 0.002358 | valid loss: 0.004769\n","Epoch:  1984 | train loss: 0.001893 | valid loss: 0.004684\n","Epoch:  1985 | train loss: 0.001771 | valid loss: 0.004609\n","Epoch:  1986 | train loss: 0.003245 | valid loss: 0.004707\n","Epoch:  1987 | train loss: 0.001639 | valid loss: 0.004640\n","Epoch:  1988 | train loss: 0.002298 | valid loss: 0.004721\n","Epoch:  1989 | train loss: 0.002142 | valid loss: 0.004724\n","Epoch:  1990 | train loss: 0.002941 | valid loss: 0.004849\n","Epoch:  1991 | train loss: 0.002089 | valid loss: 0.004855\n","Epoch:  1992 | train loss: 0.002684 | valid loss: 0.004987\n","Epoch:  1993 | train loss: 0.002108 | valid loss: 0.004785\n","Epoch:  1994 | train loss: 0.002627 | valid loss: 0.004776\n","Epoch:  1995 | train loss: 0.002244 | valid loss: 0.004770\n","Epoch:  1996 | train loss: 0.002483 | valid loss: 0.004640\n","Epoch:  1997 | train loss: 0.001755 | valid loss: 0.004751\n","Epoch:  1998 | train loss: 0.002243 | valid loss: 0.004619\n","Epoch:  1999 | train loss: 0.002098 | valid loss: 0.004789\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mAjmfk8Cdb6C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629656626198,"user_tz":-60,"elapsed":32,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"721f4690-3604-4cfb-9339-03e429483727"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Train time: 339.24222207069397\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"u5ksuAnM1qpz","executionInfo":{"status":"ok","timestamp":1629656627290,"user_tz":-60,"elapsed":1106,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"9e2399d0-9947-4699-8b9d-269abdd83be0"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtzYkOB4NKa8","executionInfo":{"status":"ok","timestamp":1629656641234,"user_tz":-60,"elapsed":9600,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"19d7fab1-b8a6-4c30-840f-3742ff451c14"},"source":["t_pre_0 = time.time()\n","encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","t_pre_1 = time.time()\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","t_pre_2 = time.time()\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","t_pre_3 = time.time()\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())\n","print(\"Prediction time: \",t_pre_3 - t_pre_2 + t_pre_1 - t_pre_0)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 7.810613870249324e-05\n","MSE_err of valid data 0.00018667691873052502\n","MSE_err of test data 0.00016113375176323867\n","MSE_err of total data 9.726597892927583e-05\n","Prediction time:  3.5831544399261475\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-OjCo1s01X0l"},"source":["##### Convert csv to vtu"]},{"cell_type":"code","metadata":{"id":"DgP6ILa80yhN","executionInfo":{"status":"ok","timestamp":1629655566307,"user_tz":-60,"elapsed":1549,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["# total_decoded[:, :, 0] = (total_decoded[:, :, 0] - bu)/ku\n","# total_decoded[:, :, 1] = (total_decoded[:, :, 1] - bv)/kv\n","\n","# total_data[:, :, 3] = (total_data[:, :, 3] - bu)/ku\n","# total_data[:, :, 4] = (total_data[:, :, 4] - bv)/kv"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKJ3ksur1XIz","executionInfo":{"status":"ok","timestamp":1629652533510,"user_tz":-60,"elapsed":82676,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"42a8ae32-5d58-4312-b4e5-d92f98024808"},"source":["# results = np.concatenate((training_decoded.cpu().data.numpy(), valid_decoded.cpu().data.numpy(), test_decoded.cpu().data.numpy()))\n","Latent_num = 64\n","results = total_decoded\n","print('results shape', results.shape)\n","N = results.shape[1] * results.shape[2]\n","results = results.reshape((results.shape[0],N), order='F')\n","print('results shape', results.shape, type(results))\n","# The path can be defined by user depending on the requirements\n","path = \"./SFC_CAE/SVDAE_II\"+\"_LV\"+str(Latent_num) + \"_B\"+str(BATCH_SIZE)+'E_'+str(2000)+\"_result.csv\"\n","# write results to file\n","np.savetxt(path, results , delimiter=',')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["results shape (2000, 20550, 2)\n","results shape (2000, 41100) <class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C0gMimTKAxe4","executionInfo":{"status":"ok","timestamp":1629655571230,"user_tz":-60,"elapsed":610,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}}},"source":["error = total_decoded - total_data[:, :, 3:5]"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRj1igdlA2f1","executionInfo":{"status":"ok","timestamp":1629655655558,"user_tz":-60,"elapsed":83716,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"3653ce2f-6e6b-4c27-8473-fcb0d4d3a04f"},"source":["# results = np.concatenate((training_decoded.cpu().data.numpy(), valid_decoded.cpu().data.numpy(), test_decoded.cpu().data.numpy()))\n","Latent_num = 64\n","results = error\n","print('results shape', results.shape)\n","N = results.shape[1] * results.shape[2]\n","results = results.reshape((results.shape[0],N), order='F')\n","print('results shape', results.shape, type(results))\n","# The path can be defined by user depending on the requirements\n","path = \"./SFC_CAE/SVDAE\"+\"_LV\"+str(Latent_num) + \"_B\"+str(BATCH_SIZE)+'E_'+str(2000)+\"_error.csv\"\n","# write results to file\n","np.savetxt(path, results , delimiter=',')"],"execution_count":87,"outputs":[{"output_type":"stream","text":["results shape (2000, 20550, 2)\n","results shape (2000, 41100) <class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BAspD25n1sJh"},"source":["#### 128 variable"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqR0RuO31yuH","executionInfo":{"status":"ok","timestamp":1629653848796,"user_tz":-60,"elapsed":28,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"193c033d-8fe9-4b55-89e6-f865a1f89619"},"source":["print(\"compress to 128\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 2000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["compress to 128\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoBFUAe_12Sa","executionInfo":{"status":"ok","timestamp":1629654086786,"user_tz":-60,"elapsed":238007,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"f61407ae-110d-4bce-c2a1-3f9eda2cb949"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(128).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 0.958752 | valid loss: 0.973674\n","Epoch:  1 | train loss: 0.135198 | valid loss: 0.126030\n","Epoch:  2 | train loss: 0.092240 | valid loss: 0.075568\n","Epoch:  3 | train loss: 0.065874 | valid loss: 0.060051\n","Epoch:  4 | train loss: 0.052634 | valid loss: 0.048782\n","Epoch:  5 | train loss: 0.055738 | valid loss: 0.042834\n","Epoch:  6 | train loss: 0.031382 | valid loss: 0.038251\n","Epoch:  7 | train loss: 0.030692 | valid loss: 0.032892\n","Epoch:  8 | train loss: 0.023432 | valid loss: 0.030827\n","Epoch:  9 | train loss: 0.028454 | valid loss: 0.027518\n","Epoch:  10 | train loss: 0.036840 | valid loss: 0.025655\n","Epoch:  11 | train loss: 0.022831 | valid loss: 0.023902\n","Epoch:  12 | train loss: 0.013873 | valid loss: 0.022002\n","Epoch:  13 | train loss: 0.029140 | valid loss: 0.021164\n","Epoch:  14 | train loss: 0.027350 | valid loss: 0.019283\n","Epoch:  15 | train loss: 0.022627 | valid loss: 0.018040\n","Epoch:  16 | train loss: 0.016004 | valid loss: 0.017549\n","Epoch:  17 | train loss: 0.019731 | valid loss: 0.016680\n","Epoch:  18 | train loss: 0.012462 | valid loss: 0.015644\n","Epoch:  19 | train loss: 0.018235 | valid loss: 0.015820\n","Epoch:  20 | train loss: 0.022681 | valid loss: 0.014859\n","Epoch:  21 | train loss: 0.011118 | valid loss: 0.013910\n","Epoch:  22 | train loss: 0.011133 | valid loss: 0.013598\n","Epoch:  23 | train loss: 0.018501 | valid loss: 0.012588\n","Epoch:  24 | train loss: 0.009956 | valid loss: 0.012115\n","Epoch:  25 | train loss: 0.009461 | valid loss: 0.011997\n","Epoch:  26 | train loss: 0.012743 | valid loss: 0.011939\n","Epoch:  27 | train loss: 0.017945 | valid loss: 0.011179\n","Epoch:  28 | train loss: 0.010538 | valid loss: 0.011736\n","Epoch:  29 | train loss: 0.008021 | valid loss: 0.011738\n","Epoch:  30 | train loss: 0.014586 | valid loss: 0.009651\n","Epoch:  31 | train loss: 0.008491 | valid loss: 0.009233\n","Epoch:  32 | train loss: 0.014563 | valid loss: 0.008913\n","Epoch:  33 | train loss: 0.009289 | valid loss: 0.008916\n","Epoch:  34 | train loss: 0.010056 | valid loss: 0.008383\n","Epoch:  35 | train loss: 0.012481 | valid loss: 0.008544\n","Epoch:  36 | train loss: 0.007226 | valid loss: 0.008141\n","Epoch:  37 | train loss: 0.006828 | valid loss: 0.008086\n","Epoch:  38 | train loss: 0.008062 | valid loss: 0.008151\n","Epoch:  39 | train loss: 0.008156 | valid loss: 0.007922\n","Epoch:  40 | train loss: 0.010191 | valid loss: 0.008156\n","Epoch:  41 | train loss: 0.008094 | valid loss: 0.007406\n","Epoch:  42 | train loss: 0.006757 | valid loss: 0.006963\n","Epoch:  43 | train loss: 0.006430 | valid loss: 0.007238\n","Epoch:  44 | train loss: 0.007608 | valid loss: 0.007009\n","Epoch:  45 | train loss: 0.006123 | valid loss: 0.007189\n","Epoch:  46 | train loss: 0.005767 | valid loss: 0.006315\n","Epoch:  47 | train loss: 0.004366 | valid loss: 0.006339\n","Epoch:  48 | train loss: 0.007140 | valid loss: 0.006281\n","Epoch:  49 | train loss: 0.005891 | valid loss: 0.006281\n","Epoch:  50 | train loss: 0.004701 | valid loss: 0.005922\n","Epoch:  51 | train loss: 0.006170 | valid loss: 0.005969\n","Epoch:  52 | train loss: 0.003827 | valid loss: 0.005603\n","Epoch:  53 | train loss: 0.004641 | valid loss: 0.005551\n","Epoch:  54 | train loss: 0.004703 | valid loss: 0.005722\n","Epoch:  55 | train loss: 0.005809 | valid loss: 0.005783\n","Epoch:  56 | train loss: 0.006175 | valid loss: 0.005514\n","Epoch:  57 | train loss: 0.004259 | valid loss: 0.005541\n","Epoch:  58 | train loss: 0.006356 | valid loss: 0.005599\n","Epoch:  59 | train loss: 0.006330 | valid loss: 0.005369\n","Epoch:  60 | train loss: 0.004317 | valid loss: 0.005177\n","Epoch:  61 | train loss: 0.004665 | valid loss: 0.005367\n","Epoch:  62 | train loss: 0.004894 | valid loss: 0.005030\n","Epoch:  63 | train loss: 0.004603 | valid loss: 0.005355\n","Epoch:  64 | train loss: 0.003727 | valid loss: 0.005010\n","Epoch:  65 | train loss: 0.004235 | valid loss: 0.005065\n","Epoch:  66 | train loss: 0.003474 | valid loss: 0.004880\n","Epoch:  67 | train loss: 0.005460 | valid loss: 0.005164\n","Epoch:  68 | train loss: 0.003215 | valid loss: 0.004888\n","Epoch:  69 | train loss: 0.004396 | valid loss: 0.004831\n","Epoch:  70 | train loss: 0.005087 | valid loss: 0.005359\n","Epoch:  71 | train loss: 0.003017 | valid loss: 0.004535\n","Epoch:  72 | train loss: 0.004222 | valid loss: 0.004676\n","Epoch:  73 | train loss: 0.004493 | valid loss: 0.004472\n","Epoch:  74 | train loss: 0.003812 | valid loss: 0.004485\n","Epoch:  75 | train loss: 0.004685 | valid loss: 0.004632\n","Epoch:  76 | train loss: 0.004515 | valid loss: 0.004606\n","Epoch:  77 | train loss: 0.003250 | valid loss: 0.004285\n","Epoch:  78 | train loss: 0.004386 | valid loss: 0.004088\n","Epoch:  79 | train loss: 0.003677 | valid loss: 0.004210\n","Epoch:  80 | train loss: 0.002802 | valid loss: 0.004240\n","Epoch:  81 | train loss: 0.003520 | valid loss: 0.004247\n","Epoch:  82 | train loss: 0.003801 | valid loss: 0.004414\n","Epoch:  83 | train loss: 0.003614 | valid loss: 0.003991\n","Epoch:  84 | train loss: 0.003531 | valid loss: 0.004211\n","Epoch:  85 | train loss: 0.002220 | valid loss: 0.003993\n","Epoch:  86 | train loss: 0.003074 | valid loss: 0.004085\n","Epoch:  87 | train loss: 0.002938 | valid loss: 0.004464\n","Epoch:  88 | train loss: 0.003792 | valid loss: 0.004015\n","Epoch:  89 | train loss: 0.003601 | valid loss: 0.004263\n","Epoch:  90 | train loss: 0.004033 | valid loss: 0.003877\n","Epoch:  91 | train loss: 0.003387 | valid loss: 0.003886\n","Epoch:  92 | train loss: 0.004266 | valid loss: 0.003855\n","Epoch:  93 | train loss: 0.002871 | valid loss: 0.003713\n","Epoch:  94 | train loss: 0.002689 | valid loss: 0.003703\n","Epoch:  95 | train loss: 0.003273 | valid loss: 0.003779\n","Epoch:  96 | train loss: 0.003170 | valid loss: 0.004268\n","Epoch:  97 | train loss: 0.004432 | valid loss: 0.003687\n","Epoch:  98 | train loss: 0.003550 | valid loss: 0.003975\n","Epoch:  99 | train loss: 0.003498 | valid loss: 0.003718\n","Epoch:  100 | train loss: 0.002908 | valid loss: 0.003507\n","Epoch:  101 | train loss: 0.003786 | valid loss: 0.003611\n","Epoch:  102 | train loss: 0.002943 | valid loss: 0.003768\n","Epoch:  103 | train loss: 0.003490 | valid loss: 0.003784\n","Epoch:  104 | train loss: 0.003184 | valid loss: 0.003607\n","Epoch:  105 | train loss: 0.002852 | valid loss: 0.003623\n","Epoch:  106 | train loss: 0.002360 | valid loss: 0.003460\n","Epoch:  107 | train loss: 0.003716 | valid loss: 0.003704\n","Epoch:  108 | train loss: 0.002161 | valid loss: 0.003553\n","Epoch:  109 | train loss: 0.002960 | valid loss: 0.003611\n","Epoch:  110 | train loss: 0.002757 | valid loss: 0.003425\n","Epoch:  111 | train loss: 0.002885 | valid loss: 0.003656\n","Epoch:  112 | train loss: 0.002416 | valid loss: 0.003376\n","Epoch:  113 | train loss: 0.002383 | valid loss: 0.003357\n","Epoch:  114 | train loss: 0.003264 | valid loss: 0.003347\n","Epoch:  115 | train loss: 0.002385 | valid loss: 0.003255\n","Epoch:  116 | train loss: 0.002373 | valid loss: 0.003155\n","Epoch:  117 | train loss: 0.002772 | valid loss: 0.003421\n","Epoch:  118 | train loss: 0.002276 | valid loss: 0.003314\n","Epoch:  119 | train loss: 0.002191 | valid loss: 0.003173\n","Epoch:  120 | train loss: 0.002379 | valid loss: 0.003374\n","Epoch:  121 | train loss: 0.002271 | valid loss: 0.003425\n","Epoch:  122 | train loss: 0.001938 | valid loss: 0.003288\n","Epoch:  123 | train loss: 0.003048 | valid loss: 0.003416\n","Epoch:  124 | train loss: 0.002148 | valid loss: 0.003012\n","Epoch:  125 | train loss: 0.002081 | valid loss: 0.003139\n","Epoch:  126 | train loss: 0.002907 | valid loss: 0.003758\n","Epoch:  127 | train loss: 0.003466 | valid loss: 0.003352\n","Epoch:  128 | train loss: 0.002177 | valid loss: 0.002998\n","Epoch:  129 | train loss: 0.002154 | valid loss: 0.003035\n","Epoch:  130 | train loss: 0.002390 | valid loss: 0.003264\n","Epoch:  131 | train loss: 0.001810 | valid loss: 0.003207\n","Epoch:  132 | train loss: 0.002281 | valid loss: 0.003034\n","Epoch:  133 | train loss: 0.002009 | valid loss: 0.002967\n","Epoch:  134 | train loss: 0.002228 | valid loss: 0.003002\n","Epoch:  135 | train loss: 0.001636 | valid loss: 0.002934\n","Epoch:  136 | train loss: 0.002211 | valid loss: 0.003147\n","Epoch:  137 | train loss: 0.003135 | valid loss: 0.003131\n","Epoch:  138 | train loss: 0.002200 | valid loss: 0.003102\n","Epoch:  139 | train loss: 0.002165 | valid loss: 0.003021\n","Epoch:  140 | train loss: 0.001974 | valid loss: 0.002870\n","Epoch:  141 | train loss: 0.002402 | valid loss: 0.002940\n","Epoch:  142 | train loss: 0.002831 | valid loss: 0.003040\n","Epoch:  143 | train loss: 0.002695 | valid loss: 0.002840\n","Epoch:  144 | train loss: 0.002257 | valid loss: 0.002968\n","Epoch:  145 | train loss: 0.002055 | valid loss: 0.002851\n","Epoch:  146 | train loss: 0.001972 | valid loss: 0.002845\n","Epoch:  147 | train loss: 0.002381 | valid loss: 0.002961\n","Epoch:  148 | train loss: 0.002206 | valid loss: 0.003160\n","Epoch:  149 | train loss: 0.002074 | valid loss: 0.002942\n","Epoch:  150 | train loss: 0.001912 | valid loss: 0.002799\n","Epoch:  151 | train loss: 0.002264 | valid loss: 0.002774\n","Epoch:  152 | train loss: 0.002521 | valid loss: 0.002873\n","Epoch:  153 | train loss: 0.001720 | valid loss: 0.002806\n","Epoch:  154 | train loss: 0.002435 | valid loss: 0.002846\n","Epoch:  155 | train loss: 0.002228 | valid loss: 0.002662\n","Epoch:  156 | train loss: 0.001664 | valid loss: 0.002866\n","Epoch:  157 | train loss: 0.003311 | valid loss: 0.002979\n","Epoch:  158 | train loss: 0.001791 | valid loss: 0.002885\n","Epoch:  159 | train loss: 0.002106 | valid loss: 0.002823\n","Epoch:  160 | train loss: 0.002449 | valid loss: 0.002855\n","Epoch:  161 | train loss: 0.001757 | valid loss: 0.002898\n","Epoch:  162 | train loss: 0.002006 | valid loss: 0.002654\n","Epoch:  163 | train loss: 0.002147 | valid loss: 0.002820\n","Epoch:  164 | train loss: 0.001525 | valid loss: 0.002787\n","Epoch:  165 | train loss: 0.002202 | valid loss: 0.002838\n","Epoch:  166 | train loss: 0.001921 | valid loss: 0.002622\n","Epoch:  167 | train loss: 0.002130 | valid loss: 0.002752\n","Epoch:  168 | train loss: 0.002295 | valid loss: 0.002691\n","Epoch:  169 | train loss: 0.003927 | valid loss: 0.002894\n","Epoch:  170 | train loss: 0.001882 | valid loss: 0.002915\n","Epoch:  171 | train loss: 0.002003 | valid loss: 0.002549\n","Epoch:  172 | train loss: 0.001858 | valid loss: 0.002702\n","Epoch:  173 | train loss: 0.002601 | valid loss: 0.002678\n","Epoch:  174 | train loss: 0.001842 | valid loss: 0.002550\n","Epoch:  175 | train loss: 0.002266 | valid loss: 0.002656\n","Epoch:  176 | train loss: 0.001923 | valid loss: 0.002600\n","Epoch:  177 | train loss: 0.001558 | valid loss: 0.002522\n","Epoch:  178 | train loss: 0.002753 | valid loss: 0.003012\n","Epoch:  179 | train loss: 0.001661 | valid loss: 0.002971\n","Epoch:  180 | train loss: 0.002058 | valid loss: 0.002569\n","Epoch:  181 | train loss: 0.002050 | valid loss: 0.002769\n","Epoch:  182 | train loss: 0.002065 | valid loss: 0.002514\n","Epoch:  183 | train loss: 0.002077 | valid loss: 0.002552\n","Epoch:  184 | train loss: 0.001910 | valid loss: 0.002545\n","Epoch:  185 | train loss: 0.001393 | valid loss: 0.002453\n","Epoch:  186 | train loss: 0.001668 | valid loss: 0.002510\n","Epoch:  187 | train loss: 0.001488 | valid loss: 0.002634\n","Epoch:  188 | train loss: 0.001920 | valid loss: 0.002363\n","Epoch:  189 | train loss: 0.001301 | valid loss: 0.002451\n","Epoch:  190 | train loss: 0.001604 | valid loss: 0.002644\n","Epoch:  191 | train loss: 0.003127 | valid loss: 0.002933\n","Epoch:  192 | train loss: 0.001674 | valid loss: 0.002576\n","Epoch:  193 | train loss: 0.001919 | valid loss: 0.002442\n","Epoch:  194 | train loss: 0.002139 | valid loss: 0.002436\n","Epoch:  195 | train loss: 0.001703 | valid loss: 0.002382\n","Epoch:  196 | train loss: 0.001935 | valid loss: 0.002340\n","Epoch:  197 | train loss: 0.002189 | valid loss: 0.002454\n","Epoch:  198 | train loss: 0.001764 | valid loss: 0.002573\n","Epoch:  199 | train loss: 0.001450 | valid loss: 0.002446\n","Epoch:  200 | train loss: 0.001498 | valid loss: 0.002380\n","Epoch:  201 | train loss: 0.002777 | valid loss: 0.002541\n","Epoch:  202 | train loss: 0.001559 | valid loss: 0.002456\n","Epoch:  203 | train loss: 0.001683 | valid loss: 0.002312\n","Epoch:  204 | train loss: 0.001841 | valid loss: 0.002442\n","Epoch:  205 | train loss: 0.001648 | valid loss: 0.002412\n","Epoch:  206 | train loss: 0.002514 | valid loss: 0.002473\n","Epoch:  207 | train loss: 0.001594 | valid loss: 0.002568\n","Epoch:  208 | train loss: 0.002090 | valid loss: 0.002700\n","Epoch:  209 | train loss: 0.001532 | valid loss: 0.002432\n","Epoch:  210 | train loss: 0.001494 | valid loss: 0.002337\n","Epoch:  211 | train loss: 0.001535 | valid loss: 0.002303\n","Epoch:  212 | train loss: 0.001492 | valid loss: 0.002509\n","Epoch:  213 | train loss: 0.001600 | valid loss: 0.002455\n","Epoch:  214 | train loss: 0.001690 | valid loss: 0.002278\n","Epoch:  215 | train loss: 0.001692 | valid loss: 0.002416\n","Epoch:  216 | train loss: 0.001633 | valid loss: 0.002414\n","Epoch:  217 | train loss: 0.001724 | valid loss: 0.002254\n","Epoch:  218 | train loss: 0.001403 | valid loss: 0.002245\n","Epoch:  219 | train loss: 0.001552 | valid loss: 0.002369\n","Epoch:  220 | train loss: 0.001548 | valid loss: 0.002320\n","Epoch:  221 | train loss: 0.001351 | valid loss: 0.002390\n","Epoch:  222 | train loss: 0.001565 | valid loss: 0.002460\n","Epoch:  223 | train loss: 0.001762 | valid loss: 0.002292\n","Epoch:  224 | train loss: 0.001785 | valid loss: 0.002298\n","Epoch:  225 | train loss: 0.001258 | valid loss: 0.002377\n","Epoch:  226 | train loss: 0.001484 | valid loss: 0.002574\n","Epoch:  227 | train loss: 0.001310 | valid loss: 0.002432\n","Epoch:  228 | train loss: 0.002026 | valid loss: 0.002343\n","Epoch:  229 | train loss: 0.001245 | valid loss: 0.002256\n","Epoch:  230 | train loss: 0.001586 | valid loss: 0.002349\n","Epoch:  231 | train loss: 0.001140 | valid loss: 0.002203\n","Epoch:  232 | train loss: 0.001469 | valid loss: 0.002396\n","Epoch:  233 | train loss: 0.001578 | valid loss: 0.002314\n","Epoch:  234 | train loss: 0.001680 | valid loss: 0.002586\n","Epoch:  235 | train loss: 0.001545 | valid loss: 0.002370\n","Epoch:  236 | train loss: 0.001122 | valid loss: 0.002319\n","Epoch:  237 | train loss: 0.001272 | valid loss: 0.002502\n","Epoch:  238 | train loss: 0.001387 | valid loss: 0.002346\n","Epoch:  239 | train loss: 0.002101 | valid loss: 0.002535\n","Epoch:  240 | train loss: 0.001402 | valid loss: 0.002291\n","Epoch:  241 | train loss: 0.001783 | valid loss: 0.002430\n","Epoch:  242 | train loss: 0.001263 | valid loss: 0.002266\n","Epoch:  243 | train loss: 0.001065 | valid loss: 0.002200\n","Epoch:  244 | train loss: 0.001256 | valid loss: 0.002261\n","Epoch:  245 | train loss: 0.001567 | valid loss: 0.002285\n","Epoch:  246 | train loss: 0.002453 | valid loss: 0.002296\n","Epoch:  247 | train loss: 0.001547 | valid loss: 0.002363\n","Epoch:  248 | train loss: 0.000991 | valid loss: 0.002161\n","Epoch:  249 | train loss: 0.001643 | valid loss: 0.002442\n","Epoch:  250 | train loss: 0.001258 | valid loss: 0.002222\n","Epoch:  251 | train loss: 0.001418 | valid loss: 0.002194\n","Epoch:  252 | train loss: 0.001222 | valid loss: 0.002223\n","Epoch:  253 | train loss: 0.001579 | valid loss: 0.002235\n","Epoch:  254 | train loss: 0.001381 | valid loss: 0.002227\n","Epoch:  255 | train loss: 0.001808 | valid loss: 0.002276\n","Epoch:  256 | train loss: 0.001623 | valid loss: 0.002363\n","Epoch:  257 | train loss: 0.001362 | valid loss: 0.002241\n","Epoch:  258 | train loss: 0.001271 | valid loss: 0.002181\n","Epoch:  259 | train loss: 0.001422 | valid loss: 0.002228\n","Epoch:  260 | train loss: 0.001308 | valid loss: 0.002318\n","Epoch:  261 | train loss: 0.001419 | valid loss: 0.002284\n","Epoch:  262 | train loss: 0.001629 | valid loss: 0.002186\n","Epoch:  263 | train loss: 0.001363 | valid loss: 0.002273\n","Epoch:  264 | train loss: 0.001501 | valid loss: 0.002082\n","Epoch:  265 | train loss: 0.001309 | valid loss: 0.002246\n","Epoch:  266 | train loss: 0.001426 | valid loss: 0.002116\n","Epoch:  267 | train loss: 0.001196 | valid loss: 0.002261\n","Epoch:  268 | train loss: 0.001260 | valid loss: 0.002173\n","Epoch:  269 | train loss: 0.001439 | valid loss: 0.002275\n","Epoch:  270 | train loss: 0.001180 | valid loss: 0.002325\n","Epoch:  271 | train loss: 0.001261 | valid loss: 0.002239\n","Epoch:  272 | train loss: 0.001399 | valid loss: 0.002125\n","Epoch:  273 | train loss: 0.001449 | valid loss: 0.002216\n","Epoch:  274 | train loss: 0.001190 | valid loss: 0.002233\n","Epoch:  275 | train loss: 0.001446 | valid loss: 0.002197\n","Epoch:  276 | train loss: 0.001668 | valid loss: 0.002137\n","Epoch:  277 | train loss: 0.001832 | valid loss: 0.002111\n","Epoch:  278 | train loss: 0.001394 | valid loss: 0.002143\n","Epoch:  279 | train loss: 0.001223 | valid loss: 0.002116\n","Epoch:  280 | train loss: 0.001249 | valid loss: 0.002346\n","Epoch:  281 | train loss: 0.001247 | valid loss: 0.002208\n","Epoch:  282 | train loss: 0.001235 | valid loss: 0.002454\n","Epoch:  283 | train loss: 0.001306 | valid loss: 0.002150\n","Epoch:  284 | train loss: 0.000987 | valid loss: 0.002103\n","Epoch:  285 | train loss: 0.001348 | valid loss: 0.002150\n","Epoch:  286 | train loss: 0.001407 | valid loss: 0.002142\n","Epoch:  287 | train loss: 0.001191 | valid loss: 0.002212\n","Epoch:  288 | train loss: 0.000954 | valid loss: 0.002146\n","Epoch:  289 | train loss: 0.000998 | valid loss: 0.002108\n","Epoch:  290 | train loss: 0.001004 | valid loss: 0.002142\n","Epoch:  291 | train loss: 0.001250 | valid loss: 0.002112\n","Epoch:  292 | train loss: 0.001398 | valid loss: 0.002274\n","Epoch:  293 | train loss: 0.001657 | valid loss: 0.002192\n","Epoch:  294 | train loss: 0.001295 | valid loss: 0.002129\n","Epoch:  295 | train loss: 0.001365 | valid loss: 0.002081\n","Epoch:  296 | train loss: 0.001452 | valid loss: 0.002108\n","Epoch:  297 | train loss: 0.001409 | valid loss: 0.002262\n","Epoch:  298 | train loss: 0.001077 | valid loss: 0.002135\n","Epoch:  299 | train loss: 0.001456 | valid loss: 0.002359\n","Epoch:  300 | train loss: 0.001613 | valid loss: 0.002246\n","Epoch:  301 | train loss: 0.000958 | valid loss: 0.002175\n","Epoch:  302 | train loss: 0.001246 | valid loss: 0.002046\n","Epoch:  303 | train loss: 0.001431 | valid loss: 0.002029\n","Epoch:  304 | train loss: 0.001417 | valid loss: 0.002144\n","Epoch:  305 | train loss: 0.001420 | valid loss: 0.002045\n","Epoch:  306 | train loss: 0.001013 | valid loss: 0.002170\n","Epoch:  307 | train loss: 0.001027 | valid loss: 0.002264\n","Epoch:  308 | train loss: 0.001265 | valid loss: 0.002187\n","Epoch:  309 | train loss: 0.001239 | valid loss: 0.002109\n","Epoch:  310 | train loss: 0.000897 | valid loss: 0.002133\n","Epoch:  311 | train loss: 0.001145 | valid loss: 0.002138\n","Epoch:  312 | train loss: 0.002792 | valid loss: 0.002404\n","Epoch:  313 | train loss: 0.001318 | valid loss: 0.002259\n","Epoch:  314 | train loss: 0.001451 | valid loss: 0.002148\n","Epoch:  315 | train loss: 0.001118 | valid loss: 0.002162\n","Epoch:  316 | train loss: 0.000978 | valid loss: 0.002229\n","Epoch:  317 | train loss: 0.001141 | valid loss: 0.002214\n","Epoch:  318 | train loss: 0.001236 | valid loss: 0.002173\n","Epoch:  319 | train loss: 0.001402 | valid loss: 0.002155\n","Epoch:  320 | train loss: 0.001004 | valid loss: 0.002079\n","Epoch:  321 | train loss: 0.000960 | valid loss: 0.002130\n","Epoch:  322 | train loss: 0.001204 | valid loss: 0.002140\n","Epoch:  323 | train loss: 0.000794 | valid loss: 0.002098\n","Epoch:  324 | train loss: 0.000911 | valid loss: 0.002034\n","Epoch:  325 | train loss: 0.001086 | valid loss: 0.002104\n","Epoch:  326 | train loss: 0.001108 | valid loss: 0.002241\n","Epoch:  327 | train loss: 0.001491 | valid loss: 0.002157\n","Epoch:  328 | train loss: 0.001236 | valid loss: 0.002038\n","Epoch:  329 | train loss: 0.001026 | valid loss: 0.002084\n","Epoch:  330 | train loss: 0.001073 | valid loss: 0.002194\n","Epoch:  331 | train loss: 0.001348 | valid loss: 0.002220\n","Epoch:  332 | train loss: 0.000920 | valid loss: 0.002130\n","Epoch:  333 | train loss: 0.001756 | valid loss: 0.002140\n","Epoch:  334 | train loss: 0.001210 | valid loss: 0.002139\n","Epoch:  335 | train loss: 0.000849 | valid loss: 0.002085\n","Epoch:  336 | train loss: 0.001116 | valid loss: 0.002179\n","Epoch:  337 | train loss: 0.001194 | valid loss: 0.002250\n","Epoch:  338 | train loss: 0.001432 | valid loss: 0.002059\n","Epoch:  339 | train loss: 0.001322 | valid loss: 0.002127\n","Epoch:  340 | train loss: 0.001219 | valid loss: 0.002128\n","Epoch:  341 | train loss: 0.001027 | valid loss: 0.002171\n","Epoch:  342 | train loss: 0.001178 | valid loss: 0.002094\n","Epoch:  343 | train loss: 0.001017 | valid loss: 0.002057\n","Epoch:  344 | train loss: 0.001264 | valid loss: 0.002161\n","Epoch:  345 | train loss: 0.001505 | valid loss: 0.002070\n","Epoch:  346 | train loss: 0.001018 | valid loss: 0.002148\n","Epoch:  347 | train loss: 0.000815 | valid loss: 0.002030\n","Epoch:  348 | train loss: 0.001276 | valid loss: 0.002110\n","Epoch:  349 | train loss: 0.001545 | valid loss: 0.002175\n","Epoch:  350 | train loss: 0.001374 | valid loss: 0.002258\n","Epoch:  351 | train loss: 0.001606 | valid loss: 0.002154\n","Epoch:  352 | train loss: 0.001175 | valid loss: 0.002039\n","Epoch:  353 | train loss: 0.000672 | valid loss: 0.002115\n","Epoch:  354 | train loss: 0.001231 | valid loss: 0.002076\n","Epoch:  355 | train loss: 0.001079 | valid loss: 0.002211\n","Epoch:  356 | train loss: 0.000952 | valid loss: 0.002112\n","Epoch:  357 | train loss: 0.001068 | valid loss: 0.002116\n","Epoch:  358 | train loss: 0.001045 | valid loss: 0.002056\n","Epoch:  359 | train loss: 0.001226 | valid loss: 0.002126\n","Epoch:  360 | train loss: 0.001171 | valid loss: 0.002188\n","Epoch:  361 | train loss: 0.001330 | valid loss: 0.002161\n","Epoch:  362 | train loss: 0.001222 | valid loss: 0.002240\n","Epoch:  363 | train loss: 0.001202 | valid loss: 0.002357\n","Epoch:  364 | train loss: 0.001181 | valid loss: 0.002165\n","Epoch:  365 | train loss: 0.001182 | valid loss: 0.002077\n","Epoch:  366 | train loss: 0.000968 | valid loss: 0.002074\n","Epoch:  367 | train loss: 0.001120 | valid loss: 0.002182\n","Epoch:  368 | train loss: 0.000941 | valid loss: 0.002062\n","Epoch:  369 | train loss: 0.000898 | valid loss: 0.002031\n","Epoch:  370 | train loss: 0.001068 | valid loss: 0.002040\n","Epoch:  371 | train loss: 0.000894 | valid loss: 0.002070\n","Epoch:  372 | train loss: 0.000818 | valid loss: 0.002076\n","Epoch:  373 | train loss: 0.000909 | valid loss: 0.002110\n","Epoch:  374 | train loss: 0.001148 | valid loss: 0.002070\n","Epoch:  375 | train loss: 0.001147 | valid loss: 0.002324\n","Epoch:  376 | train loss: 0.000957 | valid loss: 0.002184\n","Epoch:  377 | train loss: 0.000976 | valid loss: 0.002131\n","Epoch:  378 | train loss: 0.002408 | valid loss: 0.002183\n","Epoch:  379 | train loss: 0.001087 | valid loss: 0.002006\n","Epoch:  380 | train loss: 0.001372 | valid loss: 0.001951\n","Epoch:  381 | train loss: 0.000751 | valid loss: 0.001997\n","Epoch:  382 | train loss: 0.001238 | valid loss: 0.002040\n","Epoch:  383 | train loss: 0.000681 | valid loss: 0.002135\n","Epoch:  384 | train loss: 0.001293 | valid loss: 0.002086\n","Epoch:  385 | train loss: 0.001816 | valid loss: 0.002249\n","Epoch:  386 | train loss: 0.001243 | valid loss: 0.002004\n","Epoch:  387 | train loss: 0.001328 | valid loss: 0.002070\n","Epoch:  388 | train loss: 0.000909 | valid loss: 0.002041\n","Epoch:  389 | train loss: 0.001661 | valid loss: 0.002168\n","Epoch:  390 | train loss: 0.001063 | valid loss: 0.002107\n","Epoch:  391 | train loss: 0.001370 | valid loss: 0.002064\n","Epoch:  392 | train loss: 0.001092 | valid loss: 0.002178\n","Epoch:  393 | train loss: 0.000926 | valid loss: 0.002199\n","Epoch:  394 | train loss: 0.001092 | valid loss: 0.002072\n","Epoch:  395 | train loss: 0.000987 | valid loss: 0.002061\n","Epoch:  396 | train loss: 0.001187 | valid loss: 0.002060\n","Epoch:  397 | train loss: 0.001066 | valid loss: 0.002183\n","Epoch:  398 | train loss: 0.001110 | valid loss: 0.002124\n","Epoch:  399 | train loss: 0.000836 | valid loss: 0.002186\n","Epoch:  400 | train loss: 0.001179 | valid loss: 0.002146\n","Epoch:  401 | train loss: 0.001057 | valid loss: 0.002117\n","Epoch:  402 | train loss: 0.000987 | valid loss: 0.002073\n","Epoch:  403 | train loss: 0.001348 | valid loss: 0.002202\n","Epoch:  404 | train loss: 0.001051 | valid loss: 0.002089\n","Epoch:  405 | train loss: 0.000882 | valid loss: 0.002038\n","Epoch:  406 | train loss: 0.001323 | valid loss: 0.001975\n","Epoch:  407 | train loss: 0.001082 | valid loss: 0.002109\n","Epoch:  408 | train loss: 0.001068 | valid loss: 0.002120\n","Epoch:  409 | train loss: 0.001732 | valid loss: 0.002280\n","Epoch:  410 | train loss: 0.000775 | valid loss: 0.002036\n","Epoch:  411 | train loss: 0.001201 | valid loss: 0.002052\n","Epoch:  412 | train loss: 0.001154 | valid loss: 0.002203\n","Epoch:  413 | train loss: 0.000970 | valid loss: 0.002165\n","Epoch:  414 | train loss: 0.001443 | valid loss: 0.002058\n","Epoch:  415 | train loss: 0.000815 | valid loss: 0.002118\n","Epoch:  416 | train loss: 0.000979 | valid loss: 0.002299\n","Epoch:  417 | train loss: 0.001078 | valid loss: 0.002119\n","Epoch:  418 | train loss: 0.000920 | valid loss: 0.002101\n","Epoch:  419 | train loss: 0.001483 | valid loss: 0.002208\n","Epoch:  420 | train loss: 0.001001 | valid loss: 0.002059\n","Epoch:  421 | train loss: 0.001163 | valid loss: 0.002017\n","Epoch:  422 | train loss: 0.000955 | valid loss: 0.002034\n","Epoch:  423 | train loss: 0.000723 | valid loss: 0.001982\n","Epoch:  424 | train loss: 0.000740 | valid loss: 0.002138\n","Epoch:  425 | train loss: 0.001409 | valid loss: 0.002144\n","Epoch:  426 | train loss: 0.001188 | valid loss: 0.002083\n","Epoch:  427 | train loss: 0.001199 | valid loss: 0.002335\n","Epoch:  428 | train loss: 0.001155 | valid loss: 0.002486\n","Epoch:  429 | train loss: 0.001118 | valid loss: 0.002100\n","Epoch:  430 | train loss: 0.000873 | valid loss: 0.002105\n","Epoch:  431 | train loss: 0.001019 | valid loss: 0.002123\n","Epoch:  432 | train loss: 0.000945 | valid loss: 0.002044\n","Epoch:  433 | train loss: 0.000795 | valid loss: 0.002117\n","Epoch:  434 | train loss: 0.001198 | valid loss: 0.002069\n","Epoch:  435 | train loss: 0.001524 | valid loss: 0.002172\n","Epoch:  436 | train loss: 0.001298 | valid loss: 0.002198\n","Epoch:  437 | train loss: 0.001235 | valid loss: 0.002143\n","Epoch:  438 | train loss: 0.001065 | valid loss: 0.002070\n","Epoch:  439 | train loss: 0.001093 | valid loss: 0.002133\n","Epoch:  440 | train loss: 0.001201 | valid loss: 0.002214\n","Epoch:  441 | train loss: 0.001483 | valid loss: 0.002173\n","Epoch:  442 | train loss: 0.001655 | valid loss: 0.002242\n","Epoch:  443 | train loss: 0.000798 | valid loss: 0.002194\n","Epoch:  444 | train loss: 0.001032 | valid loss: 0.002189\n","Epoch:  445 | train loss: 0.000944 | valid loss: 0.002183\n","Epoch:  446 | train loss: 0.000825 | valid loss: 0.002064\n","Epoch:  447 | train loss: 0.000834 | valid loss: 0.002005\n","Epoch:  448 | train loss: 0.001382 | valid loss: 0.002098\n","Epoch:  449 | train loss: 0.000969 | valid loss: 0.002191\n","Epoch:  450 | train loss: 0.000962 | valid loss: 0.002123\n","Epoch:  451 | train loss: 0.000928 | valid loss: 0.002074\n","Epoch:  452 | train loss: 0.000774 | valid loss: 0.002104\n","Epoch:  453 | train loss: 0.000913 | valid loss: 0.002122\n","Epoch:  454 | train loss: 0.001114 | valid loss: 0.002181\n","Epoch:  455 | train loss: 0.001063 | valid loss: 0.002145\n","Epoch:  456 | train loss: 0.000829 | valid loss: 0.002068\n","Epoch:  457 | train loss: 0.000798 | valid loss: 0.001993\n","Epoch:  458 | train loss: 0.001130 | valid loss: 0.002068\n","Epoch:  459 | train loss: 0.001516 | valid loss: 0.002169\n","Epoch:  460 | train loss: 0.000967 | valid loss: 0.002225\n","Epoch:  461 | train loss: 0.001305 | valid loss: 0.002101\n","Epoch:  462 | train loss: 0.001686 | valid loss: 0.002278\n","Epoch:  463 | train loss: 0.001145 | valid loss: 0.002195\n","Epoch:  464 | train loss: 0.001236 | valid loss: 0.002092\n","Epoch:  465 | train loss: 0.001175 | valid loss: 0.002074\n","Epoch:  466 | train loss: 0.000859 | valid loss: 0.002237\n","Epoch:  467 | train loss: 0.000712 | valid loss: 0.002093\n","Epoch:  468 | train loss: 0.000963 | valid loss: 0.002131\n","Epoch:  469 | train loss: 0.000666 | valid loss: 0.002122\n","Epoch:  470 | train loss: 0.000900 | valid loss: 0.002149\n","Epoch:  471 | train loss: 0.001232 | valid loss: 0.002100\n","Epoch:  472 | train loss: 0.000903 | valid loss: 0.002279\n","Epoch:  473 | train loss: 0.001404 | valid loss: 0.002209\n","Epoch:  474 | train loss: 0.001019 | valid loss: 0.002162\n","Epoch:  475 | train loss: 0.001138 | valid loss: 0.002175\n","Epoch:  476 | train loss: 0.001105 | valid loss: 0.002197\n","Epoch:  477 | train loss: 0.000717 | valid loss: 0.002153\n","Epoch:  478 | train loss: 0.001151 | valid loss: 0.002194\n","Epoch:  479 | train loss: 0.001160 | valid loss: 0.002066\n","Epoch:  480 | train loss: 0.002388 | valid loss: 0.002149\n","Epoch:  481 | train loss: 0.000913 | valid loss: 0.002102\n","Epoch:  482 | train loss: 0.001070 | valid loss: 0.002124\n","Epoch:  483 | train loss: 0.000651 | valid loss: 0.002202\n","Epoch:  484 | train loss: 0.001442 | valid loss: 0.002142\n","Epoch:  485 | train loss: 0.001001 | valid loss: 0.002064\n","Epoch:  486 | train loss: 0.001085 | valid loss: 0.002079\n","Epoch:  487 | train loss: 0.001063 | valid loss: 0.002076\n","Epoch:  488 | train loss: 0.000891 | valid loss: 0.002037\n","Epoch:  489 | train loss: 0.001036 | valid loss: 0.002101\n","Epoch:  490 | train loss: 0.000918 | valid loss: 0.002127\n","Epoch:  491 | train loss: 0.000978 | valid loss: 0.002091\n","Epoch:  492 | train loss: 0.001152 | valid loss: 0.002292\n","Epoch:  493 | train loss: 0.001012 | valid loss: 0.002233\n","Epoch:  494 | train loss: 0.001261 | valid loss: 0.002300\n","Epoch:  495 | train loss: 0.002143 | valid loss: 0.002298\n","Epoch:  496 | train loss: 0.001195 | valid loss: 0.002233\n","Epoch:  497 | train loss: 0.001053 | valid loss: 0.002237\n","Epoch:  498 | train loss: 0.001051 | valid loss: 0.002176\n","Epoch:  499 | train loss: 0.000938 | valid loss: 0.002089\n","Epoch:  500 | train loss: 0.001037 | valid loss: 0.002068\n","Epoch:  501 | train loss: 0.000953 | valid loss: 0.002053\n","Epoch:  502 | train loss: 0.000827 | valid loss: 0.002048\n","Epoch:  503 | train loss: 0.000590 | valid loss: 0.002053\n","Epoch:  504 | train loss: 0.000944 | valid loss: 0.002073\n","Epoch:  505 | train loss: 0.001001 | valid loss: 0.002111\n","Epoch:  506 | train loss: 0.000757 | valid loss: 0.002060\n","Epoch:  507 | train loss: 0.001054 | valid loss: 0.002141\n","Epoch:  508 | train loss: 0.000730 | valid loss: 0.002221\n","Epoch:  509 | train loss: 0.000899 | valid loss: 0.002214\n","Epoch:  510 | train loss: 0.001051 | valid loss: 0.002223\n","Epoch:  511 | train loss: 0.001135 | valid loss: 0.002121\n","Epoch:  512 | train loss: 0.000825 | valid loss: 0.002139\n","Epoch:  513 | train loss: 0.001104 | valid loss: 0.002152\n","Epoch:  514 | train loss: 0.000957 | valid loss: 0.002123\n","Epoch:  515 | train loss: 0.000670 | valid loss: 0.002062\n","Epoch:  516 | train loss: 0.000992 | valid loss: 0.002146\n","Epoch:  517 | train loss: 0.001300 | valid loss: 0.002079\n","Epoch:  518 | train loss: 0.000947 | valid loss: 0.002257\n","Epoch:  519 | train loss: 0.000835 | valid loss: 0.002102\n","Epoch:  520 | train loss: 0.000762 | valid loss: 0.002160\n","Epoch:  521 | train loss: 0.000940 | valid loss: 0.002130\n","Epoch:  522 | train loss: 0.000850 | valid loss: 0.002068\n","Epoch:  523 | train loss: 0.000848 | valid loss: 0.002136\n","Epoch:  524 | train loss: 0.000880 | valid loss: 0.002080\n","Epoch:  525 | train loss: 0.001062 | valid loss: 0.002118\n","Epoch:  526 | train loss: 0.000768 | valid loss: 0.002118\n","Epoch:  527 | train loss: 0.001028 | valid loss: 0.002180\n","Epoch:  528 | train loss: 0.000774 | valid loss: 0.002071\n","Epoch:  529 | train loss: 0.000888 | valid loss: 0.002103\n","Epoch:  530 | train loss: 0.000987 | valid loss: 0.002345\n","Epoch:  531 | train loss: 0.001362 | valid loss: 0.002199\n","Epoch:  532 | train loss: 0.000958 | valid loss: 0.002068\n","Epoch:  533 | train loss: 0.001089 | valid loss: 0.002192\n","Epoch:  534 | train loss: 0.001261 | valid loss: 0.002278\n","Epoch:  535 | train loss: 0.000791 | valid loss: 0.002236\n","Epoch:  536 | train loss: 0.001111 | valid loss: 0.002128\n","Epoch:  537 | train loss: 0.001058 | valid loss: 0.002127\n","Epoch:  538 | train loss: 0.000839 | valid loss: 0.002192\n","Epoch:  539 | train loss: 0.000800 | valid loss: 0.002100\n","Epoch:  540 | train loss: 0.001555 | valid loss: 0.002251\n","Epoch:  541 | train loss: 0.000973 | valid loss: 0.002117\n","Epoch:  542 | train loss: 0.001070 | valid loss: 0.002125\n","Epoch:  543 | train loss: 0.001337 | valid loss: 0.002192\n","Epoch:  544 | train loss: 0.000859 | valid loss: 0.002177\n","Epoch:  545 | train loss: 0.000721 | valid loss: 0.002166\n","Epoch:  546 | train loss: 0.000741 | valid loss: 0.002053\n","Epoch:  547 | train loss: 0.001467 | valid loss: 0.002190\n","Epoch:  548 | train loss: 0.000953 | valid loss: 0.002129\n","Epoch:  549 | train loss: 0.000944 | valid loss: 0.002149\n","Epoch:  550 | train loss: 0.000707 | valid loss: 0.002161\n","Epoch:  551 | train loss: 0.000935 | valid loss: 0.002167\n","Epoch:  552 | train loss: 0.000724 | valid loss: 0.002162\n","Epoch:  553 | train loss: 0.000982 | valid loss: 0.002201\n","Epoch:  554 | train loss: 0.001207 | valid loss: 0.002288\n","Epoch:  555 | train loss: 0.000834 | valid loss: 0.002176\n","Epoch:  556 | train loss: 0.001075 | valid loss: 0.002184\n","Epoch:  557 | train loss: 0.001107 | valid loss: 0.002239\n","Epoch:  558 | train loss: 0.000822 | valid loss: 0.002085\n","Epoch:  559 | train loss: 0.001332 | valid loss: 0.002160\n","Epoch:  560 | train loss: 0.001055 | valid loss: 0.002184\n","Epoch:  561 | train loss: 0.001061 | valid loss: 0.002152\n","Epoch:  562 | train loss: 0.000937 | valid loss: 0.002117\n","Epoch:  563 | train loss: 0.000929 | valid loss: 0.002112\n","Epoch:  564 | train loss: 0.002115 | valid loss: 0.002165\n","Epoch:  565 | train loss: 0.000770 | valid loss: 0.002103\n","Epoch:  566 | train loss: 0.000881 | valid loss: 0.002195\n","Epoch:  567 | train loss: 0.000930 | valid loss: 0.002147\n","Epoch:  568 | train loss: 0.000803 | valid loss: 0.002263\n","Epoch:  569 | train loss: 0.000716 | valid loss: 0.002075\n","Epoch:  570 | train loss: 0.001018 | valid loss: 0.002180\n","Epoch:  571 | train loss: 0.001037 | valid loss: 0.002125\n","Epoch:  572 | train loss: 0.000959 | valid loss: 0.002230\n","Epoch:  573 | train loss: 0.000920 | valid loss: 0.002221\n","Epoch:  574 | train loss: 0.001362 | valid loss: 0.002191\n","Epoch:  575 | train loss: 0.000847 | valid loss: 0.002204\n","Epoch:  576 | train loss: 0.001250 | valid loss: 0.002133\n","Epoch:  577 | train loss: 0.001274 | valid loss: 0.002124\n","Epoch:  578 | train loss: 0.000757 | valid loss: 0.002144\n","Epoch:  579 | train loss: 0.001290 | valid loss: 0.002159\n","Epoch:  580 | train loss: 0.000907 | valid loss: 0.002164\n","Epoch:  581 | train loss: 0.000742 | valid loss: 0.002169\n","Epoch:  582 | train loss: 0.000711 | valid loss: 0.002179\n","Epoch:  583 | train loss: 0.000741 | valid loss: 0.002205\n","Epoch:  584 | train loss: 0.001369 | valid loss: 0.002257\n","Epoch:  585 | train loss: 0.000751 | valid loss: 0.002108\n","Epoch:  586 | train loss: 0.001393 | valid loss: 0.002317\n","Epoch:  587 | train loss: 0.001060 | valid loss: 0.002050\n","Epoch:  588 | train loss: 0.001088 | valid loss: 0.002145\n","Epoch:  589 | train loss: 0.000800 | valid loss: 0.002159\n","Epoch:  590 | train loss: 0.001181 | valid loss: 0.002185\n","Epoch:  591 | train loss: 0.001438 | valid loss: 0.002392\n","Epoch:  592 | train loss: 0.000773 | valid loss: 0.002090\n","Epoch:  593 | train loss: 0.001277 | valid loss: 0.002173\n","Epoch:  594 | train loss: 0.000802 | valid loss: 0.002248\n","Epoch:  595 | train loss: 0.001263 | valid loss: 0.002109\n","Epoch:  596 | train loss: 0.000941 | valid loss: 0.002098\n","Epoch:  597 | train loss: 0.000705 | valid loss: 0.002081\n","Epoch:  598 | train loss: 0.000858 | valid loss: 0.002096\n","Epoch:  599 | train loss: 0.000669 | valid loss: 0.002076\n","Epoch:  600 | train loss: 0.000664 | valid loss: 0.002103\n","Epoch:  601 | train loss: 0.001022 | valid loss: 0.002180\n","Epoch:  602 | train loss: 0.001170 | valid loss: 0.002438\n","Epoch:  603 | train loss: 0.001719 | valid loss: 0.002438\n","Epoch:  604 | train loss: 0.000929 | valid loss: 0.002265\n","Epoch:  605 | train loss: 0.001037 | valid loss: 0.002135\n","Epoch:  606 | train loss: 0.000643 | valid loss: 0.002018\n","Epoch:  607 | train loss: 0.001319 | valid loss: 0.002217\n","Epoch:  608 | train loss: 0.001211 | valid loss: 0.002124\n","Epoch:  609 | train loss: 0.001076 | valid loss: 0.002052\n","Epoch:  610 | train loss: 0.000944 | valid loss: 0.002203\n","Epoch:  611 | train loss: 0.000827 | valid loss: 0.002093\n","Epoch:  612 | train loss: 0.000729 | valid loss: 0.002150\n","Epoch:  613 | train loss: 0.000911 | valid loss: 0.002066\n","Epoch:  614 | train loss: 0.001104 | valid loss: 0.002323\n","Epoch:  615 | train loss: 0.001325 | valid loss: 0.002309\n","Epoch:  616 | train loss: 0.001253 | valid loss: 0.002199\n","Epoch:  617 | train loss: 0.000943 | valid loss: 0.002342\n","Epoch:  618 | train loss: 0.001666 | valid loss: 0.002411\n","Epoch:  619 | train loss: 0.000983 | valid loss: 0.002250\n","Epoch:  620 | train loss: 0.000904 | valid loss: 0.002110\n","Epoch:  621 | train loss: 0.000994 | valid loss: 0.002226\n","Epoch:  622 | train loss: 0.000928 | valid loss: 0.002125\n","Epoch:  623 | train loss: 0.000960 | valid loss: 0.002111\n","Epoch:  624 | train loss: 0.001094 | valid loss: 0.002132\n","Epoch:  625 | train loss: 0.001410 | valid loss: 0.002165\n","Epoch:  626 | train loss: 0.001186 | valid loss: 0.002148\n","Epoch:  627 | train loss: 0.000702 | valid loss: 0.002187\n","Epoch:  628 | train loss: 0.000695 | valid loss: 0.002199\n","Epoch:  629 | train loss: 0.000869 | valid loss: 0.002290\n","Epoch:  630 | train loss: 0.000860 | valid loss: 0.002256\n","Epoch:  631 | train loss: 0.001066 | valid loss: 0.002214\n","Epoch:  632 | train loss: 0.000972 | valid loss: 0.002233\n","Epoch:  633 | train loss: 0.001063 | valid loss: 0.002257\n","Epoch:  634 | train loss: 0.000714 | valid loss: 0.002287\n","Epoch:  635 | train loss: 0.000963 | valid loss: 0.002280\n","Epoch:  636 | train loss: 0.000979 | valid loss: 0.002242\n","Epoch:  637 | train loss: 0.001183 | valid loss: 0.002277\n","Epoch:  638 | train loss: 0.000977 | valid loss: 0.002238\n","Epoch:  639 | train loss: 0.000673 | valid loss: 0.002123\n","Epoch:  640 | train loss: 0.000797 | valid loss: 0.002136\n","Epoch:  641 | train loss: 0.000762 | valid loss: 0.002146\n","Epoch:  642 | train loss: 0.001043 | valid loss: 0.002195\n","Epoch:  643 | train loss: 0.000911 | valid loss: 0.002091\n","Epoch:  644 | train loss: 0.000945 | valid loss: 0.002172\n","Epoch:  645 | train loss: 0.000991 | valid loss: 0.002246\n","Epoch:  646 | train loss: 0.000953 | valid loss: 0.002136\n","Epoch:  647 | train loss: 0.000973 | valid loss: 0.002119\n","Epoch:  648 | train loss: 0.000864 | valid loss: 0.002169\n","Epoch:  649 | train loss: 0.000849 | valid loss: 0.002226\n","Epoch:  650 | train loss: 0.001151 | valid loss: 0.002209\n","Epoch:  651 | train loss: 0.001089 | valid loss: 0.002226\n","Epoch:  652 | train loss: 0.000975 | valid loss: 0.002270\n","Epoch:  653 | train loss: 0.001072 | valid loss: 0.002129\n","Epoch:  654 | train loss: 0.001239 | valid loss: 0.002250\n","Epoch:  655 | train loss: 0.000862 | valid loss: 0.002150\n","Epoch:  656 | train loss: 0.000858 | valid loss: 0.002117\n","Epoch:  657 | train loss: 0.000992 | valid loss: 0.002174\n","Epoch:  658 | train loss: 0.001048 | valid loss: 0.002396\n","Epoch:  659 | train loss: 0.000981 | valid loss: 0.002213\n","Epoch:  660 | train loss: 0.001585 | valid loss: 0.002249\n","Epoch:  661 | train loss: 0.000990 | valid loss: 0.002278\n","Epoch:  662 | train loss: 0.001029 | valid loss: 0.002209\n","Epoch:  663 | train loss: 0.000991 | valid loss: 0.002115\n","Epoch:  664 | train loss: 0.000843 | valid loss: 0.002145\n","Epoch:  665 | train loss: 0.001186 | valid loss: 0.002144\n","Epoch:  666 | train loss: 0.000849 | valid loss: 0.002326\n","Epoch:  667 | train loss: 0.001094 | valid loss: 0.002154\n","Epoch:  668 | train loss: 0.001393 | valid loss: 0.002219\n","Epoch:  669 | train loss: 0.000761 | valid loss: 0.002149\n","Epoch:  670 | train loss: 0.001052 | valid loss: 0.002205\n","Epoch:  671 | train loss: 0.000902 | valid loss: 0.002150\n","Epoch:  672 | train loss: 0.000923 | valid loss: 0.002173\n","Epoch:  673 | train loss: 0.000892 | valid loss: 0.002132\n","Epoch:  674 | train loss: 0.000750 | valid loss: 0.002252\n","Epoch:  675 | train loss: 0.000901 | valid loss: 0.002142\n","Epoch:  676 | train loss: 0.001071 | valid loss: 0.002260\n","Epoch:  677 | train loss: 0.001207 | valid loss: 0.002215\n","Epoch:  678 | train loss: 0.001855 | valid loss: 0.002291\n","Epoch:  679 | train loss: 0.000895 | valid loss: 0.002111\n","Epoch:  680 | train loss: 0.000680 | valid loss: 0.002240\n","Epoch:  681 | train loss: 0.000767 | valid loss: 0.002156\n","Epoch:  682 | train loss: 0.000730 | valid loss: 0.002187\n","Epoch:  683 | train loss: 0.000965 | valid loss: 0.002266\n","Epoch:  684 | train loss: 0.000718 | valid loss: 0.002136\n","Epoch:  685 | train loss: 0.001047 | valid loss: 0.002174\n","Epoch:  686 | train loss: 0.000695 | valid loss: 0.002230\n","Epoch:  687 | train loss: 0.000748 | valid loss: 0.002206\n","Epoch:  688 | train loss: 0.001188 | valid loss: 0.002323\n","Epoch:  689 | train loss: 0.000937 | valid loss: 0.002203\n","Epoch:  690 | train loss: 0.000969 | valid loss: 0.002318\n","Epoch:  691 | train loss: 0.001038 | valid loss: 0.002240\n","Epoch:  692 | train loss: 0.000675 | valid loss: 0.002272\n","Epoch:  693 | train loss: 0.000826 | valid loss: 0.002373\n","Epoch:  694 | train loss: 0.000897 | valid loss: 0.002211\n","Epoch:  695 | train loss: 0.000868 | valid loss: 0.002255\n","Epoch:  696 | train loss: 0.001132 | valid loss: 0.002177\n","Epoch:  697 | train loss: 0.001020 | valid loss: 0.002212\n","Epoch:  698 | train loss: 0.000744 | valid loss: 0.002245\n","Epoch:  699 | train loss: 0.000941 | valid loss: 0.002207\n","Epoch:  700 | train loss: 0.002589 | valid loss: 0.002382\n","Epoch:  701 | train loss: 0.001371 | valid loss: 0.002420\n","Epoch:  702 | train loss: 0.001026 | valid loss: 0.002333\n","Epoch:  703 | train loss: 0.000999 | valid loss: 0.002259\n","Epoch:  704 | train loss: 0.001307 | valid loss: 0.002324\n","Epoch:  705 | train loss: 0.000954 | valid loss: 0.002197\n","Epoch:  706 | train loss: 0.001048 | valid loss: 0.002088\n","Epoch:  707 | train loss: 0.000953 | valid loss: 0.002261\n","Epoch:  708 | train loss: 0.000673 | valid loss: 0.002204\n","Epoch:  709 | train loss: 0.001187 | valid loss: 0.002092\n","Epoch:  710 | train loss: 0.000989 | valid loss: 0.002217\n","Epoch:  711 | train loss: 0.001078 | valid loss: 0.002111\n","Epoch:  712 | train loss: 0.001199 | valid loss: 0.002158\n","Epoch:  713 | train loss: 0.000752 | valid loss: 0.002216\n","Epoch:  714 | train loss: 0.000953 | valid loss: 0.002203\n","Epoch:  715 | train loss: 0.001147 | valid loss: 0.002228\n","Epoch:  716 | train loss: 0.000981 | valid loss: 0.002157\n","Epoch:  717 | train loss: 0.000838 | valid loss: 0.002282\n","Epoch:  718 | train loss: 0.001447 | valid loss: 0.002240\n","Epoch:  719 | train loss: 0.000931 | valid loss: 0.002252\n","Epoch:  720 | train loss: 0.000771 | valid loss: 0.002363\n","Epoch:  721 | train loss: 0.001202 | valid loss: 0.002357\n","Epoch:  722 | train loss: 0.000874 | valid loss: 0.002253\n","Epoch:  723 | train loss: 0.000695 | valid loss: 0.002147\n","Epoch:  724 | train loss: 0.000685 | valid loss: 0.002188\n","Epoch:  725 | train loss: 0.000899 | valid loss: 0.002160\n","Epoch:  726 | train loss: 0.000839 | valid loss: 0.002270\n","Epoch:  727 | train loss: 0.000936 | valid loss: 0.002229\n","Epoch:  728 | train loss: 0.000790 | valid loss: 0.002068\n","Epoch:  729 | train loss: 0.000836 | valid loss: 0.002135\n","Epoch:  730 | train loss: 0.000848 | valid loss: 0.002198\n","Epoch:  731 | train loss: 0.000900 | valid loss: 0.002276\n","Epoch:  732 | train loss: 0.001018 | valid loss: 0.002326\n","Epoch:  733 | train loss: 0.001007 | valid loss: 0.002228\n","Epoch:  734 | train loss: 0.001008 | valid loss: 0.002309\n","Epoch:  735 | train loss: 0.001197 | valid loss: 0.002282\n","Epoch:  736 | train loss: 0.000689 | valid loss: 0.002186\n","Epoch:  737 | train loss: 0.000948 | valid loss: 0.002308\n","Epoch:  738 | train loss: 0.000814 | valid loss: 0.002457\n","Epoch:  739 | train loss: 0.001103 | valid loss: 0.002325\n","Epoch:  740 | train loss: 0.000778 | valid loss: 0.002189\n","Epoch:  741 | train loss: 0.001229 | valid loss: 0.002153\n","Epoch:  742 | train loss: 0.001211 | valid loss: 0.002186\n","Epoch:  743 | train loss: 0.000901 | valid loss: 0.002089\n","Epoch:  744 | train loss: 0.000805 | valid loss: 0.002105\n","Epoch:  745 | train loss: 0.000916 | valid loss: 0.002196\n","Epoch:  746 | train loss: 0.001166 | valid loss: 0.002253\n","Epoch:  747 | train loss: 0.001047 | valid loss: 0.002280\n","Epoch:  748 | train loss: 0.001119 | valid loss: 0.002411\n","Epoch:  749 | train loss: 0.000845 | valid loss: 0.002371\n","Epoch:  750 | train loss: 0.001162 | valid loss: 0.002273\n","Epoch:  751 | train loss: 0.000715 | valid loss: 0.002242\n","Epoch:  752 | train loss: 0.001348 | valid loss: 0.002368\n","Epoch:  753 | train loss: 0.001405 | valid loss: 0.002236\n","Epoch:  754 | train loss: 0.001046 | valid loss: 0.002259\n","Epoch:  755 | train loss: 0.001309 | valid loss: 0.002272\n","Epoch:  756 | train loss: 0.001309 | valid loss: 0.002236\n","Epoch:  757 | train loss: 0.001158 | valid loss: 0.002413\n","Epoch:  758 | train loss: 0.001068 | valid loss: 0.002167\n","Epoch:  759 | train loss: 0.000914 | valid loss: 0.002193\n","Epoch:  760 | train loss: 0.000994 | valid loss: 0.002181\n","Epoch:  761 | train loss: 0.000693 | valid loss: 0.002155\n","Epoch:  762 | train loss: 0.001576 | valid loss: 0.002244\n","Epoch:  763 | train loss: 0.000676 | valid loss: 0.002297\n","Epoch:  764 | train loss: 0.000943 | valid loss: 0.002258\n","Epoch:  765 | train loss: 0.000784 | valid loss: 0.002144\n","Epoch:  766 | train loss: 0.001022 | valid loss: 0.002350\n","Epoch:  767 | train loss: 0.000989 | valid loss: 0.002320\n","Epoch:  768 | train loss: 0.000693 | valid loss: 0.002302\n","Epoch:  769 | train loss: 0.000861 | valid loss: 0.002133\n","Epoch:  770 | train loss: 0.000929 | valid loss: 0.002187\n","Epoch:  771 | train loss: 0.001602 | valid loss: 0.002205\n","Epoch:  772 | train loss: 0.000801 | valid loss: 0.002283\n","Epoch:  773 | train loss: 0.000758 | valid loss: 0.002120\n","Epoch:  774 | train loss: 0.000920 | valid loss: 0.002329\n","Epoch:  775 | train loss: 0.000716 | valid loss: 0.002303\n","Epoch:  776 | train loss: 0.001010 | valid loss: 0.002153\n","Epoch:  777 | train loss: 0.000725 | valid loss: 0.002121\n","Epoch:  778 | train loss: 0.000741 | valid loss: 0.002167\n","Epoch:  779 | train loss: 0.000840 | valid loss: 0.002276\n","Epoch:  780 | train loss: 0.000700 | valid loss: 0.002345\n","Epoch:  781 | train loss: 0.000880 | valid loss: 0.002274\n","Epoch:  782 | train loss: 0.001178 | valid loss: 0.002257\n","Epoch:  783 | train loss: 0.001183 | valid loss: 0.002253\n","Epoch:  784 | train loss: 0.000836 | valid loss: 0.002204\n","Epoch:  785 | train loss: 0.001381 | valid loss: 0.002253\n","Epoch:  786 | train loss: 0.000875 | valid loss: 0.002299\n","Epoch:  787 | train loss: 0.001168 | valid loss: 0.002241\n","Epoch:  788 | train loss: 0.001358 | valid loss: 0.002271\n","Epoch:  789 | train loss: 0.000979 | valid loss: 0.002213\n","Epoch:  790 | train loss: 0.000891 | valid loss: 0.002283\n","Epoch:  791 | train loss: 0.001257 | valid loss: 0.002271\n","Epoch:  792 | train loss: 0.000857 | valid loss: 0.002299\n","Epoch:  793 | train loss: 0.001073 | valid loss: 0.002147\n","Epoch:  794 | train loss: 0.000665 | valid loss: 0.002218\n","Epoch:  795 | train loss: 0.000879 | valid loss: 0.002251\n","Epoch:  796 | train loss: 0.001099 | valid loss: 0.002299\n","Epoch:  797 | train loss: 0.000856 | valid loss: 0.002185\n","Epoch:  798 | train loss: 0.000675 | valid loss: 0.002244\n","Epoch:  799 | train loss: 0.000813 | valid loss: 0.002194\n","Epoch:  800 | train loss: 0.001147 | valid loss: 0.002203\n","Epoch:  801 | train loss: 0.000742 | valid loss: 0.002235\n","Epoch:  802 | train loss: 0.001211 | valid loss: 0.002364\n","Epoch:  803 | train loss: 0.000885 | valid loss: 0.002242\n","Epoch:  804 | train loss: 0.000809 | valid loss: 0.002376\n","Epoch:  805 | train loss: 0.000910 | valid loss: 0.002378\n","Epoch:  806 | train loss: 0.001022 | valid loss: 0.002419\n","Epoch:  807 | train loss: 0.000837 | valid loss: 0.002237\n","Epoch:  808 | train loss: 0.000571 | valid loss: 0.002166\n","Epoch:  809 | train loss: 0.000918 | valid loss: 0.002130\n","Epoch:  810 | train loss: 0.000710 | valid loss: 0.002222\n","Epoch:  811 | train loss: 0.000735 | valid loss: 0.002210\n","Epoch:  812 | train loss: 0.000769 | valid loss: 0.002210\n","Epoch:  813 | train loss: 0.000871 | valid loss: 0.002223\n","Epoch:  814 | train loss: 0.000685 | valid loss: 0.002300\n","Epoch:  815 | train loss: 0.001259 | valid loss: 0.002201\n","Epoch:  816 | train loss: 0.000966 | valid loss: 0.002239\n","Epoch:  817 | train loss: 0.001228 | valid loss: 0.002369\n","Epoch:  818 | train loss: 0.001694 | valid loss: 0.002203\n","Epoch:  819 | train loss: 0.000984 | valid loss: 0.002297\n","Epoch:  820 | train loss: 0.000888 | valid loss: 0.002353\n","Epoch:  821 | train loss: 0.000828 | valid loss: 0.002313\n","Epoch:  822 | train loss: 0.000844 | valid loss: 0.002273\n","Epoch:  823 | train loss: 0.000842 | valid loss: 0.002199\n","Epoch:  824 | train loss: 0.000979 | valid loss: 0.002271\n","Epoch:  825 | train loss: 0.000928 | valid loss: 0.002154\n","Epoch:  826 | train loss: 0.001278 | valid loss: 0.002198\n","Epoch:  827 | train loss: 0.000981 | valid loss: 0.002259\n","Epoch:  828 | train loss: 0.001150 | valid loss: 0.002250\n","Epoch:  829 | train loss: 0.000729 | valid loss: 0.002364\n","Epoch:  830 | train loss: 0.000849 | valid loss: 0.002235\n","Epoch:  831 | train loss: 0.000668 | valid loss: 0.002274\n","Epoch:  832 | train loss: 0.001033 | valid loss: 0.002412\n","Epoch:  833 | train loss: 0.000766 | valid loss: 0.002363\n","Epoch:  834 | train loss: 0.000604 | valid loss: 0.002323\n","Epoch:  835 | train loss: 0.000787 | valid loss: 0.002268\n","Epoch:  836 | train loss: 0.000749 | valid loss: 0.002353\n","Epoch:  837 | train loss: 0.001159 | valid loss: 0.002232\n","Epoch:  838 | train loss: 0.001046 | valid loss: 0.002353\n","Epoch:  839 | train loss: 0.000996 | valid loss: 0.002146\n","Epoch:  840 | train loss: 0.001168 | valid loss: 0.002282\n","Epoch:  841 | train loss: 0.000846 | valid loss: 0.002261\n","Epoch:  842 | train loss: 0.000680 | valid loss: 0.002202\n","Epoch:  843 | train loss: 0.000827 | valid loss: 0.002315\n","Epoch:  844 | train loss: 0.001222 | valid loss: 0.002339\n","Epoch:  845 | train loss: 0.000747 | valid loss: 0.002315\n","Epoch:  846 | train loss: 0.000644 | valid loss: 0.002188\n","Epoch:  847 | train loss: 0.000896 | valid loss: 0.002280\n","Epoch:  848 | train loss: 0.000846 | valid loss: 0.002320\n","Epoch:  849 | train loss: 0.000954 | valid loss: 0.002366\n","Epoch:  850 | train loss: 0.000745 | valid loss: 0.002347\n","Epoch:  851 | train loss: 0.001194 | valid loss: 0.002276\n","Epoch:  852 | train loss: 0.000935 | valid loss: 0.002315\n","Epoch:  853 | train loss: 0.000769 | valid loss: 0.002280\n","Epoch:  854 | train loss: 0.000879 | valid loss: 0.002218\n","Epoch:  855 | train loss: 0.000787 | valid loss: 0.002319\n","Epoch:  856 | train loss: 0.001036 | valid loss: 0.002250\n","Epoch:  857 | train loss: 0.000690 | valid loss: 0.002184\n","Epoch:  858 | train loss: 0.000919 | valid loss: 0.002175\n","Epoch:  859 | train loss: 0.001020 | valid loss: 0.002148\n","Epoch:  860 | train loss: 0.001108 | valid loss: 0.002421\n","Epoch:  861 | train loss: 0.001032 | valid loss: 0.002399\n","Epoch:  862 | train loss: 0.000864 | valid loss: 0.002304\n","Epoch:  863 | train loss: 0.001696 | valid loss: 0.002245\n","Epoch:  864 | train loss: 0.001080 | valid loss: 0.002217\n","Epoch:  865 | train loss: 0.000991 | valid loss: 0.002180\n","Epoch:  866 | train loss: 0.000754 | valid loss: 0.002194\n","Epoch:  867 | train loss: 0.001082 | valid loss: 0.002278\n","Epoch:  868 | train loss: 0.001016 | valid loss: 0.002334\n","Epoch:  869 | train loss: 0.000955 | valid loss: 0.002253\n","Epoch:  870 | train loss: 0.000665 | valid loss: 0.002196\n","Epoch:  871 | train loss: 0.001039 | valid loss: 0.002346\n","Epoch:  872 | train loss: 0.000901 | valid loss: 0.002288\n","Epoch:  873 | train loss: 0.001209 | valid loss: 0.002283\n","Epoch:  874 | train loss: 0.000860 | valid loss: 0.002470\n","Epoch:  875 | train loss: 0.000932 | valid loss: 0.002373\n","Epoch:  876 | train loss: 0.000940 | valid loss: 0.002412\n","Epoch:  877 | train loss: 0.000927 | valid loss: 0.002312\n","Epoch:  878 | train loss: 0.000858 | valid loss: 0.002385\n","Epoch:  879 | train loss: 0.000759 | valid loss: 0.002286\n","Epoch:  880 | train loss: 0.000737 | valid loss: 0.002207\n","Epoch:  881 | train loss: 0.000734 | valid loss: 0.002151\n","Epoch:  882 | train loss: 0.000925 | valid loss: 0.002285\n","Epoch:  883 | train loss: 0.000730 | valid loss: 0.002276\n","Epoch:  884 | train loss: 0.001026 | valid loss: 0.002292\n","Epoch:  885 | train loss: 0.001390 | valid loss: 0.002268\n","Epoch:  886 | train loss: 0.001226 | valid loss: 0.002404\n","Epoch:  887 | train loss: 0.000811 | valid loss: 0.002290\n","Epoch:  888 | train loss: 0.000665 | valid loss: 0.002426\n","Epoch:  889 | train loss: 0.001141 | valid loss: 0.002446\n","Epoch:  890 | train loss: 0.000975 | valid loss: 0.002347\n","Epoch:  891 | train loss: 0.001210 | valid loss: 0.002325\n","Epoch:  892 | train loss: 0.001024 | valid loss: 0.002460\n","Epoch:  893 | train loss: 0.000688 | valid loss: 0.002399\n","Epoch:  894 | train loss: 0.000791 | valid loss: 0.002354\n","Epoch:  895 | train loss: 0.000842 | valid loss: 0.002332\n","Epoch:  896 | train loss: 0.000844 | valid loss: 0.002276\n","Epoch:  897 | train loss: 0.000682 | valid loss: 0.002251\n","Epoch:  898 | train loss: 0.000704 | valid loss: 0.002374\n","Epoch:  899 | train loss: 0.000980 | valid loss: 0.002250\n","Epoch:  900 | train loss: 0.001103 | valid loss: 0.002283\n","Epoch:  901 | train loss: 0.000884 | valid loss: 0.002254\n","Epoch:  902 | train loss: 0.001094 | valid loss: 0.002326\n","Epoch:  903 | train loss: 0.000845 | valid loss: 0.002254\n","Epoch:  904 | train loss: 0.000815 | valid loss: 0.002298\n","Epoch:  905 | train loss: 0.000905 | valid loss: 0.002225\n","Epoch:  906 | train loss: 0.001009 | valid loss: 0.002226\n","Epoch:  907 | train loss: 0.000695 | valid loss: 0.002297\n","Epoch:  908 | train loss: 0.001275 | valid loss: 0.002401\n","Epoch:  909 | train loss: 0.000901 | valid loss: 0.002267\n","Epoch:  910 | train loss: 0.001303 | valid loss: 0.002267\n","Epoch:  911 | train loss: 0.000832 | valid loss: 0.002277\n","Epoch:  912 | train loss: 0.000896 | valid loss: 0.002171\n","Epoch:  913 | train loss: 0.001365 | valid loss: 0.002248\n","Epoch:  914 | train loss: 0.000926 | valid loss: 0.002282\n","Epoch:  915 | train loss: 0.000757 | valid loss: 0.002302\n","Epoch:  916 | train loss: 0.001221 | valid loss: 0.002334\n","Epoch:  917 | train loss: 0.000861 | valid loss: 0.002298\n","Epoch:  918 | train loss: 0.000630 | valid loss: 0.002233\n","Epoch:  919 | train loss: 0.001241 | valid loss: 0.002334\n","Epoch:  920 | train loss: 0.000881 | valid loss: 0.002274\n","Epoch:  921 | train loss: 0.000901 | valid loss: 0.002303\n","Epoch:  922 | train loss: 0.000769 | valid loss: 0.002313\n","Epoch:  923 | train loss: 0.000681 | valid loss: 0.002294\n","Epoch:  924 | train loss: 0.000605 | valid loss: 0.002309\n","Epoch:  925 | train loss: 0.000610 | valid loss: 0.002441\n","Epoch:  926 | train loss: 0.000751 | valid loss: 0.002329\n","Epoch:  927 | train loss: 0.001051 | valid loss: 0.002323\n","Epoch:  928 | train loss: 0.000914 | valid loss: 0.002217\n","Epoch:  929 | train loss: 0.000662 | valid loss: 0.002459\n","Epoch:  930 | train loss: 0.000799 | valid loss: 0.002250\n","Epoch:  931 | train loss: 0.000784 | valid loss: 0.002293\n","Epoch:  932 | train loss: 0.000678 | valid loss: 0.002396\n","Epoch:  933 | train loss: 0.000888 | valid loss: 0.002238\n","Epoch:  934 | train loss: 0.000701 | valid loss: 0.002264\n","Epoch:  935 | train loss: 0.000953 | valid loss: 0.002228\n","Epoch:  936 | train loss: 0.000800 | valid loss: 0.002415\n","Epoch:  937 | train loss: 0.000840 | valid loss: 0.002326\n","Epoch:  938 | train loss: 0.001391 | valid loss: 0.002520\n","Epoch:  939 | train loss: 0.000892 | valid loss: 0.002467\n","Epoch:  940 | train loss: 0.000804 | valid loss: 0.002361\n","Epoch:  941 | train loss: 0.001677 | valid loss: 0.002367\n","Epoch:  942 | train loss: 0.000951 | valid loss: 0.002213\n","Epoch:  943 | train loss: 0.000780 | valid loss: 0.002261\n","Epoch:  944 | train loss: 0.000602 | valid loss: 0.002215\n","Epoch:  945 | train loss: 0.000799 | valid loss: 0.002368\n","Epoch:  946 | train loss: 0.000766 | valid loss: 0.002339\n","Epoch:  947 | train loss: 0.000667 | valid loss: 0.002324\n","Epoch:  948 | train loss: 0.000953 | valid loss: 0.002373\n","Epoch:  949 | train loss: 0.000858 | valid loss: 0.002255\n","Epoch:  950 | train loss: 0.000677 | valid loss: 0.002341\n","Epoch:  951 | train loss: 0.000822 | valid loss: 0.002228\n","Epoch:  952 | train loss: 0.000875 | valid loss: 0.002273\n","Epoch:  953 | train loss: 0.000653 | valid loss: 0.002180\n","Epoch:  954 | train loss: 0.000759 | valid loss: 0.002307\n","Epoch:  955 | train loss: 0.000799 | valid loss: 0.002300\n","Epoch:  956 | train loss: 0.000846 | valid loss: 0.002215\n","Epoch:  957 | train loss: 0.000697 | valid loss: 0.002377\n","Epoch:  958 | train loss: 0.001182 | valid loss: 0.002344\n","Epoch:  959 | train loss: 0.000642 | valid loss: 0.002416\n","Epoch:  960 | train loss: 0.000908 | valid loss: 0.002458\n","Epoch:  961 | train loss: 0.000876 | valid loss: 0.002361\n","Epoch:  962 | train loss: 0.000862 | valid loss: 0.002380\n","Epoch:  963 | train loss: 0.001014 | valid loss: 0.002371\n","Epoch:  964 | train loss: 0.000774 | valid loss: 0.002457\n","Epoch:  965 | train loss: 0.000714 | valid loss: 0.002208\n","Epoch:  966 | train loss: 0.000966 | valid loss: 0.002323\n","Epoch:  967 | train loss: 0.001003 | valid loss: 0.002621\n","Epoch:  968 | train loss: 0.001053 | valid loss: 0.002511\n","Epoch:  969 | train loss: 0.000913 | valid loss: 0.002415\n","Epoch:  970 | train loss: 0.001302 | valid loss: 0.002450\n","Epoch:  971 | train loss: 0.000969 | valid loss: 0.002373\n","Epoch:  972 | train loss: 0.000820 | valid loss: 0.002357\n","Epoch:  973 | train loss: 0.000610 | valid loss: 0.002195\n","Epoch:  974 | train loss: 0.001100 | valid loss: 0.002277\n","Epoch:  975 | train loss: 0.001080 | valid loss: 0.002290\n","Epoch:  976 | train loss: 0.000565 | valid loss: 0.002341\n","Epoch:  977 | train loss: 0.000689 | valid loss: 0.002311\n","Epoch:  978 | train loss: 0.000732 | valid loss: 0.002282\n","Epoch:  979 | train loss: 0.000890 | valid loss: 0.002262\n","Epoch:  980 | train loss: 0.000627 | valid loss: 0.002340\n","Epoch:  981 | train loss: 0.000995 | valid loss: 0.002293\n","Epoch:  982 | train loss: 0.000799 | valid loss: 0.002360\n","Epoch:  983 | train loss: 0.000707 | valid loss: 0.002423\n","Epoch:  984 | train loss: 0.000932 | valid loss: 0.002456\n","Epoch:  985 | train loss: 0.000951 | valid loss: 0.002358\n","Epoch:  986 | train loss: 0.001560 | valid loss: 0.002391\n","Epoch:  987 | train loss: 0.000828 | valid loss: 0.002273\n","Epoch:  988 | train loss: 0.001028 | valid loss: 0.002362\n","Epoch:  989 | train loss: 0.000902 | valid loss: 0.002407\n","Epoch:  990 | train loss: 0.000922 | valid loss: 0.002277\n","Epoch:  991 | train loss: 0.000779 | valid loss: 0.002269\n","Epoch:  992 | train loss: 0.000680 | valid loss: 0.002286\n","Epoch:  993 | train loss: 0.000713 | valid loss: 0.002312\n","Epoch:  994 | train loss: 0.000885 | valid loss: 0.002349\n","Epoch:  995 | train loss: 0.000589 | valid loss: 0.002329\n","Epoch:  996 | train loss: 0.000968 | valid loss: 0.002493\n","Epoch:  997 | train loss: 0.000868 | valid loss: 0.002361\n","Epoch:  998 | train loss: 0.000772 | valid loss: 0.002389\n","Epoch:  999 | train loss: 0.001102 | valid loss: 0.002459\n","Epoch:  1000 | train loss: 0.000659 | valid loss: 0.002280\n","Epoch:  1001 | train loss: 0.000838 | valid loss: 0.002315\n","Epoch:  1002 | train loss: 0.001012 | valid loss: 0.002223\n","Epoch:  1003 | train loss: 0.000977 | valid loss: 0.002335\n","Epoch:  1004 | train loss: 0.001088 | valid loss: 0.002332\n","Epoch:  1005 | train loss: 0.000720 | valid loss: 0.002221\n","Epoch:  1006 | train loss: 0.000900 | valid loss: 0.002325\n","Epoch:  1007 | train loss: 0.000991 | valid loss: 0.002303\n","Epoch:  1008 | train loss: 0.000766 | valid loss: 0.002460\n","Epoch:  1009 | train loss: 0.000823 | valid loss: 0.002434\n","Epoch:  1010 | train loss: 0.001147 | valid loss: 0.002561\n","Epoch:  1011 | train loss: 0.000952 | valid loss: 0.002432\n","Epoch:  1012 | train loss: 0.000699 | valid loss: 0.002274\n","Epoch:  1013 | train loss: 0.001021 | valid loss: 0.002314\n","Epoch:  1014 | train loss: 0.000948 | valid loss: 0.002265\n","Epoch:  1015 | train loss: 0.000964 | valid loss: 0.002224\n","Epoch:  1016 | train loss: 0.000948 | valid loss: 0.002167\n","Epoch:  1017 | train loss: 0.000817 | valid loss: 0.002197\n","Epoch:  1018 | train loss: 0.000833 | valid loss: 0.002309\n","Epoch:  1019 | train loss: 0.000764 | valid loss: 0.002214\n","Epoch:  1020 | train loss: 0.000811 | valid loss: 0.002280\n","Epoch:  1021 | train loss: 0.000705 | valid loss: 0.002197\n","Epoch:  1022 | train loss: 0.000857 | valid loss: 0.002242\n","Epoch:  1023 | train loss: 0.000791 | valid loss: 0.002287\n","Epoch:  1024 | train loss: 0.001411 | valid loss: 0.002329\n","Epoch:  1025 | train loss: 0.000736 | valid loss: 0.002461\n","Epoch:  1026 | train loss: 0.001104 | valid loss: 0.002478\n","Epoch:  1027 | train loss: 0.000906 | valid loss: 0.002405\n","Epoch:  1028 | train loss: 0.000728 | valid loss: 0.002307\n","Epoch:  1029 | train loss: 0.000930 | valid loss: 0.002349\n","Epoch:  1030 | train loss: 0.000786 | valid loss: 0.002268\n","Epoch:  1031 | train loss: 0.001531 | valid loss: 0.002316\n","Epoch:  1032 | train loss: 0.000842 | valid loss: 0.002583\n","Epoch:  1033 | train loss: 0.000647 | valid loss: 0.002392\n","Epoch:  1034 | train loss: 0.000771 | valid loss: 0.002320\n","Epoch:  1035 | train loss: 0.001014 | valid loss: 0.002396\n","Epoch:  1036 | train loss: 0.000672 | valid loss: 0.002391\n","Epoch:  1037 | train loss: 0.000736 | valid loss: 0.002487\n","Epoch:  1038 | train loss: 0.000769 | valid loss: 0.002326\n","Epoch:  1039 | train loss: 0.000849 | valid loss: 0.002375\n","Epoch:  1040 | train loss: 0.000730 | valid loss: 0.002320\n","Epoch:  1041 | train loss: 0.000860 | valid loss: 0.002289\n","Epoch:  1042 | train loss: 0.000829 | valid loss: 0.002361\n","Epoch:  1043 | train loss: 0.000707 | valid loss: 0.002429\n","Epoch:  1044 | train loss: 0.001070 | valid loss: 0.002396\n","Epoch:  1045 | train loss: 0.000768 | valid loss: 0.002303\n","Epoch:  1046 | train loss: 0.000861 | valid loss: 0.002423\n","Epoch:  1047 | train loss: 0.001226 | valid loss: 0.002326\n","Epoch:  1048 | train loss: 0.000731 | valid loss: 0.002454\n","Epoch:  1049 | train loss: 0.000942 | valid loss: 0.002441\n","Epoch:  1050 | train loss: 0.000668 | valid loss: 0.002350\n","Epoch:  1051 | train loss: 0.000833 | valid loss: 0.002351\n","Epoch:  1052 | train loss: 0.000805 | valid loss: 0.002358\n","Epoch:  1053 | train loss: 0.000663 | valid loss: 0.002335\n","Epoch:  1054 | train loss: 0.000783 | valid loss: 0.002336\n","Epoch:  1055 | train loss: 0.000924 | valid loss: 0.002337\n","Epoch:  1056 | train loss: 0.000763 | valid loss: 0.002480\n","Epoch:  1057 | train loss: 0.000896 | valid loss: 0.002480\n","Epoch:  1058 | train loss: 0.003474 | valid loss: 0.002751\n","Epoch:  1059 | train loss: 0.000919 | valid loss: 0.002551\n","Epoch:  1060 | train loss: 0.000653 | valid loss: 0.002461\n","Epoch:  1061 | train loss: 0.000823 | valid loss: 0.002255\n","Epoch:  1062 | train loss: 0.000947 | valid loss: 0.002411\n","Epoch:  1063 | train loss: 0.000854 | valid loss: 0.002337\n","Epoch:  1064 | train loss: 0.000591 | valid loss: 0.002380\n","Epoch:  1065 | train loss: 0.000852 | valid loss: 0.002367\n","Epoch:  1066 | train loss: 0.000893 | valid loss: 0.002395\n","Epoch:  1067 | train loss: 0.000781 | valid loss: 0.002362\n","Epoch:  1068 | train loss: 0.001036 | valid loss: 0.002442\n","Epoch:  1069 | train loss: 0.001095 | valid loss: 0.002439\n","Epoch:  1070 | train loss: 0.000748 | valid loss: 0.002290\n","Epoch:  1071 | train loss: 0.000933 | valid loss: 0.002387\n","Epoch:  1072 | train loss: 0.000686 | valid loss: 0.002347\n","Epoch:  1073 | train loss: 0.001142 | valid loss: 0.002386\n","Epoch:  1074 | train loss: 0.001039 | valid loss: 0.002374\n","Epoch:  1075 | train loss: 0.000903 | valid loss: 0.002334\n","Epoch:  1076 | train loss: 0.001017 | valid loss: 0.002375\n","Epoch:  1077 | train loss: 0.001080 | valid loss: 0.002448\n","Epoch:  1078 | train loss: 0.001102 | valid loss: 0.002484\n","Epoch:  1079 | train loss: 0.000751 | valid loss: 0.002514\n","Epoch:  1080 | train loss: 0.001013 | valid loss: 0.002360\n","Epoch:  1081 | train loss: 0.001248 | valid loss: 0.002426\n","Epoch:  1082 | train loss: 0.000867 | valid loss: 0.002439\n","Epoch:  1083 | train loss: 0.000745 | valid loss: 0.002453\n","Epoch:  1084 | train loss: 0.000660 | valid loss: 0.002544\n","Epoch:  1085 | train loss: 0.000786 | valid loss: 0.002350\n","Epoch:  1086 | train loss: 0.000659 | valid loss: 0.002373\n","Epoch:  1087 | train loss: 0.000756 | valid loss: 0.002435\n","Epoch:  1088 | train loss: 0.000685 | valid loss: 0.002401\n","Epoch:  1089 | train loss: 0.000756 | valid loss: 0.002341\n","Epoch:  1090 | train loss: 0.000891 | valid loss: 0.002335\n","Epoch:  1091 | train loss: 0.000791 | valid loss: 0.002314\n","Epoch:  1092 | train loss: 0.000788 | valid loss: 0.002516\n","Epoch:  1093 | train loss: 0.000878 | valid loss: 0.002591\n","Epoch:  1094 | train loss: 0.000907 | valid loss: 0.002411\n","Epoch:  1095 | train loss: 0.000721 | valid loss: 0.002490\n","Epoch:  1096 | train loss: 0.000914 | valid loss: 0.002342\n","Epoch:  1097 | train loss: 0.000850 | valid loss: 0.002499\n","Epoch:  1098 | train loss: 0.000980 | valid loss: 0.002391\n","Epoch:  1099 | train loss: 0.000949 | valid loss: 0.002427\n","Epoch:  1100 | train loss: 0.000663 | valid loss: 0.002497\n","Epoch:  1101 | train loss: 0.000704 | valid loss: 0.002407\n","Epoch:  1102 | train loss: 0.000788 | valid loss: 0.002403\n","Epoch:  1103 | train loss: 0.000791 | valid loss: 0.002354\n","Epoch:  1104 | train loss: 0.000804 | valid loss: 0.002471\n","Epoch:  1105 | train loss: 0.001035 | valid loss: 0.002542\n","Epoch:  1106 | train loss: 0.000674 | valid loss: 0.002323\n","Epoch:  1107 | train loss: 0.000921 | valid loss: 0.002361\n","Epoch:  1108 | train loss: 0.000938 | valid loss: 0.002377\n","Epoch:  1109 | train loss: 0.000955 | valid loss: 0.002438\n","Epoch:  1110 | train loss: 0.001077 | valid loss: 0.002549\n","Epoch:  1111 | train loss: 0.000954 | valid loss: 0.002596\n","Epoch:  1112 | train loss: 0.000793 | valid loss: 0.002493\n","Epoch:  1113 | train loss: 0.000617 | valid loss: 0.002474\n","Epoch:  1114 | train loss: 0.000976 | valid loss: 0.002332\n","Epoch:  1115 | train loss: 0.000554 | valid loss: 0.002311\n","Epoch:  1116 | train loss: 0.000851 | valid loss: 0.002458\n","Epoch:  1117 | train loss: 0.000911 | valid loss: 0.002434\n","Epoch:  1118 | train loss: 0.000675 | valid loss: 0.002627\n","Epoch:  1119 | train loss: 0.001009 | valid loss: 0.002372\n","Epoch:  1120 | train loss: 0.001282 | valid loss: 0.002494\n","Epoch:  1121 | train loss: 0.000982 | valid loss: 0.002569\n","Epoch:  1122 | train loss: 0.000935 | valid loss: 0.002394\n","Epoch:  1123 | train loss: 0.000742 | valid loss: 0.002440\n","Epoch:  1124 | train loss: 0.000989 | valid loss: 0.002383\n","Epoch:  1125 | train loss: 0.000694 | valid loss: 0.002352\n","Epoch:  1126 | train loss: 0.001138 | valid loss: 0.002331\n","Epoch:  1127 | train loss: 0.000740 | valid loss: 0.002315\n","Epoch:  1128 | train loss: 0.000745 | valid loss: 0.002240\n","Epoch:  1129 | train loss: 0.000757 | valid loss: 0.002393\n","Epoch:  1130 | train loss: 0.000981 | valid loss: 0.002465\n","Epoch:  1131 | train loss: 0.000725 | valid loss: 0.002567\n","Epoch:  1132 | train loss: 0.001023 | valid loss: 0.002508\n","Epoch:  1133 | train loss: 0.001752 | valid loss: 0.002499\n","Epoch:  1134 | train loss: 0.001095 | valid loss: 0.002398\n","Epoch:  1135 | train loss: 0.000887 | valid loss: 0.002497\n","Epoch:  1136 | train loss: 0.000954 | valid loss: 0.002456\n","Epoch:  1137 | train loss: 0.000590 | valid loss: 0.002372\n","Epoch:  1138 | train loss: 0.001028 | valid loss: 0.002330\n","Epoch:  1139 | train loss: 0.000658 | valid loss: 0.002397\n","Epoch:  1140 | train loss: 0.000613 | valid loss: 0.002321\n","Epoch:  1141 | train loss: 0.000790 | valid loss: 0.002304\n","Epoch:  1142 | train loss: 0.000719 | valid loss: 0.002339\n","Epoch:  1143 | train loss: 0.000636 | valid loss: 0.002342\n","Epoch:  1144 | train loss: 0.000922 | valid loss: 0.002340\n","Epoch:  1145 | train loss: 0.000707 | valid loss: 0.002445\n","Epoch:  1146 | train loss: 0.000705 | valid loss: 0.002455\n","Epoch:  1147 | train loss: 0.001013 | valid loss: 0.002550\n","Epoch:  1148 | train loss: 0.000891 | valid loss: 0.002462\n","Epoch:  1149 | train loss: 0.000651 | valid loss: 0.002459\n","Epoch:  1150 | train loss: 0.001089 | valid loss: 0.002445\n","Epoch:  1151 | train loss: 0.000667 | valid loss: 0.002523\n","Epoch:  1152 | train loss: 0.000765 | valid loss: 0.002367\n","Epoch:  1153 | train loss: 0.000695 | valid loss: 0.002437\n","Epoch:  1154 | train loss: 0.000736 | valid loss: 0.002300\n","Epoch:  1155 | train loss: 0.000629 | valid loss: 0.002408\n","Epoch:  1156 | train loss: 0.000508 | valid loss: 0.002399\n","Epoch:  1157 | train loss: 0.000831 | valid loss: 0.002376\n","Epoch:  1158 | train loss: 0.000729 | valid loss: 0.002511\n","Epoch:  1159 | train loss: 0.000996 | valid loss: 0.002397\n","Epoch:  1160 | train loss: 0.000814 | valid loss: 0.002338\n","Epoch:  1161 | train loss: 0.000848 | valid loss: 0.002453\n","Epoch:  1162 | train loss: 0.000764 | valid loss: 0.002521\n","Epoch:  1163 | train loss: 0.000812 | valid loss: 0.002425\n","Epoch:  1164 | train loss: 0.001057 | valid loss: 0.002515\n","Epoch:  1165 | train loss: 0.000966 | valid loss: 0.002534\n","Epoch:  1166 | train loss: 0.002822 | valid loss: 0.002636\n","Epoch:  1167 | train loss: 0.000860 | valid loss: 0.002545\n","Epoch:  1168 | train loss: 0.000860 | valid loss: 0.002510\n","Epoch:  1169 | train loss: 0.001174 | valid loss: 0.002528\n","Epoch:  1170 | train loss: 0.000608 | valid loss: 0.002491\n","Epoch:  1171 | train loss: 0.000778 | valid loss: 0.002462\n","Epoch:  1172 | train loss: 0.000712 | valid loss: 0.002364\n","Epoch:  1173 | train loss: 0.000752 | valid loss: 0.002443\n","Epoch:  1174 | train loss: 0.001164 | valid loss: 0.002409\n","Epoch:  1175 | train loss: 0.001084 | valid loss: 0.002511\n","Epoch:  1176 | train loss: 0.000842 | valid loss: 0.002365\n","Epoch:  1177 | train loss: 0.000869 | valid loss: 0.002497\n","Epoch:  1178 | train loss: 0.000957 | valid loss: 0.002476\n","Epoch:  1179 | train loss: 0.000980 | valid loss: 0.002472\n","Epoch:  1180 | train loss: 0.000928 | valid loss: 0.002459\n","Epoch:  1181 | train loss: 0.000773 | valid loss: 0.002434\n","Epoch:  1182 | train loss: 0.000838 | valid loss: 0.002449\n","Epoch:  1183 | train loss: 0.001063 | valid loss: 0.002446\n","Epoch:  1184 | train loss: 0.000859 | valid loss: 0.002576\n","Epoch:  1185 | train loss: 0.000850 | valid loss: 0.002453\n","Epoch:  1186 | train loss: 0.001773 | valid loss: 0.002454\n","Epoch:  1187 | train loss: 0.001078 | valid loss: 0.002594\n","Epoch:  1188 | train loss: 0.000861 | valid loss: 0.002487\n","Epoch:  1189 | train loss: 0.000572 | valid loss: 0.002424\n","Epoch:  1190 | train loss: 0.000768 | valid loss: 0.002435\n","Epoch:  1191 | train loss: 0.000825 | valid loss: 0.002366\n","Epoch:  1192 | train loss: 0.000628 | valid loss: 0.002329\n","Epoch:  1193 | train loss: 0.000833 | valid loss: 0.002423\n","Epoch:  1194 | train loss: 0.001004 | valid loss: 0.002398\n","Epoch:  1195 | train loss: 0.000716 | valid loss: 0.002565\n","Epoch:  1196 | train loss: 0.001237 | valid loss: 0.002432\n","Epoch:  1197 | train loss: 0.000674 | valid loss: 0.002690\n","Epoch:  1198 | train loss: 0.000642 | valid loss: 0.002485\n","Epoch:  1199 | train loss: 0.001275 | valid loss: 0.002555\n","Epoch:  1200 | train loss: 0.000874 | valid loss: 0.002497\n","Epoch:  1201 | train loss: 0.000717 | valid loss: 0.002447\n","Epoch:  1202 | train loss: 0.000876 | valid loss: 0.002481\n","Epoch:  1203 | train loss: 0.000831 | valid loss: 0.002488\n","Epoch:  1204 | train loss: 0.000860 | valid loss: 0.002493\n","Epoch:  1205 | train loss: 0.000625 | valid loss: 0.002401\n","Epoch:  1206 | train loss: 0.000716 | valid loss: 0.002424\n","Epoch:  1207 | train loss: 0.000836 | valid loss: 0.002469\n","Epoch:  1208 | train loss: 0.000926 | valid loss: 0.002390\n","Epoch:  1209 | train loss: 0.000723 | valid loss: 0.002402\n","Epoch:  1210 | train loss: 0.000901 | valid loss: 0.002408\n","Epoch:  1211 | train loss: 0.000811 | valid loss: 0.002525\n","Epoch:  1212 | train loss: 0.000832 | valid loss: 0.002509\n","Epoch:  1213 | train loss: 0.000588 | valid loss: 0.002456\n","Epoch:  1214 | train loss: 0.000832 | valid loss: 0.002517\n","Epoch:  1215 | train loss: 0.001149 | valid loss: 0.002631\n","Epoch:  1216 | train loss: 0.000826 | valid loss: 0.002450\n","Epoch:  1217 | train loss: 0.000797 | valid loss: 0.002404\n","Epoch:  1218 | train loss: 0.000586 | valid loss: 0.002378\n","Epoch:  1219 | train loss: 0.000897 | valid loss: 0.002368\n","Epoch:  1220 | train loss: 0.000581 | valid loss: 0.002366\n","Epoch:  1221 | train loss: 0.000748 | valid loss: 0.002373\n","Epoch:  1222 | train loss: 0.000669 | valid loss: 0.002466\n","Epoch:  1223 | train loss: 0.001136 | valid loss: 0.002612\n","Epoch:  1224 | train loss: 0.000825 | valid loss: 0.002599\n","Epoch:  1225 | train loss: 0.000860 | valid loss: 0.002548\n","Epoch:  1226 | train loss: 0.000859 | valid loss: 0.002596\n","Epoch:  1227 | train loss: 0.000920 | valid loss: 0.002606\n","Epoch:  1228 | train loss: 0.000696 | valid loss: 0.002492\n","Epoch:  1229 | train loss: 0.001226 | valid loss: 0.002757\n","Epoch:  1230 | train loss: 0.000949 | valid loss: 0.002396\n","Epoch:  1231 | train loss: 0.000535 | valid loss: 0.002367\n","Epoch:  1232 | train loss: 0.001125 | valid loss: 0.002352\n","Epoch:  1233 | train loss: 0.000765 | valid loss: 0.002418\n","Epoch:  1234 | train loss: 0.001001 | valid loss: 0.002370\n","Epoch:  1235 | train loss: 0.000683 | valid loss: 0.002348\n","Epoch:  1236 | train loss: 0.000705 | valid loss: 0.002417\n","Epoch:  1237 | train loss: 0.000717 | valid loss: 0.002377\n","Epoch:  1238 | train loss: 0.000856 | valid loss: 0.002360\n","Epoch:  1239 | train loss: 0.000903 | valid loss: 0.002548\n","Epoch:  1240 | train loss: 0.000759 | valid loss: 0.002574\n","Epoch:  1241 | train loss: 0.001155 | valid loss: 0.002492\n","Epoch:  1242 | train loss: 0.000787 | valid loss: 0.002495\n","Epoch:  1243 | train loss: 0.001161 | valid loss: 0.002620\n","Epoch:  1244 | train loss: 0.000631 | valid loss: 0.002618\n","Epoch:  1245 | train loss: 0.000596 | valid loss: 0.002399\n","Epoch:  1246 | train loss: 0.000540 | valid loss: 0.002382\n","Epoch:  1247 | train loss: 0.000995 | valid loss: 0.002466\n","Epoch:  1248 | train loss: 0.000797 | valid loss: 0.002478\n","Epoch:  1249 | train loss: 0.000844 | valid loss: 0.002588\n","Epoch:  1250 | train loss: 0.000631 | valid loss: 0.002471\n","Epoch:  1251 | train loss: 0.000621 | valid loss: 0.002364\n","Epoch:  1252 | train loss: 0.000700 | valid loss: 0.002401\n","Epoch:  1253 | train loss: 0.000801 | valid loss: 0.002471\n","Epoch:  1254 | train loss: 0.000736 | valid loss: 0.002377\n","Epoch:  1255 | train loss: 0.001064 | valid loss: 0.002482\n","Epoch:  1256 | train loss: 0.000767 | valid loss: 0.002464\n","Epoch:  1257 | train loss: 0.000825 | valid loss: 0.002406\n","Epoch:  1258 | train loss: 0.000598 | valid loss: 0.002487\n","Epoch:  1259 | train loss: 0.000812 | valid loss: 0.002544\n","Epoch:  1260 | train loss: 0.000872 | valid loss: 0.002566\n","Epoch:  1261 | train loss: 0.001092 | valid loss: 0.002394\n","Epoch:  1262 | train loss: 0.000879 | valid loss: 0.002623\n","Epoch:  1263 | train loss: 0.001188 | valid loss: 0.002551\n","Epoch:  1264 | train loss: 0.000924 | valid loss: 0.002499\n","Epoch:  1265 | train loss: 0.000840 | valid loss: 0.002690\n","Epoch:  1266 | train loss: 0.000898 | valid loss: 0.002505\n","Epoch:  1267 | train loss: 0.000777 | valid loss: 0.002545\n","Epoch:  1268 | train loss: 0.001011 | valid loss: 0.002435\n","Epoch:  1269 | train loss: 0.000778 | valid loss: 0.002458\n","Epoch:  1270 | train loss: 0.000662 | valid loss: 0.002433\n","Epoch:  1271 | train loss: 0.000975 | valid loss: 0.002416\n","Epoch:  1272 | train loss: 0.000727 | valid loss: 0.002623\n","Epoch:  1273 | train loss: 0.000953 | valid loss: 0.002662\n","Epoch:  1274 | train loss: 0.001031 | valid loss: 0.002497\n","Epoch:  1275 | train loss: 0.000986 | valid loss: 0.002546\n","Epoch:  1276 | train loss: 0.000778 | valid loss: 0.002437\n","Epoch:  1277 | train loss: 0.001189 | valid loss: 0.002352\n","Epoch:  1278 | train loss: 0.000877 | valid loss: 0.002501\n","Epoch:  1279 | train loss: 0.001208 | valid loss: 0.002449\n","Epoch:  1280 | train loss: 0.000685 | valid loss: 0.002654\n","Epoch:  1281 | train loss: 0.001176 | valid loss: 0.002550\n","Epoch:  1282 | train loss: 0.001232 | valid loss: 0.002580\n","Epoch:  1283 | train loss: 0.001085 | valid loss: 0.002522\n","Epoch:  1284 | train loss: 0.001178 | valid loss: 0.002571\n","Epoch:  1285 | train loss: 0.000969 | valid loss: 0.002563\n","Epoch:  1286 | train loss: 0.000601 | valid loss: 0.002518\n","Epoch:  1287 | train loss: 0.001282 | valid loss: 0.002401\n","Epoch:  1288 | train loss: 0.000710 | valid loss: 0.002583\n","Epoch:  1289 | train loss: 0.000633 | valid loss: 0.002503\n","Epoch:  1290 | train loss: 0.000982 | valid loss: 0.002531\n","Epoch:  1291 | train loss: 0.001122 | valid loss: 0.002427\n","Epoch:  1292 | train loss: 0.000894 | valid loss: 0.002485\n","Epoch:  1293 | train loss: 0.000820 | valid loss: 0.002587\n","Epoch:  1294 | train loss: 0.000613 | valid loss: 0.002485\n","Epoch:  1295 | train loss: 0.000670 | valid loss: 0.002484\n","Epoch:  1296 | train loss: 0.001086 | valid loss: 0.002566\n","Epoch:  1297 | train loss: 0.000808 | valid loss: 0.002526\n","Epoch:  1298 | train loss: 0.000979 | valid loss: 0.002581\n","Epoch:  1299 | train loss: 0.003036 | valid loss: 0.002527\n","Epoch:  1300 | train loss: 0.000978 | valid loss: 0.002577\n","Epoch:  1301 | train loss: 0.000812 | valid loss: 0.002441\n","Epoch:  1302 | train loss: 0.000560 | valid loss: 0.002468\n","Epoch:  1303 | train loss: 0.000761 | valid loss: 0.002509\n","Epoch:  1304 | train loss: 0.000720 | valid loss: 0.002495\n","Epoch:  1305 | train loss: 0.001161 | valid loss: 0.002718\n","Epoch:  1306 | train loss: 0.000643 | valid loss: 0.002536\n","Epoch:  1307 | train loss: 0.000952 | valid loss: 0.002483\n","Epoch:  1308 | train loss: 0.000686 | valid loss: 0.002462\n","Epoch:  1309 | train loss: 0.001024 | valid loss: 0.002455\n","Epoch:  1310 | train loss: 0.000845 | valid loss: 0.002593\n","Epoch:  1311 | train loss: 0.000796 | valid loss: 0.002495\n","Epoch:  1312 | train loss: 0.001081 | valid loss: 0.002551\n","Epoch:  1313 | train loss: 0.000816 | valid loss: 0.002548\n","Epoch:  1314 | train loss: 0.000974 | valid loss: 0.002676\n","Epoch:  1315 | train loss: 0.001018 | valid loss: 0.002498\n","Epoch:  1316 | train loss: 0.001255 | valid loss: 0.002505\n","Epoch:  1317 | train loss: 0.000512 | valid loss: 0.002557\n","Epoch:  1318 | train loss: 0.000595 | valid loss: 0.002628\n","Epoch:  1319 | train loss: 0.001164 | valid loss: 0.002565\n","Epoch:  1320 | train loss: 0.000767 | valid loss: 0.002536\n","Epoch:  1321 | train loss: 0.000651 | valid loss: 0.002479\n","Epoch:  1322 | train loss: 0.000726 | valid loss: 0.002556\n","Epoch:  1323 | train loss: 0.000748 | valid loss: 0.002437\n","Epoch:  1324 | train loss: 0.000709 | valid loss: 0.002467\n","Epoch:  1325 | train loss: 0.000714 | valid loss: 0.002585\n","Epoch:  1326 | train loss: 0.000727 | valid loss: 0.002471\n","Epoch:  1327 | train loss: 0.000757 | valid loss: 0.002487\n","Epoch:  1328 | train loss: 0.000742 | valid loss: 0.002522\n","Epoch:  1329 | train loss: 0.000534 | valid loss: 0.002581\n","Epoch:  1330 | train loss: 0.000854 | valid loss: 0.002575\n","Epoch:  1331 | train loss: 0.000993 | valid loss: 0.002647\n","Epoch:  1332 | train loss: 0.001010 | valid loss: 0.002521\n","Epoch:  1333 | train loss: 0.000913 | valid loss: 0.002519\n","Epoch:  1334 | train loss: 0.000706 | valid loss: 0.002464\n","Epoch:  1335 | train loss: 0.000953 | valid loss: 0.002508\n","Epoch:  1336 | train loss: 0.001027 | valid loss: 0.002600\n","Epoch:  1337 | train loss: 0.000844 | valid loss: 0.002531\n","Epoch:  1338 | train loss: 0.000938 | valid loss: 0.002561\n","Epoch:  1339 | train loss: 0.001061 | valid loss: 0.002445\n","Epoch:  1340 | train loss: 0.000655 | valid loss: 0.002509\n","Epoch:  1341 | train loss: 0.000777 | valid loss: 0.002487\n","Epoch:  1342 | train loss: 0.000639 | valid loss: 0.002498\n","Epoch:  1343 | train loss: 0.000646 | valid loss: 0.002523\n","Epoch:  1344 | train loss: 0.000811 | valid loss: 0.002473\n","Epoch:  1345 | train loss: 0.000658 | valid loss: 0.002494\n","Epoch:  1346 | train loss: 0.000897 | valid loss: 0.002568\n","Epoch:  1347 | train loss: 0.000791 | valid loss: 0.002590\n","Epoch:  1348 | train loss: 0.000983 | valid loss: 0.002672\n","Epoch:  1349 | train loss: 0.000724 | valid loss: 0.002495\n","Epoch:  1350 | train loss: 0.001145 | valid loss: 0.002606\n","Epoch:  1351 | train loss: 0.003439 | valid loss: 0.002586\n","Epoch:  1352 | train loss: 0.001329 | valid loss: 0.002538\n","Epoch:  1353 | train loss: 0.000652 | valid loss: 0.002592\n","Epoch:  1354 | train loss: 0.000971 | valid loss: 0.002518\n","Epoch:  1355 | train loss: 0.000863 | valid loss: 0.002657\n","Epoch:  1356 | train loss: 0.000678 | valid loss: 0.002507\n","Epoch:  1357 | train loss: 0.000625 | valid loss: 0.002487\n","Epoch:  1358 | train loss: 0.000730 | valid loss: 0.002431\n","Epoch:  1359 | train loss: 0.000606 | valid loss: 0.002453\n","Epoch:  1360 | train loss: 0.000897 | valid loss: 0.002514\n","Epoch:  1361 | train loss: 0.000716 | valid loss: 0.002640\n","Epoch:  1362 | train loss: 0.001891 | valid loss: 0.002590\n","Epoch:  1363 | train loss: 0.000842 | valid loss: 0.002679\n","Epoch:  1364 | train loss: 0.001041 | valid loss: 0.002534\n","Epoch:  1365 | train loss: 0.000814 | valid loss: 0.002593\n","Epoch:  1366 | train loss: 0.000850 | valid loss: 0.002592\n","Epoch:  1367 | train loss: 0.000699 | valid loss: 0.002617\n","Epoch:  1368 | train loss: 0.001034 | valid loss: 0.002461\n","Epoch:  1369 | train loss: 0.000681 | valid loss: 0.002525\n","Epoch:  1370 | train loss: 0.000890 | valid loss: 0.002471\n","Epoch:  1371 | train loss: 0.000658 | valid loss: 0.002486\n","Epoch:  1372 | train loss: 0.000789 | valid loss: 0.002450\n","Epoch:  1373 | train loss: 0.000792 | valid loss: 0.002528\n","Epoch:  1374 | train loss: 0.000910 | valid loss: 0.002575\n","Epoch:  1375 | train loss: 0.000789 | valid loss: 0.002569\n","Epoch:  1376 | train loss: 0.000614 | valid loss: 0.002603\n","Epoch:  1377 | train loss: 0.001010 | valid loss: 0.002574\n","Epoch:  1378 | train loss: 0.003160 | valid loss: 0.002681\n","Epoch:  1379 | train loss: 0.001042 | valid loss: 0.002554\n","Epoch:  1380 | train loss: 0.000649 | valid loss: 0.002641\n","Epoch:  1381 | train loss: 0.000841 | valid loss: 0.002665\n","Epoch:  1382 | train loss: 0.001339 | valid loss: 0.002750\n","Epoch:  1383 | train loss: 0.001145 | valid loss: 0.002802\n","Epoch:  1384 | train loss: 0.000767 | valid loss: 0.002627\n","Epoch:  1385 | train loss: 0.000715 | valid loss: 0.002597\n","Epoch:  1386 | train loss: 0.000660 | valid loss: 0.002504\n","Epoch:  1387 | train loss: 0.000801 | valid loss: 0.002516\n","Epoch:  1388 | train loss: 0.000787 | valid loss: 0.002460\n","Epoch:  1389 | train loss: 0.001043 | valid loss: 0.002524\n","Epoch:  1390 | train loss: 0.000541 | valid loss: 0.002564\n","Epoch:  1391 | train loss: 0.000712 | valid loss: 0.002769\n","Epoch:  1392 | train loss: 0.000855 | valid loss: 0.002690\n","Epoch:  1393 | train loss: 0.000666 | valid loss: 0.002621\n","Epoch:  1394 | train loss: 0.000903 | valid loss: 0.002682\n","Epoch:  1395 | train loss: 0.000813 | valid loss: 0.002717\n","Epoch:  1396 | train loss: 0.000901 | valid loss: 0.002438\n","Epoch:  1397 | train loss: 0.000965 | valid loss: 0.002506\n","Epoch:  1398 | train loss: 0.000513 | valid loss: 0.002413\n","Epoch:  1399 | train loss: 0.000513 | valid loss: 0.002414\n","Epoch:  1400 | train loss: 0.000677 | valid loss: 0.002613\n","Epoch:  1401 | train loss: 0.000800 | valid loss: 0.002536\n","Epoch:  1402 | train loss: 0.000724 | valid loss: 0.002562\n","Epoch:  1403 | train loss: 0.001191 | valid loss: 0.002503\n","Epoch:  1404 | train loss: 0.000951 | valid loss: 0.002538\n","Epoch:  1405 | train loss: 0.001173 | valid loss: 0.002535\n","Epoch:  1406 | train loss: 0.000988 | valid loss: 0.002558\n","Epoch:  1407 | train loss: 0.000845 | valid loss: 0.002667\n","Epoch:  1408 | train loss: 0.000779 | valid loss: 0.002598\n","Epoch:  1409 | train loss: 0.000945 | valid loss: 0.002702\n","Epoch:  1410 | train loss: 0.000658 | valid loss: 0.002581\n","Epoch:  1411 | train loss: 0.001017 | valid loss: 0.002475\n","Epoch:  1412 | train loss: 0.001105 | valid loss: 0.002555\n","Epoch:  1413 | train loss: 0.000713 | valid loss: 0.002511\n","Epoch:  1414 | train loss: 0.000648 | valid loss: 0.002456\n","Epoch:  1415 | train loss: 0.000516 | valid loss: 0.002516\n","Epoch:  1416 | train loss: 0.001022 | valid loss: 0.002686\n","Epoch:  1417 | train loss: 0.000953 | valid loss: 0.002481\n","Epoch:  1418 | train loss: 0.000778 | valid loss: 0.002621\n","Epoch:  1419 | train loss: 0.000617 | valid loss: 0.002520\n","Epoch:  1420 | train loss: 0.000753 | valid loss: 0.002629\n","Epoch:  1421 | train loss: 0.000761 | valid loss: 0.002451\n","Epoch:  1422 | train loss: 0.001157 | valid loss: 0.002636\n","Epoch:  1423 | train loss: 0.000933 | valid loss: 0.002567\n","Epoch:  1424 | train loss: 0.000793 | valid loss: 0.002581\n","Epoch:  1425 | train loss: 0.000979 | valid loss: 0.002661\n","Epoch:  1426 | train loss: 0.000580 | valid loss: 0.002600\n","Epoch:  1427 | train loss: 0.000860 | valid loss: 0.002572\n","Epoch:  1428 | train loss: 0.000723 | valid loss: 0.002491\n","Epoch:  1429 | train loss: 0.000863 | valid loss: 0.002636\n","Epoch:  1430 | train loss: 0.000710 | valid loss: 0.002461\n","Epoch:  1431 | train loss: 0.000597 | valid loss: 0.002565\n","Epoch:  1432 | train loss: 0.000570 | valid loss: 0.002583\n","Epoch:  1433 | train loss: 0.000928 | valid loss: 0.002547\n","Epoch:  1434 | train loss: 0.000613 | valid loss: 0.002627\n","Epoch:  1435 | train loss: 0.001019 | valid loss: 0.002807\n","Epoch:  1436 | train loss: 0.000903 | valid loss: 0.002670\n","Epoch:  1437 | train loss: 0.000811 | valid loss: 0.002798\n","Epoch:  1438 | train loss: 0.000722 | valid loss: 0.002682\n","Epoch:  1439 | train loss: 0.001084 | valid loss: 0.002644\n","Epoch:  1440 | train loss: 0.000963 | valid loss: 0.002554\n","Epoch:  1441 | train loss: 0.000758 | valid loss: 0.002632\n","Epoch:  1442 | train loss: 0.000807 | valid loss: 0.002544\n","Epoch:  1443 | train loss: 0.000776 | valid loss: 0.002572\n","Epoch:  1444 | train loss: 0.000670 | valid loss: 0.002562\n","Epoch:  1445 | train loss: 0.000683 | valid loss: 0.002540\n","Epoch:  1446 | train loss: 0.000497 | valid loss: 0.002470\n","Epoch:  1447 | train loss: 0.000920 | valid loss: 0.002531\n","Epoch:  1448 | train loss: 0.000881 | valid loss: 0.002494\n","Epoch:  1449 | train loss: 0.000770 | valid loss: 0.002600\n","Epoch:  1450 | train loss: 0.001161 | valid loss: 0.002638\n","Epoch:  1451 | train loss: 0.000996 | valid loss: 0.002615\n","Epoch:  1452 | train loss: 0.000639 | valid loss: 0.002573\n","Epoch:  1453 | train loss: 0.000597 | valid loss: 0.002472\n","Epoch:  1454 | train loss: 0.000781 | valid loss: 0.002631\n","Epoch:  1455 | train loss: 0.000866 | valid loss: 0.002560\n","Epoch:  1456 | train loss: 0.000728 | valid loss: 0.002651\n","Epoch:  1457 | train loss: 0.000691 | valid loss: 0.002608\n","Epoch:  1458 | train loss: 0.000689 | valid loss: 0.002569\n","Epoch:  1459 | train loss: 0.000693 | valid loss: 0.002595\n","Epoch:  1460 | train loss: 0.000776 | valid loss: 0.002639\n","Epoch:  1461 | train loss: 0.000950 | valid loss: 0.002674\n","Epoch:  1462 | train loss: 0.000919 | valid loss: 0.002634\n","Epoch:  1463 | train loss: 0.000656 | valid loss: 0.002654\n","Epoch:  1464 | train loss: 0.000922 | valid loss: 0.002545\n","Epoch:  1465 | train loss: 0.000580 | valid loss: 0.002510\n","Epoch:  1466 | train loss: 0.000943 | valid loss: 0.002633\n","Epoch:  1467 | train loss: 0.001022 | valid loss: 0.002697\n","Epoch:  1468 | train loss: 0.001114 | valid loss: 0.002809\n","Epoch:  1469 | train loss: 0.000901 | valid loss: 0.002603\n","Epoch:  1470 | train loss: 0.001097 | valid loss: 0.002609\n","Epoch:  1471 | train loss: 0.000775 | valid loss: 0.002571\n","Epoch:  1472 | train loss: 0.000716 | valid loss: 0.002729\n","Epoch:  1473 | train loss: 0.000633 | valid loss: 0.002623\n","Epoch:  1474 | train loss: 0.000588 | valid loss: 0.002593\n","Epoch:  1475 | train loss: 0.001001 | valid loss: 0.002636\n","Epoch:  1476 | train loss: 0.000800 | valid loss: 0.002483\n","Epoch:  1477 | train loss: 0.000915 | valid loss: 0.002594\n","Epoch:  1478 | train loss: 0.001078 | valid loss: 0.002507\n","Epoch:  1479 | train loss: 0.000658 | valid loss: 0.002598\n","Epoch:  1480 | train loss: 0.000678 | valid loss: 0.002609\n","Epoch:  1481 | train loss: 0.000614 | valid loss: 0.002594\n","Epoch:  1482 | train loss: 0.000747 | valid loss: 0.002752\n","Epoch:  1483 | train loss: 0.000963 | valid loss: 0.002692\n","Epoch:  1484 | train loss: 0.000795 | valid loss: 0.002688\n","Epoch:  1485 | train loss: 0.000959 | valid loss: 0.002659\n","Epoch:  1486 | train loss: 0.000904 | valid loss: 0.002545\n","Epoch:  1487 | train loss: 0.002169 | valid loss: 0.002595\n","Epoch:  1488 | train loss: 0.000852 | valid loss: 0.002531\n","Epoch:  1489 | train loss: 0.000543 | valid loss: 0.002465\n","Epoch:  1490 | train loss: 0.000936 | valid loss: 0.002526\n","Epoch:  1491 | train loss: 0.000771 | valid loss: 0.002507\n","Epoch:  1492 | train loss: 0.001105 | valid loss: 0.002544\n","Epoch:  1493 | train loss: 0.000957 | valid loss: 0.002616\n","Epoch:  1494 | train loss: 0.000747 | valid loss: 0.002671\n","Epoch:  1495 | train loss: 0.001474 | valid loss: 0.002657\n","Epoch:  1496 | train loss: 0.000859 | valid loss: 0.002694\n","Epoch:  1497 | train loss: 0.000723 | valid loss: 0.002687\n","Epoch:  1498 | train loss: 0.000894 | valid loss: 0.002628\n","Epoch:  1499 | train loss: 0.001266 | valid loss: 0.002674\n","Epoch:  1500 | train loss: 0.000810 | valid loss: 0.002673\n","Epoch:  1501 | train loss: 0.000979 | valid loss: 0.002715\n","Epoch:  1502 | train loss: 0.001230 | valid loss: 0.002644\n","Epoch:  1503 | train loss: 0.001261 | valid loss: 0.002713\n","Epoch:  1504 | train loss: 0.000703 | valid loss: 0.002718\n","Epoch:  1505 | train loss: 0.000691 | valid loss: 0.002568\n","Epoch:  1506 | train loss: 0.000792 | valid loss: 0.002634\n","Epoch:  1507 | train loss: 0.001069 | valid loss: 0.002592\n","Epoch:  1508 | train loss: 0.000812 | valid loss: 0.002511\n","Epoch:  1509 | train loss: 0.000484 | valid loss: 0.002576\n","Epoch:  1510 | train loss: 0.000515 | valid loss: 0.002594\n","Epoch:  1511 | train loss: 0.000599 | valid loss: 0.002483\n","Epoch:  1512 | train loss: 0.000861 | valid loss: 0.002563\n","Epoch:  1513 | train loss: 0.001048 | valid loss: 0.002702\n","Epoch:  1514 | train loss: 0.000718 | valid loss: 0.002700\n","Epoch:  1515 | train loss: 0.000881 | valid loss: 0.002731\n","Epoch:  1516 | train loss: 0.000762 | valid loss: 0.002578\n","Epoch:  1517 | train loss: 0.000694 | valid loss: 0.002617\n","Epoch:  1518 | train loss: 0.000745 | valid loss: 0.002659\n","Epoch:  1519 | train loss: 0.000638 | valid loss: 0.002677\n","Epoch:  1520 | train loss: 0.000956 | valid loss: 0.002653\n","Epoch:  1521 | train loss: 0.000867 | valid loss: 0.002632\n","Epoch:  1522 | train loss: 0.000699 | valid loss: 0.002667\n","Epoch:  1523 | train loss: 0.000793 | valid loss: 0.002615\n","Epoch:  1524 | train loss: 0.001021 | valid loss: 0.002645\n","Epoch:  1525 | train loss: 0.000954 | valid loss: 0.002574\n","Epoch:  1526 | train loss: 0.000717 | valid loss: 0.002498\n","Epoch:  1527 | train loss: 0.000715 | valid loss: 0.002622\n","Epoch:  1528 | train loss: 0.000601 | valid loss: 0.002588\n","Epoch:  1529 | train loss: 0.000993 | valid loss: 0.002669\n","Epoch:  1530 | train loss: 0.001223 | valid loss: 0.002757\n","Epoch:  1531 | train loss: 0.000698 | valid loss: 0.002672\n","Epoch:  1532 | train loss: 0.001162 | valid loss: 0.002628\n","Epoch:  1533 | train loss: 0.000974 | valid loss: 0.002549\n","Epoch:  1534 | train loss: 0.000825 | valid loss: 0.002681\n","Epoch:  1535 | train loss: 0.000718 | valid loss: 0.002611\n","Epoch:  1536 | train loss: 0.000604 | valid loss: 0.002660\n","Epoch:  1537 | train loss: 0.000912 | valid loss: 0.002622\n","Epoch:  1538 | train loss: 0.001012 | valid loss: 0.002771\n","Epoch:  1539 | train loss: 0.001173 | valid loss: 0.002637\n","Epoch:  1540 | train loss: 0.000935 | valid loss: 0.002665\n","Epoch:  1541 | train loss: 0.001347 | valid loss: 0.002636\n","Epoch:  1542 | train loss: 0.000787 | valid loss: 0.002623\n","Epoch:  1543 | train loss: 0.000888 | valid loss: 0.002753\n","Epoch:  1544 | train loss: 0.000497 | valid loss: 0.002562\n","Epoch:  1545 | train loss: 0.000541 | valid loss: 0.002622\n","Epoch:  1546 | train loss: 0.001009 | valid loss: 0.002588\n","Epoch:  1547 | train loss: 0.000927 | valid loss: 0.002717\n","Epoch:  1548 | train loss: 0.000667 | valid loss: 0.002660\n","Epoch:  1549 | train loss: 0.000634 | valid loss: 0.002601\n","Epoch:  1550 | train loss: 0.000936 | valid loss: 0.002763\n","Epoch:  1551 | train loss: 0.000791 | valid loss: 0.002715\n","Epoch:  1552 | train loss: 0.000844 | valid loss: 0.002600\n","Epoch:  1553 | train loss: 0.001277 | valid loss: 0.002552\n","Epoch:  1554 | train loss: 0.000633 | valid loss: 0.002580\n","Epoch:  1555 | train loss: 0.001240 | valid loss: 0.002608\n","Epoch:  1556 | train loss: 0.000574 | valid loss: 0.002684\n","Epoch:  1557 | train loss: 0.000807 | valid loss: 0.002570\n","Epoch:  1558 | train loss: 0.000690 | valid loss: 0.002647\n","Epoch:  1559 | train loss: 0.000748 | valid loss: 0.002666\n","Epoch:  1560 | train loss: 0.000698 | valid loss: 0.002557\n","Epoch:  1561 | train loss: 0.001455 | valid loss: 0.002605\n","Epoch:  1562 | train loss: 0.000769 | valid loss: 0.002632\n","Epoch:  1563 | train loss: 0.000926 | valid loss: 0.002646\n","Epoch:  1564 | train loss: 0.000748 | valid loss: 0.002672\n","Epoch:  1565 | train loss: 0.001392 | valid loss: 0.002703\n","Epoch:  1566 | train loss: 0.000626 | valid loss: 0.002922\n","Epoch:  1567 | train loss: 0.000962 | valid loss: 0.002694\n","Epoch:  1568 | train loss: 0.000933 | valid loss: 0.002714\n","Epoch:  1569 | train loss: 0.000551 | valid loss: 0.002603\n","Epoch:  1570 | train loss: 0.000947 | valid loss: 0.002705\n","Epoch:  1571 | train loss: 0.000416 | valid loss: 0.002557\n","Epoch:  1572 | train loss: 0.000567 | valid loss: 0.002650\n","Epoch:  1573 | train loss: 0.001016 | valid loss: 0.002686\n","Epoch:  1574 | train loss: 0.000722 | valid loss: 0.002667\n","Epoch:  1575 | train loss: 0.002233 | valid loss: 0.002714\n","Epoch:  1576 | train loss: 0.000777 | valid loss: 0.002677\n","Epoch:  1577 | train loss: 0.000630 | valid loss: 0.002692\n","Epoch:  1578 | train loss: 0.000904 | valid loss: 0.002632\n","Epoch:  1579 | train loss: 0.001262 | valid loss: 0.002683\n","Epoch:  1580 | train loss: 0.000941 | valid loss: 0.002623\n","Epoch:  1581 | train loss: 0.000737 | valid loss: 0.002616\n","Epoch:  1582 | train loss: 0.001136 | valid loss: 0.002706\n","Epoch:  1583 | train loss: 0.000762 | valid loss: 0.002723\n","Epoch:  1584 | train loss: 0.000968 | valid loss: 0.002627\n","Epoch:  1585 | train loss: 0.000797 | valid loss: 0.002602\n","Epoch:  1586 | train loss: 0.000798 | valid loss: 0.002741\n","Epoch:  1587 | train loss: 0.000894 | valid loss: 0.002648\n","Epoch:  1588 | train loss: 0.000720 | valid loss: 0.002672\n","Epoch:  1589 | train loss: 0.000704 | valid loss: 0.002739\n","Epoch:  1590 | train loss: 0.001181 | valid loss: 0.002689\n","Epoch:  1591 | train loss: 0.001150 | valid loss: 0.002603\n","Epoch:  1592 | train loss: 0.000698 | valid loss: 0.002680\n","Epoch:  1593 | train loss: 0.000641 | valid loss: 0.002689\n","Epoch:  1594 | train loss: 0.001078 | valid loss: 0.002729\n","Epoch:  1595 | train loss: 0.000843 | valid loss: 0.002685\n","Epoch:  1596 | train loss: 0.001168 | valid loss: 0.002801\n","Epoch:  1597 | train loss: 0.000701 | valid loss: 0.002758\n","Epoch:  1598 | train loss: 0.000698 | valid loss: 0.002672\n","Epoch:  1599 | train loss: 0.000814 | valid loss: 0.002792\n","Epoch:  1600 | train loss: 0.000770 | valid loss: 0.002764\n","Epoch:  1601 | train loss: 0.000567 | valid loss: 0.002708\n","Epoch:  1602 | train loss: 0.001340 | valid loss: 0.002642\n","Epoch:  1603 | train loss: 0.000666 | valid loss: 0.002620\n","Epoch:  1604 | train loss: 0.000693 | valid loss: 0.002785\n","Epoch:  1605 | train loss: 0.001015 | valid loss: 0.002633\n","Epoch:  1606 | train loss: 0.000708 | valid loss: 0.002536\n","Epoch:  1607 | train loss: 0.000781 | valid loss: 0.002648\n","Epoch:  1608 | train loss: 0.001066 | valid loss: 0.002567\n","Epoch:  1609 | train loss: 0.001063 | valid loss: 0.002726\n","Epoch:  1610 | train loss: 0.000935 | valid loss: 0.002693\n","Epoch:  1611 | train loss: 0.001039 | valid loss: 0.002759\n","Epoch:  1612 | train loss: 0.000563 | valid loss: 0.002655\n","Epoch:  1613 | train loss: 0.000800 | valid loss: 0.002652\n","Epoch:  1614 | train loss: 0.000814 | valid loss: 0.002782\n","Epoch:  1615 | train loss: 0.000681 | valid loss: 0.002614\n","Epoch:  1616 | train loss: 0.000888 | valid loss: 0.002703\n","Epoch:  1617 | train loss: 0.000779 | valid loss: 0.002643\n","Epoch:  1618 | train loss: 0.001438 | valid loss: 0.002707\n","Epoch:  1619 | train loss: 0.000626 | valid loss: 0.002697\n","Epoch:  1620 | train loss: 0.000754 | valid loss: 0.002612\n","Epoch:  1621 | train loss: 0.001172 | valid loss: 0.002787\n","Epoch:  1622 | train loss: 0.000697 | valid loss: 0.002618\n","Epoch:  1623 | train loss: 0.001025 | valid loss: 0.002638\n","Epoch:  1624 | train loss: 0.000884 | valid loss: 0.002657\n","Epoch:  1625 | train loss: 0.000771 | valid loss: 0.002756\n","Epoch:  1626 | train loss: 0.001015 | valid loss: 0.002832\n","Epoch:  1627 | train loss: 0.001079 | valid loss: 0.002851\n","Epoch:  1628 | train loss: 0.000811 | valid loss: 0.002859\n","Epoch:  1629 | train loss: 0.001068 | valid loss: 0.002692\n","Epoch:  1630 | train loss: 0.000829 | valid loss: 0.002653\n","Epoch:  1631 | train loss: 0.000773 | valid loss: 0.002617\n","Epoch:  1632 | train loss: 0.000804 | valid loss: 0.002763\n","Epoch:  1633 | train loss: 0.000974 | valid loss: 0.002733\n","Epoch:  1634 | train loss: 0.000852 | valid loss: 0.002653\n","Epoch:  1635 | train loss: 0.000828 | valid loss: 0.002585\n","Epoch:  1636 | train loss: 0.000700 | valid loss: 0.002597\n","Epoch:  1637 | train loss: 0.000942 | valid loss: 0.002734\n","Epoch:  1638 | train loss: 0.000734 | valid loss: 0.002706\n","Epoch:  1639 | train loss: 0.000944 | valid loss: 0.002682\n","Epoch:  1640 | train loss: 0.000755 | valid loss: 0.002743\n","Epoch:  1641 | train loss: 0.000662 | valid loss: 0.002643\n","Epoch:  1642 | train loss: 0.000922 | valid loss: 0.002625\n","Epoch:  1643 | train loss: 0.000912 | valid loss: 0.002671\n","Epoch:  1644 | train loss: 0.000871 | valid loss: 0.002587\n","Epoch:  1645 | train loss: 0.000710 | valid loss: 0.002628\n","Epoch:  1646 | train loss: 0.000872 | valid loss: 0.002650\n","Epoch:  1647 | train loss: 0.000870 | valid loss: 0.002711\n","Epoch:  1648 | train loss: 0.000960 | valid loss: 0.002754\n","Epoch:  1649 | train loss: 0.001080 | valid loss: 0.002734\n","Epoch:  1650 | train loss: 0.000821 | valid loss: 0.002840\n","Epoch:  1651 | train loss: 0.000696 | valid loss: 0.002816\n","Epoch:  1652 | train loss: 0.001470 | valid loss: 0.002556\n","Epoch:  1653 | train loss: 0.000813 | valid loss: 0.002649\n","Epoch:  1654 | train loss: 0.000744 | valid loss: 0.002613\n","Epoch:  1655 | train loss: 0.000610 | valid loss: 0.002580\n","Epoch:  1656 | train loss: 0.000905 | valid loss: 0.002591\n","Epoch:  1657 | train loss: 0.001157 | valid loss: 0.002573\n","Epoch:  1658 | train loss: 0.001121 | valid loss: 0.002711\n","Epoch:  1659 | train loss: 0.000815 | valid loss: 0.002642\n","Epoch:  1660 | train loss: 0.000898 | valid loss: 0.002634\n","Epoch:  1661 | train loss: 0.000943 | valid loss: 0.002630\n","Epoch:  1662 | train loss: 0.000865 | valid loss: 0.002706\n","Epoch:  1663 | train loss: 0.000705 | valid loss: 0.002697\n","Epoch:  1664 | train loss: 0.000626 | valid loss: 0.002647\n","Epoch:  1665 | train loss: 0.000903 | valid loss: 0.002718\n","Epoch:  1666 | train loss: 0.000784 | valid loss: 0.002724\n","Epoch:  1667 | train loss: 0.000727 | valid loss: 0.002633\n","Epoch:  1668 | train loss: 0.000822 | valid loss: 0.002644\n","Epoch:  1669 | train loss: 0.000968 | valid loss: 0.002739\n","Epoch:  1670 | train loss: 0.000871 | valid loss: 0.002656\n","Epoch:  1671 | train loss: 0.001211 | valid loss: 0.002742\n","Epoch:  1672 | train loss: 0.000592 | valid loss: 0.002736\n","Epoch:  1673 | train loss: 0.000823 | valid loss: 0.002689\n","Epoch:  1674 | train loss: 0.000598 | valid loss: 0.002662\n","Epoch:  1675 | train loss: 0.000868 | valid loss: 0.002820\n","Epoch:  1676 | train loss: 0.001104 | valid loss: 0.002672\n","Epoch:  1677 | train loss: 0.000781 | valid loss: 0.002727\n","Epoch:  1678 | train loss: 0.000733 | valid loss: 0.002710\n","Epoch:  1679 | train loss: 0.000746 | valid loss: 0.002679\n","Epoch:  1680 | train loss: 0.000899 | valid loss: 0.002756\n","Epoch:  1681 | train loss: 0.000746 | valid loss: 0.002695\n","Epoch:  1682 | train loss: 0.000686 | valid loss: 0.002704\n","Epoch:  1683 | train loss: 0.000851 | valid loss: 0.002598\n","Epoch:  1684 | train loss: 0.000873 | valid loss: 0.002664\n","Epoch:  1685 | train loss: 0.000633 | valid loss: 0.002694\n","Epoch:  1686 | train loss: 0.000726 | valid loss: 0.002704\n","Epoch:  1687 | train loss: 0.000664 | valid loss: 0.002672\n","Epoch:  1688 | train loss: 0.000965 | valid loss: 0.002645\n","Epoch:  1689 | train loss: 0.001012 | valid loss: 0.002749\n","Epoch:  1690 | train loss: 0.001017 | valid loss: 0.002746\n","Epoch:  1691 | train loss: 0.000556 | valid loss: 0.002743\n","Epoch:  1692 | train loss: 0.000502 | valid loss: 0.002724\n","Epoch:  1693 | train loss: 0.000865 | valid loss: 0.002846\n","Epoch:  1694 | train loss: 0.000724 | valid loss: 0.002665\n","Epoch:  1695 | train loss: 0.000727 | valid loss: 0.002770\n","Epoch:  1696 | train loss: 0.000872 | valid loss: 0.002718\n","Epoch:  1697 | train loss: 0.000684 | valid loss: 0.002660\n","Epoch:  1698 | train loss: 0.000749 | valid loss: 0.002626\n","Epoch:  1699 | train loss: 0.000654 | valid loss: 0.002763\n","Epoch:  1700 | train loss: 0.000849 | valid loss: 0.002698\n","Epoch:  1701 | train loss: 0.000516 | valid loss: 0.002681\n","Epoch:  1702 | train loss: 0.001018 | valid loss: 0.002668\n","Epoch:  1703 | train loss: 0.001082 | valid loss: 0.002782\n","Epoch:  1704 | train loss: 0.000677 | valid loss: 0.002735\n","Epoch:  1705 | train loss: 0.000857 | valid loss: 0.002982\n","Epoch:  1706 | train loss: 0.000989 | valid loss: 0.002706\n","Epoch:  1707 | train loss: 0.000856 | valid loss: 0.002696\n","Epoch:  1708 | train loss: 0.001102 | valid loss: 0.002711\n","Epoch:  1709 | train loss: 0.000964 | valid loss: 0.002734\n","Epoch:  1710 | train loss: 0.000513 | valid loss: 0.002682\n","Epoch:  1711 | train loss: 0.000571 | valid loss: 0.002637\n","Epoch:  1712 | train loss: 0.000541 | valid loss: 0.002680\n","Epoch:  1713 | train loss: 0.000833 | valid loss: 0.002832\n","Epoch:  1714 | train loss: 0.000533 | valid loss: 0.002733\n","Epoch:  1715 | train loss: 0.000750 | valid loss: 0.002728\n","Epoch:  1716 | train loss: 0.001222 | valid loss: 0.002825\n","Epoch:  1717 | train loss: 0.001157 | valid loss: 0.002935\n","Epoch:  1718 | train loss: 0.000824 | valid loss: 0.002758\n","Epoch:  1719 | train loss: 0.000745 | valid loss: 0.002729\n","Epoch:  1720 | train loss: 0.000890 | valid loss: 0.002903\n","Epoch:  1721 | train loss: 0.000798 | valid loss: 0.002631\n","Epoch:  1722 | train loss: 0.000537 | valid loss: 0.002660\n","Epoch:  1723 | train loss: 0.000694 | valid loss: 0.002692\n","Epoch:  1724 | train loss: 0.000781 | valid loss: 0.002633\n","Epoch:  1725 | train loss: 0.000493 | valid loss: 0.002796\n","Epoch:  1726 | train loss: 0.000802 | valid loss: 0.002743\n","Epoch:  1727 | train loss: 0.001076 | valid loss: 0.002747\n","Epoch:  1728 | train loss: 0.000844 | valid loss: 0.002898\n","Epoch:  1729 | train loss: 0.001084 | valid loss: 0.002816\n","Epoch:  1730 | train loss: 0.000895 | valid loss: 0.002749\n","Epoch:  1731 | train loss: 0.000726 | valid loss: 0.002832\n","Epoch:  1732 | train loss: 0.000733 | valid loss: 0.002793\n","Epoch:  1733 | train loss: 0.000653 | valid loss: 0.002738\n","Epoch:  1734 | train loss: 0.001055 | valid loss: 0.002846\n","Epoch:  1735 | train loss: 0.000746 | valid loss: 0.002715\n","Epoch:  1736 | train loss: 0.000721 | valid loss: 0.002755\n","Epoch:  1737 | train loss: 0.000693 | valid loss: 0.002629\n","Epoch:  1738 | train loss: 0.000516 | valid loss: 0.002695\n","Epoch:  1739 | train loss: 0.001066 | valid loss: 0.002685\n","Epoch:  1740 | train loss: 0.000577 | valid loss: 0.002729\n","Epoch:  1741 | train loss: 0.001105 | valid loss: 0.002764\n","Epoch:  1742 | train loss: 0.000788 | valid loss: 0.002749\n","Epoch:  1743 | train loss: 0.000727 | valid loss: 0.002723\n","Epoch:  1744 | train loss: 0.000997 | valid loss: 0.002824\n","Epoch:  1745 | train loss: 0.000820 | valid loss: 0.002625\n","Epoch:  1746 | train loss: 0.000565 | valid loss: 0.002627\n","Epoch:  1747 | train loss: 0.000995 | valid loss: 0.002726\n","Epoch:  1748 | train loss: 0.000774 | valid loss: 0.002794\n","Epoch:  1749 | train loss: 0.000786 | valid loss: 0.002733\n","Epoch:  1750 | train loss: 0.000804 | valid loss: 0.002918\n","Epoch:  1751 | train loss: 0.000734 | valid loss: 0.002743\n","Epoch:  1752 | train loss: 0.000755 | valid loss: 0.002785\n","Epoch:  1753 | train loss: 0.001087 | valid loss: 0.002785\n","Epoch:  1754 | train loss: 0.000899 | valid loss: 0.002754\n","Epoch:  1755 | train loss: 0.000839 | valid loss: 0.002855\n","Epoch:  1756 | train loss: 0.001155 | valid loss: 0.002839\n","Epoch:  1757 | train loss: 0.000716 | valid loss: 0.002704\n","Epoch:  1758 | train loss: 0.000578 | valid loss: 0.002558\n","Epoch:  1759 | train loss: 0.000887 | valid loss: 0.002728\n","Epoch:  1760 | train loss: 0.000601 | valid loss: 0.002721\n","Epoch:  1761 | train loss: 0.000897 | valid loss: 0.002712\n","Epoch:  1762 | train loss: 0.000803 | valid loss: 0.002747\n","Epoch:  1763 | train loss: 0.000655 | valid loss: 0.002690\n","Epoch:  1764 | train loss: 0.000759 | valid loss: 0.002709\n","Epoch:  1765 | train loss: 0.000823 | valid loss: 0.002713\n","Epoch:  1766 | train loss: 0.001002 | valid loss: 0.002747\n","Epoch:  1767 | train loss: 0.000619 | valid loss: 0.002685\n","Epoch:  1768 | train loss: 0.001093 | valid loss: 0.002699\n","Epoch:  1769 | train loss: 0.000925 | valid loss: 0.002756\n","Epoch:  1770 | train loss: 0.000917 | valid loss: 0.002776\n","Epoch:  1771 | train loss: 0.000968 | valid loss: 0.002907\n","Epoch:  1772 | train loss: 0.000958 | valid loss: 0.003024\n","Epoch:  1773 | train loss: 0.001061 | valid loss: 0.002774\n","Epoch:  1774 | train loss: 0.001005 | valid loss: 0.002716\n","Epoch:  1775 | train loss: 0.000902 | valid loss: 0.002713\n","Epoch:  1776 | train loss: 0.000521 | valid loss: 0.002669\n","Epoch:  1777 | train loss: 0.000757 | valid loss: 0.002659\n","Epoch:  1778 | train loss: 0.000797 | valid loss: 0.002741\n","Epoch:  1779 | train loss: 0.000913 | valid loss: 0.002723\n","Epoch:  1780 | train loss: 0.000758 | valid loss: 0.002626\n","Epoch:  1781 | train loss: 0.000879 | valid loss: 0.002681\n","Epoch:  1782 | train loss: 0.000819 | valid loss: 0.002738\n","Epoch:  1783 | train loss: 0.001073 | valid loss: 0.002685\n","Epoch:  1784 | train loss: 0.000724 | valid loss: 0.002711\n","Epoch:  1785 | train loss: 0.000721 | valid loss: 0.002667\n","Epoch:  1786 | train loss: 0.001337 | valid loss: 0.002798\n","Epoch:  1787 | train loss: 0.000834 | valid loss: 0.002648\n","Epoch:  1788 | train loss: 0.000587 | valid loss: 0.002705\n","Epoch:  1789 | train loss: 0.000868 | valid loss: 0.002748\n","Epoch:  1790 | train loss: 0.000876 | valid loss: 0.002691\n","Epoch:  1791 | train loss: 0.000906 | valid loss: 0.002714\n","Epoch:  1792 | train loss: 0.000812 | valid loss: 0.002784\n","Epoch:  1793 | train loss: 0.000732 | valid loss: 0.002762\n","Epoch:  1794 | train loss: 0.000774 | valid loss: 0.002804\n","Epoch:  1795 | train loss: 0.000721 | valid loss: 0.002763\n","Epoch:  1796 | train loss: 0.000568 | valid loss: 0.002838\n","Epoch:  1797 | train loss: 0.000938 | valid loss: 0.002889\n","Epoch:  1798 | train loss: 0.000863 | valid loss: 0.002732\n","Epoch:  1799 | train loss: 0.000697 | valid loss: 0.002767\n","Epoch:  1800 | train loss: 0.000688 | valid loss: 0.002716\n","Epoch:  1801 | train loss: 0.000731 | valid loss: 0.002693\n","Epoch:  1802 | train loss: 0.001076 | valid loss: 0.002776\n","Epoch:  1803 | train loss: 0.000795 | valid loss: 0.002715\n","Epoch:  1804 | train loss: 0.000789 | valid loss: 0.002938\n","Epoch:  1805 | train loss: 0.000780 | valid loss: 0.002783\n","Epoch:  1806 | train loss: 0.000768 | valid loss: 0.002727\n","Epoch:  1807 | train loss: 0.001007 | valid loss: 0.002818\n","Epoch:  1808 | train loss: 0.001214 | valid loss: 0.002745\n","Epoch:  1809 | train loss: 0.000849 | valid loss: 0.002749\n","Epoch:  1810 | train loss: 0.000966 | valid loss: 0.002712\n","Epoch:  1811 | train loss: 0.001438 | valid loss: 0.002759\n","Epoch:  1812 | train loss: 0.000851 | valid loss: 0.002775\n","Epoch:  1813 | train loss: 0.000656 | valid loss: 0.002805\n","Epoch:  1814 | train loss: 0.000970 | valid loss: 0.002697\n","Epoch:  1815 | train loss: 0.000950 | valid loss: 0.002757\n","Epoch:  1816 | train loss: 0.000754 | valid loss: 0.002730\n","Epoch:  1817 | train loss: 0.001038 | valid loss: 0.002693\n","Epoch:  1818 | train loss: 0.000919 | valid loss: 0.002791\n","Epoch:  1819 | train loss: 0.000975 | valid loss: 0.002711\n","Epoch:  1820 | train loss: 0.000610 | valid loss: 0.002777\n","Epoch:  1821 | train loss: 0.000783 | valid loss: 0.002898\n","Epoch:  1822 | train loss: 0.001080 | valid loss: 0.002733\n","Epoch:  1823 | train loss: 0.000906 | valid loss: 0.002791\n","Epoch:  1824 | train loss: 0.000958 | valid loss: 0.002811\n","Epoch:  1825 | train loss: 0.000683 | valid loss: 0.002812\n","Epoch:  1826 | train loss: 0.000854 | valid loss: 0.002880\n","Epoch:  1827 | train loss: 0.000867 | valid loss: 0.002752\n","Epoch:  1828 | train loss: 0.000955 | valid loss: 0.002746\n","Epoch:  1829 | train loss: 0.000498 | valid loss: 0.002642\n","Epoch:  1830 | train loss: 0.000834 | valid loss: 0.002764\n","Epoch:  1831 | train loss: 0.000529 | valid loss: 0.002724\n","Epoch:  1832 | train loss: 0.000696 | valid loss: 0.002940\n","Epoch:  1833 | train loss: 0.001168 | valid loss: 0.002835\n","Epoch:  1834 | train loss: 0.000970 | valid loss: 0.002833\n","Epoch:  1835 | train loss: 0.001159 | valid loss: 0.002917\n","Epoch:  1836 | train loss: 0.000823 | valid loss: 0.002788\n","Epoch:  1837 | train loss: 0.000544 | valid loss: 0.002834\n","Epoch:  1838 | train loss: 0.000836 | valid loss: 0.002768\n","Epoch:  1839 | train loss: 0.000887 | valid loss: 0.002719\n","Epoch:  1840 | train loss: 0.000654 | valid loss: 0.002722\n","Epoch:  1841 | train loss: 0.000674 | valid loss: 0.002833\n","Epoch:  1842 | train loss: 0.000652 | valid loss: 0.002743\n","Epoch:  1843 | train loss: 0.000561 | valid loss: 0.002721\n","Epoch:  1844 | train loss: 0.001023 | valid loss: 0.002801\n","Epoch:  1845 | train loss: 0.000803 | valid loss: 0.002822\n","Epoch:  1846 | train loss: 0.001214 | valid loss: 0.002708\n","Epoch:  1847 | train loss: 0.000665 | valid loss: 0.002788\n","Epoch:  1848 | train loss: 0.000709 | valid loss: 0.002791\n","Epoch:  1849 | train loss: 0.000914 | valid loss: 0.002741\n","Epoch:  1850 | train loss: 0.001052 | valid loss: 0.002856\n","Epoch:  1851 | train loss: 0.000625 | valid loss: 0.002884\n","Epoch:  1852 | train loss: 0.000670 | valid loss: 0.002802\n","Epoch:  1853 | train loss: 0.000886 | valid loss: 0.002820\n","Epoch:  1854 | train loss: 0.000875 | valid loss: 0.002840\n","Epoch:  1855 | train loss: 0.000636 | valid loss: 0.002832\n","Epoch:  1856 | train loss: 0.000803 | valid loss: 0.002781\n","Epoch:  1857 | train loss: 0.000950 | valid loss: 0.002754\n","Epoch:  1858 | train loss: 0.001091 | valid loss: 0.002754\n","Epoch:  1859 | train loss: 0.001059 | valid loss: 0.002828\n","Epoch:  1860 | train loss: 0.000883 | valid loss: 0.002808\n","Epoch:  1861 | train loss: 0.000795 | valid loss: 0.002789\n","Epoch:  1862 | train loss: 0.000876 | valid loss: 0.002839\n","Epoch:  1863 | train loss: 0.000919 | valid loss: 0.002775\n","Epoch:  1864 | train loss: 0.000725 | valid loss: 0.002750\n","Epoch:  1865 | train loss: 0.000633 | valid loss: 0.002764\n","Epoch:  1866 | train loss: 0.001059 | valid loss: 0.002842\n","Epoch:  1867 | train loss: 0.000723 | valid loss: 0.002706\n","Epoch:  1868 | train loss: 0.000715 | valid loss: 0.002950\n","Epoch:  1869 | train loss: 0.000815 | valid loss: 0.002764\n","Epoch:  1870 | train loss: 0.000946 | valid loss: 0.002938\n","Epoch:  1871 | train loss: 0.000856 | valid loss: 0.002865\n","Epoch:  1872 | train loss: 0.001342 | valid loss: 0.002779\n","Epoch:  1873 | train loss: 0.000812 | valid loss: 0.002680\n","Epoch:  1874 | train loss: 0.001188 | valid loss: 0.002792\n","Epoch:  1875 | train loss: 0.001751 | valid loss: 0.002715\n","Epoch:  1876 | train loss: 0.000644 | valid loss: 0.002754\n","Epoch:  1877 | train loss: 0.000745 | valid loss: 0.002839\n","Epoch:  1878 | train loss: 0.000740 | valid loss: 0.002677\n","Epoch:  1879 | train loss: 0.000815 | valid loss: 0.002833\n","Epoch:  1880 | train loss: 0.001015 | valid loss: 0.002802\n","Epoch:  1881 | train loss: 0.001054 | valid loss: 0.002972\n","Epoch:  1882 | train loss: 0.000904 | valid loss: 0.002877\n","Epoch:  1883 | train loss: 0.000796 | valid loss: 0.002854\n","Epoch:  1884 | train loss: 0.000863 | valid loss: 0.002831\n","Epoch:  1885 | train loss: 0.000830 | valid loss: 0.002759\n","Epoch:  1886 | train loss: 0.000595 | valid loss: 0.002764\n","Epoch:  1887 | train loss: 0.000733 | valid loss: 0.002777\n","Epoch:  1888 | train loss: 0.000788 | valid loss: 0.002681\n","Epoch:  1889 | train loss: 0.000719 | valid loss: 0.002688\n","Epoch:  1890 | train loss: 0.000804 | valid loss: 0.002758\n","Epoch:  1891 | train loss: 0.000743 | valid loss: 0.002924\n","Epoch:  1892 | train loss: 0.000807 | valid loss: 0.002868\n","Epoch:  1893 | train loss: 0.000891 | valid loss: 0.002836\n","Epoch:  1894 | train loss: 0.001110 | valid loss: 0.002855\n","Epoch:  1895 | train loss: 0.000913 | valid loss: 0.002800\n","Epoch:  1896 | train loss: 0.000880 | valid loss: 0.002828\n","Epoch:  1897 | train loss: 0.001224 | valid loss: 0.002814\n","Epoch:  1898 | train loss: 0.000741 | valid loss: 0.002866\n","Epoch:  1899 | train loss: 0.000644 | valid loss: 0.002722\n","Epoch:  1900 | train loss: 0.000733 | valid loss: 0.002779\n","Epoch:  1901 | train loss: 0.000424 | valid loss: 0.002686\n","Epoch:  1902 | train loss: 0.000706 | valid loss: 0.002766\n","Epoch:  1903 | train loss: 0.000646 | valid loss: 0.002706\n","Epoch:  1904 | train loss: 0.000722 | valid loss: 0.002834\n","Epoch:  1905 | train loss: 0.001160 | valid loss: 0.002760\n","Epoch:  1906 | train loss: 0.000928 | valid loss: 0.002913\n","Epoch:  1907 | train loss: 0.000912 | valid loss: 0.002811\n","Epoch:  1908 | train loss: 0.000684 | valid loss: 0.002704\n","Epoch:  1909 | train loss: 0.000616 | valid loss: 0.002809\n","Epoch:  1910 | train loss: 0.000863 | valid loss: 0.002891\n","Epoch:  1911 | train loss: 0.001058 | valid loss: 0.002771\n","Epoch:  1912 | train loss: 0.000726 | valid loss: 0.002795\n","Epoch:  1913 | train loss: 0.000730 | valid loss: 0.002882\n","Epoch:  1914 | train loss: 0.000921 | valid loss: 0.002735\n","Epoch:  1915 | train loss: 0.000709 | valid loss: 0.002735\n","Epoch:  1916 | train loss: 0.001077 | valid loss: 0.002677\n","Epoch:  1917 | train loss: 0.000714 | valid loss: 0.002736\n","Epoch:  1918 | train loss: 0.000666 | valid loss: 0.002716\n","Epoch:  1919 | train loss: 0.000764 | valid loss: 0.002823\n","Epoch:  1920 | train loss: 0.001022 | valid loss: 0.002800\n","Epoch:  1921 | train loss: 0.000624 | valid loss: 0.002785\n","Epoch:  1922 | train loss: 0.000547 | valid loss: 0.002731\n","Epoch:  1923 | train loss: 0.001124 | valid loss: 0.002912\n","Epoch:  1924 | train loss: 0.000853 | valid loss: 0.002864\n","Epoch:  1925 | train loss: 0.001049 | valid loss: 0.002899\n","Epoch:  1926 | train loss: 0.000797 | valid loss: 0.002933\n","Epoch:  1927 | train loss: 0.000879 | valid loss: 0.002976\n","Epoch:  1928 | train loss: 0.000656 | valid loss: 0.002966\n","Epoch:  1929 | train loss: 0.000824 | valid loss: 0.002821\n","Epoch:  1930 | train loss: 0.001116 | valid loss: 0.002749\n","Epoch:  1931 | train loss: 0.000700 | valid loss: 0.002843\n","Epoch:  1932 | train loss: 0.000851 | valid loss: 0.002714\n","Epoch:  1933 | train loss: 0.000651 | valid loss: 0.002727\n","Epoch:  1934 | train loss: 0.000595 | valid loss: 0.002709\n","Epoch:  1935 | train loss: 0.000573 | valid loss: 0.002753\n","Epoch:  1936 | train loss: 0.000939 | valid loss: 0.002707\n","Epoch:  1937 | train loss: 0.000976 | valid loss: 0.003033\n","Epoch:  1938 | train loss: 0.001030 | valid loss: 0.002936\n","Epoch:  1939 | train loss: 0.000816 | valid loss: 0.003019\n","Epoch:  1940 | train loss: 0.001100 | valid loss: 0.003123\n","Epoch:  1941 | train loss: 0.000698 | valid loss: 0.002803\n","Epoch:  1942 | train loss: 0.001343 | valid loss: 0.002815\n","Epoch:  1943 | train loss: 0.000655 | valid loss: 0.002873\n","Epoch:  1944 | train loss: 0.000664 | valid loss: 0.003011\n","Epoch:  1945 | train loss: 0.000552 | valid loss: 0.002857\n","Epoch:  1946 | train loss: 0.000753 | valid loss: 0.002796\n","Epoch:  1947 | train loss: 0.001160 | valid loss: 0.002815\n","Epoch:  1948 | train loss: 0.000858 | valid loss: 0.002853\n","Epoch:  1949 | train loss: 0.000641 | valid loss: 0.002753\n","Epoch:  1950 | train loss: 0.000739 | valid loss: 0.002759\n","Epoch:  1951 | train loss: 0.000525 | valid loss: 0.002782\n","Epoch:  1952 | train loss: 0.000863 | valid loss: 0.002840\n","Epoch:  1953 | train loss: 0.000969 | valid loss: 0.002764\n","Epoch:  1954 | train loss: 0.000725 | valid loss: 0.002829\n","Epoch:  1955 | train loss: 0.000682 | valid loss: 0.002702\n","Epoch:  1956 | train loss: 0.000921 | valid loss: 0.002748\n","Epoch:  1957 | train loss: 0.001114 | valid loss: 0.002784\n","Epoch:  1958 | train loss: 0.000758 | valid loss: 0.002831\n","Epoch:  1959 | train loss: 0.001060 | valid loss: 0.002824\n","Epoch:  1960 | train loss: 0.000573 | valid loss: 0.002908\n","Epoch:  1961 | train loss: 0.000948 | valid loss: 0.002854\n","Epoch:  1962 | train loss: 0.001096 | valid loss: 0.002894\n","Epoch:  1963 | train loss: 0.000806 | valid loss: 0.002906\n","Epoch:  1964 | train loss: 0.000723 | valid loss: 0.002793\n","Epoch:  1965 | train loss: 0.000668 | valid loss: 0.002781\n","Epoch:  1966 | train loss: 0.000730 | valid loss: 0.002885\n","Epoch:  1967 | train loss: 0.000997 | valid loss: 0.002764\n","Epoch:  1968 | train loss: 0.001049 | valid loss: 0.002753\n","Epoch:  1969 | train loss: 0.000839 | valid loss: 0.002825\n","Epoch:  1970 | train loss: 0.000760 | valid loss: 0.002839\n","Epoch:  1971 | train loss: 0.000640 | valid loss: 0.002783\n","Epoch:  1972 | train loss: 0.000830 | valid loss: 0.002786\n","Epoch:  1973 | train loss: 0.001062 | valid loss: 0.002734\n","Epoch:  1974 | train loss: 0.000618 | valid loss: 0.002914\n","Epoch:  1975 | train loss: 0.000967 | valid loss: 0.002855\n","Epoch:  1976 | train loss: 0.001129 | valid loss: 0.002830\n","Epoch:  1977 | train loss: 0.000780 | valid loss: 0.002926\n","Epoch:  1978 | train loss: 0.001012 | valid loss: 0.002870\n","Epoch:  1979 | train loss: 0.000866 | valid loss: 0.002872\n","Epoch:  1980 | train loss: 0.000722 | valid loss: 0.002794\n","Epoch:  1981 | train loss: 0.000565 | valid loss: 0.002828\n","Epoch:  1982 | train loss: 0.000832 | valid loss: 0.002870\n","Epoch:  1983 | train loss: 0.000814 | valid loss: 0.002818\n","Epoch:  1984 | train loss: 0.000897 | valid loss: 0.002736\n","Epoch:  1985 | train loss: 0.000728 | valid loss: 0.002824\n","Epoch:  1986 | train loss: 0.001279 | valid loss: 0.002786\n","Epoch:  1987 | train loss: 0.001319 | valid loss: 0.002781\n","Epoch:  1988 | train loss: 0.000590 | valid loss: 0.002863\n","Epoch:  1989 | train loss: 0.001318 | valid loss: 0.002864\n","Epoch:  1990 | train loss: 0.000740 | valid loss: 0.002834\n","Epoch:  1991 | train loss: 0.000923 | valid loss: 0.002815\n","Epoch:  1992 | train loss: 0.000707 | valid loss: 0.002707\n","Epoch:  1993 | train loss: 0.000507 | valid loss: 0.002760\n","Epoch:  1994 | train loss: 0.000614 | valid loss: 0.002683\n","Epoch:  1995 | train loss: 0.000838 | valid loss: 0.002912\n","Epoch:  1996 | train loss: 0.000636 | valid loss: 0.002765\n","Epoch:  1997 | train loss: 0.000537 | valid loss: 0.002863\n","Epoch:  1998 | train loss: 0.000724 | valid loss: 0.002796\n","Epoch:  1999 | train loss: 0.000863 | valid loss: 0.002826\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rb-JgLMqddFd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629654086787,"user_tz":-60,"elapsed":39,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"34f67ecf-5aa1-442e-d439-017ad24ebbb3"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Train time: 302.5202536582947\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"v74VrYNi2UI6","executionInfo":{"status":"ok","timestamp":1629654087833,"user_tz":-60,"elapsed":1066,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"347dc2b2-975c-486c-e8bf-bd31bd9a4a70"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":63},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BUvr8lhNP4c","executionInfo":{"status":"ok","timestamp":1629654095442,"user_tz":-60,"elapsed":7622,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"a46c272c-0bf1-400a-888a-6960b582082b"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":64,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 3.236452466264138e-05\n","MSE_err of valid data 0.00011025352006998719\n","MSE_err of test data 0.00010655007564184651\n","MSE_err of total data 4.75719795539822e-05\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LZiLaQV86gWv"},"source":["#### 256 variables"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vT1GmC36ilH","executionInfo":{"status":"ok","timestamp":1629654095443,"user_tz":-60,"elapsed":22,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"5daf6de6-1c7f-4d3d-dcf2-bf3b113605b2"},"source":["print(\"compress to 256\")\n","torch.manual_seed(42)\n","# Hyper-parameters\n","EPOCH = 2000\n","BATCH_SIZE = 16\n","LR = 0.001\n","k = 20550 # number of nodes - this has to match training_data.shape[0]\n","\n","print(training_data.shape) # nTrain by number of nodes by 5\n","\n","# Data Loader for easy mini-batch return in training\n","train_loader = Data.DataLoader(dataset = train_data_svd, batch_size = BATCH_SIZE, shuffle=True)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["compress to 256\n","(1600, 20550, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eU502QU-6iqP","executionInfo":{"status":"ok","timestamp":1629654334348,"user_tz":-60,"elapsed":238920,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"d0073b5c-3a00-4f08-a89f-bef7ab83bda8"},"source":["t_train_4 = time.time()\n","autoencoder_1 = FC(256).to(device)\n","optimizer = torch.optim.Adam(autoencoder_1.parameters(), lr=LR)  # Set the optimizer\n","autoencoder_1.apply(weight_init)  # Apply normalisation\n","loss_func = nn.MSELoss()\n","\n","loss_list = []\n","loss_valid = []\n","epoch_list=[]\n","for epoch in range(EPOCH):\n","    for step, x in enumerate(train_loader):\n","        #print(\"x\", x.shape)\n","        b_x = x.to(device)    # bx: False   x: False\n","        #print(\"b_y\",b_y.shape)\n","        \n","        encoded, decoded = autoencoder_1(b_x.float())   #decoded true  by:False\n","        loss = loss_func(decoded, b_x.float())  #Loss: True  # mean square error\n","        optimizer.zero_grad()                   # clear gradients for this training step\n","        loss.backward()                      # backpropagation, compute gradients\n","        optimizer.step()                     # apply gradients\n","\n","    loss_list.append(loss)\n","    encoded, decoded = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","    error_autoencoder = (decoded.detach() - torch.tensor(valid_data_svd).float().to(device))\n","    MSE_valid = (error_autoencoder**2).mean()\n","    loss_valid.append(MSE_valid)\n","    epoch_list.append(epoch)\n","    print('Epoch: ', epoch, '| train loss: %.6f' % loss.cpu().data.numpy(), '| valid loss: %.6f' % MSE_valid)\n","t_train_5 = time.time()"],"execution_count":66,"outputs":[{"output_type":"stream","text":["Epoch:  0 | train loss: 0.614901 | valid loss: 0.584030\n","Epoch:  1 | train loss: 0.080158 | valid loss: 0.080582\n","Epoch:  2 | train loss: 0.044919 | valid loss: 0.054066\n","Epoch:  3 | train loss: 0.041080 | valid loss: 0.041570\n","Epoch:  4 | train loss: 0.031750 | valid loss: 0.034243\n","Epoch:  5 | train loss: 0.043448 | valid loss: 0.030081\n","Epoch:  6 | train loss: 0.033291 | valid loss: 0.028336\n","Epoch:  7 | train loss: 0.023666 | valid loss: 0.022888\n","Epoch:  8 | train loss: 0.017090 | valid loss: 0.021544\n","Epoch:  9 | train loss: 0.024673 | valid loss: 0.020544\n","Epoch:  10 | train loss: 0.012505 | valid loss: 0.017472\n","Epoch:  11 | train loss: 0.016826 | valid loss: 0.018508\n","Epoch:  12 | train loss: 0.015731 | valid loss: 0.015622\n","Epoch:  13 | train loss: 0.014804 | valid loss: 0.015440\n","Epoch:  14 | train loss: 0.013776 | valid loss: 0.013570\n","Epoch:  15 | train loss: 0.011701 | valid loss: 0.013312\n","Epoch:  16 | train loss: 0.009727 | valid loss: 0.011868\n","Epoch:  17 | train loss: 0.011508 | valid loss: 0.013156\n","Epoch:  18 | train loss: 0.012989 | valid loss: 0.012331\n","Epoch:  19 | train loss: 0.009606 | valid loss: 0.010513\n","Epoch:  20 | train loss: 0.009764 | valid loss: 0.010167\n","Epoch:  21 | train loss: 0.008901 | valid loss: 0.009563\n","Epoch:  22 | train loss: 0.013174 | valid loss: 0.008975\n","Epoch:  23 | train loss: 0.007611 | valid loss: 0.009627\n","Epoch:  24 | train loss: 0.007016 | valid loss: 0.009069\n","Epoch:  25 | train loss: 0.008044 | valid loss: 0.008450\n","Epoch:  26 | train loss: 0.006779 | valid loss: 0.007791\n","Epoch:  27 | train loss: 0.005970 | valid loss: 0.007445\n","Epoch:  28 | train loss: 0.006629 | valid loss: 0.007163\n","Epoch:  29 | train loss: 0.007117 | valid loss: 0.007189\n","Epoch:  30 | train loss: 0.008583 | valid loss: 0.007227\n","Epoch:  31 | train loss: 0.006496 | valid loss: 0.006522\n","Epoch:  32 | train loss: 0.006162 | valid loss: 0.007103\n","Epoch:  33 | train loss: 0.004610 | valid loss: 0.006158\n","Epoch:  34 | train loss: 0.006209 | valid loss: 0.006914\n","Epoch:  35 | train loss: 0.007505 | valid loss: 0.007035\n","Epoch:  36 | train loss: 0.004616 | valid loss: 0.006187\n","Epoch:  37 | train loss: 0.004929 | valid loss: 0.005776\n","Epoch:  38 | train loss: 0.004918 | valid loss: 0.005505\n","Epoch:  39 | train loss: 0.003890 | valid loss: 0.005299\n","Epoch:  40 | train loss: 0.003536 | valid loss: 0.005153\n","Epoch:  41 | train loss: 0.007132 | valid loss: 0.006152\n","Epoch:  42 | train loss: 0.005919 | valid loss: 0.006173\n","Epoch:  43 | train loss: 0.005051 | valid loss: 0.005319\n","Epoch:  44 | train loss: 0.004922 | valid loss: 0.005644\n","Epoch:  45 | train loss: 0.005206 | valid loss: 0.005161\n","Epoch:  46 | train loss: 0.004987 | valid loss: 0.005497\n","Epoch:  47 | train loss: 0.004738 | valid loss: 0.005592\n","Epoch:  48 | train loss: 0.004476 | valid loss: 0.005378\n","Epoch:  49 | train loss: 0.005817 | valid loss: 0.005266\n","Epoch:  50 | train loss: 0.004514 | valid loss: 0.004899\n","Epoch:  51 | train loss: 0.003637 | valid loss: 0.004680\n","Epoch:  52 | train loss: 0.004369 | valid loss: 0.004835\n","Epoch:  53 | train loss: 0.004252 | valid loss: 0.004563\n","Epoch:  54 | train loss: 0.004760 | valid loss: 0.004679\n","Epoch:  55 | train loss: 0.003909 | valid loss: 0.004690\n","Epoch:  56 | train loss: 0.005255 | valid loss: 0.004824\n","Epoch:  57 | train loss: 0.005182 | valid loss: 0.004824\n","Epoch:  58 | train loss: 0.003286 | valid loss: 0.004628\n","Epoch:  59 | train loss: 0.004327 | valid loss: 0.004463\n","Epoch:  60 | train loss: 0.003255 | valid loss: 0.004424\n","Epoch:  61 | train loss: 0.004602 | valid loss: 0.004398\n","Epoch:  62 | train loss: 0.003968 | valid loss: 0.004517\n","Epoch:  63 | train loss: 0.002832 | valid loss: 0.003915\n","Epoch:  64 | train loss: 0.003035 | valid loss: 0.003855\n","Epoch:  65 | train loss: 0.002829 | valid loss: 0.003711\n","Epoch:  66 | train loss: 0.004273 | valid loss: 0.004223\n","Epoch:  67 | train loss: 0.003176 | valid loss: 0.003903\n","Epoch:  68 | train loss: 0.003363 | valid loss: 0.003841\n","Epoch:  69 | train loss: 0.003970 | valid loss: 0.003769\n","Epoch:  70 | train loss: 0.003024 | valid loss: 0.004590\n","Epoch:  71 | train loss: 0.003863 | valid loss: 0.004186\n","Epoch:  72 | train loss: 0.003914 | valid loss: 0.003977\n","Epoch:  73 | train loss: 0.002392 | valid loss: 0.003445\n","Epoch:  74 | train loss: 0.002822 | valid loss: 0.003732\n","Epoch:  75 | train loss: 0.002175 | valid loss: 0.003727\n","Epoch:  76 | train loss: 0.003564 | valid loss: 0.004083\n","Epoch:  77 | train loss: 0.002887 | valid loss: 0.003639\n","Epoch:  78 | train loss: 0.003555 | valid loss: 0.003885\n","Epoch:  79 | train loss: 0.003135 | valid loss: 0.003728\n","Epoch:  80 | train loss: 0.002893 | valid loss: 0.003432\n","Epoch:  81 | train loss: 0.002794 | valid loss: 0.003305\n","Epoch:  82 | train loss: 0.003909 | valid loss: 0.003270\n","Epoch:  83 | train loss: 0.002339 | valid loss: 0.003171\n","Epoch:  84 | train loss: 0.002602 | valid loss: 0.003226\n","Epoch:  85 | train loss: 0.002723 | valid loss: 0.003837\n","Epoch:  86 | train loss: 0.002803 | valid loss: 0.003818\n","Epoch:  87 | train loss: 0.003690 | valid loss: 0.004009\n","Epoch:  88 | train loss: 0.004108 | valid loss: 0.003188\n","Epoch:  89 | train loss: 0.002044 | valid loss: 0.003282\n","Epoch:  90 | train loss: 0.002279 | valid loss: 0.002801\n","Epoch:  91 | train loss: 0.002393 | valid loss: 0.003262\n","Epoch:  92 | train loss: 0.002480 | valid loss: 0.003323\n","Epoch:  93 | train loss: 0.002575 | valid loss: 0.003155\n","Epoch:  94 | train loss: 0.002524 | valid loss: 0.003072\n","Epoch:  95 | train loss: 0.002169 | valid loss: 0.002804\n","Epoch:  96 | train loss: 0.002411 | valid loss: 0.002945\n","Epoch:  97 | train loss: 0.002681 | valid loss: 0.003187\n","Epoch:  98 | train loss: 0.004237 | valid loss: 0.004263\n","Epoch:  99 | train loss: 0.001929 | valid loss: 0.003071\n","Epoch:  100 | train loss: 0.002469 | valid loss: 0.003158\n","Epoch:  101 | train loss: 0.002099 | valid loss: 0.003138\n","Epoch:  102 | train loss: 0.002372 | valid loss: 0.003416\n","Epoch:  103 | train loss: 0.002849 | valid loss: 0.003034\n","Epoch:  104 | train loss: 0.002656 | valid loss: 0.003125\n","Epoch:  105 | train loss: 0.002409 | valid loss: 0.003149\n","Epoch:  106 | train loss: 0.002030 | valid loss: 0.003024\n","Epoch:  107 | train loss: 0.002117 | valid loss: 0.002858\n","Epoch:  108 | train loss: 0.002971 | valid loss: 0.002806\n","Epoch:  109 | train loss: 0.002142 | valid loss: 0.002941\n","Epoch:  110 | train loss: 0.001837 | valid loss: 0.003015\n","Epoch:  111 | train loss: 0.002665 | valid loss: 0.003092\n","Epoch:  112 | train loss: 0.002032 | valid loss: 0.002731\n","Epoch:  113 | train loss: 0.001930 | valid loss: 0.002621\n","Epoch:  114 | train loss: 0.002817 | valid loss: 0.002832\n","Epoch:  115 | train loss: 0.002893 | valid loss: 0.002810\n","Epoch:  116 | train loss: 0.002631 | valid loss: 0.002593\n","Epoch:  117 | train loss: 0.001671 | valid loss: 0.002801\n","Epoch:  118 | train loss: 0.002048 | valid loss: 0.002470\n","Epoch:  119 | train loss: 0.002233 | valid loss: 0.002539\n","Epoch:  120 | train loss: 0.001933 | valid loss: 0.002673\n","Epoch:  121 | train loss: 0.001940 | valid loss: 0.002762\n","Epoch:  122 | train loss: 0.001901 | valid loss: 0.002658\n","Epoch:  123 | train loss: 0.001583 | valid loss: 0.002710\n","Epoch:  124 | train loss: 0.003064 | valid loss: 0.002800\n","Epoch:  125 | train loss: 0.003925 | valid loss: 0.002617\n","Epoch:  126 | train loss: 0.001921 | valid loss: 0.002718\n","Epoch:  127 | train loss: 0.002183 | valid loss: 0.002919\n","Epoch:  128 | train loss: 0.002636 | valid loss: 0.002510\n","Epoch:  129 | train loss: 0.002323 | valid loss: 0.002559\n","Epoch:  130 | train loss: 0.001610 | valid loss: 0.002506\n","Epoch:  131 | train loss: 0.001645 | valid loss: 0.002452\n","Epoch:  132 | train loss: 0.002345 | valid loss: 0.002814\n","Epoch:  133 | train loss: 0.001644 | valid loss: 0.002988\n","Epoch:  134 | train loss: 0.001653 | valid loss: 0.002518\n","Epoch:  135 | train loss: 0.001510 | valid loss: 0.002342\n","Epoch:  136 | train loss: 0.002045 | valid loss: 0.002505\n","Epoch:  137 | train loss: 0.002120 | valid loss: 0.002559\n","Epoch:  138 | train loss: 0.002046 | valid loss: 0.002503\n","Epoch:  139 | train loss: 0.002151 | valid loss: 0.002634\n","Epoch:  140 | train loss: 0.002032 | valid loss: 0.002473\n","Epoch:  141 | train loss: 0.001561 | valid loss: 0.002293\n","Epoch:  142 | train loss: 0.001644 | valid loss: 0.002601\n","Epoch:  143 | train loss: 0.002218 | valid loss: 0.002565\n","Epoch:  144 | train loss: 0.001731 | valid loss: 0.002569\n","Epoch:  145 | train loss: 0.001711 | valid loss: 0.002751\n","Epoch:  146 | train loss: 0.001744 | valid loss: 0.002439\n","Epoch:  147 | train loss: 0.001395 | valid loss: 0.002349\n","Epoch:  148 | train loss: 0.001542 | valid loss: 0.002336\n","Epoch:  149 | train loss: 0.001872 | valid loss: 0.002255\n","Epoch:  150 | train loss: 0.001667 | valid loss: 0.002441\n","Epoch:  151 | train loss: 0.002111 | valid loss: 0.002468\n","Epoch:  152 | train loss: 0.001764 | valid loss: 0.002667\n","Epoch:  153 | train loss: 0.001814 | valid loss: 0.002363\n","Epoch:  154 | train loss: 0.002349 | valid loss: 0.002608\n","Epoch:  155 | train loss: 0.001883 | valid loss: 0.002259\n","Epoch:  156 | train loss: 0.001665 | valid loss: 0.002430\n","Epoch:  157 | train loss: 0.002330 | valid loss: 0.002594\n","Epoch:  158 | train loss: 0.001478 | valid loss: 0.002314\n","Epoch:  159 | train loss: 0.003317 | valid loss: 0.002670\n","Epoch:  160 | train loss: 0.001445 | valid loss: 0.002640\n","Epoch:  161 | train loss: 0.001501 | valid loss: 0.002263\n","Epoch:  162 | train loss: 0.001717 | valid loss: 0.002574\n","Epoch:  163 | train loss: 0.001429 | valid loss: 0.002463\n","Epoch:  164 | train loss: 0.002355 | valid loss: 0.002497\n","Epoch:  165 | train loss: 0.001353 | valid loss: 0.002333\n","Epoch:  166 | train loss: 0.001060 | valid loss: 0.002167\n","Epoch:  167 | train loss: 0.001666 | valid loss: 0.002147\n","Epoch:  168 | train loss: 0.001454 | valid loss: 0.002129\n","Epoch:  169 | train loss: 0.001581 | valid loss: 0.002292\n","Epoch:  170 | train loss: 0.002092 | valid loss: 0.002318\n","Epoch:  171 | train loss: 0.001671 | valid loss: 0.002317\n","Epoch:  172 | train loss: 0.001561 | valid loss: 0.002406\n","Epoch:  173 | train loss: 0.001393 | valid loss: 0.002112\n","Epoch:  174 | train loss: 0.001916 | valid loss: 0.002352\n","Epoch:  175 | train loss: 0.001546 | valid loss: 0.002496\n","Epoch:  176 | train loss: 0.002028 | valid loss: 0.002559\n","Epoch:  177 | train loss: 0.001744 | valid loss: 0.002196\n","Epoch:  178 | train loss: 0.001825 | valid loss: 0.002255\n","Epoch:  179 | train loss: 0.001820 | valid loss: 0.002202\n","Epoch:  180 | train loss: 0.001103 | valid loss: 0.002120\n","Epoch:  181 | train loss: 0.002268 | valid loss: 0.002176\n","Epoch:  182 | train loss: 0.002273 | valid loss: 0.002216\n","Epoch:  183 | train loss: 0.001365 | valid loss: 0.002075\n","Epoch:  184 | train loss: 0.001435 | valid loss: 0.002064\n","Epoch:  185 | train loss: 0.001705 | valid loss: 0.002167\n","Epoch:  186 | train loss: 0.001673 | valid loss: 0.002333\n","Epoch:  187 | train loss: 0.001580 | valid loss: 0.002261\n","Epoch:  188 | train loss: 0.001050 | valid loss: 0.002183\n","Epoch:  189 | train loss: 0.001573 | valid loss: 0.002206\n","Epoch:  190 | train loss: 0.001579 | valid loss: 0.002504\n","Epoch:  191 | train loss: 0.001627 | valid loss: 0.002105\n","Epoch:  192 | train loss: 0.002067 | valid loss: 0.002581\n","Epoch:  193 | train loss: 0.001557 | valid loss: 0.002153\n","Epoch:  194 | train loss: 0.001489 | valid loss: 0.002174\n","Epoch:  195 | train loss: 0.001579 | valid loss: 0.002147\n","Epoch:  196 | train loss: 0.001439 | valid loss: 0.002341\n","Epoch:  197 | train loss: 0.001606 | valid loss: 0.002305\n","Epoch:  198 | train loss: 0.001252 | valid loss: 0.002362\n","Epoch:  199 | train loss: 0.001353 | valid loss: 0.002209\n","Epoch:  200 | train loss: 0.001147 | valid loss: 0.002020\n","Epoch:  201 | train loss: 0.001385 | valid loss: 0.001999\n","Epoch:  202 | train loss: 0.001415 | valid loss: 0.002261\n","Epoch:  203 | train loss: 0.001674 | valid loss: 0.002085\n","Epoch:  204 | train loss: 0.001144 | valid loss: 0.002081\n","Epoch:  205 | train loss: 0.000911 | valid loss: 0.001976\n","Epoch:  206 | train loss: 0.001625 | valid loss: 0.002000\n","Epoch:  207 | train loss: 0.001266 | valid loss: 0.001964\n","Epoch:  208 | train loss: 0.001342 | valid loss: 0.001985\n","Epoch:  209 | train loss: 0.001273 | valid loss: 0.002212\n","Epoch:  210 | train loss: 0.001454 | valid loss: 0.002283\n","Epoch:  211 | train loss: 0.002173 | valid loss: 0.002204\n","Epoch:  212 | train loss: 0.001311 | valid loss: 0.002267\n","Epoch:  213 | train loss: 0.001791 | valid loss: 0.002173\n","Epoch:  214 | train loss: 0.001860 | valid loss: 0.002012\n","Epoch:  215 | train loss: 0.001984 | valid loss: 0.002899\n","Epoch:  216 | train loss: 0.001423 | valid loss: 0.002373\n","Epoch:  217 | train loss: 0.001202 | valid loss: 0.002009\n","Epoch:  218 | train loss: 0.001760 | valid loss: 0.002218\n","Epoch:  219 | train loss: 0.001844 | valid loss: 0.002099\n","Epoch:  220 | train loss: 0.001241 | valid loss: 0.001807\n","Epoch:  221 | train loss: 0.001137 | valid loss: 0.001922\n","Epoch:  222 | train loss: 0.001105 | valid loss: 0.002011\n","Epoch:  223 | train loss: 0.001036 | valid loss: 0.002028\n","Epoch:  224 | train loss: 0.001412 | valid loss: 0.002355\n","Epoch:  225 | train loss: 0.001527 | valid loss: 0.002163\n","Epoch:  226 | train loss: 0.001285 | valid loss: 0.002259\n","Epoch:  227 | train loss: 0.002669 | valid loss: 0.002297\n","Epoch:  228 | train loss: 0.001491 | valid loss: 0.002038\n","Epoch:  229 | train loss: 0.001522 | valid loss: 0.001969\n","Epoch:  230 | train loss: 0.000905 | valid loss: 0.002171\n","Epoch:  231 | train loss: 0.001001 | valid loss: 0.001997\n","Epoch:  232 | train loss: 0.001577 | valid loss: 0.002062\n","Epoch:  233 | train loss: 0.001253 | valid loss: 0.002008\n","Epoch:  234 | train loss: 0.001569 | valid loss: 0.001949\n","Epoch:  235 | train loss: 0.001001 | valid loss: 0.001873\n","Epoch:  236 | train loss: 0.001723 | valid loss: 0.002027\n","Epoch:  237 | train loss: 0.001289 | valid loss: 0.001981\n","Epoch:  238 | train loss: 0.001313 | valid loss: 0.002078\n","Epoch:  239 | train loss: 0.001634 | valid loss: 0.002358\n","Epoch:  240 | train loss: 0.002085 | valid loss: 0.002534\n","Epoch:  241 | train loss: 0.002155 | valid loss: 0.002231\n","Epoch:  242 | train loss: 0.001335 | valid loss: 0.002108\n","Epoch:  243 | train loss: 0.001622 | valid loss: 0.001991\n","Epoch:  244 | train loss: 0.001322 | valid loss: 0.002089\n","Epoch:  245 | train loss: 0.001338 | valid loss: 0.002094\n","Epoch:  246 | train loss: 0.000894 | valid loss: 0.002076\n","Epoch:  247 | train loss: 0.001516 | valid loss: 0.002017\n","Epoch:  248 | train loss: 0.001123 | valid loss: 0.001999\n","Epoch:  249 | train loss: 0.000960 | valid loss: 0.002134\n","Epoch:  250 | train loss: 0.001504 | valid loss: 0.002099\n","Epoch:  251 | train loss: 0.001055 | valid loss: 0.001990\n","Epoch:  252 | train loss: 0.001236 | valid loss: 0.002285\n","Epoch:  253 | train loss: 0.000911 | valid loss: 0.002274\n","Epoch:  254 | train loss: 0.002149 | valid loss: 0.002060\n","Epoch:  255 | train loss: 0.001233 | valid loss: 0.001891\n","Epoch:  256 | train loss: 0.001012 | valid loss: 0.001894\n","Epoch:  257 | train loss: 0.001170 | valid loss: 0.001892\n","Epoch:  258 | train loss: 0.001232 | valid loss: 0.001891\n","Epoch:  259 | train loss: 0.000985 | valid loss: 0.002035\n","Epoch:  260 | train loss: 0.000902 | valid loss: 0.002096\n","Epoch:  261 | train loss: 0.001233 | valid loss: 0.002163\n","Epoch:  262 | train loss: 0.001193 | valid loss: 0.002191\n","Epoch:  263 | train loss: 0.001477 | valid loss: 0.002258\n","Epoch:  264 | train loss: 0.001065 | valid loss: 0.002202\n","Epoch:  265 | train loss: 0.001358 | valid loss: 0.002062\n","Epoch:  266 | train loss: 0.001144 | valid loss: 0.002064\n","Epoch:  267 | train loss: 0.000998 | valid loss: 0.001942\n","Epoch:  268 | train loss: 0.001514 | valid loss: 0.002418\n","Epoch:  269 | train loss: 0.000971 | valid loss: 0.001849\n","Epoch:  270 | train loss: 0.001050 | valid loss: 0.001911\n","Epoch:  271 | train loss: 0.001202 | valid loss: 0.002094\n","Epoch:  272 | train loss: 0.000828 | valid loss: 0.001850\n","Epoch:  273 | train loss: 0.000838 | valid loss: 0.001842\n","Epoch:  274 | train loss: 0.001173 | valid loss: 0.001934\n","Epoch:  275 | train loss: 0.001021 | valid loss: 0.002096\n","Epoch:  276 | train loss: 0.001492 | valid loss: 0.002329\n","Epoch:  277 | train loss: 0.000966 | valid loss: 0.002002\n","Epoch:  278 | train loss: 0.001796 | valid loss: 0.002136\n","Epoch:  279 | train loss: 0.002254 | valid loss: 0.002281\n","Epoch:  280 | train loss: 0.001357 | valid loss: 0.002126\n","Epoch:  281 | train loss: 0.001355 | valid loss: 0.002090\n","Epoch:  282 | train loss: 0.000799 | valid loss: 0.001864\n","Epoch:  283 | train loss: 0.001079 | valid loss: 0.001903\n","Epoch:  284 | train loss: 0.001671 | valid loss: 0.001890\n","Epoch:  285 | train loss: 0.001054 | valid loss: 0.001751\n","Epoch:  286 | train loss: 0.001243 | valid loss: 0.001793\n","Epoch:  287 | train loss: 0.001685 | valid loss: 0.001850\n","Epoch:  288 | train loss: 0.001075 | valid loss: 0.002000\n","Epoch:  289 | train loss: 0.001154 | valid loss: 0.001959\n","Epoch:  290 | train loss: 0.001083 | valid loss: 0.001825\n","Epoch:  291 | train loss: 0.000999 | valid loss: 0.001876\n","Epoch:  292 | train loss: 0.001283 | valid loss: 0.001954\n","Epoch:  293 | train loss: 0.001245 | valid loss: 0.002077\n","Epoch:  294 | train loss: 0.001011 | valid loss: 0.002089\n","Epoch:  295 | train loss: 0.001346 | valid loss: 0.002007\n","Epoch:  296 | train loss: 0.001083 | valid loss: 0.002103\n","Epoch:  297 | train loss: 0.001506 | valid loss: 0.002056\n","Epoch:  298 | train loss: 0.000983 | valid loss: 0.002147\n","Epoch:  299 | train loss: 0.000859 | valid loss: 0.002446\n","Epoch:  300 | train loss: 0.001327 | valid loss: 0.002026\n","Epoch:  301 | train loss: 0.001409 | valid loss: 0.002017\n","Epoch:  302 | train loss: 0.000938 | valid loss: 0.001861\n","Epoch:  303 | train loss: 0.000984 | valid loss: 0.001985\n","Epoch:  304 | train loss: 0.001271 | valid loss: 0.001934\n","Epoch:  305 | train loss: 0.001003 | valid loss: 0.001880\n","Epoch:  306 | train loss: 0.001090 | valid loss: 0.002009\n","Epoch:  307 | train loss: 0.001175 | valid loss: 0.002008\n","Epoch:  308 | train loss: 0.001230 | valid loss: 0.002008\n","Epoch:  309 | train loss: 0.001078 | valid loss: 0.001935\n","Epoch:  310 | train loss: 0.001092 | valid loss: 0.001944\n","Epoch:  311 | train loss: 0.001056 | valid loss: 0.001913\n","Epoch:  312 | train loss: 0.001073 | valid loss: 0.001928\n","Epoch:  313 | train loss: 0.001157 | valid loss: 0.002262\n","Epoch:  314 | train loss: 0.001224 | valid loss: 0.002086\n","Epoch:  315 | train loss: 0.001455 | valid loss: 0.002073\n","Epoch:  316 | train loss: 0.001230 | valid loss: 0.001978\n","Epoch:  317 | train loss: 0.001070 | valid loss: 0.001946\n","Epoch:  318 | train loss: 0.001096 | valid loss: 0.002044\n","Epoch:  319 | train loss: 0.001646 | valid loss: 0.001899\n","Epoch:  320 | train loss: 0.000993 | valid loss: 0.001919\n","Epoch:  321 | train loss: 0.001339 | valid loss: 0.002137\n","Epoch:  322 | train loss: 0.001000 | valid loss: 0.002092\n","Epoch:  323 | train loss: 0.000939 | valid loss: 0.001851\n","Epoch:  324 | train loss: 0.001001 | valid loss: 0.001943\n","Epoch:  325 | train loss: 0.000957 | valid loss: 0.001983\n","Epoch:  326 | train loss: 0.000834 | valid loss: 0.001897\n","Epoch:  327 | train loss: 0.001015 | valid loss: 0.001896\n","Epoch:  328 | train loss: 0.001836 | valid loss: 0.002081\n","Epoch:  329 | train loss: 0.001120 | valid loss: 0.001907\n","Epoch:  330 | train loss: 0.001380 | valid loss: 0.001899\n","Epoch:  331 | train loss: 0.001413 | valid loss: 0.001976\n","Epoch:  332 | train loss: 0.001147 | valid loss: 0.001969\n","Epoch:  333 | train loss: 0.000754 | valid loss: 0.001906\n","Epoch:  334 | train loss: 0.001244 | valid loss: 0.002053\n","Epoch:  335 | train loss: 0.000975 | valid loss: 0.002028\n","Epoch:  336 | train loss: 0.001062 | valid loss: 0.002219\n","Epoch:  337 | train loss: 0.001051 | valid loss: 0.002279\n","Epoch:  338 | train loss: 0.001250 | valid loss: 0.002020\n","Epoch:  339 | train loss: 0.000950 | valid loss: 0.002021\n","Epoch:  340 | train loss: 0.001361 | valid loss: 0.002233\n","Epoch:  341 | train loss: 0.000855 | valid loss: 0.001943\n","Epoch:  342 | train loss: 0.000933 | valid loss: 0.001848\n","Epoch:  343 | train loss: 0.001070 | valid loss: 0.001962\n","Epoch:  344 | train loss: 0.000840 | valid loss: 0.001920\n","Epoch:  345 | train loss: 0.000876 | valid loss: 0.001747\n","Epoch:  346 | train loss: 0.001162 | valid loss: 0.001865\n","Epoch:  347 | train loss: 0.000667 | valid loss: 0.001895\n","Epoch:  348 | train loss: 0.000920 | valid loss: 0.001962\n","Epoch:  349 | train loss: 0.001174 | valid loss: 0.001940\n","Epoch:  350 | train loss: 0.000706 | valid loss: 0.001958\n","Epoch:  351 | train loss: 0.001051 | valid loss: 0.002026\n","Epoch:  352 | train loss: 0.001166 | valid loss: 0.002046\n","Epoch:  353 | train loss: 0.000939 | valid loss: 0.001961\n","Epoch:  354 | train loss: 0.001067 | valid loss: 0.001945\n","Epoch:  355 | train loss: 0.000968 | valid loss: 0.002061\n","Epoch:  356 | train loss: 0.000735 | valid loss: 0.001986\n","Epoch:  357 | train loss: 0.000809 | valid loss: 0.002303\n","Epoch:  358 | train loss: 0.000878 | valid loss: 0.002028\n","Epoch:  359 | train loss: 0.000969 | valid loss: 0.002042\n","Epoch:  360 | train loss: 0.001123 | valid loss: 0.001957\n","Epoch:  361 | train loss: 0.001458 | valid loss: 0.001965\n","Epoch:  362 | train loss: 0.001367 | valid loss: 0.001910\n","Epoch:  363 | train loss: 0.000915 | valid loss: 0.001981\n","Epoch:  364 | train loss: 0.001367 | valid loss: 0.001975\n","Epoch:  365 | train loss: 0.000849 | valid loss: 0.001959\n","Epoch:  366 | train loss: 0.001260 | valid loss: 0.001917\n","Epoch:  367 | train loss: 0.001189 | valid loss: 0.002021\n","Epoch:  368 | train loss: 0.001179 | valid loss: 0.001940\n","Epoch:  369 | train loss: 0.000994 | valid loss: 0.001848\n","Epoch:  370 | train loss: 0.001220 | valid loss: 0.001892\n","Epoch:  371 | train loss: 0.001071 | valid loss: 0.001911\n","Epoch:  372 | train loss: 0.000714 | valid loss: 0.001992\n","Epoch:  373 | train loss: 0.001567 | valid loss: 0.002151\n","Epoch:  374 | train loss: 0.001042 | valid loss: 0.002094\n","Epoch:  375 | train loss: 0.000938 | valid loss: 0.001959\n","Epoch:  376 | train loss: 0.001062 | valid loss: 0.002096\n","Epoch:  377 | train loss: 0.000710 | valid loss: 0.002030\n","Epoch:  378 | train loss: 0.000889 | valid loss: 0.002000\n","Epoch:  379 | train loss: 0.001059 | valid loss: 0.001846\n","Epoch:  380 | train loss: 0.000925 | valid loss: 0.001981\n","Epoch:  381 | train loss: 0.003389 | valid loss: 0.001888\n","Epoch:  382 | train loss: 0.001291 | valid loss: 0.001805\n","Epoch:  383 | train loss: 0.001307 | valid loss: 0.002007\n","Epoch:  384 | train loss: 0.000885 | valid loss: 0.002043\n","Epoch:  385 | train loss: 0.001136 | valid loss: 0.002072\n","Epoch:  386 | train loss: 0.000949 | valid loss: 0.002036\n","Epoch:  387 | train loss: 0.001129 | valid loss: 0.001900\n","Epoch:  388 | train loss: 0.001136 | valid loss: 0.001971\n","Epoch:  389 | train loss: 0.001139 | valid loss: 0.001952\n","Epoch:  390 | train loss: 0.000757 | valid loss: 0.001911\n","Epoch:  391 | train loss: 0.001128 | valid loss: 0.002051\n","Epoch:  392 | train loss: 0.001310 | valid loss: 0.001956\n","Epoch:  393 | train loss: 0.000949 | valid loss: 0.002018\n","Epoch:  394 | train loss: 0.000758 | valid loss: 0.001910\n","Epoch:  395 | train loss: 0.000883 | valid loss: 0.001893\n","Epoch:  396 | train loss: 0.000878 | valid loss: 0.001954\n","Epoch:  397 | train loss: 0.001024 | valid loss: 0.001976\n","Epoch:  398 | train loss: 0.000893 | valid loss: 0.001939\n","Epoch:  399 | train loss: 0.000953 | valid loss: 0.001858\n","Epoch:  400 | train loss: 0.000979 | valid loss: 0.001893\n","Epoch:  401 | train loss: 0.001075 | valid loss: 0.001888\n","Epoch:  402 | train loss: 0.000951 | valid loss: 0.001877\n","Epoch:  403 | train loss: 0.000870 | valid loss: 0.001916\n","Epoch:  404 | train loss: 0.000975 | valid loss: 0.001983\n","Epoch:  405 | train loss: 0.000967 | valid loss: 0.001893\n","Epoch:  406 | train loss: 0.001300 | valid loss: 0.002091\n","Epoch:  407 | train loss: 0.000916 | valid loss: 0.002143\n","Epoch:  408 | train loss: 0.000867 | valid loss: 0.001960\n","Epoch:  409 | train loss: 0.000662 | valid loss: 0.001925\n","Epoch:  410 | train loss: 0.000782 | valid loss: 0.001828\n","Epoch:  411 | train loss: 0.000867 | valid loss: 0.001867\n","Epoch:  412 | train loss: 0.001227 | valid loss: 0.002005\n","Epoch:  413 | train loss: 0.001072 | valid loss: 0.002142\n","Epoch:  414 | train loss: 0.001788 | valid loss: 0.002454\n","Epoch:  415 | train loss: 0.000960 | valid loss: 0.002175\n","Epoch:  416 | train loss: 0.001204 | valid loss: 0.001911\n","Epoch:  417 | train loss: 0.001388 | valid loss: 0.002093\n","Epoch:  418 | train loss: 0.000810 | valid loss: 0.001747\n","Epoch:  419 | train loss: 0.000851 | valid loss: 0.001702\n","Epoch:  420 | train loss: 0.000947 | valid loss: 0.001650\n","Epoch:  421 | train loss: 0.000842 | valid loss: 0.001765\n","Epoch:  422 | train loss: 0.000898 | valid loss: 0.001844\n","Epoch:  423 | train loss: 0.001119 | valid loss: 0.001989\n","Epoch:  424 | train loss: 0.000742 | valid loss: 0.001901\n","Epoch:  425 | train loss: 0.000614 | valid loss: 0.001976\n","Epoch:  426 | train loss: 0.000741 | valid loss: 0.001884\n","Epoch:  427 | train loss: 0.000932 | valid loss: 0.001921\n","Epoch:  428 | train loss: 0.001114 | valid loss: 0.002029\n","Epoch:  429 | train loss: 0.001014 | valid loss: 0.002161\n","Epoch:  430 | train loss: 0.000956 | valid loss: 0.002334\n","Epoch:  431 | train loss: 0.000905 | valid loss: 0.002005\n","Epoch:  432 | train loss: 0.001138 | valid loss: 0.002054\n","Epoch:  433 | train loss: 0.000883 | valid loss: 0.001884\n","Epoch:  434 | train loss: 0.000666 | valid loss: 0.001819\n","Epoch:  435 | train loss: 0.001276 | valid loss: 0.001921\n","Epoch:  436 | train loss: 0.000722 | valid loss: 0.001828\n","Epoch:  437 | train loss: 0.000825 | valid loss: 0.001910\n","Epoch:  438 | train loss: 0.001247 | valid loss: 0.001810\n","Epoch:  439 | train loss: 0.000757 | valid loss: 0.001878\n","Epoch:  440 | train loss: 0.000753 | valid loss: 0.001981\n","Epoch:  441 | train loss: 0.001061 | valid loss: 0.001855\n","Epoch:  442 | train loss: 0.000895 | valid loss: 0.001820\n","Epoch:  443 | train loss: 0.000722 | valid loss: 0.001974\n","Epoch:  444 | train loss: 0.000972 | valid loss: 0.001913\n","Epoch:  445 | train loss: 0.000845 | valid loss: 0.001845\n","Epoch:  446 | train loss: 0.000876 | valid loss: 0.002053\n","Epoch:  447 | train loss: 0.001215 | valid loss: 0.002237\n","Epoch:  448 | train loss: 0.001000 | valid loss: 0.002016\n","Epoch:  449 | train loss: 0.000794 | valid loss: 0.002052\n","Epoch:  450 | train loss: 0.000962 | valid loss: 0.001914\n","Epoch:  451 | train loss: 0.002202 | valid loss: 0.002022\n","Epoch:  452 | train loss: 0.000950 | valid loss: 0.001911\n","Epoch:  453 | train loss: 0.000928 | valid loss: 0.001914\n","Epoch:  454 | train loss: 0.000825 | valid loss: 0.001930\n","Epoch:  455 | train loss: 0.001149 | valid loss: 0.001887\n","Epoch:  456 | train loss: 0.000916 | valid loss: 0.001847\n","Epoch:  457 | train loss: 0.000919 | valid loss: 0.002001\n","Epoch:  458 | train loss: 0.000969 | valid loss: 0.002296\n","Epoch:  459 | train loss: 0.000826 | valid loss: 0.001935\n","Epoch:  460 | train loss: 0.000825 | valid loss: 0.002241\n","Epoch:  461 | train loss: 0.000969 | valid loss: 0.001918\n","Epoch:  462 | train loss: 0.000831 | valid loss: 0.001879\n","Epoch:  463 | train loss: 0.003186 | valid loss: 0.001845\n","Epoch:  464 | train loss: 0.000775 | valid loss: 0.001854\n","Epoch:  465 | train loss: 0.000892 | valid loss: 0.002094\n","Epoch:  466 | train loss: 0.000972 | valid loss: 0.001876\n","Epoch:  467 | train loss: 0.001339 | valid loss: 0.002014\n","Epoch:  468 | train loss: 0.000998 | valid loss: 0.001882\n","Epoch:  469 | train loss: 0.000990 | valid loss: 0.001842\n","Epoch:  470 | train loss: 0.000728 | valid loss: 0.001964\n","Epoch:  471 | train loss: 0.000975 | valid loss: 0.001976\n","Epoch:  472 | train loss: 0.000874 | valid loss: 0.001895\n","Epoch:  473 | train loss: 0.000880 | valid loss: 0.001897\n","Epoch:  474 | train loss: 0.000806 | valid loss: 0.002008\n","Epoch:  475 | train loss: 0.001010 | valid loss: 0.002021\n","Epoch:  476 | train loss: 0.001585 | valid loss: 0.002103\n","Epoch:  477 | train loss: 0.001011 | valid loss: 0.002007\n","Epoch:  478 | train loss: 0.000916 | valid loss: 0.002005\n","Epoch:  479 | train loss: 0.000761 | valid loss: 0.001928\n","Epoch:  480 | train loss: 0.000933 | valid loss: 0.001980\n","Epoch:  481 | train loss: 0.001013 | valid loss: 0.001831\n","Epoch:  482 | train loss: 0.000648 | valid loss: 0.001904\n","Epoch:  483 | train loss: 0.000890 | valid loss: 0.001894\n","Epoch:  484 | train loss: 0.001085 | valid loss: 0.002016\n","Epoch:  485 | train loss: 0.000800 | valid loss: 0.002067\n","Epoch:  486 | train loss: 0.000959 | valid loss: 0.001992\n","Epoch:  487 | train loss: 0.000683 | valid loss: 0.002080\n","Epoch:  488 | train loss: 0.000691 | valid loss: 0.001881\n","Epoch:  489 | train loss: 0.000963 | valid loss: 0.002000\n","Epoch:  490 | train loss: 0.000751 | valid loss: 0.001948\n","Epoch:  491 | train loss: 0.001371 | valid loss: 0.001896\n","Epoch:  492 | train loss: 0.000870 | valid loss: 0.001959\n","Epoch:  493 | train loss: 0.000724 | valid loss: 0.001976\n","Epoch:  494 | train loss: 0.000742 | valid loss: 0.001915\n","Epoch:  495 | train loss: 0.000674 | valid loss: 0.001918\n","Epoch:  496 | train loss: 0.000890 | valid loss: 0.002019\n","Epoch:  497 | train loss: 0.001409 | valid loss: 0.002046\n","Epoch:  498 | train loss: 0.001420 | valid loss: 0.001844\n","Epoch:  499 | train loss: 0.000778 | valid loss: 0.001792\n","Epoch:  500 | train loss: 0.000629 | valid loss: 0.001934\n","Epoch:  501 | train loss: 0.000841 | valid loss: 0.001956\n","Epoch:  502 | train loss: 0.000918 | valid loss: 0.002019\n","Epoch:  503 | train loss: 0.000937 | valid loss: 0.002137\n","Epoch:  504 | train loss: 0.001270 | valid loss: 0.002118\n","Epoch:  505 | train loss: 0.000992 | valid loss: 0.001995\n","Epoch:  506 | train loss: 0.000987 | valid loss: 0.002028\n","Epoch:  507 | train loss: 0.000974 | valid loss: 0.002030\n","Epoch:  508 | train loss: 0.000734 | valid loss: 0.002164\n","Epoch:  509 | train loss: 0.001399 | valid loss: 0.001993\n","Epoch:  510 | train loss: 0.000822 | valid loss: 0.001903\n","Epoch:  511 | train loss: 0.000959 | valid loss: 0.001875\n","Epoch:  512 | train loss: 0.000691 | valid loss: 0.001805\n","Epoch:  513 | train loss: 0.000946 | valid loss: 0.001817\n","Epoch:  514 | train loss: 0.000690 | valid loss: 0.001912\n","Epoch:  515 | train loss: 0.000875 | valid loss: 0.001885\n","Epoch:  516 | train loss: 0.000921 | valid loss: 0.001857\n","Epoch:  517 | train loss: 0.001070 | valid loss: 0.002097\n","Epoch:  518 | train loss: 0.000794 | valid loss: 0.002017\n","Epoch:  519 | train loss: 0.000801 | valid loss: 0.001857\n","Epoch:  520 | train loss: 0.000989 | valid loss: 0.001805\n","Epoch:  521 | train loss: 0.000821 | valid loss: 0.001764\n","Epoch:  522 | train loss: 0.000751 | valid loss: 0.001846\n","Epoch:  523 | train loss: 0.001109 | valid loss: 0.001988\n","Epoch:  524 | train loss: 0.000876 | valid loss: 0.001888\n","Epoch:  525 | train loss: 0.000551 | valid loss: 0.001839\n","Epoch:  526 | train loss: 0.000770 | valid loss: 0.001803\n","Epoch:  527 | train loss: 0.000993 | valid loss: 0.002153\n","Epoch:  528 | train loss: 0.000953 | valid loss: 0.002303\n","Epoch:  529 | train loss: 0.000892 | valid loss: 0.002087\n","Epoch:  530 | train loss: 0.001265 | valid loss: 0.001884\n","Epoch:  531 | train loss: 0.000754 | valid loss: 0.001904\n","Epoch:  532 | train loss: 0.001054 | valid loss: 0.001832\n","Epoch:  533 | train loss: 0.001074 | valid loss: 0.001811\n","Epoch:  534 | train loss: 0.000983 | valid loss: 0.001763\n","Epoch:  535 | train loss: 0.000556 | valid loss: 0.001939\n","Epoch:  536 | train loss: 0.000653 | valid loss: 0.001918\n","Epoch:  537 | train loss: 0.001102 | valid loss: 0.002012\n","Epoch:  538 | train loss: 0.001086 | valid loss: 0.002098\n","Epoch:  539 | train loss: 0.001310 | valid loss: 0.002043\n","Epoch:  540 | train loss: 0.000912 | valid loss: 0.002037\n","Epoch:  541 | train loss: 0.001061 | valid loss: 0.002041\n","Epoch:  542 | train loss: 0.000888 | valid loss: 0.002026\n","Epoch:  543 | train loss: 0.000770 | valid loss: 0.002087\n","Epoch:  544 | train loss: 0.000884 | valid loss: 0.002024\n","Epoch:  545 | train loss: 0.000865 | valid loss: 0.001856\n","Epoch:  546 | train loss: 0.000820 | valid loss: 0.002237\n","Epoch:  547 | train loss: 0.006110 | valid loss: 0.001857\n","Epoch:  548 | train loss: 0.000684 | valid loss: 0.001957\n","Epoch:  549 | train loss: 0.001255 | valid loss: 0.001831\n","Epoch:  550 | train loss: 0.000693 | valid loss: 0.001888\n","Epoch:  551 | train loss: 0.000609 | valid loss: 0.001843\n","Epoch:  552 | train loss: 0.000750 | valid loss: 0.001847\n","Epoch:  553 | train loss: 0.000659 | valid loss: 0.001841\n","Epoch:  554 | train loss: 0.000900 | valid loss: 0.001919\n","Epoch:  555 | train loss: 0.000688 | valid loss: 0.002081\n","Epoch:  556 | train loss: 0.000626 | valid loss: 0.001991\n","Epoch:  557 | train loss: 0.000812 | valid loss: 0.001836\n","Epoch:  558 | train loss: 0.000759 | valid loss: 0.001841\n","Epoch:  559 | train loss: 0.000996 | valid loss: 0.001880\n","Epoch:  560 | train loss: 0.001102 | valid loss: 0.001985\n","Epoch:  561 | train loss: 0.000884 | valid loss: 0.002007\n","Epoch:  562 | train loss: 0.000642 | valid loss: 0.002040\n","Epoch:  563 | train loss: 0.000942 | valid loss: 0.002031\n","Epoch:  564 | train loss: 0.000801 | valid loss: 0.001954\n","Epoch:  565 | train loss: 0.001085 | valid loss: 0.001887\n","Epoch:  566 | train loss: 0.000799 | valid loss: 0.001944\n","Epoch:  567 | train loss: 0.000752 | valid loss: 0.001821\n","Epoch:  568 | train loss: 0.001024 | valid loss: 0.001975\n","Epoch:  569 | train loss: 0.000696 | valid loss: 0.001882\n","Epoch:  570 | train loss: 0.001019 | valid loss: 0.001946\n","Epoch:  571 | train loss: 0.000654 | valid loss: 0.001985\n","Epoch:  572 | train loss: 0.000881 | valid loss: 0.001889\n","Epoch:  573 | train loss: 0.001224 | valid loss: 0.001965\n","Epoch:  574 | train loss: 0.000857 | valid loss: 0.002067\n","Epoch:  575 | train loss: 0.000899 | valid loss: 0.002057\n","Epoch:  576 | train loss: 0.000875 | valid loss: 0.001883\n","Epoch:  577 | train loss: 0.001013 | valid loss: 0.001881\n","Epoch:  578 | train loss: 0.000961 | valid loss: 0.002000\n","Epoch:  579 | train loss: 0.000595 | valid loss: 0.001941\n","Epoch:  580 | train loss: 0.000845 | valid loss: 0.001852\n","Epoch:  581 | train loss: 0.000881 | valid loss: 0.001856\n","Epoch:  582 | train loss: 0.000740 | valid loss: 0.001902\n","Epoch:  583 | train loss: 0.000712 | valid loss: 0.001978\n","Epoch:  584 | train loss: 0.001004 | valid loss: 0.001926\n","Epoch:  585 | train loss: 0.000576 | valid loss: 0.002050\n","Epoch:  586 | train loss: 0.000771 | valid loss: 0.001877\n","Epoch:  587 | train loss: 0.000852 | valid loss: 0.002029\n","Epoch:  588 | train loss: 0.000842 | valid loss: 0.002107\n","Epoch:  589 | train loss: 0.000984 | valid loss: 0.002090\n","Epoch:  590 | train loss: 0.000937 | valid loss: 0.001918\n","Epoch:  591 | train loss: 0.000729 | valid loss: 0.001888\n","Epoch:  592 | train loss: 0.000704 | valid loss: 0.001923\n","Epoch:  593 | train loss: 0.000574 | valid loss: 0.001763\n","Epoch:  594 | train loss: 0.000555 | valid loss: 0.001823\n","Epoch:  595 | train loss: 0.000760 | valid loss: 0.001893\n","Epoch:  596 | train loss: 0.000579 | valid loss: 0.001873\n","Epoch:  597 | train loss: 0.000636 | valid loss: 0.001943\n","Epoch:  598 | train loss: 0.000682 | valid loss: 0.001907\n","Epoch:  599 | train loss: 0.001181 | valid loss: 0.001972\n","Epoch:  600 | train loss: 0.000874 | valid loss: 0.002041\n","Epoch:  601 | train loss: 0.001237 | valid loss: 0.001927\n","Epoch:  602 | train loss: 0.000866 | valid loss: 0.002130\n","Epoch:  603 | train loss: 0.000692 | valid loss: 0.002032\n","Epoch:  604 | train loss: 0.000805 | valid loss: 0.002080\n","Epoch:  605 | train loss: 0.000761 | valid loss: 0.001812\n","Epoch:  606 | train loss: 0.002030 | valid loss: 0.001960\n","Epoch:  607 | train loss: 0.000784 | valid loss: 0.002011\n","Epoch:  608 | train loss: 0.000984 | valid loss: 0.001872\n","Epoch:  609 | train loss: 0.000840 | valid loss: 0.001883\n","Epoch:  610 | train loss: 0.000715 | valid loss: 0.002060\n","Epoch:  611 | train loss: 0.001100 | valid loss: 0.001985\n","Epoch:  612 | train loss: 0.001128 | valid loss: 0.002025\n","Epoch:  613 | train loss: 0.000825 | valid loss: 0.001873\n","Epoch:  614 | train loss: 0.000867 | valid loss: 0.001880\n","Epoch:  615 | train loss: 0.000618 | valid loss: 0.001820\n","Epoch:  616 | train loss: 0.000790 | valid loss: 0.001943\n","Epoch:  617 | train loss: 0.000758 | valid loss: 0.002019\n","Epoch:  618 | train loss: 0.000827 | valid loss: 0.001996\n","Epoch:  619 | train loss: 0.000979 | valid loss: 0.002142\n","Epoch:  620 | train loss: 0.000798 | valid loss: 0.002109\n","Epoch:  621 | train loss: 0.000831 | valid loss: 0.001952\n","Epoch:  622 | train loss: 0.000993 | valid loss: 0.001945\n","Epoch:  623 | train loss: 0.000712 | valid loss: 0.001859\n","Epoch:  624 | train loss: 0.000721 | valid loss: 0.001931\n","Epoch:  625 | train loss: 0.001227 | valid loss: 0.002009\n","Epoch:  626 | train loss: 0.000840 | valid loss: 0.001960\n","Epoch:  627 | train loss: 0.000902 | valid loss: 0.001833\n","Epoch:  628 | train loss: 0.000649 | valid loss: 0.001831\n","Epoch:  629 | train loss: 0.001011 | valid loss: 0.002037\n","Epoch:  630 | train loss: 0.000955 | valid loss: 0.002057\n","Epoch:  631 | train loss: 0.001262 | valid loss: 0.002049\n","Epoch:  632 | train loss: 0.000812 | valid loss: 0.002027\n","Epoch:  633 | train loss: 0.000875 | valid loss: 0.002020\n","Epoch:  634 | train loss: 0.001375 | valid loss: 0.002155\n","Epoch:  635 | train loss: 0.000879 | valid loss: 0.002155\n","Epoch:  636 | train loss: 0.000648 | valid loss: 0.001838\n","Epoch:  637 | train loss: 0.000621 | valid loss: 0.001851\n","Epoch:  638 | train loss: 0.000938 | valid loss: 0.001846\n","Epoch:  639 | train loss: 0.000917 | valid loss: 0.001922\n","Epoch:  640 | train loss: 0.000718 | valid loss: 0.002007\n","Epoch:  641 | train loss: 0.000534 | valid loss: 0.001980\n","Epoch:  642 | train loss: 0.000859 | valid loss: 0.001942\n","Epoch:  643 | train loss: 0.001001 | valid loss: 0.001935\n","Epoch:  644 | train loss: 0.001085 | valid loss: 0.002018\n","Epoch:  645 | train loss: 0.000980 | valid loss: 0.001995\n","Epoch:  646 | train loss: 0.000591 | valid loss: 0.001931\n","Epoch:  647 | train loss: 0.001284 | valid loss: 0.002034\n","Epoch:  648 | train loss: 0.000877 | valid loss: 0.001907\n","Epoch:  649 | train loss: 0.000844 | valid loss: 0.001913\n","Epoch:  650 | train loss: 0.000527 | valid loss: 0.001947\n","Epoch:  651 | train loss: 0.000739 | valid loss: 0.001880\n","Epoch:  652 | train loss: 0.001041 | valid loss: 0.001795\n","Epoch:  653 | train loss: 0.001079 | valid loss: 0.001960\n","Epoch:  654 | train loss: 0.000515 | valid loss: 0.001814\n","Epoch:  655 | train loss: 0.001036 | valid loss: 0.001956\n","Epoch:  656 | train loss: 0.000870 | valid loss: 0.002018\n","Epoch:  657 | train loss: 0.001159 | valid loss: 0.002083\n","Epoch:  658 | train loss: 0.001026 | valid loss: 0.002034\n","Epoch:  659 | train loss: 0.001165 | valid loss: 0.001968\n","Epoch:  660 | train loss: 0.000910 | valid loss: 0.001964\n","Epoch:  661 | train loss: 0.001062 | valid loss: 0.001997\n","Epoch:  662 | train loss: 0.001188 | valid loss: 0.001922\n","Epoch:  663 | train loss: 0.000671 | valid loss: 0.001960\n","Epoch:  664 | train loss: 0.000796 | valid loss: 0.002176\n","Epoch:  665 | train loss: 0.001102 | valid loss: 0.002005\n","Epoch:  666 | train loss: 0.000873 | valid loss: 0.001924\n","Epoch:  667 | train loss: 0.001040 | valid loss: 0.001978\n","Epoch:  668 | train loss: 0.000843 | valid loss: 0.001877\n","Epoch:  669 | train loss: 0.000996 | valid loss: 0.001917\n","Epoch:  670 | train loss: 0.000789 | valid loss: 0.001861\n","Epoch:  671 | train loss: 0.000703 | valid loss: 0.001858\n","Epoch:  672 | train loss: 0.000740 | valid loss: 0.001957\n","Epoch:  673 | train loss: 0.001126 | valid loss: 0.001978\n","Epoch:  674 | train loss: 0.000604 | valid loss: 0.001914\n","Epoch:  675 | train loss: 0.000829 | valid loss: 0.002049\n","Epoch:  676 | train loss: 0.000692 | valid loss: 0.001913\n","Epoch:  677 | train loss: 0.000735 | valid loss: 0.002030\n","Epoch:  678 | train loss: 0.000773 | valid loss: 0.001928\n","Epoch:  679 | train loss: 0.000711 | valid loss: 0.001947\n","Epoch:  680 | train loss: 0.000567 | valid loss: 0.001945\n","Epoch:  681 | train loss: 0.001256 | valid loss: 0.001959\n","Epoch:  682 | train loss: 0.000981 | valid loss: 0.001967\n","Epoch:  683 | train loss: 0.000599 | valid loss: 0.002027\n","Epoch:  684 | train loss: 0.001008 | valid loss: 0.001905\n","Epoch:  685 | train loss: 0.000928 | valid loss: 0.001987\n","Epoch:  686 | train loss: 0.000711 | valid loss: 0.001901\n","Epoch:  687 | train loss: 0.000456 | valid loss: 0.001895\n","Epoch:  688 | train loss: 0.000850 | valid loss: 0.001890\n","Epoch:  689 | train loss: 0.000913 | valid loss: 0.001972\n","Epoch:  690 | train loss: 0.000776 | valid loss: 0.001982\n","Epoch:  691 | train loss: 0.000683 | valid loss: 0.001993\n","Epoch:  692 | train loss: 0.000974 | valid loss: 0.001963\n","Epoch:  693 | train loss: 0.000995 | valid loss: 0.001955\n","Epoch:  694 | train loss: 0.000732 | valid loss: 0.001995\n","Epoch:  695 | train loss: 0.000787 | valid loss: 0.002044\n","Epoch:  696 | train loss: 0.000630 | valid loss: 0.002014\n","Epoch:  697 | train loss: 0.000817 | valid loss: 0.001936\n","Epoch:  698 | train loss: 0.000583 | valid loss: 0.001946\n","Epoch:  699 | train loss: 0.000707 | valid loss: 0.002100\n","Epoch:  700 | train loss: 0.000864 | valid loss: 0.001935\n","Epoch:  701 | train loss: 0.001082 | valid loss: 0.002007\n","Epoch:  702 | train loss: 0.000750 | valid loss: 0.002045\n","Epoch:  703 | train loss: 0.000941 | valid loss: 0.001995\n","Epoch:  704 | train loss: 0.000777 | valid loss: 0.001949\n","Epoch:  705 | train loss: 0.001020 | valid loss: 0.001939\n","Epoch:  706 | train loss: 0.000756 | valid loss: 0.001963\n","Epoch:  707 | train loss: 0.000737 | valid loss: 0.002036\n","Epoch:  708 | train loss: 0.000723 | valid loss: 0.001881\n","Epoch:  709 | train loss: 0.000754 | valid loss: 0.002126\n","Epoch:  710 | train loss: 0.001020 | valid loss: 0.002034\n","Epoch:  711 | train loss: 0.000761 | valid loss: 0.001932\n","Epoch:  712 | train loss: 0.001180 | valid loss: 0.002043\n","Epoch:  713 | train loss: 0.001078 | valid loss: 0.001984\n","Epoch:  714 | train loss: 0.000651 | valid loss: 0.002075\n","Epoch:  715 | train loss: 0.000973 | valid loss: 0.002187\n","Epoch:  716 | train loss: 0.000868 | valid loss: 0.001906\n","Epoch:  717 | train loss: 0.000800 | valid loss: 0.001891\n","Epoch:  718 | train loss: 0.000621 | valid loss: 0.001942\n","Epoch:  719 | train loss: 0.000644 | valid loss: 0.001952\n","Epoch:  720 | train loss: 0.000628 | valid loss: 0.001919\n","Epoch:  721 | train loss: 0.000768 | valid loss: 0.001921\n","Epoch:  722 | train loss: 0.000908 | valid loss: 0.002035\n","Epoch:  723 | train loss: 0.000726 | valid loss: 0.002006\n","Epoch:  724 | train loss: 0.001012 | valid loss: 0.001925\n","Epoch:  725 | train loss: 0.000581 | valid loss: 0.001956\n","Epoch:  726 | train loss: 0.000614 | valid loss: 0.002043\n","Epoch:  727 | train loss: 0.000962 | valid loss: 0.002054\n","Epoch:  728 | train loss: 0.000895 | valid loss: 0.002044\n","Epoch:  729 | train loss: 0.000987 | valid loss: 0.002049\n","Epoch:  730 | train loss: 0.000877 | valid loss: 0.002046\n","Epoch:  731 | train loss: 0.000652 | valid loss: 0.002239\n","Epoch:  732 | train loss: 0.001074 | valid loss: 0.001908\n","Epoch:  733 | train loss: 0.000819 | valid loss: 0.002017\n","Epoch:  734 | train loss: 0.001052 | valid loss: 0.001959\n","Epoch:  735 | train loss: 0.000984 | valid loss: 0.002050\n","Epoch:  736 | train loss: 0.000671 | valid loss: 0.001966\n","Epoch:  737 | train loss: 0.000992 | valid loss: 0.001987\n","Epoch:  738 | train loss: 0.000716 | valid loss: 0.001965\n","Epoch:  739 | train loss: 0.001042 | valid loss: 0.001936\n","Epoch:  740 | train loss: 0.000843 | valid loss: 0.002080\n","Epoch:  741 | train loss: 0.000731 | valid loss: 0.001992\n","Epoch:  742 | train loss: 0.000620 | valid loss: 0.001963\n","Epoch:  743 | train loss: 0.000741 | valid loss: 0.001951\n","Epoch:  744 | train loss: 0.000875 | valid loss: 0.002005\n","Epoch:  745 | train loss: 0.000769 | valid loss: 0.002030\n","Epoch:  746 | train loss: 0.000795 | valid loss: 0.002025\n","Epoch:  747 | train loss: 0.000782 | valid loss: 0.002204\n","Epoch:  748 | train loss: 0.000715 | valid loss: 0.001919\n","Epoch:  749 | train loss: 0.000509 | valid loss: 0.001906\n","Epoch:  750 | train loss: 0.000757 | valid loss: 0.001988\n","Epoch:  751 | train loss: 0.000639 | valid loss: 0.001993\n","Epoch:  752 | train loss: 0.000888 | valid loss: 0.002206\n","Epoch:  753 | train loss: 0.000842 | valid loss: 0.001943\n","Epoch:  754 | train loss: 0.001053 | valid loss: 0.001923\n","Epoch:  755 | train loss: 0.000709 | valid loss: 0.002004\n","Epoch:  756 | train loss: 0.000698 | valid loss: 0.001900\n","Epoch:  757 | train loss: 0.001143 | valid loss: 0.002043\n","Epoch:  758 | train loss: 0.000855 | valid loss: 0.001922\n","Epoch:  759 | train loss: 0.000723 | valid loss: 0.002021\n","Epoch:  760 | train loss: 0.001637 | valid loss: 0.001937\n","Epoch:  761 | train loss: 0.000881 | valid loss: 0.001979\n","Epoch:  762 | train loss: 0.000975 | valid loss: 0.002076\n","Epoch:  763 | train loss: 0.000614 | valid loss: 0.001936\n","Epoch:  764 | train loss: 0.000721 | valid loss: 0.001927\n","Epoch:  765 | train loss: 0.000757 | valid loss: 0.001902\n","Epoch:  766 | train loss: 0.000561 | valid loss: 0.001964\n","Epoch:  767 | train loss: 0.000873 | valid loss: 0.001897\n","Epoch:  768 | train loss: 0.000611 | valid loss: 0.001995\n","Epoch:  769 | train loss: 0.000880 | valid loss: 0.002048\n","Epoch:  770 | train loss: 0.000787 | valid loss: 0.001994\n","Epoch:  771 | train loss: 0.000922 | valid loss: 0.002009\n","Epoch:  772 | train loss: 0.000845 | valid loss: 0.001936\n","Epoch:  773 | train loss: 0.000490 | valid loss: 0.001989\n","Epoch:  774 | train loss: 0.000518 | valid loss: 0.001968\n","Epoch:  775 | train loss: 0.000775 | valid loss: 0.001926\n","Epoch:  776 | train loss: 0.000553 | valid loss: 0.001971\n","Epoch:  777 | train loss: 0.000609 | valid loss: 0.001976\n","Epoch:  778 | train loss: 0.000672 | valid loss: 0.001915\n","Epoch:  779 | train loss: 0.000596 | valid loss: 0.002000\n","Epoch:  780 | train loss: 0.000763 | valid loss: 0.001948\n","Epoch:  781 | train loss: 0.000544 | valid loss: 0.002001\n","Epoch:  782 | train loss: 0.000667 | valid loss: 0.002078\n","Epoch:  783 | train loss: 0.000927 | valid loss: 0.002160\n","Epoch:  784 | train loss: 0.000831 | valid loss: 0.002115\n","Epoch:  785 | train loss: 0.000657 | valid loss: 0.002038\n","Epoch:  786 | train loss: 0.000791 | valid loss: 0.001997\n","Epoch:  787 | train loss: 0.001077 | valid loss: 0.001926\n","Epoch:  788 | train loss: 0.000953 | valid loss: 0.002061\n","Epoch:  789 | train loss: 0.000597 | valid loss: 0.001973\n","Epoch:  790 | train loss: 0.000952 | valid loss: 0.002017\n","Epoch:  791 | train loss: 0.001143 | valid loss: 0.002039\n","Epoch:  792 | train loss: 0.000629 | valid loss: 0.001992\n","Epoch:  793 | train loss: 0.000807 | valid loss: 0.001939\n","Epoch:  794 | train loss: 0.001262 | valid loss: 0.002011\n","Epoch:  795 | train loss: 0.000750 | valid loss: 0.002107\n","Epoch:  796 | train loss: 0.000817 | valid loss: 0.002085\n","Epoch:  797 | train loss: 0.000551 | valid loss: 0.001976\n","Epoch:  798 | train loss: 0.001086 | valid loss: 0.001943\n","Epoch:  799 | train loss: 0.001110 | valid loss: 0.001977\n","Epoch:  800 | train loss: 0.000919 | valid loss: 0.001933\n","Epoch:  801 | train loss: 0.000734 | valid loss: 0.001885\n","Epoch:  802 | train loss: 0.001012 | valid loss: 0.001832\n","Epoch:  803 | train loss: 0.000611 | valid loss: 0.002016\n","Epoch:  804 | train loss: 0.000729 | valid loss: 0.002063\n","Epoch:  805 | train loss: 0.000657 | valid loss: 0.002134\n","Epoch:  806 | train loss: 0.001142 | valid loss: 0.002071\n","Epoch:  807 | train loss: 0.000881 | valid loss: 0.002017\n","Epoch:  808 | train loss: 0.000876 | valid loss: 0.002060\n","Epoch:  809 | train loss: 0.000824 | valid loss: 0.002093\n","Epoch:  810 | train loss: 0.001015 | valid loss: 0.002090\n","Epoch:  811 | train loss: 0.000752 | valid loss: 0.002072\n","Epoch:  812 | train loss: 0.000581 | valid loss: 0.001945\n","Epoch:  813 | train loss: 0.000567 | valid loss: 0.001978\n","Epoch:  814 | train loss: 0.000793 | valid loss: 0.001964\n","Epoch:  815 | train loss: 0.000802 | valid loss: 0.002124\n","Epoch:  816 | train loss: 0.000484 | valid loss: 0.001897\n","Epoch:  817 | train loss: 0.000554 | valid loss: 0.001964\n","Epoch:  818 | train loss: 0.000594 | valid loss: 0.001950\n","Epoch:  819 | train loss: 0.000821 | valid loss: 0.002027\n","Epoch:  820 | train loss: 0.000591 | valid loss: 0.001933\n","Epoch:  821 | train loss: 0.000758 | valid loss: 0.001998\n","Epoch:  822 | train loss: 0.000758 | valid loss: 0.001985\n","Epoch:  823 | train loss: 0.000560 | valid loss: 0.002085\n","Epoch:  824 | train loss: 0.000706 | valid loss: 0.001992\n","Epoch:  825 | train loss: 0.001169 | valid loss: 0.001999\n","Epoch:  826 | train loss: 0.000995 | valid loss: 0.002058\n","Epoch:  827 | train loss: 0.000687 | valid loss: 0.002140\n","Epoch:  828 | train loss: 0.000913 | valid loss: 0.002006\n","Epoch:  829 | train loss: 0.000563 | valid loss: 0.001973\n","Epoch:  830 | train loss: 0.000747 | valid loss: 0.001991\n","Epoch:  831 | train loss: 0.000686 | valid loss: 0.002072\n","Epoch:  832 | train loss: 0.000538 | valid loss: 0.001894\n","Epoch:  833 | train loss: 0.000699 | valid loss: 0.002107\n","Epoch:  834 | train loss: 0.000892 | valid loss: 0.002050\n","Epoch:  835 | train loss: 0.001091 | valid loss: 0.002067\n","Epoch:  836 | train loss: 0.000794 | valid loss: 0.002024\n","Epoch:  837 | train loss: 0.000807 | valid loss: 0.002013\n","Epoch:  838 | train loss: 0.000606 | valid loss: 0.002092\n","Epoch:  839 | train loss: 0.002041 | valid loss: 0.002055\n","Epoch:  840 | train loss: 0.001046 | valid loss: 0.002080\n","Epoch:  841 | train loss: 0.000917 | valid loss: 0.002128\n","Epoch:  842 | train loss: 0.000649 | valid loss: 0.001989\n","Epoch:  843 | train loss: 0.000568 | valid loss: 0.001946\n","Epoch:  844 | train loss: 0.000641 | valid loss: 0.002021\n","Epoch:  845 | train loss: 0.001034 | valid loss: 0.002046\n","Epoch:  846 | train loss: 0.001289 | valid loss: 0.002126\n","Epoch:  847 | train loss: 0.000716 | valid loss: 0.001958\n","Epoch:  848 | train loss: 0.000788 | valid loss: 0.001990\n","Epoch:  849 | train loss: 0.000790 | valid loss: 0.001961\n","Epoch:  850 | train loss: 0.000757 | valid loss: 0.002047\n","Epoch:  851 | train loss: 0.000885 | valid loss: 0.002082\n","Epoch:  852 | train loss: 0.000611 | valid loss: 0.002019\n","Epoch:  853 | train loss: 0.000791 | valid loss: 0.002029\n","Epoch:  854 | train loss: 0.000618 | valid loss: 0.002082\n","Epoch:  855 | train loss: 0.000490 | valid loss: 0.001957\n","Epoch:  856 | train loss: 0.000712 | valid loss: 0.002174\n","Epoch:  857 | train loss: 0.000577 | valid loss: 0.002039\n","Epoch:  858 | train loss: 0.000600 | valid loss: 0.002083\n","Epoch:  859 | train loss: 0.000822 | valid loss: 0.002221\n","Epoch:  860 | train loss: 0.000957 | valid loss: 0.002111\n","Epoch:  861 | train loss: 0.000913 | valid loss: 0.002099\n","Epoch:  862 | train loss: 0.000540 | valid loss: 0.001904\n","Epoch:  863 | train loss: 0.000867 | valid loss: 0.002086\n","Epoch:  864 | train loss: 0.000871 | valid loss: 0.001905\n","Epoch:  865 | train loss: 0.000521 | valid loss: 0.002021\n","Epoch:  866 | train loss: 0.000619 | valid loss: 0.001962\n","Epoch:  867 | train loss: 0.000589 | valid loss: 0.002047\n","Epoch:  868 | train loss: 0.000830 | valid loss: 0.002102\n","Epoch:  869 | train loss: 0.000500 | valid loss: 0.001958\n","Epoch:  870 | train loss: 0.000799 | valid loss: 0.001992\n","Epoch:  871 | train loss: 0.000475 | valid loss: 0.002033\n","Epoch:  872 | train loss: 0.002340 | valid loss: 0.002194\n","Epoch:  873 | train loss: 0.000697 | valid loss: 0.002220\n","Epoch:  874 | train loss: 0.000919 | valid loss: 0.002098\n","Epoch:  875 | train loss: 0.000493 | valid loss: 0.001924\n","Epoch:  876 | train loss: 0.000668 | valid loss: 0.001974\n","Epoch:  877 | train loss: 0.000581 | valid loss: 0.001948\n","Epoch:  878 | train loss: 0.000741 | valid loss: 0.002051\n","Epoch:  879 | train loss: 0.000610 | valid loss: 0.002025\n","Epoch:  880 | train loss: 0.000615 | valid loss: 0.002164\n","Epoch:  881 | train loss: 0.000857 | valid loss: 0.002060\n","Epoch:  882 | train loss: 0.000982 | valid loss: 0.002073\n","Epoch:  883 | train loss: 0.001075 | valid loss: 0.002099\n","Epoch:  884 | train loss: 0.000575 | valid loss: 0.001931\n","Epoch:  885 | train loss: 0.000501 | valid loss: 0.002003\n","Epoch:  886 | train loss: 0.000998 | valid loss: 0.001939\n","Epoch:  887 | train loss: 0.000852 | valid loss: 0.002020\n","Epoch:  888 | train loss: 0.000792 | valid loss: 0.002080\n","Epoch:  889 | train loss: 0.000592 | valid loss: 0.002087\n","Epoch:  890 | train loss: 0.000883 | valid loss: 0.002120\n","Epoch:  891 | train loss: 0.000770 | valid loss: 0.002126\n","Epoch:  892 | train loss: 0.000656 | valid loss: 0.002148\n","Epoch:  893 | train loss: 0.000922 | valid loss: 0.002211\n","Epoch:  894 | train loss: 0.000731 | valid loss: 0.002338\n","Epoch:  895 | train loss: 0.000599 | valid loss: 0.002070\n","Epoch:  896 | train loss: 0.000881 | valid loss: 0.002016\n","Epoch:  897 | train loss: 0.000532 | valid loss: 0.001984\n","Epoch:  898 | train loss: 0.000640 | valid loss: 0.001985\n","Epoch:  899 | train loss: 0.000663 | valid loss: 0.001945\n","Epoch:  900 | train loss: 0.000910 | valid loss: 0.002040\n","Epoch:  901 | train loss: 0.000602 | valid loss: 0.001960\n","Epoch:  902 | train loss: 0.000802 | valid loss: 0.002096\n","Epoch:  903 | train loss: 0.000933 | valid loss: 0.002012\n","Epoch:  904 | train loss: 0.001596 | valid loss: 0.002116\n","Epoch:  905 | train loss: 0.000727 | valid loss: 0.002190\n","Epoch:  906 | train loss: 0.000880 | valid loss: 0.002153\n","Epoch:  907 | train loss: 0.000752 | valid loss: 0.002111\n","Epoch:  908 | train loss: 0.000628 | valid loss: 0.002135\n","Epoch:  909 | train loss: 0.000625 | valid loss: 0.002136\n","Epoch:  910 | train loss: 0.000641 | valid loss: 0.002208\n","Epoch:  911 | train loss: 0.000666 | valid loss: 0.002129\n","Epoch:  912 | train loss: 0.000807 | valid loss: 0.002088\n","Epoch:  913 | train loss: 0.001159 | valid loss: 0.002231\n","Epoch:  914 | train loss: 0.000843 | valid loss: 0.002155\n","Epoch:  915 | train loss: 0.001022 | valid loss: 0.001996\n","Epoch:  916 | train loss: 0.000518 | valid loss: 0.002100\n","Epoch:  917 | train loss: 0.000605 | valid loss: 0.001993\n","Epoch:  918 | train loss: 0.000700 | valid loss: 0.002062\n","Epoch:  919 | train loss: 0.003371 | valid loss: 0.001971\n","Epoch:  920 | train loss: 0.000556 | valid loss: 0.001974\n","Epoch:  921 | train loss: 0.000716 | valid loss: 0.002026\n","Epoch:  922 | train loss: 0.000612 | valid loss: 0.002124\n","Epoch:  923 | train loss: 0.000741 | valid loss: 0.002076\n","Epoch:  924 | train loss: 0.000493 | valid loss: 0.002225\n","Epoch:  925 | train loss: 0.000789 | valid loss: 0.002122\n","Epoch:  926 | train loss: 0.000835 | valid loss: 0.002429\n","Epoch:  927 | train loss: 0.001109 | valid loss: 0.002095\n","Epoch:  928 | train loss: 0.000723 | valid loss: 0.002155\n","Epoch:  929 | train loss: 0.000785 | valid loss: 0.002093\n","Epoch:  930 | train loss: 0.000934 | valid loss: 0.002124\n","Epoch:  931 | train loss: 0.000773 | valid loss: 0.002095\n","Epoch:  932 | train loss: 0.000496 | valid loss: 0.002004\n","Epoch:  933 | train loss: 0.000939 | valid loss: 0.002026\n","Epoch:  934 | train loss: 0.000636 | valid loss: 0.002062\n","Epoch:  935 | train loss: 0.000500 | valid loss: 0.002077\n","Epoch:  936 | train loss: 0.001173 | valid loss: 0.002041\n","Epoch:  937 | train loss: 0.000629 | valid loss: 0.002089\n","Epoch:  938 | train loss: 0.000775 | valid loss: 0.002132\n","Epoch:  939 | train loss: 0.000689 | valid loss: 0.002147\n","Epoch:  940 | train loss: 0.000666 | valid loss: 0.002064\n","Epoch:  941 | train loss: 0.000536 | valid loss: 0.002132\n","Epoch:  942 | train loss: 0.000697 | valid loss: 0.002094\n","Epoch:  943 | train loss: 0.000915 | valid loss: 0.002074\n","Epoch:  944 | train loss: 0.000815 | valid loss: 0.002079\n","Epoch:  945 | train loss: 0.000806 | valid loss: 0.002048\n","Epoch:  946 | train loss: 0.000740 | valid loss: 0.002057\n","Epoch:  947 | train loss: 0.001022 | valid loss: 0.002035\n","Epoch:  948 | train loss: 0.000673 | valid loss: 0.002051\n","Epoch:  949 | train loss: 0.001052 | valid loss: 0.002017\n","Epoch:  950 | train loss: 0.000427 | valid loss: 0.002086\n","Epoch:  951 | train loss: 0.000816 | valid loss: 0.002038\n","Epoch:  952 | train loss: 0.000757 | valid loss: 0.002010\n","Epoch:  953 | train loss: 0.000547 | valid loss: 0.001943\n","Epoch:  954 | train loss: 0.000446 | valid loss: 0.002061\n","Epoch:  955 | train loss: 0.000675 | valid loss: 0.002149\n","Epoch:  956 | train loss: 0.000550 | valid loss: 0.002096\n","Epoch:  957 | train loss: 0.000449 | valid loss: 0.002131\n","Epoch:  958 | train loss: 0.000532 | valid loss: 0.001988\n","Epoch:  959 | train loss: 0.001292 | valid loss: 0.002109\n","Epoch:  960 | train loss: 0.000600 | valid loss: 0.002140\n","Epoch:  961 | train loss: 0.000620 | valid loss: 0.002086\n","Epoch:  962 | train loss: 0.000995 | valid loss: 0.002094\n","Epoch:  963 | train loss: 0.000646 | valid loss: 0.002127\n","Epoch:  964 | train loss: 0.000534 | valid loss: 0.002081\n","Epoch:  965 | train loss: 0.000778 | valid loss: 0.002095\n","Epoch:  966 | train loss: 0.000864 | valid loss: 0.002214\n","Epoch:  967 | train loss: 0.001025 | valid loss: 0.002136\n","Epoch:  968 | train loss: 0.000853 | valid loss: 0.002186\n","Epoch:  969 | train loss: 0.000550 | valid loss: 0.002048\n","Epoch:  970 | train loss: 0.000616 | valid loss: 0.002096\n","Epoch:  971 | train loss: 0.000568 | valid loss: 0.002015\n","Epoch:  972 | train loss: 0.000789 | valid loss: 0.002084\n","Epoch:  973 | train loss: 0.000637 | valid loss: 0.002120\n","Epoch:  974 | train loss: 0.000949 | valid loss: 0.001997\n","Epoch:  975 | train loss: 0.000863 | valid loss: 0.002155\n","Epoch:  976 | train loss: 0.000819 | valid loss: 0.002078\n","Epoch:  977 | train loss: 0.000500 | valid loss: 0.002105\n","Epoch:  978 | train loss: 0.000530 | valid loss: 0.002015\n","Epoch:  979 | train loss: 0.000678 | valid loss: 0.002124\n","Epoch:  980 | train loss: 0.000579 | valid loss: 0.002082\n","Epoch:  981 | train loss: 0.000672 | valid loss: 0.002149\n","Epoch:  982 | train loss: 0.000618 | valid loss: 0.002227\n","Epoch:  983 | train loss: 0.000866 | valid loss: 0.002184\n","Epoch:  984 | train loss: 0.000739 | valid loss: 0.002144\n","Epoch:  985 | train loss: 0.000699 | valid loss: 0.002085\n","Epoch:  986 | train loss: 0.000674 | valid loss: 0.002094\n","Epoch:  987 | train loss: 0.000710 | valid loss: 0.002067\n","Epoch:  988 | train loss: 0.000711 | valid loss: 0.002118\n","Epoch:  989 | train loss: 0.000565 | valid loss: 0.002072\n","Epoch:  990 | train loss: 0.000499 | valid loss: 0.002197\n","Epoch:  991 | train loss: 0.000590 | valid loss: 0.002127\n","Epoch:  992 | train loss: 0.000624 | valid loss: 0.002166\n","Epoch:  993 | train loss: 0.000858 | valid loss: 0.002106\n","Epoch:  994 | train loss: 0.000579 | valid loss: 0.002026\n","Epoch:  995 | train loss: 0.000647 | valid loss: 0.002052\n","Epoch:  996 | train loss: 0.000577 | valid loss: 0.002012\n","Epoch:  997 | train loss: 0.000529 | valid loss: 0.002062\n","Epoch:  998 | train loss: 0.000795 | valid loss: 0.002133\n","Epoch:  999 | train loss: 0.000837 | valid loss: 0.002096\n","Epoch:  1000 | train loss: 0.000984 | valid loss: 0.002144\n","Epoch:  1001 | train loss: 0.000706 | valid loss: 0.002108\n","Epoch:  1002 | train loss: 0.000694 | valid loss: 0.002152\n","Epoch:  1003 | train loss: 0.001504 | valid loss: 0.002294\n","Epoch:  1004 | train loss: 0.000913 | valid loss: 0.002175\n","Epoch:  1005 | train loss: 0.000535 | valid loss: 0.002090\n","Epoch:  1006 | train loss: 0.000594 | valid loss: 0.002186\n","Epoch:  1007 | train loss: 0.000687 | valid loss: 0.002077\n","Epoch:  1008 | train loss: 0.000733 | valid loss: 0.002037\n","Epoch:  1009 | train loss: 0.000950 | valid loss: 0.002060\n","Epoch:  1010 | train loss: 0.000516 | valid loss: 0.002068\n","Epoch:  1011 | train loss: 0.000770 | valid loss: 0.002078\n","Epoch:  1012 | train loss: 0.000563 | valid loss: 0.002082\n","Epoch:  1013 | train loss: 0.000650 | valid loss: 0.002070\n","Epoch:  1014 | train loss: 0.000568 | valid loss: 0.002188\n","Epoch:  1015 | train loss: 0.000631 | valid loss: 0.002004\n","Epoch:  1016 | train loss: 0.000667 | valid loss: 0.002054\n","Epoch:  1017 | train loss: 0.000678 | valid loss: 0.002117\n","Epoch:  1018 | train loss: 0.000808 | valid loss: 0.002102\n","Epoch:  1019 | train loss: 0.000891 | valid loss: 0.002264\n","Epoch:  1020 | train loss: 0.000948 | valid loss: 0.002048\n","Epoch:  1021 | train loss: 0.000568 | valid loss: 0.002121\n","Epoch:  1022 | train loss: 0.000829 | valid loss: 0.002081\n","Epoch:  1023 | train loss: 0.000845 | valid loss: 0.002180\n","Epoch:  1024 | train loss: 0.000652 | valid loss: 0.002078\n","Epoch:  1025 | train loss: 0.000572 | valid loss: 0.002057\n","Epoch:  1026 | train loss: 0.000632 | valid loss: 0.002135\n","Epoch:  1027 | train loss: 0.000748 | valid loss: 0.002117\n","Epoch:  1028 | train loss: 0.000582 | valid loss: 0.002132\n","Epoch:  1029 | train loss: 0.000822 | valid loss: 0.002155\n","Epoch:  1030 | train loss: 0.000499 | valid loss: 0.002186\n","Epoch:  1031 | train loss: 0.000787 | valid loss: 0.002213\n","Epoch:  1032 | train loss: 0.000608 | valid loss: 0.002164\n","Epoch:  1033 | train loss: 0.001026 | valid loss: 0.002151\n","Epoch:  1034 | train loss: 0.000668 | valid loss: 0.002261\n","Epoch:  1035 | train loss: 0.000807 | valid loss: 0.002155\n","Epoch:  1036 | train loss: 0.000498 | valid loss: 0.002126\n","Epoch:  1037 | train loss: 0.000743 | valid loss: 0.002076\n","Epoch:  1038 | train loss: 0.000861 | valid loss: 0.002092\n","Epoch:  1039 | train loss: 0.000511 | valid loss: 0.002023\n","Epoch:  1040 | train loss: 0.000814 | valid loss: 0.002002\n","Epoch:  1041 | train loss: 0.000948 | valid loss: 0.002081\n","Epoch:  1042 | train loss: 0.000532 | valid loss: 0.002085\n","Epoch:  1043 | train loss: 0.000557 | valid loss: 0.002115\n","Epoch:  1044 | train loss: 0.001096 | valid loss: 0.002112\n","Epoch:  1045 | train loss: 0.000525 | valid loss: 0.002079\n","Epoch:  1046 | train loss: 0.000771 | valid loss: 0.002154\n","Epoch:  1047 | train loss: 0.000614 | valid loss: 0.002176\n","Epoch:  1048 | train loss: 0.000615 | valid loss: 0.002098\n","Epoch:  1049 | train loss: 0.000720 | valid loss: 0.002168\n","Epoch:  1050 | train loss: 0.000790 | valid loss: 0.002176\n","Epoch:  1051 | train loss: 0.000544 | valid loss: 0.002073\n","Epoch:  1052 | train loss: 0.000773 | valid loss: 0.001996\n","Epoch:  1053 | train loss: 0.000867 | valid loss: 0.001992\n","Epoch:  1054 | train loss: 0.000501 | valid loss: 0.002118\n","Epoch:  1055 | train loss: 0.000668 | valid loss: 0.002163\n","Epoch:  1056 | train loss: 0.000778 | valid loss: 0.002119\n","Epoch:  1057 | train loss: 0.001040 | valid loss: 0.002198\n","Epoch:  1058 | train loss: 0.000557 | valid loss: 0.002064\n","Epoch:  1059 | train loss: 0.000725 | valid loss: 0.002279\n","Epoch:  1060 | train loss: 0.000773 | valid loss: 0.002093\n","Epoch:  1061 | train loss: 0.000608 | valid loss: 0.002107\n","Epoch:  1062 | train loss: 0.000550 | valid loss: 0.002104\n","Epoch:  1063 | train loss: 0.001213 | valid loss: 0.002123\n","Epoch:  1064 | train loss: 0.000668 | valid loss: 0.002111\n","Epoch:  1065 | train loss: 0.000757 | valid loss: 0.002176\n","Epoch:  1066 | train loss: 0.000780 | valid loss: 0.002119\n","Epoch:  1067 | train loss: 0.000611 | valid loss: 0.002100\n","Epoch:  1068 | train loss: 0.000865 | valid loss: 0.002056\n","Epoch:  1069 | train loss: 0.000762 | valid loss: 0.002200\n","Epoch:  1070 | train loss: 0.000544 | valid loss: 0.002128\n","Epoch:  1071 | train loss: 0.000740 | valid loss: 0.002063\n","Epoch:  1072 | train loss: 0.000951 | valid loss: 0.002120\n","Epoch:  1073 | train loss: 0.001101 | valid loss: 0.002199\n","Epoch:  1074 | train loss: 0.001997 | valid loss: 0.002148\n","Epoch:  1075 | train loss: 0.000754 | valid loss: 0.002055\n","Epoch:  1076 | train loss: 0.000965 | valid loss: 0.002172\n","Epoch:  1077 | train loss: 0.000537 | valid loss: 0.002097\n","Epoch:  1078 | train loss: 0.000507 | valid loss: 0.002259\n","Epoch:  1079 | train loss: 0.000873 | valid loss: 0.002196\n","Epoch:  1080 | train loss: 0.000757 | valid loss: 0.002160\n","Epoch:  1081 | train loss: 0.000418 | valid loss: 0.002082\n","Epoch:  1082 | train loss: 0.000581 | valid loss: 0.002119\n","Epoch:  1083 | train loss: 0.000512 | valid loss: 0.002051\n","Epoch:  1084 | train loss: 0.000713 | valid loss: 0.002033\n","Epoch:  1085 | train loss: 0.000642 | valid loss: 0.002104\n","Epoch:  1086 | train loss: 0.000714 | valid loss: 0.002212\n","Epoch:  1087 | train loss: 0.000964 | valid loss: 0.002165\n","Epoch:  1088 | train loss: 0.000816 | valid loss: 0.002165\n","Epoch:  1089 | train loss: 0.000565 | valid loss: 0.002208\n","Epoch:  1090 | train loss: 0.000814 | valid loss: 0.002221\n","Epoch:  1091 | train loss: 0.000586 | valid loss: 0.002142\n","Epoch:  1092 | train loss: 0.000625 | valid loss: 0.002084\n","Epoch:  1093 | train loss: 0.000923 | valid loss: 0.002101\n","Epoch:  1094 | train loss: 0.000430 | valid loss: 0.002124\n","Epoch:  1095 | train loss: 0.000469 | valid loss: 0.002066\n","Epoch:  1096 | train loss: 0.000567 | valid loss: 0.002083\n","Epoch:  1097 | train loss: 0.000610 | valid loss: 0.002022\n","Epoch:  1098 | train loss: 0.000639 | valid loss: 0.002052\n","Epoch:  1099 | train loss: 0.000577 | valid loss: 0.002140\n","Epoch:  1100 | train loss: 0.000684 | valid loss: 0.002057\n","Epoch:  1101 | train loss: 0.000424 | valid loss: 0.002102\n","Epoch:  1102 | train loss: 0.000842 | valid loss: 0.002137\n","Epoch:  1103 | train loss: 0.000704 | valid loss: 0.002155\n","Epoch:  1104 | train loss: 0.000793 | valid loss: 0.002138\n","Epoch:  1105 | train loss: 0.000886 | valid loss: 0.002129\n","Epoch:  1106 | train loss: 0.000578 | valid loss: 0.002116\n","Epoch:  1107 | train loss: 0.000771 | valid loss: 0.002227\n","Epoch:  1108 | train loss: 0.000736 | valid loss: 0.002148\n","Epoch:  1109 | train loss: 0.000449 | valid loss: 0.002072\n","Epoch:  1110 | train loss: 0.000523 | valid loss: 0.002102\n","Epoch:  1111 | train loss: 0.000687 | valid loss: 0.002243\n","Epoch:  1112 | train loss: 0.000525 | valid loss: 0.002060\n","Epoch:  1113 | train loss: 0.000506 | valid loss: 0.002196\n","Epoch:  1114 | train loss: 0.000810 | valid loss: 0.002136\n","Epoch:  1115 | train loss: 0.000525 | valid loss: 0.002186\n","Epoch:  1116 | train loss: 0.000876 | valid loss: 0.002080\n","Epoch:  1117 | train loss: 0.000466 | valid loss: 0.002117\n","Epoch:  1118 | train loss: 0.000932 | valid loss: 0.002267\n","Epoch:  1119 | train loss: 0.001133 | valid loss: 0.002263\n","Epoch:  1120 | train loss: 0.000661 | valid loss: 0.002082\n","Epoch:  1121 | train loss: 0.000507 | valid loss: 0.002154\n","Epoch:  1122 | train loss: 0.000694 | valid loss: 0.002127\n","Epoch:  1123 | train loss: 0.000778 | valid loss: 0.002012\n","Epoch:  1124 | train loss: 0.001949 | valid loss: 0.002112\n","Epoch:  1125 | train loss: 0.000577 | valid loss: 0.002100\n","Epoch:  1126 | train loss: 0.000602 | valid loss: 0.002047\n","Epoch:  1127 | train loss: 0.000757 | valid loss: 0.002168\n","Epoch:  1128 | train loss: 0.001170 | valid loss: 0.002176\n","Epoch:  1129 | train loss: 0.000464 | valid loss: 0.002132\n","Epoch:  1130 | train loss: 0.000519 | valid loss: 0.002150\n","Epoch:  1131 | train loss: 0.000699 | valid loss: 0.002104\n","Epoch:  1132 | train loss: 0.000622 | valid loss: 0.002018\n","Epoch:  1133 | train loss: 0.000745 | valid loss: 0.002077\n","Epoch:  1134 | train loss: 0.000826 | valid loss: 0.002195\n","Epoch:  1135 | train loss: 0.000550 | valid loss: 0.002175\n","Epoch:  1136 | train loss: 0.000586 | valid loss: 0.002059\n","Epoch:  1137 | train loss: 0.000458 | valid loss: 0.002140\n","Epoch:  1138 | train loss: 0.000493 | valid loss: 0.002118\n","Epoch:  1139 | train loss: 0.000704 | valid loss: 0.002077\n","Epoch:  1140 | train loss: 0.000715 | valid loss: 0.002121\n","Epoch:  1141 | train loss: 0.000615 | valid loss: 0.002160\n","Epoch:  1142 | train loss: 0.000831 | valid loss: 0.002120\n","Epoch:  1143 | train loss: 0.000564 | valid loss: 0.002158\n","Epoch:  1144 | train loss: 0.000572 | valid loss: 0.002213\n","Epoch:  1145 | train loss: 0.000749 | valid loss: 0.002129\n","Epoch:  1146 | train loss: 0.000764 | valid loss: 0.002184\n","Epoch:  1147 | train loss: 0.000542 | valid loss: 0.002141\n","Epoch:  1148 | train loss: 0.000776 | valid loss: 0.002100\n","Epoch:  1149 | train loss: 0.000646 | valid loss: 0.002190\n","Epoch:  1150 | train loss: 0.000507 | valid loss: 0.002081\n","Epoch:  1151 | train loss: 0.000640 | valid loss: 0.002059\n","Epoch:  1152 | train loss: 0.000554 | valid loss: 0.002057\n","Epoch:  1153 | train loss: 0.000728 | valid loss: 0.002029\n","Epoch:  1154 | train loss: 0.000648 | valid loss: 0.002237\n","Epoch:  1155 | train loss: 0.000790 | valid loss: 0.002278\n","Epoch:  1156 | train loss: 0.000827 | valid loss: 0.002086\n","Epoch:  1157 | train loss: 0.000420 | valid loss: 0.002119\n","Epoch:  1158 | train loss: 0.000574 | valid loss: 0.002015\n","Epoch:  1159 | train loss: 0.000604 | valid loss: 0.002283\n","Epoch:  1160 | train loss: 0.001326 | valid loss: 0.002126\n","Epoch:  1161 | train loss: 0.000569 | valid loss: 0.002139\n","Epoch:  1162 | train loss: 0.000574 | valid loss: 0.002088\n","Epoch:  1163 | train loss: 0.000910 | valid loss: 0.002192\n","Epoch:  1164 | train loss: 0.000692 | valid loss: 0.002054\n","Epoch:  1165 | train loss: 0.000356 | valid loss: 0.002097\n","Epoch:  1166 | train loss: 0.000751 | valid loss: 0.002100\n","Epoch:  1167 | train loss: 0.001015 | valid loss: 0.002211\n","Epoch:  1168 | train loss: 0.000853 | valid loss: 0.002189\n","Epoch:  1169 | train loss: 0.000727 | valid loss: 0.002206\n","Epoch:  1170 | train loss: 0.000607 | valid loss: 0.002129\n","Epoch:  1171 | train loss: 0.000804 | valid loss: 0.002198\n","Epoch:  1172 | train loss: 0.000646 | valid loss: 0.002192\n","Epoch:  1173 | train loss: 0.000835 | valid loss: 0.002186\n","Epoch:  1174 | train loss: 0.000671 | valid loss: 0.002256\n","Epoch:  1175 | train loss: 0.000690 | valid loss: 0.002215\n","Epoch:  1176 | train loss: 0.000505 | valid loss: 0.002102\n","Epoch:  1177 | train loss: 0.000546 | valid loss: 0.002188\n","Epoch:  1178 | train loss: 0.000792 | valid loss: 0.002185\n","Epoch:  1179 | train loss: 0.000925 | valid loss: 0.002082\n","Epoch:  1180 | train loss: 0.000566 | valid loss: 0.002154\n","Epoch:  1181 | train loss: 0.000734 | valid loss: 0.002190\n","Epoch:  1182 | train loss: 0.000810 | valid loss: 0.002150\n","Epoch:  1183 | train loss: 0.000619 | valid loss: 0.002142\n","Epoch:  1184 | train loss: 0.000890 | valid loss: 0.002129\n","Epoch:  1185 | train loss: 0.000483 | valid loss: 0.002143\n","Epoch:  1186 | train loss: 0.000612 | valid loss: 0.002087\n","Epoch:  1187 | train loss: 0.000583 | valid loss: 0.002150\n","Epoch:  1188 | train loss: 0.000484 | valid loss: 0.002242\n","Epoch:  1189 | train loss: 0.001346 | valid loss: 0.002245\n","Epoch:  1190 | train loss: 0.001177 | valid loss: 0.002368\n","Epoch:  1191 | train loss: 0.000616 | valid loss: 0.002240\n","Epoch:  1192 | train loss: 0.001332 | valid loss: 0.002313\n","Epoch:  1193 | train loss: 0.000606 | valid loss: 0.002250\n","Epoch:  1194 | train loss: 0.000815 | valid loss: 0.002283\n","Epoch:  1195 | train loss: 0.000747 | valid loss: 0.002162\n","Epoch:  1196 | train loss: 0.000536 | valid loss: 0.002056\n","Epoch:  1197 | train loss: 0.000605 | valid loss: 0.002097\n","Epoch:  1198 | train loss: 0.000585 | valid loss: 0.002130\n","Epoch:  1199 | train loss: 0.000643 | valid loss: 0.002174\n","Epoch:  1200 | train loss: 0.000610 | valid loss: 0.002230\n","Epoch:  1201 | train loss: 0.000677 | valid loss: 0.002255\n","Epoch:  1202 | train loss: 0.000800 | valid loss: 0.002235\n","Epoch:  1203 | train loss: 0.000750 | valid loss: 0.002306\n","Epoch:  1204 | train loss: 0.000665 | valid loss: 0.002249\n","Epoch:  1205 | train loss: 0.002652 | valid loss: 0.002235\n","Epoch:  1206 | train loss: 0.000572 | valid loss: 0.002190\n","Epoch:  1207 | train loss: 0.000527 | valid loss: 0.002195\n","Epoch:  1208 | train loss: 0.000962 | valid loss: 0.002179\n","Epoch:  1209 | train loss: 0.000563 | valid loss: 0.002079\n","Epoch:  1210 | train loss: 0.000728 | valid loss: 0.002117\n","Epoch:  1211 | train loss: 0.000363 | valid loss: 0.002109\n","Epoch:  1212 | train loss: 0.000463 | valid loss: 0.002093\n","Epoch:  1213 | train loss: 0.000453 | valid loss: 0.002143\n","Epoch:  1214 | train loss: 0.000591 | valid loss: 0.002170\n","Epoch:  1215 | train loss: 0.000564 | valid loss: 0.002213\n","Epoch:  1216 | train loss: 0.000527 | valid loss: 0.002246\n","Epoch:  1217 | train loss: 0.000623 | valid loss: 0.002322\n","Epoch:  1218 | train loss: 0.000674 | valid loss: 0.002155\n","Epoch:  1219 | train loss: 0.000536 | valid loss: 0.002059\n","Epoch:  1220 | train loss: 0.000469 | valid loss: 0.002225\n","Epoch:  1221 | train loss: 0.000643 | valid loss: 0.002087\n","Epoch:  1222 | train loss: 0.000607 | valid loss: 0.002127\n","Epoch:  1223 | train loss: 0.000642 | valid loss: 0.002147\n","Epoch:  1224 | train loss: 0.000440 | valid loss: 0.002096\n","Epoch:  1225 | train loss: 0.000537 | valid loss: 0.002159\n","Epoch:  1226 | train loss: 0.000694 | valid loss: 0.002127\n","Epoch:  1227 | train loss: 0.000663 | valid loss: 0.002270\n","Epoch:  1228 | train loss: 0.000636 | valid loss: 0.002210\n","Epoch:  1229 | train loss: 0.000665 | valid loss: 0.002219\n","Epoch:  1230 | train loss: 0.000471 | valid loss: 0.002241\n","Epoch:  1231 | train loss: 0.000658 | valid loss: 0.002211\n","Epoch:  1232 | train loss: 0.000882 | valid loss: 0.002153\n","Epoch:  1233 | train loss: 0.000577 | valid loss: 0.002191\n","Epoch:  1234 | train loss: 0.000405 | valid loss: 0.002075\n","Epoch:  1235 | train loss: 0.000542 | valid loss: 0.002110\n","Epoch:  1236 | train loss: 0.000736 | valid loss: 0.002181\n","Epoch:  1237 | train loss: 0.000515 | valid loss: 0.002088\n","Epoch:  1238 | train loss: 0.000894 | valid loss: 0.002147\n","Epoch:  1239 | train loss: 0.000497 | valid loss: 0.002244\n","Epoch:  1240 | train loss: 0.000530 | valid loss: 0.002157\n","Epoch:  1241 | train loss: 0.000914 | valid loss: 0.002202\n","Epoch:  1242 | train loss: 0.000686 | valid loss: 0.002177\n","Epoch:  1243 | train loss: 0.000716 | valid loss: 0.002252\n","Epoch:  1244 | train loss: 0.000666 | valid loss: 0.002122\n","Epoch:  1245 | train loss: 0.000526 | valid loss: 0.002167\n","Epoch:  1246 | train loss: 0.000504 | valid loss: 0.002224\n","Epoch:  1247 | train loss: 0.000543 | valid loss: 0.002320\n","Epoch:  1248 | train loss: 0.000722 | valid loss: 0.002207\n","Epoch:  1249 | train loss: 0.000602 | valid loss: 0.002340\n","Epoch:  1250 | train loss: 0.000614 | valid loss: 0.002271\n","Epoch:  1251 | train loss: 0.000472 | valid loss: 0.002268\n","Epoch:  1252 | train loss: 0.000652 | valid loss: 0.002274\n","Epoch:  1253 | train loss: 0.000870 | valid loss: 0.002228\n","Epoch:  1254 | train loss: 0.000750 | valid loss: 0.002212\n","Epoch:  1255 | train loss: 0.000840 | valid loss: 0.002259\n","Epoch:  1256 | train loss: 0.000740 | valid loss: 0.002249\n","Epoch:  1257 | train loss: 0.000500 | valid loss: 0.002166\n","Epoch:  1258 | train loss: 0.000692 | valid loss: 0.002276\n","Epoch:  1259 | train loss: 0.000810 | valid loss: 0.002319\n","Epoch:  1260 | train loss: 0.000711 | valid loss: 0.002238\n","Epoch:  1261 | train loss: 0.000582 | valid loss: 0.002243\n","Epoch:  1262 | train loss: 0.001326 | valid loss: 0.002243\n","Epoch:  1263 | train loss: 0.000954 | valid loss: 0.002207\n","Epoch:  1264 | train loss: 0.000864 | valid loss: 0.002182\n","Epoch:  1265 | train loss: 0.000578 | valid loss: 0.002192\n","Epoch:  1266 | train loss: 0.000379 | valid loss: 0.002149\n","Epoch:  1267 | train loss: 0.001276 | valid loss: 0.002286\n","Epoch:  1268 | train loss: 0.000860 | valid loss: 0.002327\n","Epoch:  1269 | train loss: 0.000785 | valid loss: 0.002228\n","Epoch:  1270 | train loss: 0.000571 | valid loss: 0.002156\n","Epoch:  1271 | train loss: 0.000594 | valid loss: 0.002191\n","Epoch:  1272 | train loss: 0.000659 | valid loss: 0.002245\n","Epoch:  1273 | train loss: 0.000792 | valid loss: 0.002293\n","Epoch:  1274 | train loss: 0.000796 | valid loss: 0.002192\n","Epoch:  1275 | train loss: 0.000495 | valid loss: 0.002130\n","Epoch:  1276 | train loss: 0.000557 | valid loss: 0.002191\n","Epoch:  1277 | train loss: 0.000926 | valid loss: 0.002207\n","Epoch:  1278 | train loss: 0.000527 | valid loss: 0.002190\n","Epoch:  1279 | train loss: 0.000545 | valid loss: 0.002158\n","Epoch:  1280 | train loss: 0.000829 | valid loss: 0.002286\n","Epoch:  1281 | train loss: 0.000634 | valid loss: 0.002288\n","Epoch:  1282 | train loss: 0.000747 | valid loss: 0.002388\n","Epoch:  1283 | train loss: 0.000659 | valid loss: 0.002333\n","Epoch:  1284 | train loss: 0.000720 | valid loss: 0.002291\n","Epoch:  1285 | train loss: 0.000838 | valid loss: 0.002137\n","Epoch:  1286 | train loss: 0.000546 | valid loss: 0.002292\n","Epoch:  1287 | train loss: 0.000730 | valid loss: 0.002212\n","Epoch:  1288 | train loss: 0.000788 | valid loss: 0.002188\n","Epoch:  1289 | train loss: 0.000651 | valid loss: 0.002200\n","Epoch:  1290 | train loss: 0.000566 | valid loss: 0.002216\n","Epoch:  1291 | train loss: 0.000495 | valid loss: 0.002222\n","Epoch:  1292 | train loss: 0.000447 | valid loss: 0.002175\n","Epoch:  1293 | train loss: 0.000881 | valid loss: 0.002333\n","Epoch:  1294 | train loss: 0.000627 | valid loss: 0.002249\n","Epoch:  1295 | train loss: 0.000712 | valid loss: 0.002248\n","Epoch:  1296 | train loss: 0.000651 | valid loss: 0.002268\n","Epoch:  1297 | train loss: 0.000638 | valid loss: 0.002116\n","Epoch:  1298 | train loss: 0.000608 | valid loss: 0.002183\n","Epoch:  1299 | train loss: 0.000603 | valid loss: 0.002194\n","Epoch:  1300 | train loss: 0.000709 | valid loss: 0.002233\n","Epoch:  1301 | train loss: 0.000857 | valid loss: 0.002258\n","Epoch:  1302 | train loss: 0.000648 | valid loss: 0.002219\n","Epoch:  1303 | train loss: 0.000843 | valid loss: 0.002212\n","Epoch:  1304 | train loss: 0.000603 | valid loss: 0.002148\n","Epoch:  1305 | train loss: 0.000636 | valid loss: 0.002271\n","Epoch:  1306 | train loss: 0.000440 | valid loss: 0.002193\n","Epoch:  1307 | train loss: 0.000668 | valid loss: 0.002304\n","Epoch:  1308 | train loss: 0.000467 | valid loss: 0.002195\n","Epoch:  1309 | train loss: 0.000802 | valid loss: 0.002356\n","Epoch:  1310 | train loss: 0.000502 | valid loss: 0.002100\n","Epoch:  1311 | train loss: 0.000670 | valid loss: 0.002227\n","Epoch:  1312 | train loss: 0.000812 | valid loss: 0.002147\n","Epoch:  1313 | train loss: 0.000558 | valid loss: 0.002241\n","Epoch:  1314 | train loss: 0.000731 | valid loss: 0.002241\n","Epoch:  1315 | train loss: 0.001023 | valid loss: 0.002166\n","Epoch:  1316 | train loss: 0.000571 | valid loss: 0.002212\n","Epoch:  1317 | train loss: 0.000563 | valid loss: 0.002331\n","Epoch:  1318 | train loss: 0.000585 | valid loss: 0.002154\n","Epoch:  1319 | train loss: 0.000523 | valid loss: 0.002222\n","Epoch:  1320 | train loss: 0.000542 | valid loss: 0.002251\n","Epoch:  1321 | train loss: 0.000757 | valid loss: 0.002224\n","Epoch:  1322 | train loss: 0.000657 | valid loss: 0.002303\n","Epoch:  1323 | train loss: 0.000835 | valid loss: 0.002175\n","Epoch:  1324 | train loss: 0.000551 | valid loss: 0.002332\n","Epoch:  1325 | train loss: 0.000478 | valid loss: 0.002241\n","Epoch:  1326 | train loss: 0.000852 | valid loss: 0.002181\n","Epoch:  1327 | train loss: 0.000640 | valid loss: 0.002219\n","Epoch:  1328 | train loss: 0.000470 | valid loss: 0.002197\n","Epoch:  1329 | train loss: 0.000570 | valid loss: 0.002253\n","Epoch:  1330 | train loss: 0.000561 | valid loss: 0.002316\n","Epoch:  1331 | train loss: 0.000500 | valid loss: 0.002251\n","Epoch:  1332 | train loss: 0.000542 | valid loss: 0.002156\n","Epoch:  1333 | train loss: 0.000681 | valid loss: 0.002322\n","Epoch:  1334 | train loss: 0.000807 | valid loss: 0.002237\n","Epoch:  1335 | train loss: 0.000937 | valid loss: 0.002460\n","Epoch:  1336 | train loss: 0.000655 | valid loss: 0.002243\n","Epoch:  1337 | train loss: 0.000659 | valid loss: 0.002219\n","Epoch:  1338 | train loss: 0.000533 | valid loss: 0.002156\n","Epoch:  1339 | train loss: 0.000626 | valid loss: 0.002244\n","Epoch:  1340 | train loss: 0.000983 | valid loss: 0.002292\n","Epoch:  1341 | train loss: 0.000493 | valid loss: 0.002368\n","Epoch:  1342 | train loss: 0.000482 | valid loss: 0.002297\n","Epoch:  1343 | train loss: 0.000681 | valid loss: 0.002227\n","Epoch:  1344 | train loss: 0.000890 | valid loss: 0.002295\n","Epoch:  1345 | train loss: 0.000698 | valid loss: 0.002330\n","Epoch:  1346 | train loss: 0.000849 | valid loss: 0.002155\n","Epoch:  1347 | train loss: 0.000594 | valid loss: 0.002205\n","Epoch:  1348 | train loss: 0.000703 | valid loss: 0.002229\n","Epoch:  1349 | train loss: 0.000591 | valid loss: 0.002335\n","Epoch:  1350 | train loss: 0.000557 | valid loss: 0.002182\n","Epoch:  1351 | train loss: 0.000550 | valid loss: 0.002265\n","Epoch:  1352 | train loss: 0.000609 | valid loss: 0.002220\n","Epoch:  1353 | train loss: 0.000857 | valid loss: 0.002340\n","Epoch:  1354 | train loss: 0.000642 | valid loss: 0.002235\n","Epoch:  1355 | train loss: 0.000976 | valid loss: 0.002297\n","Epoch:  1356 | train loss: 0.000502 | valid loss: 0.002226\n","Epoch:  1357 | train loss: 0.000751 | valid loss: 0.002340\n","Epoch:  1358 | train loss: 0.000907 | valid loss: 0.002333\n","Epoch:  1359 | train loss: 0.001061 | valid loss: 0.002460\n","Epoch:  1360 | train loss: 0.000641 | valid loss: 0.002170\n","Epoch:  1361 | train loss: 0.000727 | valid loss: 0.002464\n","Epoch:  1362 | train loss: 0.000622 | valid loss: 0.002231\n","Epoch:  1363 | train loss: 0.001034 | valid loss: 0.002186\n","Epoch:  1364 | train loss: 0.000713 | valid loss: 0.002258\n","Epoch:  1365 | train loss: 0.000995 | valid loss: 0.002227\n","Epoch:  1366 | train loss: 0.000709 | valid loss: 0.002191\n","Epoch:  1367 | train loss: 0.000548 | valid loss: 0.002302\n","Epoch:  1368 | train loss: 0.000525 | valid loss: 0.002224\n","Epoch:  1369 | train loss: 0.000471 | valid loss: 0.002184\n","Epoch:  1370 | train loss: 0.000692 | valid loss: 0.002173\n","Epoch:  1371 | train loss: 0.000570 | valid loss: 0.002276\n","Epoch:  1372 | train loss: 0.000835 | valid loss: 0.002216\n","Epoch:  1373 | train loss: 0.000455 | valid loss: 0.002172\n","Epoch:  1374 | train loss: 0.000846 | valid loss: 0.002250\n","Epoch:  1375 | train loss: 0.001085 | valid loss: 0.002306\n","Epoch:  1376 | train loss: 0.000771 | valid loss: 0.002338\n","Epoch:  1377 | train loss: 0.000626 | valid loss: 0.002301\n","Epoch:  1378 | train loss: 0.000476 | valid loss: 0.002215\n","Epoch:  1379 | train loss: 0.000570 | valid loss: 0.002304\n","Epoch:  1380 | train loss: 0.000507 | valid loss: 0.002299\n","Epoch:  1381 | train loss: 0.000477 | valid loss: 0.002196\n","Epoch:  1382 | train loss: 0.000505 | valid loss: 0.002312\n","Epoch:  1383 | train loss: 0.000675 | valid loss: 0.002226\n","Epoch:  1384 | train loss: 0.000666 | valid loss: 0.002309\n","Epoch:  1385 | train loss: 0.000736 | valid loss: 0.002298\n","Epoch:  1386 | train loss: 0.000772 | valid loss: 0.002262\n","Epoch:  1387 | train loss: 0.000621 | valid loss: 0.002157\n","Epoch:  1388 | train loss: 0.000410 | valid loss: 0.002192\n","Epoch:  1389 | train loss: 0.000498 | valid loss: 0.002259\n","Epoch:  1390 | train loss: 0.000642 | valid loss: 0.002238\n","Epoch:  1391 | train loss: 0.000554 | valid loss: 0.002243\n","Epoch:  1392 | train loss: 0.000887 | valid loss: 0.002334\n","Epoch:  1393 | train loss: 0.000793 | valid loss: 0.002391\n","Epoch:  1394 | train loss: 0.001777 | valid loss: 0.002232\n","Epoch:  1395 | train loss: 0.001136 | valid loss: 0.002254\n","Epoch:  1396 | train loss: 0.000754 | valid loss: 0.002240\n","Epoch:  1397 | train loss: 0.000490 | valid loss: 0.002247\n","Epoch:  1398 | train loss: 0.000479 | valid loss: 0.002257\n","Epoch:  1399 | train loss: 0.000486 | valid loss: 0.002133\n","Epoch:  1400 | train loss: 0.000435 | valid loss: 0.002181\n","Epoch:  1401 | train loss: 0.000639 | valid loss: 0.002248\n","Epoch:  1402 | train loss: 0.000425 | valid loss: 0.002155\n","Epoch:  1403 | train loss: 0.000712 | valid loss: 0.002205\n","Epoch:  1404 | train loss: 0.000997 | valid loss: 0.002348\n","Epoch:  1405 | train loss: 0.000813 | valid loss: 0.002248\n","Epoch:  1406 | train loss: 0.000756 | valid loss: 0.002298\n","Epoch:  1407 | train loss: 0.000574 | valid loss: 0.002279\n","Epoch:  1408 | train loss: 0.000793 | valid loss: 0.002397\n","Epoch:  1409 | train loss: 0.000565 | valid loss: 0.002380\n","Epoch:  1410 | train loss: 0.000584 | valid loss: 0.002269\n","Epoch:  1411 | train loss: 0.000555 | valid loss: 0.002143\n","Epoch:  1412 | train loss: 0.000627 | valid loss: 0.002218\n","Epoch:  1413 | train loss: 0.000584 | valid loss: 0.002149\n","Epoch:  1414 | train loss: 0.000516 | valid loss: 0.002153\n","Epoch:  1415 | train loss: 0.000447 | valid loss: 0.002150\n","Epoch:  1416 | train loss: 0.000516 | valid loss: 0.002197\n","Epoch:  1417 | train loss: 0.000704 | valid loss: 0.002122\n","Epoch:  1418 | train loss: 0.000606 | valid loss: 0.002329\n","Epoch:  1419 | train loss: 0.000860 | valid loss: 0.002222\n","Epoch:  1420 | train loss: 0.000837 | valid loss: 0.002319\n","Epoch:  1421 | train loss: 0.000900 | valid loss: 0.002406\n","Epoch:  1422 | train loss: 0.000619 | valid loss: 0.002188\n","Epoch:  1423 | train loss: 0.000660 | valid loss: 0.002298\n","Epoch:  1424 | train loss: 0.001113 | valid loss: 0.002250\n","Epoch:  1425 | train loss: 0.000507 | valid loss: 0.002231\n","Epoch:  1426 | train loss: 0.000639 | valid loss: 0.002234\n","Epoch:  1427 | train loss: 0.000658 | valid loss: 0.002424\n","Epoch:  1428 | train loss: 0.000848 | valid loss: 0.002442\n","Epoch:  1429 | train loss: 0.000566 | valid loss: 0.002357\n","Epoch:  1430 | train loss: 0.000803 | valid loss: 0.002369\n","Epoch:  1431 | train loss: 0.000588 | valid loss: 0.002276\n","Epoch:  1432 | train loss: 0.000606 | valid loss: 0.002205\n","Epoch:  1433 | train loss: 0.000481 | valid loss: 0.002138\n","Epoch:  1434 | train loss: 0.000916 | valid loss: 0.002213\n","Epoch:  1435 | train loss: 0.000630 | valid loss: 0.002257\n","Epoch:  1436 | train loss: 0.000828 | valid loss: 0.002222\n","Epoch:  1437 | train loss: 0.000388 | valid loss: 0.002146\n","Epoch:  1438 | train loss: 0.000606 | valid loss: 0.002305\n","Epoch:  1439 | train loss: 0.000598 | valid loss: 0.002166\n","Epoch:  1440 | train loss: 0.000977 | valid loss: 0.002333\n","Epoch:  1441 | train loss: 0.000936 | valid loss: 0.002265\n","Epoch:  1442 | train loss: 0.000618 | valid loss: 0.002219\n","Epoch:  1443 | train loss: 0.000452 | valid loss: 0.002311\n","Epoch:  1444 | train loss: 0.000380 | valid loss: 0.002278\n","Epoch:  1445 | train loss: 0.000665 | valid loss: 0.002197\n","Epoch:  1446 | train loss: 0.000483 | valid loss: 0.002263\n","Epoch:  1447 | train loss: 0.000421 | valid loss: 0.002346\n","Epoch:  1448 | train loss: 0.000501 | valid loss: 0.002284\n","Epoch:  1449 | train loss: 0.000745 | valid loss: 0.002351\n","Epoch:  1450 | train loss: 0.001158 | valid loss: 0.002361\n","Epoch:  1451 | train loss: 0.000579 | valid loss: 0.002302\n","Epoch:  1452 | train loss: 0.000811 | valid loss: 0.002276\n","Epoch:  1453 | train loss: 0.000744 | valid loss: 0.002154\n","Epoch:  1454 | train loss: 0.000518 | valid loss: 0.002194\n","Epoch:  1455 | train loss: 0.000409 | valid loss: 0.002204\n","Epoch:  1456 | train loss: 0.000718 | valid loss: 0.002245\n","Epoch:  1457 | train loss: 0.000794 | valid loss: 0.002203\n","Epoch:  1458 | train loss: 0.000601 | valid loss: 0.002186\n","Epoch:  1459 | train loss: 0.000739 | valid loss: 0.002237\n","Epoch:  1460 | train loss: 0.000653 | valid loss: 0.002144\n","Epoch:  1461 | train loss: 0.000474 | valid loss: 0.002285\n","Epoch:  1462 | train loss: 0.000448 | valid loss: 0.002133\n","Epoch:  1463 | train loss: 0.000954 | valid loss: 0.002251\n","Epoch:  1464 | train loss: 0.000710 | valid loss: 0.002366\n","Epoch:  1465 | train loss: 0.000603 | valid loss: 0.002306\n","Epoch:  1466 | train loss: 0.000576 | valid loss: 0.002327\n","Epoch:  1467 | train loss: 0.000746 | valid loss: 0.002217\n","Epoch:  1468 | train loss: 0.000442 | valid loss: 0.002357\n","Epoch:  1469 | train loss: 0.000820 | valid loss: 0.002268\n","Epoch:  1470 | train loss: 0.000438 | valid loss: 0.002278\n","Epoch:  1471 | train loss: 0.000469 | valid loss: 0.002239\n","Epoch:  1472 | train loss: 0.000609 | valid loss: 0.002281\n","Epoch:  1473 | train loss: 0.000541 | valid loss: 0.002150\n","Epoch:  1474 | train loss: 0.000651 | valid loss: 0.002255\n","Epoch:  1475 | train loss: 0.000846 | valid loss: 0.002148\n","Epoch:  1476 | train loss: 0.000617 | valid loss: 0.002235\n","Epoch:  1477 | train loss: 0.000679 | valid loss: 0.002154\n","Epoch:  1478 | train loss: 0.000560 | valid loss: 0.002268\n","Epoch:  1479 | train loss: 0.000801 | valid loss: 0.002306\n","Epoch:  1480 | train loss: 0.000649 | valid loss: 0.002202\n","Epoch:  1481 | train loss: 0.000367 | valid loss: 0.002271\n","Epoch:  1482 | train loss: 0.000617 | valid loss: 0.002322\n","Epoch:  1483 | train loss: 0.000720 | valid loss: 0.002184\n","Epoch:  1484 | train loss: 0.000922 | valid loss: 0.002316\n","Epoch:  1485 | train loss: 0.000522 | valid loss: 0.002257\n","Epoch:  1486 | train loss: 0.000596 | valid loss: 0.002276\n","Epoch:  1487 | train loss: 0.000582 | valid loss: 0.002489\n","Epoch:  1488 | train loss: 0.000686 | valid loss: 0.002343\n","Epoch:  1489 | train loss: 0.000813 | valid loss: 0.002284\n","Epoch:  1490 | train loss: 0.000698 | valid loss: 0.002244\n","Epoch:  1491 | train loss: 0.000461 | valid loss: 0.002250\n","Epoch:  1492 | train loss: 0.000555 | valid loss: 0.002174\n","Epoch:  1493 | train loss: 0.000435 | valid loss: 0.002226\n","Epoch:  1494 | train loss: 0.000849 | valid loss: 0.002211\n","Epoch:  1495 | train loss: 0.001397 | valid loss: 0.002429\n","Epoch:  1496 | train loss: 0.001011 | valid loss: 0.002322\n","Epoch:  1497 | train loss: 0.001021 | valid loss: 0.002350\n","Epoch:  1498 | train loss: 0.000883 | valid loss: 0.002360\n","Epoch:  1499 | train loss: 0.000544 | valid loss: 0.002325\n","Epoch:  1500 | train loss: 0.000518 | valid loss: 0.002275\n","Epoch:  1501 | train loss: 0.000552 | valid loss: 0.002311\n","Epoch:  1502 | train loss: 0.000376 | valid loss: 0.002244\n","Epoch:  1503 | train loss: 0.000525 | valid loss: 0.002183\n","Epoch:  1504 | train loss: 0.000595 | valid loss: 0.002284\n","Epoch:  1505 | train loss: 0.000442 | valid loss: 0.002188\n","Epoch:  1506 | train loss: 0.000774 | valid loss: 0.002245\n","Epoch:  1507 | train loss: 0.000541 | valid loss: 0.002269\n","Epoch:  1508 | train loss: 0.000650 | valid loss: 0.002444\n","Epoch:  1509 | train loss: 0.000863 | valid loss: 0.002320\n","Epoch:  1510 | train loss: 0.000911 | valid loss: 0.002322\n","Epoch:  1511 | train loss: 0.001941 | valid loss: 0.002350\n","Epoch:  1512 | train loss: 0.000689 | valid loss: 0.002274\n","Epoch:  1513 | train loss: 0.000704 | valid loss: 0.002317\n","Epoch:  1514 | train loss: 0.000685 | valid loss: 0.002302\n","Epoch:  1515 | train loss: 0.000588 | valid loss: 0.002273\n","Epoch:  1516 | train loss: 0.000594 | valid loss: 0.002335\n","Epoch:  1517 | train loss: 0.000560 | valid loss: 0.002317\n","Epoch:  1518 | train loss: 0.000649 | valid loss: 0.002310\n","Epoch:  1519 | train loss: 0.000610 | valid loss: 0.002314\n","Epoch:  1520 | train loss: 0.000512 | valid loss: 0.002362\n","Epoch:  1521 | train loss: 0.000446 | valid loss: 0.002276\n","Epoch:  1522 | train loss: 0.000460 | valid loss: 0.002380\n","Epoch:  1523 | train loss: 0.000634 | valid loss: 0.002292\n","Epoch:  1524 | train loss: 0.000635 | valid loss: 0.002248\n","Epoch:  1525 | train loss: 0.000569 | valid loss: 0.002315\n","Epoch:  1526 | train loss: 0.000579 | valid loss: 0.002292\n","Epoch:  1527 | train loss: 0.000720 | valid loss: 0.002350\n","Epoch:  1528 | train loss: 0.000536 | valid loss: 0.002345\n","Epoch:  1529 | train loss: 0.000530 | valid loss: 0.002307\n","Epoch:  1530 | train loss: 0.000649 | valid loss: 0.002295\n","Epoch:  1531 | train loss: 0.001525 | valid loss: 0.002361\n","Epoch:  1532 | train loss: 0.000687 | valid loss: 0.002219\n","Epoch:  1533 | train loss: 0.000360 | valid loss: 0.002365\n","Epoch:  1534 | train loss: 0.000908 | valid loss: 0.002298\n","Epoch:  1535 | train loss: 0.000556 | valid loss: 0.002202\n","Epoch:  1536 | train loss: 0.000866 | valid loss: 0.002209\n","Epoch:  1537 | train loss: 0.000842 | valid loss: 0.002210\n","Epoch:  1538 | train loss: 0.000704 | valid loss: 0.002374\n","Epoch:  1539 | train loss: 0.000815 | valid loss: 0.002211\n","Epoch:  1540 | train loss: 0.000451 | valid loss: 0.002257\n","Epoch:  1541 | train loss: 0.000444 | valid loss: 0.002155\n","Epoch:  1542 | train loss: 0.000796 | valid loss: 0.002328\n","Epoch:  1543 | train loss: 0.000753 | valid loss: 0.002403\n","Epoch:  1544 | train loss: 0.000736 | valid loss: 0.002411\n","Epoch:  1545 | train loss: 0.000870 | valid loss: 0.002516\n","Epoch:  1546 | train loss: 0.000566 | valid loss: 0.002264\n","Epoch:  1547 | train loss: 0.000555 | valid loss: 0.002233\n","Epoch:  1548 | train loss: 0.000997 | valid loss: 0.002276\n","Epoch:  1549 | train loss: 0.000467 | valid loss: 0.002254\n","Epoch:  1550 | train loss: 0.000744 | valid loss: 0.002311\n","Epoch:  1551 | train loss: 0.000591 | valid loss: 0.002217\n","Epoch:  1552 | train loss: 0.000620 | valid loss: 0.002304\n","Epoch:  1553 | train loss: 0.000759 | valid loss: 0.002256\n","Epoch:  1554 | train loss: 0.000530 | valid loss: 0.002214\n","Epoch:  1555 | train loss: 0.000539 | valid loss: 0.002356\n","Epoch:  1556 | train loss: 0.000782 | valid loss: 0.002411\n","Epoch:  1557 | train loss: 0.000547 | valid loss: 0.002273\n","Epoch:  1558 | train loss: 0.000810 | valid loss: 0.002216\n","Epoch:  1559 | train loss: 0.000835 | valid loss: 0.002340\n","Epoch:  1560 | train loss: 0.000544 | valid loss: 0.002256\n","Epoch:  1561 | train loss: 0.000465 | valid loss: 0.002345\n","Epoch:  1562 | train loss: 0.000941 | valid loss: 0.002225\n","Epoch:  1563 | train loss: 0.000560 | valid loss: 0.002369\n","Epoch:  1564 | train loss: 0.000508 | valid loss: 0.002307\n","Epoch:  1565 | train loss: 0.000633 | valid loss: 0.002386\n","Epoch:  1566 | train loss: 0.000706 | valid loss: 0.002224\n","Epoch:  1567 | train loss: 0.000573 | valid loss: 0.002300\n","Epoch:  1568 | train loss: 0.000753 | valid loss: 0.002263\n","Epoch:  1569 | train loss: 0.000928 | valid loss: 0.002300\n","Epoch:  1570 | train loss: 0.000918 | valid loss: 0.002221\n","Epoch:  1571 | train loss: 0.000517 | valid loss: 0.002319\n","Epoch:  1572 | train loss: 0.000504 | valid loss: 0.002280\n","Epoch:  1573 | train loss: 0.000688 | valid loss: 0.002371\n","Epoch:  1574 | train loss: 0.000479 | valid loss: 0.002292\n","Epoch:  1575 | train loss: 0.000572 | valid loss: 0.002395\n","Epoch:  1576 | train loss: 0.000678 | valid loss: 0.002299\n","Epoch:  1577 | train loss: 0.000547 | valid loss: 0.002281\n","Epoch:  1578 | train loss: 0.000608 | valid loss: 0.002266\n","Epoch:  1579 | train loss: 0.000861 | valid loss: 0.002259\n","Epoch:  1580 | train loss: 0.000465 | valid loss: 0.002323\n","Epoch:  1581 | train loss: 0.000640 | valid loss: 0.002423\n","Epoch:  1582 | train loss: 0.000590 | valid loss: 0.002362\n","Epoch:  1583 | train loss: 0.000582 | valid loss: 0.002281\n","Epoch:  1584 | train loss: 0.000787 | valid loss: 0.002364\n","Epoch:  1585 | train loss: 0.000476 | valid loss: 0.002346\n","Epoch:  1586 | train loss: 0.000787 | valid loss: 0.002257\n","Epoch:  1587 | train loss: 0.000532 | valid loss: 0.002373\n","Epoch:  1588 | train loss: 0.000575 | valid loss: 0.002336\n","Epoch:  1589 | train loss: 0.000452 | valid loss: 0.002294\n","Epoch:  1590 | train loss: 0.000484 | valid loss: 0.002294\n","Epoch:  1591 | train loss: 0.000368 | valid loss: 0.002305\n","Epoch:  1592 | train loss: 0.000562 | valid loss: 0.002369\n","Epoch:  1593 | train loss: 0.000859 | valid loss: 0.002340\n","Epoch:  1594 | train loss: 0.000535 | valid loss: 0.002324\n","Epoch:  1595 | train loss: 0.000595 | valid loss: 0.002420\n","Epoch:  1596 | train loss: 0.000554 | valid loss: 0.002446\n","Epoch:  1597 | train loss: 0.000758 | valid loss: 0.002372\n","Epoch:  1598 | train loss: 0.000694 | valid loss: 0.002323\n","Epoch:  1599 | train loss: 0.000749 | valid loss: 0.002341\n","Epoch:  1600 | train loss: 0.000636 | valid loss: 0.002335\n","Epoch:  1601 | train loss: 0.000757 | valid loss: 0.002393\n","Epoch:  1602 | train loss: 0.000710 | valid loss: 0.002344\n","Epoch:  1603 | train loss: 0.000667 | valid loss: 0.002274\n","Epoch:  1604 | train loss: 0.000735 | valid loss: 0.002344\n","Epoch:  1605 | train loss: 0.000445 | valid loss: 0.002401\n","Epoch:  1606 | train loss: 0.000532 | valid loss: 0.002203\n","Epoch:  1607 | train loss: 0.000633 | valid loss: 0.002372\n","Epoch:  1608 | train loss: 0.001058 | valid loss: 0.002400\n","Epoch:  1609 | train loss: 0.000780 | valid loss: 0.002409\n","Epoch:  1610 | train loss: 0.000696 | valid loss: 0.002277\n","Epoch:  1611 | train loss: 0.000452 | valid loss: 0.002369\n","Epoch:  1612 | train loss: 0.000582 | valid loss: 0.002299\n","Epoch:  1613 | train loss: 0.000548 | valid loss: 0.002280\n","Epoch:  1614 | train loss: 0.000747 | valid loss: 0.002340\n","Epoch:  1615 | train loss: 0.000631 | valid loss: 0.002310\n","Epoch:  1616 | train loss: 0.000567 | valid loss: 0.002310\n","Epoch:  1617 | train loss: 0.000362 | valid loss: 0.002283\n","Epoch:  1618 | train loss: 0.001125 | valid loss: 0.002251\n","Epoch:  1619 | train loss: 0.000425 | valid loss: 0.002360\n","Epoch:  1620 | train loss: 0.000439 | valid loss: 0.002330\n","Epoch:  1621 | train loss: 0.000903 | valid loss: 0.002378\n","Epoch:  1622 | train loss: 0.000529 | valid loss: 0.002446\n","Epoch:  1623 | train loss: 0.000589 | valid loss: 0.002409\n","Epoch:  1624 | train loss: 0.000653 | valid loss: 0.002365\n","Epoch:  1625 | train loss: 0.000518 | valid loss: 0.002352\n","Epoch:  1626 | train loss: 0.000780 | valid loss: 0.002365\n","Epoch:  1627 | train loss: 0.000788 | valid loss: 0.002464\n","Epoch:  1628 | train loss: 0.000525 | valid loss: 0.002440\n","Epoch:  1629 | train loss: 0.000562 | valid loss: 0.002362\n","Epoch:  1630 | train loss: 0.000787 | valid loss: 0.002254\n","Epoch:  1631 | train loss: 0.000568 | valid loss: 0.002296\n","Epoch:  1632 | train loss: 0.000527 | valid loss: 0.002183\n","Epoch:  1633 | train loss: 0.000462 | valid loss: 0.002276\n","Epoch:  1634 | train loss: 0.000591 | valid loss: 0.002294\n","Epoch:  1635 | train loss: 0.000464 | valid loss: 0.002372\n","Epoch:  1636 | train loss: 0.000847 | valid loss: 0.002324\n","Epoch:  1637 | train loss: 0.000456 | valid loss: 0.002298\n","Epoch:  1638 | train loss: 0.000529 | valid loss: 0.002345\n","Epoch:  1639 | train loss: 0.000568 | valid loss: 0.002354\n","Epoch:  1640 | train loss: 0.000655 | valid loss: 0.002319\n","Epoch:  1641 | train loss: 0.000562 | valid loss: 0.002257\n","Epoch:  1642 | train loss: 0.000566 | valid loss: 0.002298\n","Epoch:  1643 | train loss: 0.000573 | valid loss: 0.002423\n","Epoch:  1644 | train loss: 0.000616 | valid loss: 0.002401\n","Epoch:  1645 | train loss: 0.000557 | valid loss: 0.002374\n","Epoch:  1646 | train loss: 0.000364 | valid loss: 0.002247\n","Epoch:  1647 | train loss: 0.000438 | valid loss: 0.002363\n","Epoch:  1648 | train loss: 0.000569 | valid loss: 0.002282\n","Epoch:  1649 | train loss: 0.000783 | valid loss: 0.002348\n","Epoch:  1650 | train loss: 0.000632 | valid loss: 0.002366\n","Epoch:  1651 | train loss: 0.000450 | valid loss: 0.002281\n","Epoch:  1652 | train loss: 0.000491 | valid loss: 0.002294\n","Epoch:  1653 | train loss: 0.000600 | valid loss: 0.002366\n","Epoch:  1654 | train loss: 0.000367 | valid loss: 0.002363\n","Epoch:  1655 | train loss: 0.000455 | valid loss: 0.002306\n","Epoch:  1656 | train loss: 0.000903 | valid loss: 0.002377\n","Epoch:  1657 | train loss: 0.000616 | valid loss: 0.002414\n","Epoch:  1658 | train loss: 0.000723 | valid loss: 0.002419\n","Epoch:  1659 | train loss: 0.000669 | valid loss: 0.002379\n","Epoch:  1660 | train loss: 0.000385 | valid loss: 0.002303\n","Epoch:  1661 | train loss: 0.000566 | valid loss: 0.002368\n","Epoch:  1662 | train loss: 0.000616 | valid loss: 0.002405\n","Epoch:  1663 | train loss: 0.000498 | valid loss: 0.002346\n","Epoch:  1664 | train loss: 0.000650 | valid loss: 0.002456\n","Epoch:  1665 | train loss: 0.000580 | valid loss: 0.002436\n","Epoch:  1666 | train loss: 0.000464 | valid loss: 0.002403\n","Epoch:  1667 | train loss: 0.000765 | valid loss: 0.002270\n","Epoch:  1668 | train loss: 0.000486 | valid loss: 0.002290\n","Epoch:  1669 | train loss: 0.000413 | valid loss: 0.002245\n","Epoch:  1670 | train loss: 0.000574 | valid loss: 0.002245\n","Epoch:  1671 | train loss: 0.000629 | valid loss: 0.002233\n","Epoch:  1672 | train loss: 0.001026 | valid loss: 0.002292\n","Epoch:  1673 | train loss: 0.000626 | valid loss: 0.002307\n","Epoch:  1674 | train loss: 0.000727 | valid loss: 0.002304\n","Epoch:  1675 | train loss: 0.000639 | valid loss: 0.002346\n","Epoch:  1676 | train loss: 0.000574 | valid loss: 0.002307\n","Epoch:  1677 | train loss: 0.001154 | valid loss: 0.002493\n","Epoch:  1678 | train loss: 0.000769 | valid loss: 0.002400\n","Epoch:  1679 | train loss: 0.000725 | valid loss: 0.002369\n","Epoch:  1680 | train loss: 0.000506 | valid loss: 0.002313\n","Epoch:  1681 | train loss: 0.000522 | valid loss: 0.002295\n","Epoch:  1682 | train loss: 0.000536 | valid loss: 0.002319\n","Epoch:  1683 | train loss: 0.000772 | valid loss: 0.002304\n","Epoch:  1684 | train loss: 0.000490 | valid loss: 0.002415\n","Epoch:  1685 | train loss: 0.000539 | valid loss: 0.002311\n","Epoch:  1686 | train loss: 0.000599 | valid loss: 0.002284\n","Epoch:  1687 | train loss: 0.000686 | valid loss: 0.002363\n","Epoch:  1688 | train loss: 0.000425 | valid loss: 0.002300\n","Epoch:  1689 | train loss: 0.000740 | valid loss: 0.002387\n","Epoch:  1690 | train loss: 0.000618 | valid loss: 0.002368\n","Epoch:  1691 | train loss: 0.001089 | valid loss: 0.002389\n","Epoch:  1692 | train loss: 0.000599 | valid loss: 0.002289\n","Epoch:  1693 | train loss: 0.000480 | valid loss: 0.002411\n","Epoch:  1694 | train loss: 0.000487 | valid loss: 0.002417\n","Epoch:  1695 | train loss: 0.000471 | valid loss: 0.002407\n","Epoch:  1696 | train loss: 0.000470 | valid loss: 0.002335\n","Epoch:  1697 | train loss: 0.000470 | valid loss: 0.002448\n","Epoch:  1698 | train loss: 0.000859 | valid loss: 0.002409\n","Epoch:  1699 | train loss: 0.000812 | valid loss: 0.002413\n","Epoch:  1700 | train loss: 0.000659 | valid loss: 0.002178\n","Epoch:  1701 | train loss: 0.000381 | valid loss: 0.002246\n","Epoch:  1702 | train loss: 0.000435 | valid loss: 0.002318\n","Epoch:  1703 | train loss: 0.000587 | valid loss: 0.002383\n","Epoch:  1704 | train loss: 0.000608 | valid loss: 0.002279\n","Epoch:  1705 | train loss: 0.000535 | valid loss: 0.002348\n","Epoch:  1706 | train loss: 0.000366 | valid loss: 0.002235\n","Epoch:  1707 | train loss: 0.000726 | valid loss: 0.002372\n","Epoch:  1708 | train loss: 0.001064 | valid loss: 0.002364\n","Epoch:  1709 | train loss: 0.000793 | valid loss: 0.002358\n","Epoch:  1710 | train loss: 0.000763 | valid loss: 0.002271\n","Epoch:  1711 | train loss: 0.000544 | valid loss: 0.002446\n","Epoch:  1712 | train loss: 0.000622 | valid loss: 0.002324\n","Epoch:  1713 | train loss: 0.000735 | valid loss: 0.002319\n","Epoch:  1714 | train loss: 0.000588 | valid loss: 0.002382\n","Epoch:  1715 | train loss: 0.000528 | valid loss: 0.002344\n","Epoch:  1716 | train loss: 0.000480 | valid loss: 0.002249\n","Epoch:  1717 | train loss: 0.000715 | valid loss: 0.002358\n","Epoch:  1718 | train loss: 0.000465 | valid loss: 0.002410\n","Epoch:  1719 | train loss: 0.000627 | valid loss: 0.002351\n","Epoch:  1720 | train loss: 0.000604 | valid loss: 0.002374\n","Epoch:  1721 | train loss: 0.000512 | valid loss: 0.002323\n","Epoch:  1722 | train loss: 0.000565 | valid loss: 0.002382\n","Epoch:  1723 | train loss: 0.000663 | valid loss: 0.002293\n","Epoch:  1724 | train loss: 0.000572 | valid loss: 0.002323\n","Epoch:  1725 | train loss: 0.000466 | valid loss: 0.002320\n","Epoch:  1726 | train loss: 0.000489 | valid loss: 0.002388\n","Epoch:  1727 | train loss: 0.000479 | valid loss: 0.002336\n","Epoch:  1728 | train loss: 0.000548 | valid loss: 0.002477\n","Epoch:  1729 | train loss: 0.000772 | valid loss: 0.002390\n","Epoch:  1730 | train loss: 0.001052 | valid loss: 0.002449\n","Epoch:  1731 | train loss: 0.000790 | valid loss: 0.002439\n","Epoch:  1732 | train loss: 0.000482 | valid loss: 0.002352\n","Epoch:  1733 | train loss: 0.000669 | valid loss: 0.002420\n","Epoch:  1734 | train loss: 0.000601 | valid loss: 0.002304\n","Epoch:  1735 | train loss: 0.002209 | valid loss: 0.002400\n","Epoch:  1736 | train loss: 0.000800 | valid loss: 0.002344\n","Epoch:  1737 | train loss: 0.000571 | valid loss: 0.002316\n","Epoch:  1738 | train loss: 0.000466 | valid loss: 0.002366\n","Epoch:  1739 | train loss: 0.000535 | valid loss: 0.002385\n","Epoch:  1740 | train loss: 0.000695 | valid loss: 0.002315\n","Epoch:  1741 | train loss: 0.000820 | valid loss: 0.002381\n","Epoch:  1742 | train loss: 0.001278 | valid loss: 0.002510\n","Epoch:  1743 | train loss: 0.000755 | valid loss: 0.002512\n","Epoch:  1744 | train loss: 0.000670 | valid loss: 0.002400\n","Epoch:  1745 | train loss: 0.000475 | valid loss: 0.002349\n","Epoch:  1746 | train loss: 0.000383 | valid loss: 0.002306\n","Epoch:  1747 | train loss: 0.000499 | valid loss: 0.002361\n","Epoch:  1748 | train loss: 0.000771 | valid loss: 0.002295\n","Epoch:  1749 | train loss: 0.000542 | valid loss: 0.002310\n","Epoch:  1750 | train loss: 0.000502 | valid loss: 0.002428\n","Epoch:  1751 | train loss: 0.000616 | valid loss: 0.002398\n","Epoch:  1752 | train loss: 0.000472 | valid loss: 0.002344\n","Epoch:  1753 | train loss: 0.000731 | valid loss: 0.002342\n","Epoch:  1754 | train loss: 0.000439 | valid loss: 0.002388\n","Epoch:  1755 | train loss: 0.000728 | valid loss: 0.002396\n","Epoch:  1756 | train loss: 0.000516 | valid loss: 0.002326\n","Epoch:  1757 | train loss: 0.000720 | valid loss: 0.002468\n","Epoch:  1758 | train loss: 0.000405 | valid loss: 0.002329\n","Epoch:  1759 | train loss: 0.000432 | valid loss: 0.002378\n","Epoch:  1760 | train loss: 0.000539 | valid loss: 0.002314\n","Epoch:  1761 | train loss: 0.000462 | valid loss: 0.002466\n","Epoch:  1762 | train loss: 0.000791 | valid loss: 0.002272\n","Epoch:  1763 | train loss: 0.000506 | valid loss: 0.002405\n","Epoch:  1764 | train loss: 0.000454 | valid loss: 0.002267\n","Epoch:  1765 | train loss: 0.000568 | valid loss: 0.002361\n","Epoch:  1766 | train loss: 0.000536 | valid loss: 0.002339\n","Epoch:  1767 | train loss: 0.000997 | valid loss: 0.002416\n","Epoch:  1768 | train loss: 0.000719 | valid loss: 0.002409\n","Epoch:  1769 | train loss: 0.000939 | valid loss: 0.002363\n","Epoch:  1770 | train loss: 0.002841 | valid loss: 0.002426\n","Epoch:  1771 | train loss: 0.000453 | valid loss: 0.002387\n","Epoch:  1772 | train loss: 0.000429 | valid loss: 0.002421\n","Epoch:  1773 | train loss: 0.000496 | valid loss: 0.002302\n","Epoch:  1774 | train loss: 0.000901 | valid loss: 0.002269\n","Epoch:  1775 | train loss: 0.001128 | valid loss: 0.002331\n","Epoch:  1776 | train loss: 0.000425 | valid loss: 0.002362\n","Epoch:  1777 | train loss: 0.000444 | valid loss: 0.002408\n","Epoch:  1778 | train loss: 0.000598 | valid loss: 0.002419\n","Epoch:  1779 | train loss: 0.000419 | valid loss: 0.002345\n","Epoch:  1780 | train loss: 0.000424 | valid loss: 0.002450\n","Epoch:  1781 | train loss: 0.000627 | valid loss: 0.002331\n","Epoch:  1782 | train loss: 0.000822 | valid loss: 0.002344\n","Epoch:  1783 | train loss: 0.000482 | valid loss: 0.002325\n","Epoch:  1784 | train loss: 0.000688 | valid loss: 0.002451\n","Epoch:  1785 | train loss: 0.000557 | valid loss: 0.002400\n","Epoch:  1786 | train loss: 0.000647 | valid loss: 0.002375\n","Epoch:  1787 | train loss: 0.000512 | valid loss: 0.002386\n","Epoch:  1788 | train loss: 0.000614 | valid loss: 0.002375\n","Epoch:  1789 | train loss: 0.000589 | valid loss: 0.002497\n","Epoch:  1790 | train loss: 0.000592 | valid loss: 0.002294\n","Epoch:  1791 | train loss: 0.000654 | valid loss: 0.002338\n","Epoch:  1792 | train loss: 0.000412 | valid loss: 0.002359\n","Epoch:  1793 | train loss: 0.000477 | valid loss: 0.002336\n","Epoch:  1794 | train loss: 0.000452 | valid loss: 0.002376\n","Epoch:  1795 | train loss: 0.000581 | valid loss: 0.002317\n","Epoch:  1796 | train loss: 0.000679 | valid loss: 0.002338\n","Epoch:  1797 | train loss: 0.000475 | valid loss: 0.002399\n","Epoch:  1798 | train loss: 0.000627 | valid loss: 0.002319\n","Epoch:  1799 | train loss: 0.000799 | valid loss: 0.002426\n","Epoch:  1800 | train loss: 0.000648 | valid loss: 0.002473\n","Epoch:  1801 | train loss: 0.000729 | valid loss: 0.002369\n","Epoch:  1802 | train loss: 0.000635 | valid loss: 0.002508\n","Epoch:  1803 | train loss: 0.000477 | valid loss: 0.002451\n","Epoch:  1804 | train loss: 0.000834 | valid loss: 0.002401\n","Epoch:  1805 | train loss: 0.000690 | valid loss: 0.002369\n","Epoch:  1806 | train loss: 0.000433 | valid loss: 0.002354\n","Epoch:  1807 | train loss: 0.000486 | valid loss: 0.002343\n","Epoch:  1808 | train loss: 0.000557 | valid loss: 0.002376\n","Epoch:  1809 | train loss: 0.000827 | valid loss: 0.002414\n","Epoch:  1810 | train loss: 0.000449 | valid loss: 0.002352\n","Epoch:  1811 | train loss: 0.000711 | valid loss: 0.002380\n","Epoch:  1812 | train loss: 0.000558 | valid loss: 0.002337\n","Epoch:  1813 | train loss: 0.000637 | valid loss: 0.002299\n","Epoch:  1814 | train loss: 0.000506 | valid loss: 0.002411\n","Epoch:  1815 | train loss: 0.000414 | valid loss: 0.002324\n","Epoch:  1816 | train loss: 0.000869 | valid loss: 0.002446\n","Epoch:  1817 | train loss: 0.000529 | valid loss: 0.002436\n","Epoch:  1818 | train loss: 0.000730 | valid loss: 0.002509\n","Epoch:  1819 | train loss: 0.000641 | valid loss: 0.002311\n","Epoch:  1820 | train loss: 0.000825 | valid loss: 0.002423\n","Epoch:  1821 | train loss: 0.000566 | valid loss: 0.002464\n","Epoch:  1822 | train loss: 0.000496 | valid loss: 0.002443\n","Epoch:  1823 | train loss: 0.000613 | valid loss: 0.002465\n","Epoch:  1824 | train loss: 0.000478 | valid loss: 0.002399\n","Epoch:  1825 | train loss: 0.000625 | valid loss: 0.002418\n","Epoch:  1826 | train loss: 0.000533 | valid loss: 0.002487\n","Epoch:  1827 | train loss: 0.000832 | valid loss: 0.002456\n","Epoch:  1828 | train loss: 0.000668 | valid loss: 0.002349\n","Epoch:  1829 | train loss: 0.000621 | valid loss: 0.002368\n","Epoch:  1830 | train loss: 0.000543 | valid loss: 0.002384\n","Epoch:  1831 | train loss: 0.000490 | valid loss: 0.002418\n","Epoch:  1832 | train loss: 0.000463 | valid loss: 0.002357\n","Epoch:  1833 | train loss: 0.000549 | valid loss: 0.002452\n","Epoch:  1834 | train loss: 0.000736 | valid loss: 0.002469\n","Epoch:  1835 | train loss: 0.000829 | valid loss: 0.002517\n","Epoch:  1836 | train loss: 0.000457 | valid loss: 0.002444\n","Epoch:  1837 | train loss: 0.000413 | valid loss: 0.002374\n","Epoch:  1838 | train loss: 0.000778 | valid loss: 0.002378\n","Epoch:  1839 | train loss: 0.000634 | valid loss: 0.002430\n","Epoch:  1840 | train loss: 0.000803 | valid loss: 0.002276\n","Epoch:  1841 | train loss: 0.000662 | valid loss: 0.002319\n","Epoch:  1842 | train loss: 0.000557 | valid loss: 0.002330\n","Epoch:  1843 | train loss: 0.000545 | valid loss: 0.002408\n","Epoch:  1844 | train loss: 0.000466 | valid loss: 0.002354\n","Epoch:  1845 | train loss: 0.000845 | valid loss: 0.002502\n","Epoch:  1846 | train loss: 0.000790 | valid loss: 0.002565\n","Epoch:  1847 | train loss: 0.000808 | valid loss: 0.002467\n","Epoch:  1848 | train loss: 0.000646 | valid loss: 0.002440\n","Epoch:  1849 | train loss: 0.000560 | valid loss: 0.002339\n","Epoch:  1850 | train loss: 0.000462 | valid loss: 0.002369\n","Epoch:  1851 | train loss: 0.000475 | valid loss: 0.002380\n","Epoch:  1852 | train loss: 0.000456 | valid loss: 0.002372\n","Epoch:  1853 | train loss: 0.000434 | valid loss: 0.002346\n","Epoch:  1854 | train loss: 0.002623 | valid loss: 0.002344\n","Epoch:  1855 | train loss: 0.000873 | valid loss: 0.002467\n","Epoch:  1856 | train loss: 0.000473 | valid loss: 0.002481\n","Epoch:  1857 | train loss: 0.000649 | valid loss: 0.002436\n","Epoch:  1858 | train loss: 0.000623 | valid loss: 0.002536\n","Epoch:  1859 | train loss: 0.000406 | valid loss: 0.002319\n","Epoch:  1860 | train loss: 0.000658 | valid loss: 0.002529\n","Epoch:  1861 | train loss: 0.000328 | valid loss: 0.002374\n","Epoch:  1862 | train loss: 0.000608 | valid loss: 0.002364\n","Epoch:  1863 | train loss: 0.000629 | valid loss: 0.002474\n","Epoch:  1864 | train loss: 0.000674 | valid loss: 0.002484\n","Epoch:  1865 | train loss: 0.000636 | valid loss: 0.002419\n","Epoch:  1866 | train loss: 0.000666 | valid loss: 0.002390\n","Epoch:  1867 | train loss: 0.000749 | valid loss: 0.002502\n","Epoch:  1868 | train loss: 0.000653 | valid loss: 0.002327\n","Epoch:  1869 | train loss: 0.000613 | valid loss: 0.002393\n","Epoch:  1870 | train loss: 0.000424 | valid loss: 0.002327\n","Epoch:  1871 | train loss: 0.000680 | valid loss: 0.002453\n","Epoch:  1872 | train loss: 0.000487 | valid loss: 0.002420\n","Epoch:  1873 | train loss: 0.000516 | valid loss: 0.002410\n","Epoch:  1874 | train loss: 0.000562 | valid loss: 0.002504\n","Epoch:  1875 | train loss: 0.000434 | valid loss: 0.002456\n","Epoch:  1876 | train loss: 0.000606 | valid loss: 0.002410\n","Epoch:  1877 | train loss: 0.000396 | valid loss: 0.002462\n","Epoch:  1878 | train loss: 0.000750 | valid loss: 0.002423\n","Epoch:  1879 | train loss: 0.000430 | valid loss: 0.002354\n","Epoch:  1880 | train loss: 0.000682 | valid loss: 0.002350\n","Epoch:  1881 | train loss: 0.000440 | valid loss: 0.002350\n","Epoch:  1882 | train loss: 0.000552 | valid loss: 0.002403\n","Epoch:  1883 | train loss: 0.000653 | valid loss: 0.002492\n","Epoch:  1884 | train loss: 0.000484 | valid loss: 0.002462\n","Epoch:  1885 | train loss: 0.000502 | valid loss: 0.002507\n","Epoch:  1886 | train loss: 0.000609 | valid loss: 0.002424\n","Epoch:  1887 | train loss: 0.000468 | valid loss: 0.002569\n","Epoch:  1888 | train loss: 0.000619 | valid loss: 0.002438\n","Epoch:  1889 | train loss: 0.000430 | valid loss: 0.002341\n","Epoch:  1890 | train loss: 0.000846 | valid loss: 0.002402\n","Epoch:  1891 | train loss: 0.000665 | valid loss: 0.002422\n","Epoch:  1892 | train loss: 0.000431 | valid loss: 0.002439\n","Epoch:  1893 | train loss: 0.000455 | valid loss: 0.002408\n","Epoch:  1894 | train loss: 0.000720 | valid loss: 0.002438\n","Epoch:  1895 | train loss: 0.000388 | valid loss: 0.002387\n","Epoch:  1896 | train loss: 0.000703 | valid loss: 0.002482\n","Epoch:  1897 | train loss: 0.000353 | valid loss: 0.002369\n","Epoch:  1898 | train loss: 0.000583 | valid loss: 0.002433\n","Epoch:  1899 | train loss: 0.000527 | valid loss: 0.002490\n","Epoch:  1900 | train loss: 0.000571 | valid loss: 0.002501\n","Epoch:  1901 | train loss: 0.000968 | valid loss: 0.002580\n","Epoch:  1902 | train loss: 0.000624 | valid loss: 0.002548\n","Epoch:  1903 | train loss: 0.000925 | valid loss: 0.002504\n","Epoch:  1904 | train loss: 0.000391 | valid loss: 0.002435\n","Epoch:  1905 | train loss: 0.000685 | valid loss: 0.002462\n","Epoch:  1906 | train loss: 0.000582 | valid loss: 0.002459\n","Epoch:  1907 | train loss: 0.000620 | valid loss: 0.002538\n","Epoch:  1908 | train loss: 0.000716 | valid loss: 0.002391\n","Epoch:  1909 | train loss: 0.000827 | valid loss: 0.002371\n","Epoch:  1910 | train loss: 0.001148 | valid loss: 0.002398\n","Epoch:  1911 | train loss: 0.000795 | valid loss: 0.002353\n","Epoch:  1912 | train loss: 0.000515 | valid loss: 0.002374\n","Epoch:  1913 | train loss: 0.000348 | valid loss: 0.002407\n","Epoch:  1914 | train loss: 0.000482 | valid loss: 0.002364\n","Epoch:  1915 | train loss: 0.000572 | valid loss: 0.002431\n","Epoch:  1916 | train loss: 0.000642 | valid loss: 0.002370\n","Epoch:  1917 | train loss: 0.000410 | valid loss: 0.002370\n","Epoch:  1918 | train loss: 0.000491 | valid loss: 0.002475\n","Epoch:  1919 | train loss: 0.000867 | valid loss: 0.002431\n","Epoch:  1920 | train loss: 0.000558 | valid loss: 0.002383\n","Epoch:  1921 | train loss: 0.000420 | valid loss: 0.002499\n","Epoch:  1922 | train loss: 0.000430 | valid loss: 0.002377\n","Epoch:  1923 | train loss: 0.000608 | valid loss: 0.002446\n","Epoch:  1924 | train loss: 0.000463 | valid loss: 0.002546\n","Epoch:  1925 | train loss: 0.000958 | valid loss: 0.002453\n","Epoch:  1926 | train loss: 0.001043 | valid loss: 0.002267\n","Epoch:  1927 | train loss: 0.000693 | valid loss: 0.002413\n","Epoch:  1928 | train loss: 0.000665 | valid loss: 0.002476\n","Epoch:  1929 | train loss: 0.000862 | valid loss: 0.002447\n","Epoch:  1930 | train loss: 0.000767 | valid loss: 0.002429\n","Epoch:  1931 | train loss: 0.000761 | valid loss: 0.002341\n","Epoch:  1932 | train loss: 0.000584 | valid loss: 0.002449\n","Epoch:  1933 | train loss: 0.000463 | valid loss: 0.002433\n","Epoch:  1934 | train loss: 0.000373 | valid loss: 0.002360\n","Epoch:  1935 | train loss: 0.000671 | valid loss: 0.002445\n","Epoch:  1936 | train loss: 0.000610 | valid loss: 0.002330\n","Epoch:  1937 | train loss: 0.000356 | valid loss: 0.002559\n","Epoch:  1938 | train loss: 0.000567 | valid loss: 0.002362\n","Epoch:  1939 | train loss: 0.000499 | valid loss: 0.002405\n","Epoch:  1940 | train loss: 0.000775 | valid loss: 0.002385\n","Epoch:  1941 | train loss: 0.000613 | valid loss: 0.002431\n","Epoch:  1942 | train loss: 0.000925 | valid loss: 0.002466\n","Epoch:  1943 | train loss: 0.000447 | valid loss: 0.002421\n","Epoch:  1944 | train loss: 0.000471 | valid loss: 0.002406\n","Epoch:  1945 | train loss: 0.000713 | valid loss: 0.002444\n","Epoch:  1946 | train loss: 0.000407 | valid loss: 0.002417\n","Epoch:  1947 | train loss: 0.000486 | valid loss: 0.002460\n","Epoch:  1948 | train loss: 0.000383 | valid loss: 0.002361\n","Epoch:  1949 | train loss: 0.000536 | valid loss: 0.002388\n","Epoch:  1950 | train loss: 0.000709 | valid loss: 0.002490\n","Epoch:  1951 | train loss: 0.000439 | valid loss: 0.002364\n","Epoch:  1952 | train loss: 0.000633 | valid loss: 0.002418\n","Epoch:  1953 | train loss: 0.000684 | valid loss: 0.002491\n","Epoch:  1954 | train loss: 0.000640 | valid loss: 0.002536\n","Epoch:  1955 | train loss: 0.000591 | valid loss: 0.002573\n","Epoch:  1956 | train loss: 0.000700 | valid loss: 0.002521\n","Epoch:  1957 | train loss: 0.000567 | valid loss: 0.002537\n","Epoch:  1958 | train loss: 0.000652 | valid loss: 0.002356\n","Epoch:  1959 | train loss: 0.000918 | valid loss: 0.002478\n","Epoch:  1960 | train loss: 0.000652 | valid loss: 0.002387\n","Epoch:  1961 | train loss: 0.000634 | valid loss: 0.002474\n","Epoch:  1962 | train loss: 0.000579 | valid loss: 0.002382\n","Epoch:  1963 | train loss: 0.000642 | valid loss: 0.002513\n","Epoch:  1964 | train loss: 0.000776 | valid loss: 0.002467\n","Epoch:  1965 | train loss: 0.000423 | valid loss: 0.002387\n","Epoch:  1966 | train loss: 0.000589 | valid loss: 0.002422\n","Epoch:  1967 | train loss: 0.000912 | valid loss: 0.002478\n","Epoch:  1968 | train loss: 0.000635 | valid loss: 0.002380\n","Epoch:  1969 | train loss: 0.000523 | valid loss: 0.002507\n","Epoch:  1970 | train loss: 0.000613 | valid loss: 0.002322\n","Epoch:  1971 | train loss: 0.000876 | valid loss: 0.002509\n","Epoch:  1972 | train loss: 0.000361 | valid loss: 0.002455\n","Epoch:  1973 | train loss: 0.000493 | valid loss: 0.002454\n","Epoch:  1974 | train loss: 0.000648 | valid loss: 0.002556\n","Epoch:  1975 | train loss: 0.000616 | valid loss: 0.002479\n","Epoch:  1976 | train loss: 0.000435 | valid loss: 0.002381\n","Epoch:  1977 | train loss: 0.000423 | valid loss: 0.002456\n","Epoch:  1978 | train loss: 0.000449 | valid loss: 0.002421\n","Epoch:  1979 | train loss: 0.000564 | valid loss: 0.002561\n","Epoch:  1980 | train loss: 0.000680 | valid loss: 0.002636\n","Epoch:  1981 | train loss: 0.000744 | valid loss: 0.002629\n","Epoch:  1982 | train loss: 0.000356 | valid loss: 0.002373\n","Epoch:  1983 | train loss: 0.000715 | valid loss: 0.002616\n","Epoch:  1984 | train loss: 0.000607 | valid loss: 0.002575\n","Epoch:  1985 | train loss: 0.000542 | valid loss: 0.002475\n","Epoch:  1986 | train loss: 0.000590 | valid loss: 0.002422\n","Epoch:  1987 | train loss: 0.000600 | valid loss: 0.002509\n","Epoch:  1988 | train loss: 0.000434 | valid loss: 0.002417\n","Epoch:  1989 | train loss: 0.000441 | valid loss: 0.002438\n","Epoch:  1990 | train loss: 0.000527 | valid loss: 0.002424\n","Epoch:  1991 | train loss: 0.000420 | valid loss: 0.002464\n","Epoch:  1992 | train loss: 0.000606 | valid loss: 0.002372\n","Epoch:  1993 | train loss: 0.000528 | valid loss: 0.002455\n","Epoch:  1994 | train loss: 0.000563 | valid loss: 0.002461\n","Epoch:  1995 | train loss: 0.000517 | valid loss: 0.002427\n","Epoch:  1996 | train loss: 0.000585 | valid loss: 0.002533\n","Epoch:  1997 | train loss: 0.000374 | valid loss: 0.002481\n","Epoch:  1998 | train loss: 0.000617 | valid loss: 0.002452\n","Epoch:  1999 | train loss: 0.000703 | valid loss: 0.002620\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Adm__-b6de3P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629654334349,"user_tz":-60,"elapsed":62,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"458c0e76-9179-4672-b6d3-106415580ffe"},"source":["print(\"Train time:\",t_train_1 - t_train_0 + t_train_3 - t_train_2 + t_train_5 - t_train_4)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Train time: 303.6175365447998\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"id":"5aNS8TcJ6it0","executionInfo":{"status":"ok","timestamp":1629654335371,"user_tz":-60,"elapsed":1047,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"1b26568d-284a-421b-fd0c-691c74b847d6"},"source":["fig = plt.figure(figsize=(7,7))\n","axe1 = plt.subplot(111)\n","axe1.semilogy(epoch_list,loss_list,label = \"train\")\n","axe1.semilogy(epoch_list,loss_valid,label = \"valid\")\n","axe1.legend(loc = \"best\",fontsize=14)\n","axe1.set_xlabel(\"$epoch$\",fontsize=14)\n","axe1.set_ylabel(\"$MSE loss$\",fontsize=14)"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$MSE loss$')"]},"metadata":{},"execution_count":68},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 504x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zZ45gmAO66LR","executionInfo":{"status":"ok","timestamp":1629654342876,"user_tz":-60,"elapsed":7517,"user":{"displayName":"杨钒","photoUrl":"","userId":"08129041439789093783"}},"outputId":"f35e063e-5a4b-460c-c7b3-73b152fee3ea"},"source":["encoded_train, decoded_train = autoencoder_1(torch.tensor(train_data_svd).float().to(device))\n","encoded_valid, decoded_valid = autoencoder_1(torch.tensor(valid_data_svd).float().to(device))\n","encoded_test, decoded_test = autoencoder_1(torch.tensor(test_data_svd).float().to(device))\n","encoded_total, decoded_total = autoencoder_1(torch.tensor(total_data_svd).float().to(device))\n","\n","\n","train_pre = decoded_train.cpu().data.numpy()@R\n","valid_pre = decoded_valid.cpu().data.numpy()@R\n","test_pre = decoded_test.cpu().data.numpy()@R\n","total_pre = decoded_total.cpu().data.numpy()@R\n","print(train_pre.shape)\n","\n","\n","train_decoded = np.zeros([training_data.shape[0],training_data.shape[1],2])\n","valid_decoded = np.zeros([valid_data.shape[0],valid_data.shape[1],2])\n","test_decoded = np.zeros([test_data.shape[0],test_data.shape[1],2])\n","total_decoded = np.zeros([total_data.shape[0],total_data.shape[1],2])\n","print(train_decoded.shape)\n","\n","\n","for i in range(train_decoded.shape[0]):\n","    train_decoded[i,:,0] = train_pre[i,:20550]\n","    train_decoded[i,:,1] = train_pre[i,20550:]\n","    \n","for i in range(valid_decoded.shape[0]):\n","    valid_decoded[i,:,0] = valid_pre[i,:20550]\n","    valid_decoded[i,:,1] = valid_pre[i,20550:]\n","\n","for i in range(test_decoded.shape[0]):\n","    test_decoded[i,:,0] = test_pre[i,:20550]\n","    test_decoded[i,:,1] = test_pre[i,20550:]\n","\n","for i in range(total_decoded.shape[0]):\n","    total_decoded[i,:,0] = total_pre[i,:20550]\n","    total_decoded[i,:,1] = total_pre[i,20550:]\n","\n","\n","\n","train_error = train_decoded - training_data[:,:,3:5]\n","print(\"MSE_err of training data\", (train_error**2).mean())\n","\n","valid_error = valid_decoded - valid_data[:,:,3:5]\n","print(\"MSE_err of valid data\", (valid_error**2).mean())\n","\n","test_error = test_decoded - test_data[:,:,3:5]\n","print(\"MSE_err of test data\", (test_error**2).mean())\n","\n","total_error = total_decoded - total_data[:,:,3:5]\n","print(\"MSE_err of total data\", (total_error**2).mean())"],"execution_count":69,"outputs":[{"output_type":"stream","text":["(1600, 41100)\n","(1600, 20550, 2)\n","MSE_err of training data 2.4634549930260992e-05\n","MSE_err of valid data 0.00010223833974665201\n","MSE_err of test data 0.00010013863615857223\n","MSE_err of total data 3.9945333692861535e-05\n"],"name":"stdout"}]}]}